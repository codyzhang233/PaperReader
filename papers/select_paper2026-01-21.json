[
  {
    "date": "2026-01-21",
    "title": "LLM-Based Repair of C++ Implicit Data Loss Compiler Warnings: An Industrial Case Study",
    "authors": "Chansong You, Hyun Deok Choi, Jingun Hong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14936v1",
    "source": "arXiv",
    "abstract": "This paper presents a method to automatically fix implicit data loss warnings in large C++ projects using Large Language Models (LLMs). Our approach uses the Language Server Protocol (LSP) to gather context, Tree-sitter to extract relevant code, and LLMs to make decisions and generate fixes. The method evaluates the necessity of range checks concerning performance implications and generates appropriate fixes. We tested this method in a large C++ project, resulting in a 92.73% acceptance rate of the fixes by human developers during the code review. Our LLM-generated fixes reduced the number of warning fix changes that introduced additional instructions due to range checks and exception handling by 39.09% compared to a baseline fix strategy. This result was 13.56% behind the optimal solutions created by human developers. These findings demonstrate that our LLM-based approach can reduce the manual effort to address compiler warnings while maintaining code quality and performance in a real-world scenario. Our automated approach shows promise for integration into existing development workflows, potentially improving code maintenance practices in complex C++ software projects.",
    "title_zh": "基于大语言模型的C++隐式数据丢失编译器警告修复：一项工业案例研究",
    "abstract_zh": "本文提出了一种利用大型语言模型（LLMs）自动修复大型C++项目中隐式数据丢失警告的方法。我们的方法通过语言服务器协议（LSP）获取上下文信息，使用Tree-sitter提取相关代码，并借助LLM进行决策与修复生成。该方法在评估范围检查的必要性时充分考虑了性能影响，并生成合适的修复方案。我们在一个大型C++项目中进行了测试，结果显示，在代码审查过程中，人类开发者对所生成修复方案的接受率达到92.73%。相较于基线修复策略，我们的LLM生成的修复方案使因范围检查和异常处理引入额外指令的警告修复变更数量减少了39.09%。这一效果比由人类开发者设计的最优解决方案落后13.56%。研究结果表明，基于LLM的方法能够在实际场景中有效降低修复编译器警告所需的手动工作量，同时保持代码质量和性能。该自动化方法展现出良好的应用前景，可集成至现有开发流程中，有望提升复杂C++软件项目中的代码维护水平。"
  },
  {
    "date": "2026-01-21",
    "title": "SynPerf: A Hybrid Analytical-ML Framework for GPU Performance Prediction",
    "authors": "Kaixuan Zhang, Yunfan Cui, Shuhao Zhang, Chutong Ding, Shiyou Qian, Luping Wang, Jian Cao, Guangtao Xue, Cheng Huang, Guodong Yang, Liping Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14910v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of Transformer-based large language models has dramatically increased the need for high-performance GPUs. As a result, there is growing demand for fast, accurate, and widely generalizable GPU performance models to support next-generation hardware selection and system-level exploration. However, current data-driven methods are limited, exhibiting poor generalization across hardware and inadequate modeling of complex production-level kernels common in modern inference stacks. To address these issues, we present SyncPerf, a unified GPU modeling framework. This approach first employs an analytical model to quantify a given kernel's demands on the GPU's heterogeneous instruction pipelines. These analytical features are then fed into a machine learning (ML) model to capture complex cross-pipeline interactions and resource dependencies, enabling high-fidelity performance prediction. Our evaluation across 11 GPU types from four generations of major architectures on two widely-used serving systems demonstrates that SyncPerf delivers high fidelity and strong generalizability. It achieves accurate predictions, with only 6.1% average error at the kernel level and 8.5% for end-to-end inference -- reducing the error of state-of-the-art methods by 6.7x and 4.4x, respectively. We also demonstrate SynPerf's value \"beyond simulation\" by utilizing its performance ceiling to diagnose implementation shortcomings and guide the optimization of a production fused MoE Triton kernel, achieving up to 1.7x speedup.",
    "title_zh": "SynPerf：一种用于GPU性能预测的混合分析-机器学习框架",
    "abstract_zh": "基于Transformer的大规模语言模型的迅速扩展，极大地增加了对高性能GPU的需求。因此，迫切需要快速、准确且具有广泛泛化能力的GPU性能模型，以支持下一代硬件选型和系统级探索。然而，现有的数据驱动方法存在局限性，其在不同硬件间的泛化能力较差，并且难以有效建模现代推理栈中常见的复杂生产级核函数。为解决这些问题，我们提出了SyncPerf——一种统一的GPU建模框架。该方法首先采用解析模型来量化特定核函数对GPU异构指令流水线的资源需求；随后，将这些解析特征输入机器学习（ML）模型，以捕捉复杂的跨流水线交互关系与资源依赖，从而实现高保真度的性能预测。我们在两大主流推理系统上，针对四个代际的11种GPU类型进行了评估，结果表明SyncPerf具备高保真度和强大的泛化能力：在核级别预测上平均误差仅为6.1%，端到端推理的平均误差为8.5%，分别比当前最先进的方法降低了6.7倍和4.4倍。此外，我们还展示了SyncPerf“超越仿真”的实际价值——利用其性能上限诊断实现中的瓶颈，并指导一个生产环境下的融合MoE Triton核函数优化，最终实现了最高达1.7倍的加速效果。"
  },
  {
    "date": "2026-01-21",
    "title": "How to Verify a Turing Machine with Dafny",
    "authors": "Edgar F. A. Lederer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15230v1",
    "source": "arXiv",
    "abstract": "This paper describes the formal verification of two Turing machines using the program verifier Dafny. Both machines are deciders, so we prove total correctness. They are typical first examples of Turing machines used in any course of Theoretical Computer Science; in fact, the second machine is literally taken from a relevant textbook. Usually, the correctness of such machines is made plausible by some informal explanations of their basic ideas, augmented with a few sample executions, but neither by rigorous mathematical nor mechanized formal proof. No wonder: The invariants (and variants) required for such proofs are big artifacts, peppered with overpowering technical details. Finding and checking these artifacts without mechanical support is practically impossible, and such support is only available since recent times. But nowadays, just because of these technicalities, with such subjects under proof a program verifier can really show off and demonstrate its capabilities.",
    "title_zh": "如何使用 Dafny 验证图灵机",
    "abstract_zh": "本文描述了使用程序验证工具 Dafny 对两个图灵机进行的形式化验证。由于这两个机器都是判定器，因此我们证明其完全正确性。它们是任何理论计算机科学课程中常见的典型图灵机示例；事实上，第二个机器直接取自一本相关教材。通常，这类机器的正确性仅通过对其基本思想的非正式解释以及若干样例执行来加以说明，而从未采用严格的数学证明或机械化的形式化证明。这并不奇怪：此类证明所需的不变量（及变量化）本身是庞大而复杂的构造，充斥着令人望而生畏的技术细节。在缺乏机械辅助的情况下，发现并验证这些复杂构造几乎是不可能的，而这种机械支持直到最近才得以实现。然而，正是由于这些技术上的复杂性，当我们将此类主题纳入形式化证明时，程序验证器才能真正展现其能力并凸显其优势。"
  },
  {
    "date": "2026-01-21",
    "title": "Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub",
    "authors": "Ramtin Ehsani, Sakshi Pathak, Shriya Rawal, Abdullah Al Mujahid, Mia Mohammad Imran, Preetha Chatterjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15195v1",
    "source": "arXiv",
    "abstract": "AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub. (RQ1) We first quantitatively characterize merged and not-merged PRs along four broad dimensions: 1) merge outcomes across task types, 2) code changes, 3) CI build results, and 4) review dynamics. We observe that tasks related to documentation, CI, and build update achieve the highest merge success, whereas performance and bug-fix tasks perform the worst. Not-merged PRs tend to involve larger code changes, touch more files, and often do not pass the project's CI/CD pipeline validation. (RQ2) To further investigate why some agentic PRs are not merged, we qualitatively analyze 600 PRs to derive a hierarchical taxonomy of rejection patterns. This analysis complements the quantitative findings in RQ1 by uncovering rejection reasons not captured by quantitative metrics, including lack of meaningful reviewer engagement, duplicate PRs, unwanted feature implementations, and agent misalignment. Together, our findings highlight key socio-technical and human-AI collaboration factors that are critical to improving the success of future agentic workflows.",
    "title_zh": "AI编程代理在何处失效？一项关于GitHub中失败的智能拉取请求的实证研究",
    "abstract_zh": "如今，AI编程代理正开始向软件项目提交拉取请求（PR），其角色已不再仅仅是辅助工具，而是作为自主贡献者参与其中。随着这些代理在真实代码仓库中的贡献数量迅速增长，我们对它们的实际行为模式以及为何许多PR未能被合并仍知之甚少。本文对GitHub上五个编程代理撰写的3.3万份代理生成的PR进行了大规模研究。（RQ1）我们首先从四个主要维度对成功合并与未合并的PR进行量化分析：1）不同任务类型下的合并结果，2）代码变更特征，3）CI构建结果，以及4）评审动态。研究发现，与文档编写、CI/CD配置及构建更新相关的任务具有最高的合并成功率，而性能优化和缺陷修复类任务的表现最差。未合并的PR往往涉及更大的代码改动、影响更多文件，并且通常无法通过项目的CI/CD流水线验证。\n\n（RQ2）为进一步探究部分代理PR未能被合并的原因，我们对600个PR进行了定性分析，构建了一个分层的拒因分类体系。该分析补充了RQ1中的定量发现，揭示了定量指标难以捕捉的拒因，包括缺乏有意义的评审互动、重复提交的PR、不受欢迎的功能实现，以及代理与项目目标之间的错位。综上所述，我们的研究揭示了影响未来代理式工作流成功的关键社会-技术因素以及人机协作中的核心挑战，为提升AI代理在实际开发流程中的有效性提供了重要启示。"
  },
  {
    "date": "2026-01-21",
    "title": "Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories",
    "authors": "Qian Xiong, Yuekai Huang, Yujia Zheng, Tianhao Li, Ziyou Jiang, Zhiyuan Chang, Zhaoyang Li, Huanxiang Feng, Mingyang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15120v1",
    "source": "arXiv",
    "abstract": "LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of \"intent deviation\" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a \"Real-to-Virtual\" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively.",
    "title_zh": "从地面涌现：通过将真实调用转化为虚拟轨迹来解决工具使用智能体中的意图偏差问题",
    "abstract_zh": "大语言模型（LLMs）已发展出用于现实应用的工具使用智能体，但其常导致意外行为或结果。除了明显的失败外，“意图偏差”这一细微问题严重阻碍了可靠评估与性能提升。现有的后训练方法通常依赖真实系统样本或由LLM生成的虚拟数据。然而，前者因需人工精心设计用户请求而成本高昂，后者则因与真实世界工具的分布存在偏差而受限。此外，这两种方法均缺乏针对意图偏差场景的负样本，难以有效指导偏好学习。为此，我们提出RISE——一种“从真实到虚拟”的方法，旨在缓解意图偏差问题。RISE以经过验证的工具基本操作为锚点，通过在关键参数上进行变异，合成虚拟执行轨迹并生成多样化的负样本。利用这些合成数据，RISE采用两阶段训练对基础LLM进行微调，以实现意图对齐。评估结果表明，RISE生成的数据在涵盖用户需求、执行轨迹和智能体响应的八项指标中均表现优异。结合训练流程后，RISE在任务完成率（Acctask）上平均提升35.28%，在意图对齐率（Accintent）上提升23.27%，分别优于当前最优基线方法1.20%–42.09%和1.17%–54.93%。"
  },
  {
    "date": "2026-01-21",
    "title": "The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution",
    "authors": "Chen Qian, Peng Wang, Dongrui Liu, Junyao Yang, Dadi Guo, Ling Tang, Jilin Mei, Qihan Ren, Shuai Shao, Yong Liu, Jie Fu, Jing Shao, Xia Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15075v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \\textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \\textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \\textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \\textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems.",
    "title_zh": "行动背后的缘由：通过代理归因揭示内在动因",
    "abstract_zh": "基于大语言模型（LLM）的智能体在现实世界中被广泛应用于客户服务、网页导航和软件工程等领域。随着这些系统日益自主化并大规模部署，理解智能体为何采取特定行动，对于实现责任追溯与治理变得愈发重要。然而，现有研究主要聚焦于“失败归因”，即定位失败轨迹中的显式错误，这不足以解释智能体行为背后的推理过程。为弥补这一不足，我们提出一种全新的框架——**通用智能体归因**（general agentic attribution），旨在识别驱动智能体行为的内部因素，无论任务结果如何。该框架采用分层结构，以应对智能体交互的复杂性：在**组件层面**，我们利用时间上的似然动态分析，识别出关键的交互步骤；在**句子层面**，则通过基于扰动的分析方法，进一步精确定位导致行为的具体文本证据。我们在一系列多样化的智能体场景中验证了该框架的有效性，涵盖标准工具使用以及如记忆引发偏差等微妙的可靠性风险。实验结果表明，所提框架能够可靠地定位出影响智能体行为的关键历史事件与语句，为构建更安全、更具可问责性的智能体系统迈出了关键一步。"
  },
  {
    "date": "2026-01-21",
    "title": "Specifying and Verifying RDMA Synchronisation (Extended Version)",
    "authors": "Guillaume Ambal, Max Stupple, Brijesh Dongol, Azalea Raad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14642v1",
    "source": "arXiv",
    "abstract": "Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\\text{RDMA}^\\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\\text{RDMA}^{\\text{TSO}}_{\\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$ library. Underpinned by $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\\text{RDMA}^{\\text{SC}}_{\\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability.",
    "title_zh": "指定与验证RDMA同步（扩展版）",
    "abstract_zh": "远程直接内存访问（RDMA）允许一台机器直接读写另一台远程机器的内存，从而实现高吞吐量、低延迟的数据传输。尽管最近通过形式化 $\\text{RDMA}^\\text{TSO}$ 语义（描述在 TSO 处理器上 RDMA 网络的行为）使得 RDMA 程序的正确性验证成为可能，但当前的语义仍缺乏对远程同步机制的形式化定义，导致诸如锁等常见抽象的实现无法被验证。本文通过提出 $\\text{RDMA}^{\\text{TSO}}_{\\text{RMW}}$，首次为 TSO 架构上的远程“读-修改-写”（RMW）指令建立了形式化语义。研究发现，远程 RMW 操作是较弱的，仅能保证与其他远程 RMW 操作之间的原子性。因此，我们基于此构建了一套可组合的同步抽象，起点是 $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$ 库。依托于 $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$，我们进一步规范、实现并验证了三类适用于不同场景的远程锁。此外，我们还提出了一个强 RDMA 模型 $\\text{RDMA}^{\\text{SC}}_{\\text{RMW}}$，其类似于共享内存架构中的顺序一致性。我们的库设计与现有的高性能库 LOCO 兼容，从而确保了良好的组合性与可验证性。"
  },
  {
    "date": "2026-01-21",
    "title": "Automatically Tightening Access Control Policies with Restricter",
    "authors": "Ka Lok Wu, Christa Jenkins, Scott D. Stolle, Omar Chowdhury",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14582v1",
    "source": "arXiv",
    "abstract": "Robust access control is a cornerstone of secure software, systems, and networks. An access control mechanism is as effective as the policy it enforces. However, authoring effective policies that satisfy desired properties such as the principle of least privilege is a challenging task even for experienced administrators, as evidenced by many real instances of policy misconfiguration. In this paper, we set out to address this pain point by proposing Restricter, which automatically tightens each (permit) policy rule of a policy with respect to an access log, which captures some already exercised access requests and their corresponding access decisions (i.e., allow or deny). Restricter achieves policy tightening by reducing the number of access requests permitted by a policy rule without sacrificing the functionality of the underlying system it is regulating. We implement Restricter for Amazon's Cedar policy language and demonstrate its effectiveness through two realistic case studies.",
    "title_zh": "使用 Restricter 自动收紧访问控制策略",
    "abstract_zh": "强大的访问控制是安全软件、系统和网络的基石。访问控制机制的有效性取决于其所执行策略的质量。然而，即使对于经验丰富的管理员而言，制定能够满足诸如“最小权限原则”等理想属性的有效策略也是一项极具挑战性的任务，这从大量实际发生的策略配置错误中可见一斑。本文旨在解决这一痛点，提出一种名为 Restricter 的新方法，该方法能够自动根据访问日志对策略中的每一（允许）规则进行收紧。该访问日志记录了部分已发生的访问请求及其相应的访问决策（即允许或拒绝）。Restricter 通过在不损害被监管系统功能的前提下，减少策略规则所允许的访问请求数量，从而实现策略的收紧。我们已在亚马逊的 Cedar 策略语言上实现了 Restricter，并通过两个真实的案例研究证明了其有效性。"
  },
  {
    "date": "2026-01-21",
    "title": "Reclaiming Software Engineering as the Enabling Technology for the Digital Age",
    "authors": "Tanja E. J. Vos, Tijs van der Storm, Alexander Serebrenik, Lionel Briand, Roberto Di Cosmo, J. -M Bruel, Benoît Combemale",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14861v1",
    "source": "arXiv",
    "abstract": "Software engineering is the invisible infrastructure of the digital age. Every breakthrough in artificial intelligence, quantum computing, photonics, and cybersecurity relies on advances in software engineering, yet the field is too often treated as a supportive digital component rather than as a strategic, enabling discipline. In policy frameworks, including major European programmes, software appears primarily as a building block within other technologies, while the scientific discipline of software engineering remains largely absent. This position paper argues that the long-term sustainability, dependability, and sovereignty of digital technologies depend on investment in software engineering research. It is a call to reclaim the identity of software engineering.",
    "title_zh": "重振软件工程作为数字时代的赋能技术",
    "abstract_zh": "软件工程是数字时代不可或缺的基础设施。人工智能、量子计算、光子学和网络安全领域的每一次突破，都依赖于软件工程的进步，然而该领域却常常被视为辅助性的数字组件，而非一项具有战略意义的赋能学科。在政策框架中，包括欧洲主要计划在内，软件往往被视作其他技术中的一个构建模块，而软件工程作为一门科学学科则基本缺席。本文旨在呼吁：数字技术的长期可持续性、可靠性与自主性，取决于对软件工程研究的持续投入。这是一次重拾软件工程身份的号召。"
  },
  {
    "date": "2026-01-21",
    "title": "When Agents Fail: A Comprehensive Study of Bugs in LLM Agents with Automated Labeling",
    "authors": "Niful Islam, Ragib Shahriar Ayon, Deepak George Thomas, Shibbir Ahmed, Mohammad Wardat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15232v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have revolutionized intelligent application development. While standalone LLMs cannot perform any actions, LLM agents address the limitation by integrating tools. However, debugging LLM agents is difficult and costly as the field is still in it's early stage and the community is underdeveloped. To understand the bugs encountered during agent development, we present the first comprehensive study of bug types, root causes, and effects in LLM agent-based software. We collected and analyzed 1,187 bug-related posts and code snippets from Stack Overflow, GitHub, and Hugging Face forums, focused on LLM agents built with seven widely used LLM frameworks as well as custom implementations. For a deeper analysis, we have also studied the component where the bug occurred, along with the programming language and framework. This study also investigates the feasibility of automating bug identification. For that, we have built a ReAct agent named BugReAct, equipped with adequate external tools to determine whether it can detect and annotate the bugs in our dataset. According to our study, we found that BugReAct equipped with Gemini 2.5 Flash achieved a remarkable performance in annotating bug characteristics with an average cost of 0.01 USD per post/code snippet.",
    "title_zh": "当代理失效时：基于自动标注的大型语言模型代理缺陷综合研究",
    "abstract_zh": "大型语言模型（LLMs）已彻底改变了智能应用的开发方式。尽管独立的LLM无法执行任何操作，但LLM代理通过集成工具弥补了这一局限。然而，由于该领域仍处于早期发展阶段，社区生态尚不成熟，调试LLM代理既困难又成本高昂。为了深入理解代理开发过程中遇到的各类错误，我们首次对基于LLM代理的软件中的错误类型、根本原因及其影响进行了全面研究。我们从Stack Overflow、GitHub以及Hugging Face论坛中收集并分析了1,187条与bug相关的帖子和代码片段，重点关注使用七种广泛使用的LLM框架以及自定义实现构建的LLM代理。为进一步深入分析，我们还考察了出错组件、编程语言及框架等维度。此外，本研究还探讨了自动化识别bug的可行性：为此，我们构建了一个名为BugReAct的ReAct代理，配备了充足的外部工具，以评估其在我们的数据集中检测并标注bug的能力。研究结果表明，配备Gemini 2.5 Flash的BugReAct在标注bug特征方面表现出色，平均成本仅为每篇帖子/代码片段0.01美元。"
  },
  {
    "date": "2026-01-21",
    "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback",
    "authors": "Stephan Wallraven, Tim Köhne, Hartmut Westenberger, Andreas Moser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15188v1",
    "source": "arXiv",
    "abstract": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction.",
    "title_zh": "基于编译器反馈的迭代改进：大型语言模型生成ABAP代码的基准测试——一项实证研究",
    "abstract_zh": "本研究探讨了大型语言模型（LLMs）在生成ABAP代码方面的表现。尽管生成式人工智能在多种编程语言中已取得成功应用，但迄今为止，针对ABAP代码生成的系统性分析仍极为罕见。本研究旨在通过实证方法，分析不同LLM在生成语法正确且功能有效的ABAP代码方面的能力，评估其利用编译器反馈进行迭代改进的有效性，并识别出哪些任务类型具有特殊挑战性。为此，研究设计了一个包含180个任务的基准测试，涵盖经过调整的HumanEval任务以及实际的SAP应用场景。结果表明，各模型之间存在显著性能差异：更强大的LLM在经过多次迭代后，成功率可达约75%，且能极大受益于编译器反馈；而较小的模型则表现明显较弱。总体而言，该研究凸显了强大LLM在ABAP开发流程中的巨大潜力，尤其是在迭代纠错方面。"
  },
  {
    "date": "2026-01-21",
    "title": "Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure",
    "authors": "Christopher Scofield",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15077v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems.",
    "title_zh": "多智能体约束分解揭示潜在的不变解结构",
    "abstract_zh": "由大型语言模型组成的多智能体系统（MAS）尽管基于相同的信息，却常常展现出更优的问题求解性能。在本研究中，我们基于算子理论与约束优化，为这一现象提供了形式化解释。我们将每个智能体建模为对共享解状态施加不同类别的有效性约束，证明多智能体系统实现了约束施加算子的分解组合。在较弱条件下，这些动态过程会收敛至由各智能体约束集交集所定义的不变解集。这类不变结构通常无法被单一智能体通过同时施加所有约束而动态达到，即使其表达能力与信息资源完全相同。我们将该结果从精确约束推广至软约束情形，引入近端算子进行处理，并将该理论框架应用于当前主流的基于文本的对话系统。"
  },
  {
    "date": "2026-01-21",
    "title": "SmartOracle -- An Agentic Approach to Mitigate Noise in Differential Oracles",
    "authors": "Srinath Srinivasan, Tim Menzies, Marcelo D'Amorim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15074v1",
    "source": "arXiv",
    "abstract": "Differential fuzzers detect bugs by executing identical inputs across distinct implementations of the same specification, such as JavaScript interpreters. Validating the outputs requires an oracle and for differential testing of JavaScript, these are constructed manually, making them expensive, time-consuming, and prone to false positives. Worse, when the specification evolves, this manual effort must be repeated. Inspired by the success of agentic systems in other SE domains, this paper introduces SmartOracle. SmartOracle decomposes the manual triage workflow into specialized Large Language Model (LLM) sub-agents. These agents synthesize independently gathered evidence from terminal runs and targeted specification queries to reach a final verdict. For historical benchmarks, SmartOracle achieves 0.84 recall with an 18% false positive rate. Compared to a sequential Gemini 2.5 Pro baseline, it improves triage accuracy while reducing analysis time by 4$\\times$ and API costs by 10$\\times$. In active fuzzing campaigns, SmartOracle successfully identified and reported previously unknown specification-level issues across major engines, including bugs in V8, JavaScriptCore, and GraalJS. The success of SmartOracle's agentic architecture on Javascript suggests it might be useful other software systems- a research direction we will explore in future work.",
    "title_zh": "SmartOracle——一种通过代理方法减轻差分预言机噪声的策略",
    "abstract_zh": "差异性模糊测试通过在相同规范的不同实现（如JavaScript解释器）上执行相同的输入来检测缺陷。验证输出需要一个“预言机”（oracle），而在JavaScript的差异性测试中，这些预言机通常需手动构建，导致成本高昂、耗时且容易产生误报。更严重的是，当规范发生变化时，这种手动工作必须重新进行。受其他软件工程领域中智能体系统成功的启发，本文提出了SmartOracle。SmartOracle将手动的故障分类流程分解为多个专门的大型语言模型（LLM）子智能体。这些智能体综合来自终端运行的独立证据以及针对规范的定向查询结果，最终做出判断。在历史基准测试中，SmartOracle实现了0.84的召回率，同时将误报率控制在18%。相比顺序式的Gemini 2.5 Pro基线，它不仅提升了故障分类的准确性，还将分析时间缩短了4倍，API成本降低了10倍。在实际的模糊测试活动中，SmartOracle成功识别并报告了多个主流引擎（包括V8、JavaScriptCore和GraalJS）中此前未知的规范级问题。SmartOracle在JavaScript领域中基于智能体架构的成功，表明该方法可能对其他软件系统也具有应用价值——这将是未来研究的一个重要方向。"
  },
  {
    "date": "2026-01-21",
    "title": "ARISE -- Adaptive Refinement and Iterative Scenario Engineering",
    "authors": "Konstantin Poddubnyy, Igor Vozniak, Nils Lipp, Ivan Burmistrov, Davit Hovhannisyan, Christian Mueller, Philipp Slusallek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14743v1",
    "source": "arXiv",
    "abstract": "The effectiveness of collision-free trajectory planners depends on the quality and diversity of training data, especially for rare scenarios. A widely used approach to improve dataset diversity involves generating realistic synthetic traffic scenarios. However, producing such scenarios remains difficult due to the precision required when scripting them manually or generating them in a single pass. Natural language offers a flexible way to describe scenarios, but existing text-to-simulation pipelines often rely on static snippet retrieval, limited grammar, single-pass decoding, or lack robust executability checks. Moreover, they depend heavily on constrained LLM prompting with minimal post-processing. To address these limitations, we introduce ARISE - Adaptive Refinement and Iterative Scenario Engineering, a multi-stage tool that converts natural language prompts into executable Scenic scripts through iterative LLM-guided refinement. After each generation, ARISE tests script executability in simulation software, feeding structured diagnostics back to the LLM until both syntactic and functional requirements are met. This process significantly reduces the need for manual intervention. Through extensive evaluation, ARISE outperforms the baseline in generating semantically accurate and executable traffic scenarios with greater reliability and robustness.",
    "title_zh": "ARISE——自适应精化与迭代情景工程",
    "abstract_zh": "碰撞规避轨迹规划器的有效性取决于训练数据的质量与多样性，尤其是在罕见场景下。目前广泛采用的一种提升数据集多样性的方法是生成逼真的合成交通场景。然而，由于手动编写或一次性生成时对精度要求极高，这一过程仍然十分困难。自然语言为描述场景提供了灵活的方式，但现有的文本转仿真流程通常依赖于静态片段检索、语法受限、单次解码，或缺乏可靠的可执行性检查。此外，这些方法严重依赖于受限的大型语言模型（LLM）提示词设计，且后续处理极少。为解决上述局限性，我们提出了ARISE——自适应优化与迭代场景工程系统，这是一种多阶段工具，通过迭代式的LLM引导优化，将自然语言提示转化为可执行的Scenic脚本。每次生成后，ARISE会在仿真软件中测试脚本的可执行性，并将结构化的诊断信息反馈给LLM，直至满足语法和功能双重要求。该过程显著减少了人工干预的需求。通过大量评估验证，ARISE在生成语义准确且可执行的交通场景方面，相较于基线方法展现出更高的可靠性与鲁棒性。"
  },
  {
    "date": "2026-01-21",
    "title": "CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation",
    "authors": "Yutong Chen, Jiandong Gao, Ji Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14695v1",
    "source": "arXiv",
    "abstract": "Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability.",
    "title_zh": "CoScale-RL：通过协同缩放数据与计算实现高效的后训练",
    "abstract_zh": "训练大型推理模型（LRM）通常存在不稳定和不可预测的问题，尤其是在处理复杂问题或基础模型较弱的情况下。我们发现，现有的后训练扩展策略在这些场景下依然具有提升空间。为此，我们提出了 CoScale-RL，一种新型的扩展策略，在数据和计算效率方面表现更优。我们的方法首先通过扩大解决方案来使问题变得可解：核心思想是为每个问题收集多个解法，而非简单地扩大数据集。随后，我们通过增加回放（rollout）计算量来稳定强化学习过程。此外，我们进一步采用一种称为“再蒸馏”（Re-distillation）的模型融合技术，在扩展过程中维持甚至提升计算效率。实验表明，该方法显著提升了数据与计算效率，在四个基准测试上平均实现了 3.76 倍的准确率提升。CoScale-RL 能够在无需大量监督微调（SFT）数据集的情况下，有效拓展 LRM 的能力边界。本方法为进一步提升 LRM 推理能力提供了全新的扩展方向。"
  },
  {
    "date": "2026-01-21",
    "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation",
    "authors": "Yonatan Gizachew Achamyeleh, Harsh Thomare, Mohammad Abdullah Al Faruque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14598v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build. On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets.",
    "title_zh": "HELIOS：面向结构感知大语言模型逆向工程的分层图抽象",
    "abstract_zh": "大型语言模型（LLMs）最近被应用于二进制反汇编任务，但它们通常仍将代码视为纯文本，忽略了控制流图等关键的程序结构信息。这一局限性常常导致生成的代码在语法上脆弱且逻辑不一致，尤其在处理优化过的二进制文件时更为明显。本文提出 \\textsc{HELIOS}——一个将基于 LLM 的反汇编重构为结构化推理任务的框架。\\textsc{HELIOS} 将二进制文件的控制流和函数调用关系总结为一种分层化的文本表示，明确描述基本块、其后继节点以及高级控制模式（如循环和条件分支）。该结构化表示与原始反编译输出一同输入到通用 LLM 中，可选地结合“编译器内循环”机制，在生成代码无法成功编译时返回错误信息。在 \\texttt{x86\\_64} 架构上的 HumanEval-Decompile 测试中，\\textsc{HELIOS} 使 Gemini~2.0 的目标文件平均可编译率从 45.0\\% 提升至 85.2\\%，GPT-4.1~Mini 的可编译率则从 71.4\\% 提升至 89.6\\%。引入编译器反馈后，可编译率超过 94\\%，功能正确性相比仅使用文本提示的方法最高提升 5.6 个百分点。在涵盖 x86、ARM 和 MIPS 的六种不同架构上，\\textsc{HELIOS} 显著缩小了功能正确性的波动范围，同时保持了始终如一的语法正确性，且无需任何微调。这些特性使 \\textsc{HELIOS} 成为安全领域逆向工程工作流中的实用组件，能够为分析师提供跨多种硬件平台、可重新编译且语义忠实的高质量反汇编代码。"
  },
  {
    "date": "2026-01-21",
    "title": "SAGA: Detecting Security Vulnerabilities Using Static Aspect Analysis",
    "authors": "Yoann Marquer, Domenico Bianculli, Lionel C. Briand",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15154v1",
    "source": "arXiv",
    "abstract": "Python is one of the most popular programming languages; as such, projects written in Python involve an increasing number of diverse security vulnerabilities. However, existing state-of-the-art analysis tools for Python only support a few vulnerability types. Hence, there is a need to detect a large variety of vulnerabilities in Python projects. In this paper, we propose the SAGA approach to detect and locate vulnerabilities in Python source code in a versatile way. SAGA includes a source code parser able to extract control- and data-flow information and to represent it as a symbolic control-flow graph, as well as a domain-specific language defining static aspects of the source code and their evolution during graph traversals. We have leveraged this language to define a library of static aspects for integrity, confidentiality, and other security-related properties. We have evaluated SAGA on a dataset of 108 vulnerabilities, obtaining 100% sensitivity and 99.15% specificity, with only one false positive, while outperforming four common security analysis tools. This analysis was performed in less than 31 seconds, i.e., between 2.5 and 512.1 times faster than the baseline tools.",
    "title_zh": "SAGA：利用静态方面分析检测安全漏洞",
    "abstract_zh": "Python 是最受欢迎的编程语言之一，因此使用 Python 编写的项目中所涉及的安全漏洞种类日益增多。然而，现有的最先进的 Python 安全分析工具仅能支持少数几种漏洞类型。因此，亟需一种能够检测多种安全漏洞的方案来应对 Python 项目中的安全问题。本文提出了一种名为 SAGA 的方法，以灵活多样的方式检测并定位 Python 源代码中的漏洞。SAGA 包含一个源代码解析器，能够提取控制流和数据流信息，并将其表示为符号化控制流图；同时，还引入了一种领域特定语言，用于定义源代码的静态特性及其在图遍历过程中的演化行为。我们利用该语言构建了一个静态特性库，涵盖完整性、机密性及其他与安全相关的属性。我们在包含 108 个漏洞的数据集上对 SAGA 进行了评估，取得了 100% 的灵敏度和 99.15% 的特异性，仅产生一个误报，且性能优于四种常见的安全分析工具。整个分析过程耗时不足 31 秒，比基准工具快 2.5 至 512.1 倍。"
  },
  {
    "date": "2026-01-21",
    "title": "CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning",
    "authors": "Tianshi Xu, Yuteng Chen, Meng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15141v1",
    "source": "arXiv",
    "abstract": "Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub",
    "title_zh": "清洁器：自净化轨迹提升智能体强化学习",
    "abstract_zh": "代理强化学习（Agentic Reinforcement Learning, RL）已使大型语言模型（LLMs）能够利用Python解释器等工具解决复杂问题。然而，对于参数受限的模型（如4B–7B规模），探索阶段常因频繁的执行失败而产生大量噪声轨迹，严重阻碍策略优化。在标准的结果导向奖励设置下，这种噪声导致严重的信用分配难题：错误动作与成功结果被同时强化，难以区分。现有缓解方法面临两难困境：密集奖励容易引发奖励劫持（reward hacking），而超采样则带来高昂的计算成本。为应对这些挑战，我们提出CLEANER。与依赖外部过滤的方法不同，CLEANER充分利用模型内在的自我修正能力，在数据收集过程中直接清除含错上下文。其核心是“相似性感知自适应回滚”（Similarity-Aware Adaptive Rollback, SAAR）机制，该机制通过事后追溯，将失败步骤替换为成功的自我修正，从而自主构建出干净、纯净的轨迹。SAAR基于语义相似性，自适应地调节替换粒度，从浅层执行修复到深层推理替换均可实现。通过在这些自我净化的路径上训练，模型能内化正确的推理模式，而非陷入错误恢复的循环。在AIME24/25、GPQA和LiveCodeBench上的实证结果表明，CLEANER相较基线平均提升6%、3%和5%的准确率。尤为突出的是，CLEANER仅用三分之一的训练步数即达到当前最优性能，凸显轨迹净化作为高效代理RL可扩展解决方案的巨大潜力。我们的模型与代码已开源至GitHub。"
  },
  {
    "date": "2026-01-21",
    "title": "ICLF: An Immersive Code Learning Framework based on Git for Teaching and Evaluating Student Programming Projects",
    "authors": "Pierre Schaus, Guillaume Derval, Augustin Delecluse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14814v1",
    "source": "arXiv",
    "abstract": "Programming projects are essential in computer science education for bridging theory with practice and introducing students to tools like Git, IDEs, and debuggers. However, designing and evaluating these projects (especially in MOOCs)can be challenging. We propose the Immersive Code Learning Framework (ICLF), a scalable Git-based organizational pipeline for managing and evaluating student programming project. Students begin with an existing code base, a practice that is crucial for mirroring real-world software development. Students then iteratively complete tasks that pass predefined tests. The instructor only manages a hidden parent repository containing solutions, which is used to generate an intermediate public repository with these solutions removed via a templating system. Students are invited collaborators on private forks of this intermediate repository, possibly updated throughout the semester whenever the teacher changes the parent repository. This approach reduces grading platform dependency, supports automated feedback, and allows the project to evolve without disrupting student work. Successfully tested over several years, including in an edX MOOC, this organizational pipeline provides transparent evaluation, plagiarism detection, and continuous progress tracking for each student.",
    "title_zh": "ICLF：一种基于Git的沉浸式代码学习框架，用于教学和评估学生编程项目",
    "abstract_zh": "编程项目在计算机科学教育中至关重要，它能够将理论与实践相结合，并帮助学生熟悉 Git、集成开发环境（IDE）和调试工具等实际开发工具。然而，在大规模开放在线课程（MOOCs）中设计和评估这些项目仍面临挑战。为此，我们提出了沉浸式代码学习框架（Immersive Code Learning Framework, ICLF），这是一个基于 Git 的可扩展组织流程，用于管理与评估学生的编程项目。\n\n学生从一个已有的代码库开始，这一做法对于模拟真实世界软件开发过程至关重要。随后，学生通过一系列任务逐步完成项目，每项任务都需通过预设的测试用例。教师仅需维护一个隐藏的父仓库，其中包含所有解决方案；该仓库通过模板系统生成一个中间公开仓库，自动移除解决方案内容。学生作为协作者被邀请加入此中间仓库的私有分支，且在学期过程中，当教师更新父仓库时，学生的分支可相应地进行同步更新。\n\n该方法减少了对特定评分平台的依赖，支持自动化反馈，并允许项目持续演进而不干扰学生的正常工作。经过数年实践验证，包括在 edX MOOC 课程中的应用，这一组织流程实现了透明的评估机制、有效的抄袭检测以及对每位学生学习进度的持续追踪。"
  },
  {
    "date": "2026-01-21",
    "title": "AdaTIR: Adaptive Tool-Integrated Reasoning via Difficulty-Aware Policy Optimization",
    "authors": "Zhaiyu Fang, Ruipeng Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14696v1",
    "source": "arXiv",
    "abstract": "Tool-Integrated Reasoning (TIR) has significantly enhanced the capabilities of Large Language Models (LLMs), yet current agents tend to exhibit cognitive offloading, redundantly invoking external tools even for simple tasks. In this paper, we suggest that true agentic intelligence requires not just tool invocation, but the adaptive wisdom to discern when to use them. We propose AdaTIR, a framework that shifts the paradigm from static tool invocation to difficulty-aware reasoning internalization. By introducing a difficulty-aware efficiency reward, AdaTIR dynamically adjusts tool budgets based on task complexity--internalizing reasoning for simple tasks while selectively invoking tools for complex tasks. Furthermore, we identify a sign reversal problem where tool penalties outweigh correctness rewards, mistakenly penalizing correct rollouts with negative advantages. To resolve this, we propose Clipped Advantage Shaping (CAS), which ensures that correctness remains the primary objective while using efficiency as a secondary constraint. Empirical results demonstrate that AdaTIR reduces tool calls by up to 97.6% on simple tasks and 28.2% on complex challenges while maintaining or enhancing accuracy. Notably, AdaTIR successfully internalizes reasoning, outperforming baselines by 4.8% on AIME 2024 even when tool access is strictly disabled.",
    "title_zh": "AdaTIR：基于难度感知策略优化的自适应工具集成推理",
    "abstract_zh": "工具集成推理（Tool-Integrated Reasoning, TIR）显著提升了大型语言模型（LLMs）的能力，然而当前的智能体往往表现出认知卸载现象，即使面对简单任务也会冗余地调用外部工具。本文提出，真正的代理智能不仅在于调用工具，更在于具备一种自适应的智慧——能够判断何时使用工具。为此，我们提出了AdaTIR框架，将传统的静态工具调用范式转变为基于难度感知的推理内化机制。通过引入一种基于难度感知的效率奖励，AdaTIR能够根据任务复杂度动态调整工具预算：对简单任务进行推理内化，而对复杂任务则选择性地调用工具。此外，我们识别出一个“符号反转”问题——工具调用惩罚超过了正确性奖励，导致正确执行路径因负优势而被错误惩罚。为解决这一问题，我们提出截断优势塑造（Clipped Advantage Shaping, CAS），确保正确性始终是首要目标，而效率仅作为次要约束。实验结果表明，AdaTIR在简单任务上可减少高达97.6%的工具调用，在复杂挑战中也降低了28.2%的调用次数，同时保持甚至提升了准确率。尤为关键的是，AdaTIR成功实现了推理的内化，在严格禁用工具访问的情况下，仍以4.8%的优势超越基线模型，在AIME 2024测试中表现卓越。"
  },
  {
    "date": "2026-01-21",
    "title": "Towards Cybersecurity Superintelligence: from AI-guided humans to human-guided AI",
    "authors": "Víctor Mayoral-Vilches, Stefan Rass, Martin Pinzger, Endika Gil-Uriarte, Unai Ayucar-Carbajo, Jon Ander Ruiz-Alcalde, Maite del Mundo de Torres, Luis Javier Navarrete-Lozano, María Sanz-Gómez, Francesco Balassone, Cristóbal R. J. Veas-Chavez, Vanesa Turiel, Alfonso Glera-Picón, Daniel Sánchez-Prieto, Yuri Salvatierra, Paul Zabalegui-Landa, Ruffino Reydel Cabrera-Álvarez, Patxi Mayoral-Pizarroso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14614v1",
    "source": "arXiv",
    "abstract": "Cybersecurity superintelligence -- artificial intelligence exceeding the best human capability in both speed and strategic reasoning -- represents the next frontier in security. This paper documents the emergence of such capability through three major contributions that have pioneered the field of AI Security. First, PentestGPT (2023) established LLM-guided penetration testing, achieving 228.6% improvement over baseline models through an architecture that externalizes security expertise into natural language guidance. Second, Cybersecurity AI (CAI, 2025) demonstrated automated expert-level performance, operating 3,600x faster than humans while reducing costs 156-fold, validated through #1 rankings at international competitions including the $50,000 Neurogrid CTF prize. Third, Generative Cut-the-Rope (G-CTR, 2026) introduces a neurosymbolic architecture embedding game-theoretic reasoning into LLM-based agents: symbolic equilibrium computation augments neural inference, doubling success rates while reducing behavioral variance 5.2x and achieving 2:1 advantage over non-strategic AI in Attack & Defense scenarios. Together, these advances establish a clear progression from AI-guided humans to human-guided game-theoretic cybersecurity superintelligence.",
    "title_zh": "迈向网络安全超级智能：从人工智能引导的人类到人类引导的人工智能",
    "abstract_zh": "网络安全超级智能——即在速度和战略推理能力上均超越最优秀人类的AI——代表了安全领域的新前沿。本文通过三大开创性贡献，记录了这一能力的诞生，这些贡献奠定了人工智能安全（AI Security）领域的基础。首先，PentestGPT（2023）开创了基于大语言模型（LLM）的渗透测试范式，其架构将安全专业知识外化为自然语言指导，使性能相比基线模型提升了228.6%。其次，网络安全AI（CAI，2025）实现了自动化专家级表现，运行速度比人类快3,600倍，成本降低156倍，并在国际竞赛中屡获殊荣，包括斩获5万美元的Neurogrid CTF冠军头衔。第三，生成式“剪绳子”（G-CTR，2026）提出一种神经符号架构，将博弈论推理嵌入基于LLM的智能体：通过符号均衡计算增强神经推断，使成功率翻倍，行为方差降低5.2倍，在攻防场景中相较非策略型AI取得2:1的优势。这三项进展共同勾勒出一条清晰的技术演进路径：从AI辅助人类，迈向由人类引导、具备博弈论思维的网络安全超级智能。"
  },
  {
    "date": "2026-01-21",
    "title": "IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference",
    "authors": "Qiyue Mei, Michael Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14595v1",
    "source": "arXiv",
    "abstract": "Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase.",
    "title_zh": "IntelliSA：一种基于符号规则与神经推理的智能静态分析器，用于检测IaC安全异味",
    "abstract_zh": "基础设施即代码（IaC）能够实现大规模云环境和本地环境的自动化部署，减少了重复的手动配置需求。然而，这种自动化也是一把双刃剑：IaC脚本中一个微小的配置错误就可能广泛传播，导致严重的系统宕机和安全风险。先前的研究表明，IaC脚本中常常存在“安全异味”——即可能引入漏洞的不良编码模式，并提出了基于符号规则的静态分析工具来检测这些异味。但我们的初步分析发现，仅依赖规则的检测方法往往过度泛化，产生大量误报，增加了人工审查的工作负担。\n\n在本文中，我们提出了一种名为 IntelliSA 的智能静态分析工具，用于 IaC 安全异味检测。IntelliSA 将符号规则与神经推理相结合：首先利用符号规则对潜在的安全异味进行广覆盖的过近似分析，随后通过神经推理模型过滤误报。虽然大型语言模型（LLM）在该过滤任务中表现优异，但依赖 LLM API 会带来高昂的成本和延迟，引发数据治理问题，并限制结果的可复现性及离线部署能力。\n\n为应对上述挑战，我们采用知识蒸馏的方法：由一个大型语言模型作为“教师”，生成伪标签以训练一个体积缩小超过 500 倍的紧凑型“学生”模型。该学生模型从教师的知识中学习，高效地识别并分类误报。我们在包含 11,814 行真实世界 IaC 代码、共 241 个经人工标注的安全异味的测试集上，将 IntelliSA 与两种传统静态分析工具以及三种 LLM 基线（Claude-4、Grok-4 和 GPT-5）进行了对比评估。实验结果表明，IntelliSA 达到了最高的 F1 分数（83%），相比基线提升 7% 至 42%。此外，IntelliSA 在成本效益方面表现最佳：仅需检查不到代码库总量的 2%，即可检测出 60% 的安全异味。"
  },
  {
    "date": "2026-01-21",
    "title": "How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework",
    "authors": "Choro Ulan uulu, Mikhail Kulyabin, Iris Fuhrmann, Jan Joosten, Nuno Miguel Martins Pacheco, Filippos Petridis, Rebecca Johnson, Jan Bosch, Helena Holmström Olsson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15153v1",
    "source": "arXiv",
    "abstract": "Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains.",
    "title_zh": "如何通过整合编码化的人类专家领域知识来构建AI代理？一种软件工程框架",
    "abstract_zh": "关键领域知识通常仅掌握在少数专家手中，这导致组织在可扩展性和决策过程中出现瓶颈。非专家难以创建有效的可视化，从而产生次优洞察，并进一步占用专家的时间。本文通过一个工业案例研究，探讨如何将人类领域知识捕获并嵌入AI代理系统中。我们提出了一种软件工程框架，通过增强大型语言模型（LLM）的请求分类器、用于代码生成的检索增强生成（RAG）系统、编码化的专家规则以及统一的可视化设计原则，构建一个能够自主、反应式、主动且具备社交行为能力的AI代理，以实现对仿真数据可视化的智能支持。在涵盖多个工程领域的五个场景中，由12名评估者进行的评估表明，该系统在输出质量上提升了206%，其生成结果在所有情况下均达到专家水平评分，而基线方法表现较差；同时，本系统保持了更优的代码质量且方差更低。本文的主要贡献包括：一个自动化的基于代理的可视化生成系统，以及一个经过验证的系统化框架，能够有效捕获人类领域知识，并将隐性专家经验转化为可编程的AI代理，证明非专家在专业领域也能实现专家级成果。"
  },
  {
    "date": "2026-01-21",
    "title": "Pipeline Automation Framework for Reusable High-throughput Network Applications on FPGA",
    "authors": "Jean Bruant, Pierre-Henri Horrein, Olivier Muller, Frédéric Pétrot",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15151v1",
    "source": "arXiv",
    "abstract": "In a context of ever-growing worldwide communication traffic, cloud service providers aim at deploying scalable infrastructures to address heterogeneous needs. Part of the network infrastructure, FPGAs are tailored to guarantee low-latency and high-throughput packet processing. However, slowness of the hardware design process impairs FPGA ability to be part of an agile infrastructure under constant evolution, from incident response to long-term transformation. Deploying and maintaining network functionalities across a wide variety of FPGAs raises the need to fine-tune hardware designs for several FPGA targets. To address this issue, we introduce PAF, an open-source architectural parameterization framework based on a pipeline-oriented design methodology. PAF (Pipeline Automation Framework) implementation is based on Chisel, a Scala-embedded Hardware Construction Language (HCL), that we leverage to interface with circuit elaboration. Applied to industrial network packet classification systems, PAF demonstrates efficient parameterization abilities, enabling to reuse and optimize the same pipelined design on several FPGAs. In addition, PAF focuses the pipeline description on the architectural intent, incidentally reducing the number of lines of code to express complex functionalities. Finally, PAF confirms that automation does not imply any loss of tight control on the architecture by achieving on par performance and resource usage with equivalent exhaustively described implementations.",
    "title_zh": "面向FPGA的可重用高吞吐量网络应用的流水线自动化框架",
    "abstract_zh": "在全球通信流量持续增长的背景下，云服务提供商致力于部署可扩展的基础设施，以满足多样化的应用需求。在网络基础设施中，现场可编程门阵列（FPGA）被专门用于保障低延迟和高吞吐量的数据包处理。然而，硬件设计过程的缓慢限制了FPGA在持续演进的敏捷基础设施中的应用能力，无论是应对突发故障还是实现长期转型。在多种不同FPGA平台上部署和维护网络功能，要求对硬件设计进行针对多个FPGA目标的精细调优。为解决这一问题，我们提出了PAF——一种基于流水线化设计方法的开源架构参数化框架。PAF（Pipeline Automation Framework）采用Chisel这一嵌入式Scala的硬件构造语言（HCL）实现，利用其与电路生成过程的无缝接口能力。将PAF应用于工业级网络数据包分类系统时，展现出高效的参数化能力，能够复用并优化同一流水线设计在多个FPGA平台上的部署。此外，PAF将流水线描述聚焦于架构意图本身，从而显著减少了表达复杂功能所需的代码行数。最后，PAF证实了自动化并不意味着对架构控制力的削弱：其性能和资源利用率与完全手工详尽描述的实现方案相当，达到了同等水平。"
  },
  {
    "date": "2026-01-21",
    "title": "Parameter-Efficient Multi-Task Fine-Tuning in Code-Related Tasks",
    "authors": "Md Zahidul Haque, Saima Afrin, Antonio Mastropaolo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15094v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have proven highly effective in automating software engineering tasks, bridging natural language and code semantics to achieve notable results in code generation and summarization. However, their scale incurs substantial computational costs, making full fine-tuning impractical. Parameter-Efficient Fine-Tuning (PEFT) methods like QLoRA enable efficient specialization with lower resource demands. Recent studies show QLoRA-optimized Large Code Models (LCMs) perform strongly across diverse tasks, yet it remains unclear whether this effectiveness persists when a single model is QLoRA fine-tuned for multiple code-related tasks. The interaction between Multi-task fine-tuning and QLoRA optimization, and how transfer learning affects correctness and quality of generated artifacts, remains largely unexplored. We investigate Multi-task QLoRA fine-tuning across three representative tasks: code generation, translation, and summarization. We evaluate functional correctness through execution-based and similarity-based metrics, complemented by comprehensive code quality analysis--an aspect largely overlooked in prior work. Our findings show that Multi-task QLoRA effectively leverages transfer learning, achieving competitive or superior performance relative to both Single-task QLoRA and Multi-task full fine-tuning. Larger models demonstrate more consistent balance between correctness and quality, whereas smaller models preserve functionality but exhibit a higher incidence of quality-related issues.",
    "title_zh": "代码相关任务中的参数高效多任务微调",
    "abstract_zh": "大型语言模型（LLMs）在自动化软件工程任务方面已展现出卓越的成效，能够有效连接自然语言与代码语义，在代码生成和摘要等任务中取得了显著成果。然而，其庞大的规模带来了高昂的计算成本，使得全量微调变得不切实际。参数高效微调（PEFT）方法，如QLoRA，能够在较低资源消耗下实现模型的高效定制化。近期研究表明，经过QLoRA优化的大规模代码模型（LCMs）在多种任务上表现优异，但尚不清楚当单一模型通过QLoRA微调来适应多个代码相关任务时，这种有效性是否依然成立。多任务微调与QLoRA优化之间的相互作用，以及迁移学习对生成代码的正确性与质量的影响，目前仍缺乏深入研究。本文针对代码生成、代码翻译和代码摘要三个代表性任务，系统探究了多任务QLoRA微调的效果。我们通过基于执行结果和相似性的度量评估生成代码的功能正确性，并辅以全面的代码质量分析——这一方面在以往研究中常被忽视。研究结果表明，多任务QLoRA能有效利用迁移学习，在性能上达到甚至超越单任务QLoRA及多任务全量微调的水平。更大规模的模型在正确性与质量之间表现出更稳定的平衡，而较小模型虽能保持功能完整性，却更容易出现质量问题。"
  },
  {
    "date": "2026-01-21",
    "title": "WebAssembly Based Portable and Secure Sensor Interface for Internet of Things",
    "authors": "Botong Ou, Baijian Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14555v1",
    "source": "arXiv",
    "abstract": "As the expansion of IoT connectivity continues to provide quality-of-life improvements around the world, they simultaneously introduce increasing privacy and security concerns. The lack of a clear definition in managing shared and protected access to IoT sensors offer channels by which devices can be compromised and sensitive data can be leaked. In recent years, WebAssembly has received considerable attention for its efficient application sandboxing suitable for embedded systems, making it a prime candidate for exploring a secure and portable sensor interface. This paper introduces the first WebAssembly System Interface (WASI) extension offering a secure, portable, and low-footprint sandbox enabling multi-tenant access to sensor data across heterogeneous embedded devices. The runtime extensions provide application memory isolation, ensure appropriate resource privileges by intercepting sensor access, and offer an MQTT-SN interface enabling in-network access control. When targeting the WebAssembly byte-code with the associated runtime extensions implemented atop the Zephyr RTOS, our evaluation of sensor access indicates a latency overhead of 6% with an additional memory footprint of 5% when compared to native execution. As MQTT-SN requests are dominated by network delays, the WASI-SN implementation of MQTT-SN introduces less than 1% additional latency with similar memory footprint.",
    "title_zh": "基于WebAssembly的物联网可移植且安全的传感器接口",
    "abstract_zh": "随着物联网（IoT）连接的持续扩展，全球范围内的生活质量得到了显著提升，但与此同时，隐私与安全问题也日益突出。由于在管理物联网传感器的共享与受保护访问方面缺乏明确规范，设备容易遭受攻击，敏感数据也可能被泄露。近年来，WebAssembly因其高效的程序沙箱机制，特别适用于嵌入式系统，受到广泛关注，成为探索安全且可移植的传感器接口的理想候选方案。本文首次提出一种基于WebAssembly系统接口（WASI）的扩展，该扩展提供了一个安全、可移植且低开销的沙箱环境，支持跨异构嵌入式设备的多租户传感器数据访问。运行时扩展通过应用内存隔离、拦截传感器访问以确保适当的资源权限，并提供MQTT-SN接口，实现网络内访问控制。当在Zephyr实时操作系统（RTOS）之上实现相关运行时扩展并针对WebAssembly字节码进行目标优化时，我们的评估结果显示，与原生执行相比，传感器访问的延迟开销仅为6%，内存占用增加约5%。由于MQTT-SN请求主要受网络延迟影响，因此WASI-SN对MQTT-SN的实现引入的额外延迟不足1%，内存开销也基本保持一致。"
  },
  {
    "date": "2026-01-21",
    "title": "Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models",
    "authors": "Injin Kong, Hyoungjoon Lee, Yohan Jo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14758v1",
    "source": "arXiv",
    "abstract": "Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic \"mechanism shift\" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning.",
    "title_zh": "从自回归到掩码扩散语言模型的微调过程中机制的转变",
    "abstract_zh": "将预训练的自回归模型（ARMs）后训练为掩码扩散模型（MDMs）已成为克服序列生成局限性的成本效益策略。然而，这一范式转变所引发的内部算法重构机制尚未得到充分探索，因此尚不清楚经过后训练的MDMs是否真正具备双向推理能力，还是仅仅重新包装了自回归启发式方法。在本研究中，我们通过对比分析ARMs与其MDM对应模型的电路结构，来回答这一问题。我们的分析揭示了一种系统性的“机制转移”，其依赖于任务的结构性质。在结构层面，我们观察到显著差异：对于以局部因果依赖为主导的任务，MDMs基本保留了自回归电路结构；而对于需要全局规划的任务，它们则放弃了初始化路径，表现出明显的重布线特征，即早期层处理显著增强。在语义层面，我们发现从ARMs中尖锐、局部化的专业化转向MDMs中分布式的整合。基于这些发现，我们得出结论：扩散后训练不仅调整模型参数，更从根本上重组内部计算机制，以支持非序列化的全局规划。"
  },
  {
    "date": "2026-01-21",
    "title": "INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems",
    "authors": "Yijin Zhou, Xiaoya Lu, Dongrui Liu, Junchi Yan, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14667v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of Large Language Model (LLM)-based Multi-Agent Systems (MAS) has introduced significant security vulnerabilities, where malicious influence can propagate virally through inter-agent communication. Conventional safeguards often rely on a binary paradigm that strictly distinguishes between benign and attack agents, failing to account for infected agents i.e., benign entities converted by attack agents. In this paper, we propose Infection-Aware Guard, INFA-Guard, a novel defense framework that explicitly identifies and addresses infected agents as a distinct threat category. By leveraging infection-aware detection and topological constraints, INFA-Guard accurately localizes attack sources and infected ranges. During remediation, INFA-Guard replaces attackers and rehabilitates infected ones, avoiding malicious propagation while preserving topological integrity. Extensive experiments demonstrate that INFA-Guard achieves state-of-the-art performance, reducing the Attack Success Rate (ASR) by an average of 33%, while exhibiting cross-model robustness, superior topological generalization, and high cost-effectiveness.",
    "title_zh": "INFA-Guard：通过感染感知防护机制在基于大语言模型的多智能体系统中缓解恶意传播",
    "abstract_zh": "基于大型语言模型（LLM）的多智能体系统（MAS）的快速发展带来了显著的安全漏洞，恶意影响可通过智能体间的通信呈病毒式传播。传统防护机制通常依赖于二元判断范式，严格区分良性智能体与攻击性智能体，却未能充分考虑“被感染智能体”——即原本为良性但被攻击智能体所操控的实体。本文提出一种新型防御框架——感染感知防护机制（Infection-Aware Guard, INFA-Guard），明确将被感染智能体识别为一类独立威胁。通过融合感染感知检测与拓扑约束机制，INFA-Guard能够精准定位攻击源及被感染范围。在修复阶段，INFA-Guard会替换攻击者并恢复被感染智能体，有效阻止恶意传播的同时保持系统拓扑结构的完整性。大量实验表明，INFA-Guard达到当前最优性能，平均将攻击成功率（ASR）降低33%，同时展现出跨模型鲁棒性、优越的拓扑泛化能力以及高成本效益。"
  },
  {
    "date": "2026-01-21",
    "title": "Power-Law Scaling in the Classification Performance of Small-Scale Spiking Neural Networks",
    "authors": "Zhengdi Zhang, Cong Han, Wenjun Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14961v1",
    "source": "arXiv",
    "abstract": "This paper investigates the classification capability of small-scale spiking neural networks based on the Leaky Integrate-and-Fire (LIF) neuron model. We analyze the relationship between classification accuracy and three factors: the number of neurons, the number of stimulus nodes, and the number of classification categories. Notably, we employ a large language model (LLM) to assist in discovering the underlying functional relationships among these variables, and compare its performance against traditional methods such as linear and polynomial fitting. Experimental results show that classification accuracy follows a power-law scaling primarily with the number of categories, while the effects of neuron count and stimulus nodes are relatively minor. A key advantage of the LLM-based approach is its ability to propose plausible functional forms beyond pre-defined equation templates, often leading to more concise or accurate mathematical descriptions of the observed scaling laws. This finding has important implications for understanding efficient computation in biological neural systems and for pioneering new paradigms in AI-aided scientific discovery.",
    "title_zh": "小规模脉冲神经网络分类性能中的幂律缩放规律",
    "abstract_zh": "本文研究了基于漏电积分-发放（Leaky Integrate-and-Fire, LIF）神经元模型的小规模脉冲神经网络的分类能力。我们分析了分类准确率与三个因素之间的关系：神经元数量、刺激节点数量以及分类类别数量。值得注意的是，我们采用大语言模型（LLM）辅助发现这些变量之间的潜在函数关系，并将其性能与传统的线性拟合和多项式拟合方法进行对比。实验结果表明，分类准确率主要随类别数量呈现幂律标度，而神经元数量和刺激节点数量的影响相对较小。基于大语言模型的方法的一个关键优势在于，它能够提出超越预设方程模板的合理函数形式，通常能更简洁或更准确地描述所观测到的标度规律。这一发现对于理解生物神经系统的高效计算机制，以及开创人工智能辅助科学发现的新范式具有重要意义。"
  },
  {
    "date": "2026-01-21",
    "title": "Ring oscillator performance of the ATLAS inner tracker pixel readout chip",
    "authors": "Yahya Khwaira, Abdenour Lounis, Maurice Cohen-Solal, Mohsine Menouni, Pierre Barrillon, Denis Fougeron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14924v1",
    "source": "arXiv",
    "abstract": "This paper presents experimental and simulation data to characterize the Ring Oscillators (RO) produced in 65-nm CMOS technology for the next promising generation of readout chips for the pixel detector in the Inner Tracker (ITk) at the ATLAS experiment at CERN. To enable a better understanding of the RO block embedded in ITkPixV1.1 single chip card (SCC), tests at various temperatures, voltages, accumulated total ionizing dose (TID) with X-ray irradiation, and high-temperature annealing will be presented. The objective of this study is to examine the RO output dependency based on different variable conditions and provide simulation data using Cadence, an electronic design automation (EDA) software to validate the experimental outcomes.",
    "title_zh": "ATLAS内层跟踪器像素读出芯片的环形振荡器性能",
    "abstract_zh": "本文展示了在65纳米CMOS工艺下制造的环形振荡器（RO）的实验与仿真数据，旨在表征下一代读出芯片在ATLAS实验内层跟踪器（ITk）像素探测器中的应用前景。为更好地理解嵌入在ITkPixV1.1单芯片卡（SCC）中的RO模块，本文将介绍在不同温度、电压、X射线辐照引起的累积总电离剂量（TID）以及高温退火条件下的测试结果。本研究的目标是分析RO输出在不同变量条件下的依赖关系，并利用Cadence电子设计自动化（EDA）软件提供仿真数据，以验证实验结果的准确性。"
  },
  {
    "date": "2026-01-21",
    "title": "CodeDelegator: Mitigating Context Pollution via Role Separation in Code-as-Action Agents",
    "authors": "Tianxiang Fei, Cheng Chen, Yue Pan, Mao Zheng, Mingyang Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14914v1",
    "source": "arXiv",
    "abstract": "Recent advances in large language models (LLMs) allow agents to represent actions as executable code, offering greater expressivity than traditional tool-calling. However, real-world tasks often demand both strategic planning and detailed implementation. Using a single agent for both leads to context pollution from debugging traces and intermediate failures, impairing long-horizon performance. We propose CodeDelegator, a multi-agent framework that separates planning from implementation via role specialization. A persistent Delegator maintains strategic oversight by decomposing tasks, writing specifications, and monitoring progress without executing code. For each sub-task, a new Coder agent is instantiated with a clean context containing only its specification, shielding it from prior failures. To coordinate between agents, we introduce Ephemeral-Persistent State Separation (EPSS), which isolates each Coder's execution state while preserving global coherence, preventing debugging traces from polluting the Delegator's context. Experiments on various benchmarks demonstrate the effectiveness of CodeDelegator across diverse scenarios.",
    "title_zh": "代码委托者：通过角色分离缓解代码即行动代理中的上下文污染",
    "abstract_zh": "大型语言模型（LLM）的最新进展使得智能体能够将动作表示为可执行代码，相比传统的工具调用方式具有更高的表达能力。然而，现实世界中的任务通常既需要战略规划，又需要细致的实现。若使用单一智能体同时承担这两项职责，调试痕迹和中间失败会导致上下文污染，从而影响长时序任务的表现。为此，我们提出了 CodeDelegator——一种多智能体框架，通过角色专业化将规划与实现分离。一个持续存在的“委托者”（Delegator）负责战略层面的监督，包括任务分解、编写规范以及进度监控，但不执行代码。针对每个子任务，系统会实例化一个新的“编码者”（Coder）智能体，其上下文保持纯净，仅包含该子任务的规范，从而避免受到先前失败的影响。为协调各智能体之间的协作，我们引入了“临时-持久状态分离”（Ephemeral-Persistent State Separation, EPSS）机制，该机制在隔离每个编码者执行状态的同时，维持全局一致性，防止调试痕迹污染委托者的上下文。在多个基准测试上的实验表明，CodeDelegator 在多样化场景中均表现出显著的有效性。"
  },
  {
    "date": "2026-01-21",
    "title": "Contextual Metaprogramming for Session Types",
    "authors": "Pedro Ângelo, Atsushi Igarashi, Yuito Murase, Vasco T. Vasconcelos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15180v1",
    "source": "arXiv",
    "abstract": "We propose the integration of staged metaprogramming into a session-typed message passing functional language. We build on a model of contextual modal type theory with multi-level contexts, where contextual values, closing arbitrary terms over a series of variables, may be boxed and transmitted in messages. Once received, one such value may then be unboxed and locally applied before being run. To motivate this integration, we present examples of real-world use cases, for which our system would be suitable, such as servers preparing and shipping code on demand via session typed messages. We present a type system that distinguishes linear (used exactly once) from unrestricted (used an unbounded number of times) resources, and further define a type checker, suitable for a concrete implementation. We show type preservation, a progress result for sequential computations and absence of runtime errors for the concurrent runtime environment, as well as the correctness of the type checker.",
    "title_zh": "会话类型的情境元编程",
    "abstract_zh": "我们提出将分阶段元编程集成到会话类型的消息传递函数式语言中。我们在具有多级上下文的上下文模态类型理论模型基础上进行研究，其中上下文值（可对一系列变量闭合任意项）可以被封装并作为消息传输。一旦接收，这些值便可被解封，并在本地应用后执行。为了说明这一集成的必要性，我们展示了若干实际应用场景，例如服务器通过会话类型消息按需准备并发送代码。我们设计了一种类型系统，能够区分线性资源（仅使用一次）与非限制资源（可无限次使用），并进一步定义了一个适用于具体实现的类型检查器。我们证明了类型保持性、顺序计算的进展性结果以及并发运行环境下的无运行时错误特性，同时验证了类型检查器的正确性。"
  },
  {
    "date": "2026-1-21",
    "title": "Typestate-based Fault Localization of API Usage Violations in a Deep Learning Program",
    "authors": "Fraol Batole, Ruchira Manke, Robert Dyer, Tien N. Nguyen, Hridesh Rajan",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3656464",
    "source": "IEEE",
    "abstract": "Deep Learning (DL) applications have become essential in numerous domains, yet they remain plagued by subtle bugs that cause 66% of crashes in production systems. These failures primarily stem from API usage violations in complex frameworks like TensorFlow, Keras, and PyTorch, where APIs lack formal specifications and interdependencies between operations remain undocumented. Traditional static analysis tools fail to address DL-specific constraints, such as data dependency between layers. To bridge this critical gap, we propose NEURALSTATE, an approach to detect performance and program crash bugs in a DL program. NEURALSTATE follows a four-step process: (i) gather specifications for Deep Learning operations from different sources; (ii) introduce abstract states to represent these Deep Learning operations; (iii) design formal rules for transitioning between states based on the specifications; (iv) utilize a combination of standard analysis techniques (i.e., typestate and value propagation) to identify bugs in a DL program. Our evaluation on real-world benchmarks demonstrates NEURALSTATE’s effectiveness, achieving a 25% improvement in precision and 63% improvement in recall compared to state-of-the-art tools. Most importantly, NEURALSTATE successfully detects 18 subtle bugs in 45 real-world programs that existing techniques miss entirely.",
    "title_zh": "基于类型状态的深度学习程序中API使用违规故障定位",
    "abstract_zh": "深度学习（DL）应用已在众多领域变得至关重要，但其仍受制于细微的缺陷，这些缺陷导致了生产系统中66%的崩溃。这些故障主要源于复杂框架（如TensorFlow、Keras和PyTorch）中API使用不当，而这些框架的API缺乏正式规范，且操作之间的依赖关系也未被文档化。传统的静态分析工具无法有效应对深度学习特有的约束条件，例如层间的数据依赖性。为填补这一关键空白，我们提出了NEURALSTATE——一种用于检测深度学习程序中性能问题与程序崩溃缺陷的方法。NEURALSTATE采用四步流程：(i) 从不同来源收集深度学习操作的规范；(ii) 引入抽象状态来表示这些深度学习操作；(iii) 基于规范设计状态间转换的正式规则；(iv) 结合标准分析技术（如类型状态和值传播），识别深度学习程序中的缺陷。我们在真实世界基准上的评估表明，NEURALSTATE表现出色，相较于现有最先进工具，精度提升了25%，召回率提高了63%。更重要的是，NEURALSTATE成功检测出45个真实程序中18个此前现有技术完全遗漏的隐蔽缺陷。"
  },
  {
    "date": "2026-1-21",
    "title": "Enhancing Functional Coverage Closure in Network-On-Chip Systems with Reinforcement Learning",
    "authors": "N. Vamshi Krishna, Rachana Chintalapati, Paresh Saxena, J. Soumya",
    "publish": "IEEE Embedded Systems Letters",
    "url": "https://doi.org/10.1109/les.2026.3656758",
    "source": "IEEE",
    "abstract": "As the demand for designing and validating complex technologies increases, the need for computationally efficient methodologies becomes crucial. Network-On-Chip (NoC) verification, with its vast architecture of numerous routers and links, presents significant challenges when performed using traditional methods, delaying the entry of products into the market. This paper presents a streamlined and lightweight solution that uses Reinforcement Learning to automate test vector generation. By optimizing the verification process, this approach significantly speeds up coverage closure, ensuring thorough validation and improving overall efficiency.",
    "title_zh": "基于强化学习的网络-on-芯片系统功能覆盖率提升方法",
    "abstract_zh": "随着对复杂技术设计与验证需求的不断增长，高效计算方法的重要性日益凸显。网络-on-芯片（NoC）验证因其包含大量路由器和链路的庞大架构，采用传统方法时面临巨大挑战，导致产品上市时间延迟。本文提出了一种轻量级、高效的解决方案，利用强化学习自动生成测试向量。通过优化验证流程，该方法显著加快了覆盖率收敛速度，确保全面验证的同时提升了整体效率。"
  }
]