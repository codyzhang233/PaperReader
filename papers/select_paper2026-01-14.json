[
  {
    "date": "2026-01-14",
    "title": "DepRadar: Agentic Coordination for Context Aware Defect Impact Analysis in Deep Learning Libraries",
    "authors": "Yi Gao, Xing Hu, Tongtong Xu, Jiali Zhao, Xiaohu Yang, Xin Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09440v1",
    "source": "arXiv",
    "abstract": "Deep learning libraries like Transformers and Megatron are now widely adopted in modern AI programs. However, when these libraries introduce defects, ranging from silent computation errors to subtle performance regressions, it is often challenging for downstream users to assess whether their own programs are affected. Such impact analysis requires not only understanding the defect semantics but also checking whether the client code satisfies complex triggering conditions involving configuration flags, runtime environments, and indirect API usage. We present DepRadar, an agent coordination framework for fine grained defect and impact analysis in DL library updates. DepRadar coordinates four specialized agents across three steps: 1. the PR Miner and Code Diff Analyzer extract structured defect semantics from commits or pull requests, 2. the Orchestrator Agent synthesizes these signals into a unified defect pattern with trigger conditions, and 3. the Impact Analyzer checks downstream programs to determine whether the defect can be triggered. To improve accuracy and explainability, DepRadar integrates static analysis with DL-specific domain rules for defect reasoning and client side tracing. We evaluate DepRadar on 157 PRs and 70 commits across two representative DL libraries. It achieves 90% precision in defect identification and generates high quality structured fields (average field score 1.6). On 122 client programs, DepRadar identifies affected cases with 90% recall and 80% precision, substantially outperforming other baselines.",
    "title_zh": "DepRadar：面向深度学习库中上下文感知缺陷影响分析的智能体协同机制",
    "abstract_zh": "深度学习库如 Transformers 和 Megatron 在现代人工智能程序中已得到广泛应用。然而，当这些库引入缺陷时——从无声的计算错误到细微的性能退化——下游用户往往难以判断自己的程序是否受到影响。这种影响分析不仅需要理解缺陷的语义，还需检查客户端代码是否满足涉及配置标志、运行时环境以及间接 API 使用等复杂触发条件。我们提出了 DepRadar，一个用于深度学习库更新中细粒度缺陷与影响分析的智能体协同框架。DepRadar 通过三个步骤协调四个专业智能体：1. PR Miner 和代码差异分析器从提交或拉取请求中提取结构化的缺陷语义；2. 协调智能体将这些信号整合为包含触发条件的统一缺陷模式；3. 影响分析智能体检查下游程序，以判断该缺陷是否可被触发。为提升准确性和可解释性，DepRadar 融合了静态分析与深度学习领域的特定规则，用于缺陷推理和客户端行为追踪。我们在两个代表性深度学习库的 157 个 Pull Request 和 70 个提交上评估了 DepRadar，其在缺陷识别方面达到 90% 的精确率，并生成高质量的结构化字段（平均字段得分 1.6）。在对 122 个客户端程序的测试中，DepRadar 以 90% 的召回率和 80% 的精确率成功识别出受影响案例，显著优于其他基线方法。"
  },
  {
    "date": "2026-01-14",
    "title": "Blue Teaming Function-Calling Agents",
    "authors": "Greta Dolcetti, Giulio Zizzo, Sergio Maffeis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09292v1",
    "source": "arXiv",
    "abstract": "We present an experimental evaluation that assesses the robustness of four open source LLMs claiming function-calling capabilities against three different attacks, and we measure the effectiveness of eight different defences. Our results show how these models are not safe by default, and how the defences are not yet employable in real-world scenarios.",
    "title_zh": "蓝队功能调用代理",
    "abstract_zh": "我们进行了一项实验评估，测试了四种声称具备函数调用能力的开源大语言模型在三种不同攻击下的鲁棒性，并衡量了八种不同防御措施的有效性。我们的结果表明，这些模型默认情况下并不安全，而现有的防御措施也尚未能在实际场景中投入使用。"
  },
  {
    "date": "2026-01-14",
    "title": "MAXS: Meta-Adaptive Exploration with LLM Agents",
    "authors": "Jian Zhang, Zhiyuan Wang, Zhangqi Wang, Yu He, Haoran Luo, li yuan, Lingling Zhang, Rui Mao, Qika Lin, Jun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09259v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) Agents exhibit inherent reasoning abilities through the collaboration of multiple tools. However, during agent inference, existing methods often suffer from (i) locally myopic generation, due to the absence of lookahead, and (ii) trajectory instability, where minor early errors can escalate into divergent reasoning paths. These issues make it difficult to balance global effectiveness and computational efficiency. To address these two issues, we propose meta-adaptive exploration with LLM agents https://github.com/exoskeletonzj/MAXS, a meta-adaptive reasoning framework based on LLM Agents that flexibly integrates tool execution and reasoning planning. MAXS employs a lookahead strategy to extend reasoning paths a few steps ahead, estimating the advantage value of tool usage, and combines step consistency variance and inter-step trend slopes to jointly select stable, consistent, and high-value reasoning steps. Additionally, we introduce a trajectory convergence mechanism that controls computational cost by halting further rollouts once path consistency is achieved, enabling a balance between resource efficiency and global effectiveness in multi-tool reasoning. We conduct extensive empirical studies across three base models (MiMo-VL-7B, Qwen2.5-VL-7B, Qwen2.5-VL-32B) and five datasets, demonstrating that MAXS consistently outperforms existing methods in both performance and inference efficiency. Further analysis confirms the effectiveness of our lookahead strategy and tool usage.",
    "title_zh": "MAXS：基于大语言模型代理的元自适应探索",
    "abstract_zh": "大型语言模型（LLM）代理通过多种工具的协同合作展现出内在的推理能力。然而，在代理推理过程中，现有方法常常面临两个问题：(i) 局部短视生成，由于缺乏前瞻规划；(ii) 轨迹不稳定性，即早期微小错误可能迅速演变为偏离的推理路径。这些问题使得在全局有效性与计算效率之间难以取得平衡。为解决上述挑战，我们提出了基于LLM代理的元自适应探索框架——MAXS（Meta-Adaptive eXploration with LLM Agents），其开源代码见 https://github.com/exoskeletonzj/MAXS。MAXS能够灵活整合工具执行与推理规划，采用前瞻策略将推理路径向前扩展若干步，评估工具使用的潜在优势值，并结合步骤一致性方差与跨步趋势斜率，共同选择稳定、一致且高价值的推理步骤。此外，我们引入了一种轨迹收敛机制，当路径一致性达到阈值时自动停止后续展开，从而控制计算开销，实现在多工具推理中资源效率与全局有效性的良好平衡。我们在三种基础模型（MiMo-VL-7B、Qwen2.5-VL-7B、Qwen2.5-VL-32B）和五个数据集上进行了广泛的实证研究，结果表明，MAXS在性能和推理效率方面均持续优于现有方法。进一步分析也验证了我们提出的前瞻策略与工具使用机制的有效性。"
  },
  {
    "date": "2026-01-14",
    "title": "World Craft: Agentic Framework to Create Visualizable Worlds via Text",
    "authors": "Jianwen Sun, Yukang Feng, Kaining Ying, Chuanhao Li, Zizhen Li, Fanrui Zhang, Jiaxin Ai, Yifan Chang, Yu Dai, Yifei Huang, Kaipeng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09150v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) motivate generative agent simulation (e.g., AI Town) to create a ``dynamic world'', holding immense value across entertainment and research. However, for non-experts, especially those without programming skills, it isn't easy to customize a visualizable environment by themselves. In this paper, we introduce World Craft, an agentic world creation framework to create an executable and visualizable AI Town via user textual descriptions. It consists of two main modules, World Scaffold and World Guild. World Scaffold is a structured and concise standardization to develop interactive game scenes, serving as an efficient scaffolding for LLMs to customize an executable AI Town-like environment. World Guild is a multi-agent framework to progressively analyze users' intents from rough descriptions, and synthesizes required structured contents (\\eg environment layout and assets) for World Scaffold . Moreover, we construct a high-quality error-correction dataset via reverse engineering to enhance spatial knowledge and improve the stability and controllability of layout generation, while reporting multi-dimensional evaluation metrics for further analysis. Extensive experiments demonstrate that our framework significantly outperforms existing commercial code agents (Cursor and Antigravity) and LLMs (Qwen3 and Gemini-3-Pro). in scene construction and narrative intent conveyance, providing a scalable solution for the democratization of environment creation.",
    "title_zh": "世界构建：通过文本创建可视觉化世界的智能框架",
    "abstract_zh": "大型语言模型（LLMs）推动了生成式智能体模拟（如AI Town）的发展，从而构建出“动态世界”，在娱乐与研究领域具有巨大价值。然而，对于非专业人士，尤其是缺乏编程技能的用户而言，自行定制一个可可视化环境仍存在较大挑战。本文提出World Craft——一种基于智能体的世界创建框架，仅通过用户的文本描述即可生成可执行且可视化的AI Town。该框架包含两个核心模块：World Scaffold 和 World Guild。World Scaffold 采用结构化、简洁化的标准规范，用于开发交互式游戏场景，为LLM提供高效支撑，以定制类似AI Town的可执行环境。World Guild 是一个多智能体系统，能够逐步解析用户从粗略描述中表达的意图，并合成所需结构化内容（如环境布局和资源资产），供 World Scaffold 使用。此外，我们通过逆向工程构建了一个高质量的错误修正数据集，以增强空间知识，提升布局生成的稳定性与可控性；同时报告了多维度评估指标，便于进一步分析。大量实验表明，我们的框架在场景构建与叙事意图传达方面显著优于现有的商业代码智能体（Cursor 和 Antigravity）以及主流大模型（Qwen3 和 Gemini-3-Pro），为环境创建的民主化提供了可扩展的解决方案。"
  },
  {
    "date": "2026-01-14",
    "title": "KryptoPilot: An Open-World Knowledge-Augmented LLM Agent for Automated Cryptographic Exploitation",
    "authors": "Xiaonan Liu, Zhihao Li, Xiao Lan, Hao Ren, Haizhou Wang, Xingshu Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09129v1",
    "source": "arXiv",
    "abstract": "Capture-the-Flag (CTF) competitions play a central role in modern cybersecurity as a platform for training practitioners and evaluating offensive and defensive techniques derived from real-world vulnerabilities. Despite recent advances in large language models (LLMs), existing LLM-based agents remain ineffective on high-difficulty cryptographic CTF challenges, which require precise cryptanalytic knowledge, stable long-horizon reasoning, and disciplined interaction with specialized toolchains. Through a systematic exploratory study, we show that insufficient knowledge granularity, rather than model reasoning capacity, is a primary factor limiting successful cryptographic exploitation: coarse or abstracted external knowledge often fails to support correct attack modeling and implementation. Motivated by this observation, we propose KryptoPilot, an open-world knowledge-augmented LLM agent for automated cryptographic exploitation. KryptoPilot integrates dynamic open-world knowledge acquisition via a Deep Research pipeline, a persistent workspace for structured knowledge reuse, and a governance subsystem that stabilizes reasoning through behavioral constraints and cost-aware model routing. This design enables precise knowledge alignment while maintaining efficient reasoning across heterogeneous subtasks. We evaluate KryptoPilot on two established CTF benchmarks and in six real-world CTF competitions. KryptoPilot achieves a complete solve rate on InterCode-CTF, solves between 56 and 60 percent of cryptographic challenges on the NYU-CTF benchmark, and successfully solves 26 out of 33 cryptographic challenges in live competitions, including multiple earliest-solved and uniquely-solved instances. These results demonstrate the necessity of open-world, fine-grained knowledge augmentation and governed reasoning for scaling LLM-based agents to real-world cryptographic exploitation.",
    "title_zh": "KryptoPilot：一种用于自动化密码学攻击的开放世界知识增强型大语言模型代理",
    "abstract_zh": "夺旗赛（Capture-the-Flag, CTF）在现代网络安全领域扮演着核心角色，为安全从业者提供了训练平台，并用于评估源自真实世界漏洞的攻防技术。尽管大型语言模型（LLMs）近年来取得了显著进展，但现有的基于LLM的智能体在高难度密码学CTF挑战中仍表现不佳，这类挑战需要精确的密码分析知识、稳定的长周期推理能力，以及对专用工具链的规范交互。通过一项系统性的探索性研究，我们发现：限制成功密码学攻击的主要因素并非模型的推理能力，而是外部知识的粒度不足——粗略或抽象化的知识往往无法有效支持正确的攻击建模与实现。基于这一观察，我们提出了KryptoPilot，一种面向自动化密码学攻防的开放世界知识增强型LLM智能体。KryptoPilot集成了通过深度调研（Deep Research）管道实现的动态开放世界知识获取、用于结构化知识复用的持久化工作区，以及通过行为约束和成本感知模型调度来稳定推理过程的治理子系统。该设计在保持跨异构子任务高效推理的同时，实现了精准的知识对齐。我们在两个主流CTF基准测试及六场真实世界CTF竞赛中对KryptoPilot进行了评估。结果显示，KryptoPilot在InterCode-CTF上实现了完全求解率，在NYU-CTF基准上解决了56%至60%的密码学挑战，并在实际比赛中成功破解了33个密码学题目中的26道，其中包括多个最早求解和唯一求解的案例。这些成果充分证明了开放世界、细粒度知识增强与受控推理对于提升LLM智能体在真实世界密码学攻防中应用能力的必要性。"
  },
  {
    "date": "2026-01-14",
    "title": "SubTokenTest: A Practical Benchmark for Real-World Sub-token Understanding",
    "authors": "Shuyang Hou, Yi Hu, Muhan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09089v1",
    "source": "arXiv",
    "abstract": "Recent advancements in large language models (LLMs) have significantly enhanced their reasoning capabilities. However, they continue to struggle with basic character-level tasks, such as counting letters in words, a problem rooted in their tokenization process. While existing benchmarks have highlighted this weakness through basic character operations, such failures are often dismissed due to lacking practical relevance. Yet, many real-world applications, such as navigating text-based maps or interpreting structured tables, rely heavily on precise sub-token understanding. In this regard, we introduce SubTokenTest, a comprehensive benchmark that assesses sub-token understanding through practical, utility-driven tasks. Our benchmark includes ten tasks across four domains and isolates tokenization-related failures by decoupling performance from complex reasoning. We provide a comprehensive evaluation of nine advanced LLMs. Additionally, we investigate the impact of test-time scaling on sub-token reasoning and explore how character-level information is encoded within the hidden states.",
    "title_zh": "SubTokenTest：一个面向现实世界子词理解的实用基准测试",
    "abstract_zh": "近年来，大型语言模型（LLMs）在推理能力方面取得了显著进展。然而，它们在处理基本的字符级任务时仍存在困难，例如统计单词中的字母数量，这一问题根源在于其分词（tokenization）过程。尽管现有基准测试已通过简单的字符操作揭示了这一弱点，但这些失败常因缺乏实际应用价值而被忽视。然而，在许多现实应用场景中，如导航文本地图或解析结构化表格，都高度依赖对子标记（sub-token）的精确理解。为此，我们提出了SubTokenTest——一个全面的基准测试，通过具有实际用途的任务来评估模型对子标记的理解能力。该基准涵盖四个领域的十项任务，并通过将性能与复杂推理解耦，有效隔离了由分词引发的错误。我们对九个先进的大型语言模型进行了全面评估，同时研究了测试阶段缩放（test-time scaling）对子标记推理的影响，并探索了字符级信息在隐藏状态中的编码方式。"
  },
  {
    "date": "2026-01-14",
    "title": "Distribution-Aligned Sequence Distillation for Superior Long-CoT Reasoning",
    "authors": "Shaotian Yan, Kaiyuan Liu, Chen Shen, Bing Wang, Sinan Fan, Jun Zhang, Yue Wu, Zheng Wang, Jieping Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09088v1",
    "source": "arXiv",
    "abstract": "In this report, we introduce DASD-4B-Thinking, a lightweight yet highly capable, fully open-source reasoning model. It achieves SOTA performance among open-source models of comparable scale across challenging benchmarks in mathematics, scientific reasoning, and code generation -- even outperforming several larger models. We begin by critically reexamining a widely adopted distillation paradigm in the community: SFT on teacher-generated responses, also known as sequence-level distillation. Although a series of recent works following this scheme have demonstrated remarkable efficiency and strong empirical performance, they are primarily grounded in the SFT perspective. Consequently, these approaches focus predominantly on designing heuristic rules for SFT data filtering, while largely overlooking the core principle of distillation itself -- enabling the student model to learn the teacher's full output distribution so as to inherit its generalization capability. Specifically, we identify three critical limitations in current practice: i) Inadequate representation of the teacher's sequence-level distribution; ii) Misalignment between the teacher's output distribution and the student's learning capacity; and iii) Exposure bias arising from teacher-forced training versus autoregressive inference. In summary, these shortcomings reflect a systemic absence of explicit teacher-student interaction throughout the distillation process, leaving the essence of distillation underexploited. To address these issues, we propose several methodological innovations that collectively form an enhanced sequence-level distillation training pipeline. Remarkably, DASD-4B-Thinking obtains competitive results using only 448K training samples -- an order of magnitude fewer than those employed by most existing open-source efforts. To support community research, we publicly release our models and the training dataset.",
    "title_zh": "用于卓越长链思维推理的分布对齐序列蒸馏",
    "abstract_zh": "在本报告中，我们介绍了 DASD-4B-Thinking——一个轻量级但功能强大、完全开源的推理模型。该模型在数学、科学推理和代码生成等具有挑战性的基准测试中，达到了与同类规模开源模型相比的顶尖性能，甚至超越了多个更大规模的模型。我们首先对社区中广泛采用的一种蒸馏范式进行了批判性重新审视：基于教师模型生成响应的监督微调（SFT），也称为序列级蒸馏。尽管一系列遵循该方案的近期研究已展现出卓越的效率和强劲的实证表现，但它们主要建立在 SFT 的视角之上。因此，这些方法主要集中于设计启发式规则以过滤 SFT 数据，而很大程度上忽视了蒸馏的核心原则——即让学生模型能够学习教师模型完整的输出分布，从而继承其泛化能力。\n\n具体而言，我们识别出现有实践中的三个关键局限：i）教师模型序列级分布表示不充分；ii）教师输出分布与学生模型学习能力之间存在错配；iii）由于教师强制训练与自回归推理之间的差异，导致暴露偏差。总体而言，这些缺陷反映出在整个蒸馏过程中缺乏显式的师生互动，使得蒸馏的本质未被充分挖掘。\n\n为解决上述问题，我们提出了一系列方法论创新，共同构成了一套增强的序列级蒸馏训练流程。令人瞩目的是，DASD-4B-Thinking 仅使用 44.8 万条训练样本便取得了具有竞争力的结果——这比大多数现有开源方案所使用的样本数量少了一个数量级。为支持社区研究，我们已公开发布模型及训练数据集。"
  },
  {
    "date": "2026-01-14",
    "title": "How Many Human Judgments Are Enough? Feasibility Limits of Human Preference Evaluation",
    "authors": "Wilson Y. Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09084v1",
    "source": "arXiv",
    "abstract": "Human preference evaluations are widely used to compare generative models, yet it remains unclear how many judgments are required to reliably detect small improvements. We show that when preference signal is diffuse across prompts (i.e., all prompt types are similarly informative), proportional allocation is minimax-optimal: no allocation strategy substantially improves detectability. Empirical analysis of large-scale human preference datasets shows that most comparisons fall into this diffuse regime, exhibiting small preference margins that require far more judgments than typically collected, even in well-sampled comparisons. These limits persist across evaluation protocols and modalities, including chat, image generation, and code generation with execution feedback. In contrast, curated benchmarks that reduce prompt induced variability systematically induce larger margins and improve detectability through a $1.5\\times$ reduction in prompt-level variance. Our results show that inconclusive or negative human evaluation outcomes frequently reflect underpowered evaluation rather than model equivalence, underscoring the need to account explicitly for effect size, budget, and protocol design.",
    "title_zh": "人类判断需要多少才够？人类偏好评估的可行性极限",
    "abstract_zh": "人类偏好评估被广泛用于比较生成模型，但目前仍不清楚需要多少判断才能可靠地检测到微小的改进。我们发现，当偏好信号在提示（prompt）之间分布较广时（即所有类型的提示都具有相似的信息量），按比例分配样本是极小化最大误差（minimax-optimal）的：任何其他分配策略都无法显著提升检测能力。对大规模人类偏好数据集的实证分析表明，大多数比较都处于这种“信号扩散”状态，其偏好差距很小，所需判断数量远超通常收集的数量，即使在充分采样的比较中也是如此。这些限制在不同评估协议和模态下均持续存在，包括对话、图像生成以及带有执行反馈的代码生成。相比之下，经过精心设计的基准测试通过减少提示引起的变异性，系统性地增大了偏好差距，并通过将提示层面方差降低1.5倍，显著提升了检测能力。我们的研究结果表明，许多看似不明确或负面的人类评估结果，往往反映的是评估能力不足，而非模型实际等效。这凸显出在评估中必须明确考虑效应大小、预算限制以及评估协议的设计。"
  },
  {
    "date": "2026-01-14",
    "title": "ShortCoder: Knowledge-Augmented Syntax Optimization for Token-Efficient Code Generation",
    "authors": "Sicong Liu, Yanxian Huang, Mingwei Liu, Jiachi Chen, Ensheng Shi, Yuchi Ma, Hongyu Zhang, Yin Zhang, Yanlin Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09703v1",
    "source": "arXiv",
    "abstract": "Code generation tasks aim to automate the conversion of user requirements into executable code, significantly reducing manual development efforts and enhancing software productivity. The emergence of large language models (LLMs) has significantly advanced code generation, though their efficiency is still impacted by certain inherent architectural constraints. Each token generation necessitates a complete inference pass, requiring persistent retention of contextual information in memory and escalating resource consumption. While existing research prioritizes inference-phase optimizations such as prompt compression and model quantization, the generation phase remains underexplored. To tackle these challenges, we propose a knowledge-infused framework named ShortCoder, which optimizes code generation efficiency while preserving semantic equivalence and readability. In particular, we introduce: (1) ten syntax-level simplification rules for Python, derived from AST-preserving transformations, achieving 18.1% token reduction without functional compromise; (2) a hybrid data synthesis pipeline integrating rule-based rewriting with LLM-guided refinement, producing ShorterCodeBench, a corpus of validated tuples of original code and simplified code with semantic consistency; (3) a fine-tuning strategy that injects conciseness awareness into the base LLMs. Extensive experimental results demonstrate that ShortCoder consistently outperforms state-of-the-art methods on HumanEval, achieving an improvement of 18.1%-37.8% in generation efficiency over previous methods while ensuring the performance of code generation.",
    "title_zh": "ShortCoder：面向令牌高效代码生成的知识增强型语法优化",
    "abstract_zh": "代码生成任务旨在自动化地将用户需求转化为可执行代码，显著减少人工开发工作量并提升软件生产力。大型语言模型（LLMs）的出现极大地推动了代码生成技术的发展，但其效率仍受到某些固有架构限制的影响。每次生成一个标记（token）都需要进行一次完整的推理过程，这要求持续在内存中保留上下文信息，导致资源消耗不断上升。尽管现有研究主要聚焦于推理阶段的优化，如提示压缩和模型量化，但生成阶段仍缺乏充分探索。为应对这些挑战，我们提出了一种名为ShortCoder的知识增强型框架，该框架在保持语义等价性和代码可读性的前提下，有效提升了代码生成的效率。具体而言，我们提出了以下创新：(1) 基于AST保持变换的十项Python语法级简化规则，实现了18.1%的token减少，且不改变程序功能；(2) 一种融合规则驱动重写与LLM引导优化的混合数据合成流程，构建了ShorterCodeBench数据集，包含经验证的原始代码与简化代码对，确保语义一致性；(3) 一种微调策略，将简洁性意识注入基础LLM中。大量实验结果表明，ShortCoder在HumanEval基准上持续优于当前最先进的方法，在生成效率方面相较以往方法提升18.1%至37.8%，同时保障了代码生成的质量。"
  },
  {
    "date": "2026-01-14",
    "title": "SimMerge: Learning to Select Merge Operators from Similarity Signals",
    "authors": "Oliver Bolton, Aakanksha, Arash Ahmadian, Sara Hooker, Marzieh Fadaee, Beyza Ermis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09473v1",
    "source": "arXiv",
    "abstract": "Model merging enables multiple large language models (LLMs) to be combined into a single model while preserving performance. This makes it a valuable tool in LLM development, offering a competitive alternative to multi-task training. However, merging can be difficult at scale, as successful merging requires choosing the right merge operator, selecting the right models, and merging them in the right order. This often leads researchers to run expensive merge-and-evaluate searches to select the best merge. In this work, we provide an alternative by introducing \\simmerge{}, \\emph{a predictive merge-selection method} that selects the best merge using inexpensive, task-agnostic similarity signals between models. From a small set of unlabeled probes, we compute functional and structural features and use them to predict the performance of a given 2-way merge. Using these predictions, \\simmerge{} selects the best merge operator, the subset of models to merge, and the merge order, eliminating the expensive merge-and-evaluate loop. We demonstrate that we surpass standard merge-operator performance on 2-way merges of 7B-parameter LLMs, and that \\simmerge{} generalizes to multi-way merges and 111B-parameter LLM merges without retraining. Additionally, we present a bandit variant that supports adding new tasks, models, and operators on the fly. Our results suggest that learning how to merge is a practical route to scalable model composition when checkpoint catalogs are large and evaluation budgets are tight.",
    "title_zh": "SimMerge：从相似性信号中学习选择合并操作符",
    "abstract_zh": "模型合并技术能够将多个大型语言模型（LLMs）融合为单一模型，同时保持其性能表现。这一特性使其在大模型开发中成为一项宝贵工具，为多任务训练提供了一种具有竞争力的替代方案。然而，在大规模场景下，模型合并仍面临挑战：成功的合并需要选择合适的合并算子、挑选恰当的模型，并确定正确的合并顺序。这通常迫使研究人员进行昂贵的“合并-评估”搜索以筛选最优合并方案。本文提出一种替代方法——\\simmerge{}，即一种**预测性合并选择方法**，该方法利用低成本、任务无关的模型间相似性信号，直接预测合并效果，从而避免耗时耗力的试错过程。我们仅需少量未标注样本作为探测数据，即可计算出模型的功能与结构特征，并据此预测任意两模型（2-way merge）的性能表现。基于这些预测结果，\\simmerge{}可自动选择最佳合并算子、最优模型子集以及最合理的合并顺序，彻底消除传统上反复执行“合并-评估”的开销。\n\n实验表明，\\simmerge{}在70亿参数规模的LLM两两合并任务中，显著超越了标准合并算子的性能表现；同时，该方法在不重新训练的前提下，成功推广至多路合并（multi-way merges）以及1110亿参数级LLM的合并任务中。此外，我们还提出了一个基于强化学习的“老虎机”（bandit）变体，支持在运行过程中动态添加新任务、新模型和新合并算子，具备良好的扩展性与适应性。\n\n我们的研究结果表明，当存在大量模型检查点且评估预算有限时，学习如何高效地进行模型合并，是一条实现可扩展模型组合的切实可行路径。"
  },
  {
    "date": "2026-01-14",
    "title": "Structured Knowledge Representation through Contextual Pages for Retrieval-Augmented Generation",
    "authors": "Xinze Li, Zhenghao Liu, Haidong Xin, Yukun Yan, Shuo Wang, Zheni Zeng, Sen Mei, Ge Yu, Maosong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09402v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by incorporating external knowledge. Recently, some works have incorporated iterative knowledge accumulation processes into RAG models to progressively accumulate and refine query-related knowledge, thereby constructing more comprehensive knowledge representations. However, these iterative processes often lack a coherent organizational structure, which limits the construction of more comprehensive and cohesive knowledge representations. To address this, we propose PAGER, a page-driven autonomous knowledge representation framework for RAG. PAGER first prompts an LLM to construct a structured cognitive outline for a given question, which consists of multiple slots representing a distinct knowledge aspect. Then, PAGER iteratively retrieves and refines relevant documents to populate each slot, ultimately constructing a coherent page that serves as contextual input for guiding answer generation. Experiments on multiple knowledge-intensive benchmarks and backbone models show that PAGER consistently outperforms all RAG baselines. Further analyses demonstrate that PAGER constructs higher-quality and information-dense knowledge representations, better mitigates knowledge conflicts, and enables LLMs to leverage external knowledge more effectively. All code is available at https://github.com/OpenBMB/PAGER.",
    "title_zh": "通过上下文页面进行结构化知识表示以实现检索增强生成",
    "abstract_zh": "检索增强生成（Retrieval-Augmented Generation, RAG）通过引入外部知识来提升大型语言模型（LLMs）的能力。近期一些研究将迭代式知识积累过程融入RAG模型中，以逐步累积并优化与查询相关的知识，从而构建更为全面的知识表征。然而，这些迭代过程往往缺乏连贯的组织结构，限制了更全面、更一致的知识表征的构建。为解决这一问题，我们提出PAGER——一种面向RAG的页式驱动自主知识表征框架。PAGER首先引导大语言模型为给定问题构建一个结构化的认知大纲，该大纲包含多个代表不同知识维度的槽位。随后，PAGER通过迭代检索和精炼相关文档，逐个填充每个槽位，最终形成一个逻辑连贯的“知识页”，作为指导答案生成的上下文输入。在多个知识密集型基准测试及多种主干模型上的实验表明，PAGER始终优于所有现有的RAG基线方法。进一步分析显示，PAGER能够构建质量更高、信息密度更大的知识表征，有效缓解知识冲突，并使大语言模型更高效地利用外部知识。所有代码已公开，地址为：https://github.com/OpenBMB/PAGER。"
  },
  {
    "date": "2026-01-14",
    "title": "Ability Transfer and Recovery via Modularized Parameters Localization",
    "authors": "Songyao Jin, Kun Zhou, Wenqi Li, Peng Wang, Biwei Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09398v1",
    "source": "arXiv",
    "abstract": "Large language models can be continually pre-trained or fine-tuned to improve performance in specific domains, languages, or skills, but this specialization often degrades other capabilities and may cause catastrophic forgetting. We investigate how abilities are distributed within LLM parameters by analyzing module activations under domain- and language-specific inputs for closely related models. Across layers and modules, we find that ability-related activations are highly concentrated in a small set of channels (typically <5\\%), and these channels are largely disentangled with good sufficiency and stability. Building on these observations, we propose ACT (Activation-Guided Channel-wise Ability Transfer), which localizes ability-relevant channels via activation differences and selectively transfers only the corresponding parameters, followed by lightweight fine-tuning for compatibility. Experiments on multilingual mathematical and scientific reasoning show that ACT can recover forgotten abilities while preserving retained skills. It can also merge multiple specialized models to integrate several abilities into a single model with minimal interference. Our code and data will be publicly released.",
    "title_zh": "通过模块化参数定位实现能力迁移与恢复",
    "abstract_zh": "大型语言模型可以通过持续预训练或微调来提升特定领域、语言或技能的表现，但这种专业化往往会导致其他能力的退化，并可能引发灾难性遗忘。我们通过分析在特定领域和语言输入下，一系列密切相关模型的模块激活情况，研究了能力在大模型参数中的分布特征。结果发现，在不同层和模块中，与能力相关的激活信号高度集中于一小部分通道（通常少于5%），且这些通道具有良好的解耦性、充分性和稳定性。基于这一发现，我们提出了ACT（激活引导的通道级能力迁移）方法：通过激活差异定位与能力相关的关键通道，仅选择性地迁移对应参数，并辅以轻量级微调以确保兼容性。在多语言数学与科学推理任务上的实验表明，ACT能够在恢复被遗忘能力的同时，保持原有技能不受影响。此外，该方法还可将多个专业化模型融合，将多种能力整合到单一模型中，且干扰极小。我们的代码与数据将公开发布。"
  },
  {
    "date": "2026-01-14",
    "title": "Formally Verifying Noir Zero Knowledge Programs with NAVe",
    "authors": "Pedro Antonino, Namrata Jain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09372v1",
    "source": "arXiv",
    "abstract": "Zero-Knowledge (ZK) proof systems are cryptographic protocols that can (with overwhelming probability) demonstrate that the pair $(X, W)$ is in a relation $R$ without revealing information about the private input $W$. This membership checking is captured by a complex arithmetic circuit: a set of polynomial equations over a finite field. ZK programming languages, like Noir, have been proposed to simplify the description of these circuits. A developer can write a Noir program using traditional high-level constructs that can be compiled into a lower-level ACIR (Abstract Circuit Intermediate Representation), which is essentially a high-level description of an arithmetic circuit. In this paper, we formalise some of the ACIR language using SMT-LIB and its extended theory of finite fields. We use this formalisation to create an open-source formal verifier for the Noir language using the SMT solver cvc5. Our verifier can be used to check whether Noir programs behave appropriately. For instance, it can be used to check whether a Noir program has been properly constrained, that is, the finite-field polynomial equations generated truly capture the intended relation. We evaluate our verifier over 4 distinct sets of Noir programs, demonstrating its practical applicability and identifying a hard-to-check constraint type that charts an improvement path for our verification framework.",
    "title_zh": "使用 NAVe 正式验证 Noir 零知识程序",
    "abstract_zh": "零知识（ZK）证明系统是一类密码学协议，能够在极大概率下证明某对 $(X, W)$ 属于某个关系 $R$，而无需泄露关于私有输入 $W$ 的任何信息。这种成员资格的验证通过一个复杂的算术电路来实现：即在有限域上的一组多项式方程。为简化此类电路的描述，已提出诸如 Noir 等 ZK 编程语言。开发者可以使用传统高级编程结构编写 Noir 程序，这些程序随后可被编译为低层级的 ACIR（抽象电路中间表示），ACIR 本质上是对算术电路的一种高层级描述。\n\n在本文中，我们利用 SMT-LIB 及其扩展的有限域理论，对 ACIR 语言的部分内容进行了形式化。基于这一形式化，我们构建了一个开源的 Noir 语言形式化验证器，该验证器基于 SMT 求解器 cvc5 实现。我们的验证器可用于检查 Noir 程序的行为是否符合预期。例如，它可以验证一个 Noir 程序是否得到了正确约束，即所生成的有限域多项式方程是否真实地捕捉了预期的关系。我们在四组不同的 Noir 程序上评估了该验证器，展示了其实际应用价值，并识别出一种难以检测的约束类型，这为未来验证框架的改进指明了方向。"
  },
  {
    "date": "2026-01-14",
    "title": "Cluster Workload Allocation: Semantic Soft Affinity Using Natural Language Processing",
    "authors": "Leszek Sliwko, Jolanta Mizeria-Pietraszko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09282v1",
    "source": "arXiv",
    "abstract": "Cluster workload allocation often requires complex configurations, creating a usability gap. This paper introduces a semantic, intent-driven scheduling paradigm for cluster systems using Natural Language Processing. The system employs a Large Language Model (LLM) integrated via a Kubernetes scheduler extender to interpret natural language allocation hint annotations for soft affinity preferences. A prototype featuring a cluster state cache and an intent analyzer (using AWS Bedrock) was developed. Empirical evaluation demonstrated high LLM parsing accuracy (>95% Subset Accuracy on an evaluation ground-truth dataset) for top-tier models like Amazon Nova Pro/Premier and Mistral Pixtral Large, significantly outperforming a baseline engine. Scheduling quality tests across six scenarios showed the prototype achieved superior or equivalent placement compared to standard Kubernetes configurations, particularly excelling in complex and quantitative scenarios and handling conflicting soft preferences. The results validate using LLMs for accessible scheduling but highlight limitations like synchronous LLM latency, suggesting asynchronous processing for production readiness. This work confirms the viability of semantic soft affinity for simplifying workload orchestration.",
    "title_zh": "集群工作负载分配：基于自然语言处理的语义软亲和性",
    "abstract_zh": "集群工作负载分配通常需要复杂的配置，导致用户体验上的差距。本文提出了一种基于自然语言处理（NLP）的语义化、意图驱动的集群调度范式。该系统通过集成大型语言模型（LLM）的Kubernetes调度扩展器，解析自然语言形式的工作负载分配提示注解，以表达软亲和性偏好。研究团队开发了一个原型系统，包含集群状态缓存和使用AWS Bedrock实现的意图分析器。实证评估表明，顶级模型如Amazon Nova Pro/Premier和Mistral Pixtral Large在评估基准数据集上实现了超过95%的子集准确率，显著优于基线引擎。在六个不同场景下的调度质量测试中，该原型系统在工作负载部署效果上达到或超越标准Kubernetes配置，尤其在复杂且涉及量化需求的场景中表现优异，并能有效处理冲突的软偏好。实验结果验证了利用LLM实现更易用调度的可行性，但也揭示了同步LLM延迟等局限性，建议采用异步处理以提升生产环境的可用性。本研究证实了语义化软亲和性在简化工作负载编排方面的有效性。"
  },
  {
    "date": "2026-01-14",
    "title": "Efficient Paths and Dense Rewards: Probabilistic Flow Reasoning for Large Language Models",
    "authors": "Yan Liu, Feng Zhang, Zhanyu Ma, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He, Han Liu, Yangdong Deng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09260v1",
    "source": "arXiv",
    "abstract": "High-quality chain-of-thought has demonstrated strong potential for unlocking the reasoning capabilities of large language models. However, current paradigms typically treat the reasoning process as an indivisible sequence, lacking an intrinsic mechanism to quantify step-wise information gain. This granularity gap manifests in two limitations: inference inefficiency from redundant exploration without explicit guidance, and optimization difficulty due to sparse outcome supervision or costly external verifiers. In this work, we propose CoT-Flow, a framework that reconceptualizes discrete reasoning steps as a continuous probabilistic flow, quantifying the contribution of each step toward the ground-truth answer. Built on this formulation, CoT-Flow enables two complementary methodologies: flow-guided decoding, which employs a greedy flow-based decoding strategy to extract information-efficient reasoning paths, and flow-based reinforcement learning, which constructs a verifier-free dense reward function. Experiments on challenging benchmarks demonstrate that CoT-Flow achieves a superior balance between inference efficiency and reasoning performance.",
    "title_zh": "高效路径与密集奖励：面向大语言模型的概率流推理",
    "abstract_zh": "高质量的思维链（Chain-of-Thought, CoT）已展现出解锁大语言模型推理能力的巨大潜力。然而，当前范式通常将推理过程视为一个不可分割的序列，缺乏内在机制来量化每一步的信息增益。这种粒度上的差距带来了两个主要局限：一是由于缺乏明确引导而导致冗余探索，造成推理效率低下；二是由于结果监督信号稀疏或依赖昂贵的外部验证器，使得优化困难。在本工作中，我们提出 CoT-Flow，一种将离散推理步骤重新构想为连续概率流的框架，能够量化每一步对最终正确答案的贡献。基于这一新范式，CoT-Flow 实现了两种互补的方法：**流引导解码**（flow-guided decoding），采用基于流的贪心解码策略，提取信息高效的推理路径；以及**基于流的强化学习**（flow-based reinforcement learning），构建无需验证器的密集奖励函数。在多个具有挑战性的基准测试中，实验结果表明，CoT-Flow 在推理效率与推理性能之间实现了更优的平衡。"
  },
  {
    "date": "2026-01-14",
    "title": "How well LLM-based test generation techniques perform with newer LLM versions?",
    "authors": "Michael Konstantinou, Renzo Degiovanni, Mike Papadakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09695v1",
    "source": "arXiv",
    "abstract": "The rapid evolution of Large Language Models (LLMs) has strongly impacted software engineering, leading to a growing number of studies on automated unit test generation. However, the standalone use of LLMs without post-processing has proven insufficient, often producing tests that fail to compile or achieve high coverage. Several techniques have been proposed to address these issues, reporting improvements in test compilation and coverage. While important, LLM-based test generation techniques have been evaluated against relatively weak baselines (for todays' standards), i.e., old LLM versions and relatively weak prompts, which may exacerbate the performance contribution of the approaches. In other words, stronger (newer) LLMs may obviate any advantage these techniques bring. We investigate this issue by replicating four state-of-the-art LLM-based test generation tools, HITS, SymPrompt, TestSpark, and CoverUp that include engineering components aimed at guiding the test generation process through compilation and execution feedback, and evaluate their relative effectiveness and efficiency over a plain LLM test generation method. We integrate current LLM versions in all approaches and run an experiment on 393 classes and 3,657 methods. Our results show that the plain LLM approach can outperform previous state-of-the-art approaches in all test effectiveness metrics we used: line coverage (by 17.72%), branch coverage (by 19.80%) and mutation score (by 20.92%), and it does so at a comparable cost (LLM queries). We also observe that the granularity at which the plain LLM is applied has a significant impact on the cost. We therefore propose targeting first the program classes, where test generation is more efficient, and then the uncovered methods to reduce the number of LLM requests. This strategy achieves comparable (slightly higher) effectiveness while requiring about 20% fewer LLM requests.",
    "title_zh": "基于大语言模型（LLM）的测试生成技术在较新版本的LLM上表现如何？",
    "abstract_zh": "大型语言模型（LLMs）的快速发展对软件工程产生了深远影响，推动了自动化单元测试生成研究的迅速增长。然而，仅依赖LLM而缺乏后处理的方法已被证明效果不足，常常生成无法编译或覆盖率较低的测试用例。为此，已有多种技术被提出以解决这些问题，并报告了在测试可编译性和覆盖率方面的改进。尽管如此，基于LLM的测试生成方法在评估时所采用的基线相对较弱（以当今的标准来看），即使用的是较旧版本的LLM和较弱的提示词（prompts），这可能夸大了这些方法的实际性能贡献。换句话说，更强（更新）的LLM可能已经消除了这些技术带来的任何优势。\n\n为探究这一问题，我们复现了四项最先进的基于LLM的测试生成工具：HITS、SymPrompt、TestSpark 和 CoverUp。这些工具均包含工程化组件，旨在通过编译和执行反馈来引导测试生成过程。我们评估了它们相对于纯LLM测试生成方法在有效性与效率方面的相对表现。所有方法均集成了当前最新的LLM版本，并在393个类和3,657个方法上进行了实验。结果表明，纯LLM方法在我们所使用的各项测试有效性指标上均优于以往的最先进方法：行覆盖率提升17.72%，分支覆盖率提升19.80%，突变评分（mutation score）提升20.92%，且所需LLM查询次数相当。\n\n此外，我们还发现，纯LLM方法的应用粒度对其成本有显著影响。因此，我们提出一种优化策略：优先针对程序类（class）进行测试生成，因为该阶段效率更高；随后再对未覆盖的方法进行补充生成，从而减少LLM请求次数。该策略在保持相近（甚至略高）的有效性的同时，使LLM请求量减少了约20%。"
  },
  {
    "date": "2026-01-14",
    "title": "Routing with Generated Data: Annotation-Free LLM Skill Estimation and Expert Selection",
    "authors": "Tianyi Niu, Justin Chih-Yao Chen, Genta Indra Winata, Shi-Xiong Zhang, Supriyo Chakraborty, Sambit Sahu, Yue Zhang, Elias Stengel-Eskin, Mohit Bansal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09692v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM) routers dynamically select optimal models for given inputs. Existing approaches typically assume access to ground-truth labeled data, which is often unavailable in practice, especially when user request distributions are heterogeneous and unknown. We introduce Routing with Generated Data (RGD), a challenging setting in which routers are trained exclusively on generated queries and answers produced from high-level task descriptions by generator LLMs. We evaluate query-answer routers (using both queries and labels) and query-only routers across four diverse benchmarks and 12 models, finding that query-answer routers degrade faster than query-only routers as generator quality decreases. Our analysis reveals two crucial characteristics of effective generators: they must accurately respond to their own questions, and their questions must produce sufficient performance differentiation among the model pool. We then show how filtering for these characteristics can improve the quality of generated data. We further propose CASCAL, a novel query-only router that estimates model correctness through consensus voting and identifies model-specific skill niches via hierarchical clustering. CASCAL is substantially more robust to generator quality, outperforming the best query-answer router by 4.6% absolute accuracy when trained on weak generator data.",
    "title_zh": "基于生成数据的路由：无标注的大型语言模型技能评估与专家选择",
    "abstract_zh": "大型语言模型（LLM）路由器能够根据输入动态选择最优模型。现有方法通常假设可以访问真实标签数据，但在实际应用中，这一条件往往难以满足，尤其是在用户请求分布异构且未知的情况下。我们提出了“生成数据路由”（Routing with Generated Data, RGD）这一具有挑战性的设定：路由器仅通过生成式LLM基于高层次任务描述生成的查询与答案进行训练。我们在四个不同的基准测试和12个模型上评估了使用查询和标签的路由器以及仅使用查询的路由器，发现随着生成器质量下降，使用查询和标签的路由器性能退化速度远快于仅使用查询的路由器。我们的分析揭示了高效生成器的两个关键特征：一是生成器必须准确回答自身提出的问题，二是其生成的问题必须能够在模型池中产生足够的性能差异。随后，我们展示了如何通过筛选这些特征来提升生成数据的质量。此外，我们提出了CASCAL——一种新型的仅使用查询的路由器，它通过共识投票机制估计模型正确性，并利用层次聚类识别模型特有的技能领域。CASCAL在生成器质量较弱的情况下表现出显著更强的鲁棒性，在弱生成数据上训练时，其绝对准确率比表现最佳的查询-标签路由器高出4.6%。"
  },
  {
    "date": "2026-01-14",
    "title": "SysPro: Reproducing System-level Concurrency Bugs from Bug Reports",
    "authors": "Tarannum Shaila Zaman, Zhihui Yan, Chen Wang, Chadni Islam, Jiangfan Shi, Tingting Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09616v1",
    "source": "arXiv",
    "abstract": "Reproducing system-level concurrency bugs requires both input data and the precise interleaving order of system calls. This process is challenging because such bugs are non-deterministic, and bug reports often lack the detailed information needed. Additionally, the unstructured nature of reports written in natural language makes it difficult to extract necessary details. Existing tools are inadequate to reproduce these bugs due to their inability to manage the specific interleaving at the system call level. To address these challenges, we propose SysPro, a novel approach that automatically extracts relevant system call names from bug reports and identifies their locations in the source code. It generates input data by utilizing information retrieval, regular expression matching, and the category-partition method. This extracted input and interleaving data are then used to reproduce bugs through dynamic source code instrumentation. Our empirical study on real-world benchmarks demonstrates that SysPro is both effective and efficient at localizing and reproducing system-level concurrency bugs from bug reports.",
    "title_zh": "SysPro：从漏洞报告中复现系统级并发错误",
    "abstract_zh": "重现系统级并发错误需要同时具备输入数据和系统调用的精确交错顺序。这一过程具有挑战性，因为这类错误具有非确定性特征，而错误报告通常缺乏必要的详细信息。此外，以自然语言撰写的报告结构松散，难以从中提取关键细节。现有工具由于无法在系统调用层面有效管理特定的交错顺序，因此难以重现这些错误。为应对上述挑战，我们提出了一种名为SysPro的新方法：该方法可自动从错误报告中提取相关的系统调用名称，并定位其在源代码中的位置；通过信息检索、正则表达式匹配以及分类-划分法生成输入数据；随后利用提取出的输入数据和交错信息，借助动态源代码插桩技术重现错误。我们在真实世界基准测试上的实证研究表明，SysPro能够高效且准确地从错误报告中定位并重现系统级并发错误。"
  },
  {
    "date": "2026-01-14",
    "title": "A.X K1 Technical Report",
    "authors": "Sung Jun Cheon, Jaekyung Cho, Seongho Choi, Hyunjun Eun, Seokhwan Jo, Jaehyun Jun, Minsoo Kang, Jin Kim, Jiwon Kim, Minsang Kim, Sungwan Kim, Seungsik Kim, Tae Yoon Kim, Youngrang Kim, Hyeongmun Lee, Sangyeol Lee, Sungeun Lee, Youngsoon Lee, Yujin Lee, Seongmin Ok, Chanyong Park, Hyewoong Park, Junyoung Park, Hyunho Yang, Subin Yi, Soohyun Bae, Dhammiko Arya, Yongseok Choi, Sangho Choi, Dongyeon Cho, Seungmo Cho, Gyoungeun Han, Yong-jin Han, Seokyoung Hong, Hyeon Hwang, Wonbeom Jang, Minjeong Ju, Wonjin Jung, Keummin Ka, Sungil Kang, Dongnam Kim, Joonghoon Kim, Jonghwi Kim, SaeRom Kim, Sangjin Kim, Seongwon Kim, Youngjin Kim, Seojin Lee, Sunwoo Lee, Taehoon Lee, Chanwoo Park, Sohee Park, Sooyeon Park, Yohan Ra, Sereimony Sek, Seungyeon Seo, Gun Song, Sanghoon Woo, Janghan Yoon, Sungbin Yoon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09200v1",
    "source": "arXiv",
    "abstract": "We introduce A.X K1, a 519B-parameter Mixture-of-Experts (MoE) language model trained from scratch. Our design leverages scaling laws to optimize training configurations and vocabulary size under fixed computational budgets. A.X K1 is pre-trained on a corpus of approximately 10T tokens, curated by a multi-stage data processing pipeline. Designed to bridge the gap between reasoning capability and inference efficiency, A.X K1 supports explicitly controllable reasoning to facilitate scalable deployment across diverse real-world scenarios. We propose a simple yet effective Think-Fusion training recipe, enabling user-controlled switching between thinking and non-thinking modes within a single unified model. Extensive evaluations demonstrate that A.X K1 achieves performance competitive with leading open-source models, while establishing a distinctive advantage in Korean-language benchmarks.",
    "title_zh": "A.X K1 技术报告",
    "abstract_zh": "我们推出了A.X K1，这是一个从零开始训练的5190亿参数混合专家（MoE）语言模型。我们的设计利用缩放定律，在固定计算预算下优化了训练配置和词表规模。A.X K1在约10万亿个标记的语料库上进行预训练，该语料库通过多阶段数据处理流程精心筛选。为弥合理论推理能力与推理效率之间的差距，A.X K1支持可显式控制的推理机制，从而实现跨多样化现实场景的可扩展部署。我们提出了一种简单而高效的“Think-Fusion”训练方法，使用户能够在单一统一模型中灵活切换思考模式与非思考模式。大量实验证明，A.X K1在性能上达到领先开源模型的水平，同时在韩语相关基准测试中展现出显著优势。"
  },
  {
    "date": "2026-01-14",
    "title": "Hidden States as Early Signals: Step-level Trace Evaluation and Pruning for Efficient Test-Time Scaling",
    "authors": "Zhixiang Liang, Beichen Huang, Zheng Wang, Minjia Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09093v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) can enhance reasoning capabilities through test-time scaling by generating multiple traces. However, the combination of lengthy reasoning traces with multiple sampling introduces substantial computation and high end-to-end latency. Prior work on accelerating this process has relied on similarity-based or confidence-based pruning, but these signals do not reliably indicate trace quality. To address these limitations, we propose STEP: Step-level Trace Evaluation and Pruning, a novel pruning framework that evaluates reasoning steps using hidden states and dynamically prunes unpromising traces during generation. We train a lightweight step scorer to estimate trace quality, and design a GPU memory-aware pruning strategy that triggers pruning as the GPU memory is saturated by KV cache to reduce end-to-end latency. Experiments across challenging reasoning benchmarks demonstrate that STEP reduces end-to-end inference latency by 45%-70% on average compared to self-consistency while also improving reasoning accuracy. Our code is released at: https://github.com/Supercomputing-System-AI-Lab/STEP",
    "title_zh": "隐藏状态作为早期信号：用于高效测试时扩展的逐步追踪评估与剪枝",
    "abstract_zh": "大型语言模型（LLMs）可以通过在测试时进行扩展，生成多个推理轨迹来增强其推理能力。然而，冗长的推理轨迹与多次采样相结合，带来了巨大的计算开销和较高的端到端延迟。以往加速该过程的工作依赖于基于相似性或置信度的剪枝策略，但这些信号并不能可靠地反映轨迹质量。为解决上述局限性，我们提出了STEP：**步骤级轨迹评估与剪枝**（Step-level Trace Evaluation and Pruning），一种新颖的剪枝框架。该框架利用隐藏状态对推理步骤进行评估，并在生成过程中动态剪除前景不佳的轨迹。我们训练了一个轻量级的步骤评分器以估计轨迹质量，并设计了一种考虑GPU内存使用的剪枝策略——当KV缓存占用导致GPU内存饱和时触发剪枝，从而有效降低端到端延迟。在多个具有挑战性的推理基准上的实验表明，与自一致性方法相比，STEP平均可将端到端推理延迟降低45%至70%，同时提升推理准确性。我们的代码已开源：https://github.com/Supercomputing-System-AI-Lab/STEP"
  },
  {
    "date": "2026-01-14",
    "title": "A Decompilation-Driven Framework for Malware Detection with Large Language Models",
    "authors": "Aniesh Chawla, Udbhav Prasad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09035v1",
    "source": "arXiv",
    "abstract": "The parallel evolution of Large Language Models (LLMs) with advanced code-understanding capabilities and the increasing sophistication of malware presents a new frontier for cybersecurity research. This paper evaluates the efficacy of state-of-the-art LLMs in classifying executable code as either benign or malicious. We introduce an automated pipeline that first decompiles Windows executable into a C code using Ghidra disassembler and then leverages LLMs to perform the classification. Our evaluation reveals that while standard LLMs show promise, they are not yet robust enough to replace traditional anti-virus software. We demonstrate that a fine-tuned model, trained on curated malware and benign datasets, significantly outperforms its vanilla counterpart. However, the performance of even this specialized model degrades notably when encountering newer malware. This finding demonstrates the critical need for continuous fine-tuning with emerging threats to maintain model effectiveness against the changing coding patterns and behaviors of malicious software.",
    "title_zh": "基于反编译的大型语言模型恶意软件检测框架",
    "abstract_zh": "大型语言模型（LLMs）在代码理解能力方面的快速发展，与恶意软件日益复杂化趋势并行演进，为网络安全研究开辟了新的前沿领域。本文评估了当前最先进的LLMs在将可执行代码分类为良性或恶意方面的有效性。我们提出了一种自动化流程：首先使用Ghidra反汇编器将Windows可执行文件反编译为C语言代码，随后利用LLMs完成分类任务。评估结果表明，尽管标准LLMs展现出一定潜力，但其鲁棒性尚不足以替代传统的杀毒软件。我们进一步证明，经过精心筛选的恶意软件和良性样本数据集微调后的模型，显著优于未经微调的原始模型。然而，即使该专用模型在面对新型恶意软件时，性能也出现明显下降。这一发现凸显了必须持续对模型进行针对新兴威胁的微调，以保持其对恶意软件不断变化的编码模式和行为的有效识别能力。"
  },
  {
    "date": "2026-01-14",
    "title": "SC-MAS: Constructing Cost-Efficient Multi-Agent Systems with Edge-Level Heterogeneous Collaboration",
    "authors": "Di Zhao, Longhui Ma, Siwei Wang, Miao Wang, Yi Kong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09434v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM)-based Multi-Agent Systems (MAS) enhance complex problem solving through multi-agent collaboration, but often incur substantially higher costs than single-agent systems. Recent MAS routing methods aim to balance performance and overhead by dynamically selecting agent roles and language models. However, these approaches typically rely on a homogeneous collaboration mode, where all agents follow the same interaction pattern, limiting collaboration flexibility across different roles. Motivated by Social Capital Theory, which emphasizes that different roles benefit from distinct forms of collaboration, we propose SC-MAS, a framework for constructing heterogeneous and cost-efficient multi-agent systems. SC-MAS models MAS as directed graphs, where edges explicitly represent pairwise collaboration strategies, allowing different agent pairs to interact through tailored communication patterns. Given an input query, a unified controller progressively constructs an executable MAS by selecting task-relevant agent roles, assigning edge-level collaboration strategies, and allocating appropriate LLM backbones to individual agents. Experiments on multiple benchmarks demonstrate the effectiveness of SC-MAS. In particular, SC-MAS improves accuracy by 3.35% on MMLU while reducing inference cost by 15.38%, and achieves a 3.53% accuracy gain with a 12.13% cost reduction on MBPP. These results validate the feasibility of SC-MAS and highlight the effectiveness of heterogeneous collaboration in multi-agent systems.",
    "title_zh": "SC-MAS：基于边缘级异构协作的低成本多智能体系统构建",
    "abstract_zh": "基于大语言模型（LLM）的多智能体系统（MAS）通过多智能体协作显著提升了复杂问题求解能力，但通常其开销远高于单智能体系统。近年来，一些MAS路由方法试图在性能与开销之间取得平衡，通过动态选择智能体角色和语言模型来实现。然而，这些方法通常依赖于同质化协作模式，即所有智能体遵循相同的交互方式，限制了不同角色间协作的灵活性。受社会资本理论的启发——该理论强调不同角色应从不同的协作形式中获益——我们提出了SC-MAS，一种构建异构且成本高效的多智能体系统的框架。SC-MAS将多智能体系统建模为有向图，其中边显式表示成对的协作策略，使得不同智能体对能够采用量身定制的通信模式进行交互。针对输入查询，一个统一的控制器逐步构建出可执行的MAS：选择与任务相关的智能体角色，分配细粒度的边级协作策略，并为各智能体配置合适的LLM骨干模型。在多个基准测试上的实验结果验证了SC-MAS的有效性。具体而言，SC-MAS在MMLU上将准确率提升3.35%，同时推理成本降低15.38%；在MBPP上实现了3.53%的准确率提升，且成本下降12.13%。这些结果不仅证实了SC-MAS的可行性，也凸显了异构协作在多智能体系统中的有效性。"
  },
  {
    "date": "2026-01-14",
    "title": "Draw it like Euclid: Teaching transformer models to generate CAD profiles using ruler and compass construction steps",
    "authors": "Siyi Li, Joseph G. Lambourne, Longfei Zhang, Pradeep Kumar Jayaraman, Karl. D. D. Willis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09428v1",
    "source": "arXiv",
    "abstract": "We introduce a new method of generating Computer Aided Design (CAD) profiles via a sequence of simple geometric constructions including curve offsetting, rotations and intersections. These sequences start with geometry provided by a designer and build up the points and curves of the final profile step by step. We demonstrate that adding construction steps between the designer's input geometry and the final profile improves generation quality in a similar way to the introduction of a chain of thought in language models. Similar to the constraints in a parametric CAD model, the construction sequences reduce the degrees of freedom in the modeled shape to a small set of parameter values which can be adjusted by the designer, allowing parametric editing with the constructed geometry evaluated to floating point precision. In addition we show that applying reinforcement learning to the construction sequences gives further improvements over a wide range of metrics, including some which were not explicitly optimized.",
    "title_zh": "像欧几里得那样绘制：使用尺规作图步骤教会变换器模型生成CAD轮廓",
    "abstract_zh": "我们提出了一种通过一系列简单的几何构造（包括曲线偏移、旋转和交点）生成计算机辅助设计（CAD）轮廓的新方法。这些构造序列以设计师提供的几何图形为基础，逐步构建最终轮廓的点和曲线。我们证明，在设计师输入的几何图形与最终轮廓之间添加构造步骤，能够显著提升生成质量，其效果类似于语言模型中引入“思维链”（chain of thought）的过程。与参数化CAD模型中的约束类似，这些构造序列将建模形状的自由度减少到一组可由设计师调整的小规模参数值，从而实现基于构造几何的参数化编辑，并以浮点精度评估结果。此外，我们还展示了对构造序列应用强化学习，可在多种指标上进一步提升性能，包括一些并未显式优化的指标。"
  },
  {
    "date": "2026-01-14",
    "title": "AI-NativeBench: An Open-Source White-Box Agentic Benchmark Suite for AI-Native Systems",
    "authors": "Zirui Wang, Guangba Yu, Michael R. Lyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09393v1",
    "source": "arXiv",
    "abstract": "The transition from Cloud-Native to AI-Native architectures is fundamentally reshaping software engineering, replacing deterministic microservices with probabilistic agentic services. However, this shift renders traditional black-box evaluation paradigms insufficient: existing benchmarks measure raw model capabilities while remaining blind to system-level execution dynamics. To bridge this gap, we introduce AI-NativeBench, the first application-centric and white-box AI-Native benchmark suite grounded in Model Context Protocol (MCP) and Agent-to-Agent (A2A) standards. By treating agentic spans as first-class citizens within distributed traces, our methodology enables granular analysis of engineering characteristics beyond simple capabilities. Leveraging this benchmark across 21 system variants, we uncover critical engineering realities invisible to traditional metrics: a parameter paradox where lightweight models often surpass flagships in protocol adherence, a pervasive inference dominance that renders protocol overhead secondary, and an expensive failure pattern where self-healing mechanisms paradoxically act as cost multipliers on unviable workflows. This work provides the first systematic evidence to guide the transition from measuring model capability to engineering reliable AI-Native systems. To facilitate reproducibility and further research, we have open-sourced the benchmark and dataset.",
    "title_zh": "AI-NativeBench：一个开源的白盒智能体基准测试套件，用于AI原生系统",
    "abstract_zh": "从云原生架构向AI原生架构的演进正在从根本上重塑软件工程，将确定性的微服务替换为概率性的智能体服务。然而，这一转变使得传统的黑盒评估范式变得不再充分：现有基准测试仅衡量模型的原始能力，却对系统层面的执行动态视而不见。为弥合这一差距，我们提出了AI-NativeBench——首个以应用为中心、基于白盒设计的AI原生基准测试套件，其建立在模型上下文协议（MCP）与智能体到智能体（A2A）标准之上。通过将智能体调用跨度作为分布式追踪中的第一类公民，我们的方法能够实现对工程特性的细粒度分析，超越简单的性能指标。通过对21种系统变体的应用，我们揭示了传统度量手段无法捕捉的关键工程现实：参数悖论——轻量级模型往往在协议遵循性上超越旗舰模型；普遍存在的推理主导现象，使协议开销退居次要地位；以及一种高成本失败模式，即自我修复机制在不可行工作流中反而成为成本放大器。本研究首次提供了系统性证据，指导我们从单纯衡量模型能力转向构建可靠的AI原生系统。为促进可复现性和后续研究，我们已开源该基准测试工具与数据集。"
  },
  {
    "date": "2026-01-14",
    "title": "RISER: Orchestrating Latent Reasoning Skills for Adaptive Activation Steering",
    "authors": "Wencheng Ye, Liang Peng, Xiaoyang Yuan, Yi Bin, Pengpeng Zeng, Hengyu Jin, Heng Tao Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09269v1",
    "source": "arXiv",
    "abstract": "Recent work on domain-specific reasoning with large language models (LLMs) often relies on training-intensive approaches that require parameter updates. While activation steering has emerged as a parameter efficient alternative, existing methods apply static, manual interventions that fail to adapt to the dynamic nature of complex reasoning. To address this limitation, we propose RISER (Router-based Intervention for Steerable Enhancement of Reasoning), a plug-and-play intervention framework that adaptively steers LLM reasoning in activation space. RISER constructs a library of reusable reasoning vectors and employs a lightweight Router to dynamically compose them for each input. The Router is optimized via reinforcement learning under task-level rewards, activating latent cognitive primitives in an emergent and compositional manner. Across seven diverse benchmarks, RISER yields 3.4-6.5% average zero-shot accuracy improvements over the base model while surpassing CoT-style reasoning with 2-3x higher token efficiency and robust accuracy gains. Further analysis shows that RISER autonomously combines multiple vectors into interpretable, precise control strategies, pointing toward more controllable and efficient LLM reasoning.",
    "title_zh": "RISER：用于自适应激活引导的潜在推理技能编排",
    "abstract_zh": "近期关于大语言模型（LLM）领域特定推理的研究多依赖于需要参数更新的训练密集型方法。尽管激活引导（activation steering）作为一种参数高效的替代方案已崭露头角，但现有方法仍采用静态、手动的干预方式，难以适应复杂推理过程中的动态变化。为解决这一局限性，我们提出RISER（基于路由器的推理可调增强框架），一种即插即用的干预机制，能够在激活空间中自适应地引导LLM的推理过程。RISER构建了一个可复用的推理向量库，并通过一个轻量级路由器动态组合这些向量以应对不同输入。该路由器在任务级奖励信号下通过强化学习进行优化，从而以涌现且组合的方式激活潜在的认知原语。在七个不同的基准测试中，RISER相较于基础模型实现了3.4%至6.5%的平均零样本准确率提升，同时在推理效果上超越传统的思维链（CoT）方法，实现2至3倍更高的token效率和更显著的鲁棒性准确率增益。进一步分析表明，RISER能够自主将多个向量组合成可解释、精准的控制策略，为更可控、更高效的LLM推理指明了方向。"
  },
  {
    "date": "2026-01-14",
    "title": "Relational Hoare Logic for High-Level Synthesis of Hardware Accelerators",
    "authors": "Izumi Tanaka, Ken Sakayori, Shinya Takamaeda-Yamazaki, Naoki Kobayashi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09217v1",
    "source": "arXiv",
    "abstract": "High-level synthesis (HLS) is a powerful tool for developing efficient hardware accelerators that rely on specialized memory systems to achieve sufficient on-chip data reuse and off-chip bandwidth utilization. However, even with HLS, designing such systems still requires careful manual tuning, as automatic optimizations provided by existing tools are highly sensitive to programming style and often lack transparency. To address these issues, we present a formal translation framework based on relational Hoare logic, which enables robust and transparent transformations. Our method recognizes complex memory access patterns in naïve HLS programs and automatically transforms them by inserting on-chip buffers to enforce linear access to off-chip memory, and by replacing non-sequential processing with stream processing, while preserving program semantics. Experiments using our prototype translator, combined with an off-the-shelf HLS compiler and a real FPGA board, have demonstrated significant performance improvements.",
    "title_zh": "用于硬件加速器高层次综合的关系霍尔逻辑",
    "abstract_zh": "高层次综合（HLS）是一种强大的工具，可用于开发高效的硬件加速器，这些加速器依赖于专用的内存系统以实现充分的片上数据重用和片外带宽利用。然而，即便使用HLS，设计此类系统仍需仔细的手动调优，因为现有工具提供的自动优化对编程风格极为敏感，且往往缺乏透明性。为解决这些问题，我们提出了一种基于关系霍尔逻辑的正式转换框架，能够实现稳健且透明的代码变换。我们的方法能够识别原始HLS程序中的复杂内存访问模式，并通过自动插入片上缓冲区，强制实现对片外内存的线性访问；同时将非顺序处理替换为流式处理，从而在保持程序语义不变的前提下完成优化。通过原型翻译器与现成的HLS编译器及实际FPGA开发板相结合的实验，已验证了显著的性能提升。"
  },
  {
    "date": "2026-01-14",
    "title": "STEP3-VL-10B Technical Report",
    "authors": "Ailin Huang, Chengyuan Yao, Chunrui Han, Fanqi Wan, Hangyu Guo, Haoran Lv, Hongyu Zhou, Jia Wang, Jian Zhou, Jianjian Sun, Jingcheng Hu, Kangheng Lin, Liang Zhao, Mitt Huang, Song Yuan, Wenwen Qu, Xiangfeng Wang, Yanlin Lai, Yingxiu Zhao, Yinmin Zhang, Yukang Shi, Yuyang Chen, Zejia Weng, Ziyang Meng, Ang Li, Aobo Kong, Bo Dong, Changyi Wan, David Wang, Di Qi, Dingming Li, En Yu, Guopeng Li, Haiquan Yin, Han Zhou, Hanshan Zhang, Haolong Yan, Hebin Zhou, Hongbo Peng, Jiaran Zhang, Jiashu Lv, Jiayi Fu, Jie Cheng, Jie Zhou, Jisheng Yin, Jingjing Xie, Jingwei Wu, Jun Zhang, Junfeng Liu, Kaijun Tan, Kaiwen Yan, Liangyu Chen, Lina Chen, Mingliang Li, Qian Zhao, Quan Sun, Shaoliang Pang, Shengjie Fan, Shijie Shang, Siyuan Zhang, Tianhao You, Wei Ji, Wuxun Xie, Xiaobo Yang, Xiaojie Hou, Xiaoran Jiao, Xiaoxiao Ren, Xiangwen Kong, Xin Huang, Xin Wu, Xing Chen, Xinran Wang, Xuelin Zhang, Yana Wei, Yang Li, Yanming Xu, Yeqing Shen, Yuang Peng, Yue Peng, Yu Zhou, Yusheng Li, Yuxiang Yang, Yuyang Zhang, Zhe Xie, Zhewei Huang, Zhenyi Lu, Zhimin Fan, Zihui Cheng, Daxin Jiang, Qi Han, Xiangyu Zhang, Yibo Zhu, Zheng Ge",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09668v1",
    "source": "arXiv",
    "abstract": "We present STEP3-VL-10B, a lightweight open-source foundation model designed to redefine the trade-off between compact efficiency and frontier-level multimodal intelligence. STEP3-VL-10B is realized through two strategic shifts: first, a unified, fully unfrozen pre-training strategy on 1.2T multimodal tokens that integrates a language-aligned Perception Encoder with a Qwen3-8B decoder to establish intrinsic vision-language synergy; and second, a scaled post-training pipeline featuring over 1k iterations of reinforcement learning. Crucially, we implement Parallel Coordinated Reasoning (PaCoRe) to scale test-time compute, allocating resources to scalable perceptual reasoning that explores and synthesizes diverse visual hypotheses. Consequently, despite its compact 10B footprint, STEP3-VL-10B rivals or surpasses models 10$\\times$-20$\\times$ larger (e.g., GLM-4.6V-106B, Qwen3-VL-235B) and top-tier proprietary flagships like Gemini 2.5 Pro and Seed-1.5-VL. Delivering best-in-class performance, it records 92.2% on MMBench and 80.11% on MMMU, while excelling in complex reasoning with 94.43% on AIME2025 and 75.95% on MathVision. We release the full model suite to provide the community with a powerful, efficient, and reproducible baseline.",
    "title_zh": "STEP3-VL-10B 技术报告",
    "abstract_zh": "我们提出STEP3-VL-10B，一个轻量级开源基础模型，旨在重新定义紧凑效率与前沿级多模态智能之间的权衡。STEP3-VL-10B通过两项战略转型实现：其一，在1.2万亿多模态标记上采用统一且完全未冻结的预训练策略，将语言对齐的感知编码器与Qwen3-8B解码器相结合，建立内在的视觉-语言协同机制；其二，采用大规模后训练流程，包含超过1000轮强化学习迭代。尤为重要的是，我们引入并行协同推理（PaCoRe）以扩展推理时计算资源，将算力分配给可扩展的感知推理能力，从而探索并综合多种视觉假设。因此，尽管模型规模仅为100亿参数，STEP3-VL-10B在性能上可媲美甚至超越规模大10至20倍的模型（如GLM-4.6V-106B、Qwen3-VL-235B），以及顶级专有旗舰模型如Gemini 2.5 Pro和Seed-1.5-VL。该模型表现出卓越的综合性能，在MMBench上达到92.2%，在MMMU上达到80.11%；在复杂推理任务中表现尤为突出，AIME2025得分达94.43%，MathVision得分为75.95%。我们已完整发布该模型系列，为社区提供一个强大、高效且可复现的基准。"
  },
  {
    "date": "2026-01-14",
    "title": "From Prompt to Protocol: Fast Charging Batteries with Large Language Models",
    "authors": "Ge Lei, Ferran Brosa Planella, Sterling G. Baird, Samuel J. Cooper",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09626v1",
    "source": "arXiv",
    "abstract": "Efficiently optimizing battery charging protocols is challenging because each evaluation is slow, costly, and non-differentiable. Many existing approaches address this difficulty by heavily constraining the protocol search space, which limits the diversity of protocols that can be explored, preventing the discovery of higher-performing solutions. We introduce two gradient-free, LLM-driven closed-loop methods: Prompt-to-Optimizer (P2O), which uses an LLM to propose the code for small neural-network-based protocols, which are then trained by an inner loop, and Prompt-to-Protocol (P2P), which simply writes an explicit function for the current and its scalar parameters. Across our case studies, LLM-guided P2O outperforms neural networks designed by Bayesian optimization, evolutionary algorithms, and random search. In a realistic fast charging scenario, both P2O and P2P yield around a 4.2 percent improvement in state of health (capacity retention based health metric under fast charging cycling) over a state-of-the-art multi-step constant current (CC) baseline, with P2P achieving this under matched evaluation budgets (same number of protocol evaluations). These results demonstrate that LLMs can expand the space of protocol functional forms, incorporate language-based constraints, and enable efficient optimization in high cost experimental settings.",
    "title_zh": "从提示到协议：利用大语言模型实现快速充电电池",
    "abstract_zh": "高效优化电池充电协议极具挑战性，因为每次评估都耗时、成本高且不可微分。许多现有方法通过大幅限制协议搜索空间来应对这一难题，但这又限制了可探索协议的多样性，阻碍了更优解决方案的发现。我们提出了两种无需梯度、由大语言模型（LLM）驱动的闭环方法：Prompt-to-Optimizer（P2O），利用LLM生成基于小型神经网络的充电协议代码，随后由内层循环进行训练；以及Prompt-to-Protocol（P2P），直接编写出电流及其标量参数的显式函数形式。在多个案例研究中，LLM引导的P2O在性能上超越了通过贝叶斯优化、进化算法和随机搜索设计的神经网络。在真实的快速充电场景下，P2O和P2P均相较于最先进的多段恒流（CC）基准方案，在快充循环下的健康状态（以容量保持率衡量）方面实现了约4.2%的提升，且P2P在相同评估预算（即相同的协议评估次数）下达成此效果。这些结果表明，LLM能够拓展协议函数形式的探索空间，融入基于语言的约束条件，并在高成本实验环境中实现高效的优化。"
  },
  {
    "date": "2026-01-14",
    "title": "The Promptware Kill Chain: How Prompt Injections Gradually Evolved Into a Multi-Step Malware",
    "authors": "Ben Nassi, Bruce Schneier, Oleg Brodt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09625v1",
    "source": "arXiv",
    "abstract": "The rapid adoption of large language model (LLM)-based systems -- from chatbots to autonomous agents capable of executing code and financial transactions -- has created a new attack surface that existing security frameworks inadequately address. The dominant framing of these threats as \"prompt injection\" -- a catch-all phrase for security failures in LLM-based systems -- obscures a more complex reality: Attacks on LLM-based systems increasingly involve multi-step sequences that mirror traditional malware campaigns. In this paper, we propose that attacks targeting LLM-based applications constitute a distinct class of malware, which we term \\textit{promptware}, and introduce a five-step kill chain model for analyzing these threats. The framework comprises Initial Access (prompt injection), Privilege Escalation (jailbreaking), Persistence (memory and retrieval poisoning), Lateral Movement (cross-system and cross-user propagation), and Actions on Objective (ranging from data exfiltration to unauthorized transactions). By mapping recent attacks to this structure, we demonstrate that LLM-related attacks follow systematic sequences analogous to traditional malware campaigns. The promptware kill chain offers security practitioners a structured methodology for threat modeling and provides a common vocabulary for researchers across AI safety and cybersecurity to address a rapidly evolving threat landscape.",
    "title_zh": "提示词武器化链条：提示注入如何逐步演变为多步骤恶意软件",
    "abstract_zh": "基于大型语言模型（LLM）的系统——从聊天机器人到能够执行代码和金融交易的自主代理——的快速普及，催生了一个新的攻击面，而现有的安全框架对此类威胁应对不足。目前将这些威胁统称为“提示注入”（prompt injection）的做法，实际上掩盖了更为复杂的现实：针对LLM系统的攻击正日益演变为多步骤序列，其模式与传统恶意软件攻击活动高度相似。本文提出，针对LLM应用的攻击应被视为一类独特的恶意软件，我们将其命名为**提示软件**（promptware），并引入一个五步杀伤链模型以分析此类威胁。该框架包括：初始访问（提示注入）、权限提升（越狱）、持久化（内存与检索污染）、横向移动（跨系统与跨用户传播），以及目标行动（从数据窃取到未经授权的交易等）。通过将近期攻击事件映射到这一结构，我们证明了LLM相关攻击遵循系统性流程，与传统恶意软件攻击如出一辙。该提示软件杀伤链为安全从业者提供了一套结构化的威胁建模方法，并为人工智能安全与网络安全领域的研究者们构建了一个共同的语言体系，以应对不断演变的威胁环境。"
  },
  {
    "date": "2026-01-14",
    "title": "MLIR-Forge: A Modular Framework for Language Smiths",
    "authors": "Berke Ates, Philipp Schaad, Timo Schneider, Alexandru Calotoiu, Torsten Hoefler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09583v1",
    "source": "arXiv",
    "abstract": "Optimizing compilers are essential for the efficient and correct execution of software across various scientific fields. Domain-specific languages (DSL) typically use higher level intermediate representations (IR) in their compiler pipelines for domain-specific optimizations. As these IRs add to complexity, it is crucial to test them thoroughly. Random program generators have proven to be an effective tool to test compilers through differential and fuzz testing. However, developing specialized program generators for compiler IRs is not straightforward and demands considerable resources. We introduce MLIR-Forge, a novel random program generator framework that leverages the flexibility of MLIR, aiming to simplify the creation of specialized program generators. MLIR-Forge achieves this by splitting the generation process into fundamental building blocks that are language specific, and reusable program creation logic that constructs random programs from these building blocks. This hides complexity and furthermore, even the language specific components can be defined using a set of common tools. We demonstrate MLIR-Forge's capabilities by generating MLIR with built-in dialects, WebAssembly, and a data-centric program representation, DaCe -- requiring less than a week of development time in total for each of them. Using the generated programs we conduct differential testing and find 9 MLIR, 15 WebAssembly, and 774 DaCe groups of bugs with the corresponding program generators, after running them until the rate of new bugs stagnates.",
    "title_zh": "MLIR-Forge：面向语言设计者的模块化框架",
    "abstract_zh": "优化编译器对于在各个科学领域中高效且正确地执行软件至关重要。领域特定语言（DSL）通常在其编译器流水线中使用更高级别的中间表示（IR），以实现针对特定领域的优化。然而，这些中间表示增加了系统的复杂性，因此对其进行全面测试显得尤为关键。随机程序生成器已被证明是通过差分测试和模糊测试来检验编译器的有效工具。但为编译器中间表示开发专用的程序生成器并不容易，且需要大量资源投入。我们提出了 MLIR-Forge——一种新颖的随机程序生成框架，该框架利用 MLIR 的灵活性，旨在简化专用生成器的创建过程。MLIR-Forge 通过将生成过程分解为语言相关的基础构建模块，以及可复用的程序生成逻辑，从而实现从这些构建模块构造随机程序的目标。这一设计隐藏了复杂性，而且即便是语言相关的组件，也可通过一组通用工具进行定义。我们通过生成具有内置方言的 MLIR、WebAssembly 以及面向数据的程序表示 DaCe，展示了 MLIR-Forge 的强大能力，每种生成器的开发总时间均不足一周。利用生成的程序进行差分测试后，我们发现了 9 个 MLIR、15 个 WebAssembly 和 774 个 DaCe 的 bug 组，这些结果是在持续运行直至新 bug 出现率趋于稳定时获得的。"
  },
  {
    "date": "2026-01-14",
    "title": "EvoFSM: Controllable Self-Evolution for Deep Research with Finite State Machines",
    "authors": "Shuo Zhang, Chaofa Yuan, Ryan Guo, Xiaomin Yu, Rui Xu, Zhangquan Chen, Zinuo Li, Zhi Yang, Shuhao Guan, Zhenheng Tang, Sen Hu, Liwen Zhang, Ronghao Chen, Huacan Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09465v1",
    "source": "arXiv",
    "abstract": "While LLM-based agents have shown promise for deep research, most existing approaches rely on fixed workflows that struggle to adapt to real-world, open-ended queries. Recent work therefore explores self-evolution by allowing agents to rewrite their own code or prompts to improve problem-solving ability, but unconstrained optimization often triggers instability, hallucinations, and instruction drift. We propose EvoFSM, a structured self-evolving framework that achieves both adaptability and control by evolving an explicit Finite State Machine (FSM) instead of relying on free-form rewriting. EvoFSM decouples the optimization space into macroscopic Flow (state-transition logic) and microscopic Skill (state-specific behaviors), enabling targeted improvements under clear behavioral boundaries. Guided by a critic mechanism, EvoFSM refines the FSM through a small set of constrained operations, and further incorporates a self-evolving memory that distills successful trajectories as reusable priors and failure patterns as constraints for future queries. Extensive evaluations on five multi-hop QA benchmarks demonstrate the effectiveness of EvoFSM. In particular, EvoFSM reaches 58.0% accuracy on the DeepSearch benchmark. Additional results on interactive decision-making tasks further validate its generalization.",
    "title_zh": "EvoFSM：基于有限状态机的可控制自进化深度研究",
    "abstract_zh": "尽管基于大语言模型（LLM）的智能体在深度研究任务中展现出巨大潜力，但现有方法大多依赖于固定的流程，难以适应现实世界中开放性、复杂多变的问题。因此，近期研究开始探索通过让智能体自我重写代码或提示词来实现自进化，以提升问题求解能力。然而，这种无约束的优化往往导致系统不稳定、产生幻觉以及指令漂移等问题。为此，我们提出EvoFSM——一种结构化的自进化框架，通过演化显式的有限状态机（FSM）而非自由形式的重写，实现了灵活性与可控性的平衡。EvoFSM将优化空间解耦为宏观层面的“流程”（状态转移逻辑）和微观层面的“技能”（状态特定行为），从而在明确的行为边界内实现有针对性的改进。在批评者机制的引导下，EvoFSM仅通过少量受约束的操作对FSM进行精炼，并进一步引入一种自进化的记忆机制，将成功的推理轨迹提炼为可复用的先验知识，同时将失败模式作为未来查询的约束条件。在五个多跳问答基准上的大量实验验证了EvoFSM的有效性。特别是在DeepSearch基准上，EvoFSM达到了58.0%的准确率。此外，在交互式决策任务中的额外实验结果也进一步证明了其良好的泛化能力。"
  },
  {
    "date": "2026-01-14",
    "title": "Deep Learning-based Binary Analysis for Vulnerability Detection in x86-64 Machine Code",
    "authors": "Mitchell Petingola",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09157v1",
    "source": "arXiv",
    "abstract": "While much of the current research in deep learning-based vulnerability detection relies on disassembled binaries, this paper explores the feasibility of extracting features directly from raw x86-64 machine code. Although assembly language is more interpretable for humans, it requires more complex models to capture token-level context. In contrast, machine code may enable more efficient, lightweight models and preserve all information that might be lost in disassembly. This paper approaches the task of vulnerability detection through an exploratory study on two specific deep learning model architectures and aims to systematically evaluate their performance across three vulnerability types. The results demonstrate that graph-based models consistently outperform sequential models, emphasizing the importance of control flow relationships, and that machine code contains sufficient information for effective vulnerability discovery.",
    "title_zh": "基于深度学习的x86-64机器码二进制分析漏洞检测",
    "abstract_zh": "尽管当前基于深度学习的漏洞检测研究大多依赖于反汇编后的二进制文件，本文探索了直接从原始x86-64机器码中提取特征的可行性。虽然汇编语言对人类更具可读性，但需要更复杂的模型来捕捉词元级别的上下文信息。相比之下，机器码可能有助于构建更高效、轻量级的模型，并保留反汇编过程中可能丢失的所有信息。本文通过针对两种特定深度学习模型架构的探索性研究，系统评估其在三种不同漏洞类型上的表现。结果表明，基于图的模型始终优于序列模型，凸显了控制流关系的重要性，同时证明机器码中蕴含了足以实现有效漏洞发现的充分信息。"
  },
  {
    "date": "2026-01-14",
    "title": "Programming over Thinking: Efficient and Robust Multi-Constraint Planning",
    "authors": "Derrick Goh Xin Deik, Quanyu Long, Zhengyuan Liu, Nancy F. Chen, Wenya Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.09097v1",
    "source": "arXiv",
    "abstract": "Multi-constraint planning involves identifying, evaluating, and refining candidate plans while satisfying multiple, potentially conflicting constraints. Existing large language model (LLM) approaches face fundamental limitations in this domain. Pure reasoning paradigms, which rely on long natural language chains, are prone to inconsistency, error accumulation, and prohibitive cost as constraints compound. Conversely, LLMs combined with coding- or solver-based strategies lack flexibility: they often generate problem-specific code from scratch or depend on fixed solvers, failing to capture generalizable logic across diverse problems. To address these challenges, we introduce the Scalable COde Planning Engine (SCOPE), a framework that disentangles query-specific reasoning from generic code execution. By separating reasoning from execution, SCOPE produces solver functions that are consistent, deterministic, and reusable across queries while requiring only minimal changes to input parameters. SCOPE achieves state-of-the-art performance while lowering cost and latency. For example, with GPT-4o, it reaches 93.1% success on TravelPlanner, a 61.6% gain over the best baseline (CoT) while cutting inference cost by 1.4x and time by ~4.67x. Code is available at https://github.com/DerrickGXD/SCOPE.",
    "title_zh": "编程优于思考：高效且稳健的多约束规划",
    "abstract_zh": "多约束规划涉及在满足多个可能相互冲突的约束条件下，识别、评估并优化候选方案。现有的大语言模型（LLM）方法在此领域面临根本性局限。纯推理范式依赖于冗长的自然语言推理链，随着约束数量增加，容易出现不一致、错误累积以及高昂的成本问题。相反，结合编码或求解器策略的LLM方法缺乏灵活性：它们通常从头生成特定问题的代码，或依赖固定的求解器，难以捕捉跨多样化问题的通用逻辑。为解决这些挑战，我们提出了可扩展代码规划引擎（Scalable COde Planning Engine, SCOPE），一种将查询相关推理与通用代码执行相分离的框架。通过解耦推理与执行，SCOPE生成的求解函数具备一致性、确定性，并可在不同查询间复用，仅需对输入参数进行微小调整即可。SCOPE在实现顶尖性能的同时显著降低了成本与延迟。例如，在GPT-4o上，其在TravelPlanner任务中达到93.1%的成功率，较最佳基线（CoT）提升61.6%，同时推理成本降低1.4倍，耗时减少约4.67倍。代码已开源，地址为：https://github.com/DerrickGXD/SCOPE。"
  },
  {
    "date": "2026-1-14",
    "title": "A Design for Tolerating Multiple Faults in Processing-in-Memory",
    "authors": "Yunje Hwang, Seung Ho Shin, Hayoung Lee",
    "publish": "2025 22nd International SoC Design Conference (ISOCC)",
    "url": "https://doi.org/10.1109/isocc66390.2025.11329804",
    "source": "IEEE",
    "abstract": "While Processing-in-Memory (PIM) is emerging as a key technology to solve the memory bottleneck, manufacturing defects in its integrated Processing Units (PUs) present a critical challenge to production yield and reliability. This paper proposes a fault-tolerant PIM architecture that incorporates data bypass paths and a dedicated repair structure into the adder tree and accumulator. The proposed architecture utilizes Vertical and Horizontal multiplexers to bypass faulty arithmetic units and employs a dual-pipeline accumulator to process the resulting one-cycle-delayed repair data without throughput degradation. This design can repair multiple simultaneous faults (up to Four Faults).",
    "title_zh": "面向处理内存中多重故障的容错设计",
    "abstract_zh": "尽管存内计算（PIM）正成为解决内存瓶颈的关键技术，但其集成处理单元（PUs）中的制造缺陷给生产良率和可靠性带来了重大挑战。本文提出了一种容错型PIM架构，该架构在加法树和累加器中引入了数据旁路路径及专用修复结构。所提出的架构利用垂直与水平多路选择器绕过故障算术单元，并采用双流水线累加器来处理由此产生的单周期延迟修复数据，从而避免吞吐量下降。该设计能够修复多个同时发生的故障（最多达四个故障）。"
  },
  {
    "date": "2026-1-14",
    "title": "Relative Performance Bandits: An Adaptive RAG Framework with Reward-Aware Exploration",
    "authors": "Yuhang Dai, Jing Li, Bohan Li",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11322957",
    "source": "IEEE",
    "abstract": "Retrieval-Augmented Generation (RAG) plays a vital role in enhancing large language models (LLMs) by enabling them to leverage external knowledge, thereby reducing hallucinations and improving the accuracy of responses. However, current RAG systems lack the capability to adjust retrieval strategies according to the complexity of queries. This inflexibility often leads to poor performance. To address this, we propose a novel Adaptive Retrieval-Augmented Generation framework. It employs an improved multi-armed bandit algorithm as a classifier for predicting query complexity. Treating each retrieval method as an ”arm”, the algorithm balances exploration and exploitation via Relative Performance. Experiments on multiple single-hop and multi-hop datasets demonstrate robust results: it outperforms traditional static RAG systems in both accuracy and efficiency, with significant gains in handling complex multi-hop queries while not adding unnecessary computational overhead for simple single-hop ones.",
    "title_zh": "相对性能赌徒：一种具有奖励感知探索的自适应RAG框架",
    "abstract_zh": "检索增强生成（RAG）在提升大型语言模型（LLMs）性能方面发挥着至关重要的作用，通过引入外部知识，有效减少幻觉现象，提高回答的准确性。然而，当前的RAG系统缺乏根据查询复杂度动态调整检索策略的能力，这种僵化性常常导致性能不佳。为解决这一问题，我们提出了一种新型的自适应检索增强生成框架。该框架采用改进的多臂赌博机算法作为查询复杂度预测器，将每种检索方法视为一个“臂”，通过相对表现实现探索与利用之间的平衡。在多个单跳和多跳数据集上的实验表明，该方法具有出色的性能：相较于传统的静态RAG系统，在准确性和效率方面均取得显著提升，尤其在处理复杂的多跳查询时优势明显，同时对简单的单跳查询不会引入额外的计算开销。"
  },
  {
    "date": "2026-1-14",
    "title": "DySec: A Machine Learning-based Dynamic Analysis for Detecting Malicious Packages in PyPI Ecosystem",
    "authors": "Sk Tanzir Mehedi, Chadni Islam, Gowri Ramachandran, Raja Jurdak",
    "publish": "IEEE Transactions on Information Forensics and Security",
    "url": "https://doi.org/10.1109/tifs.2026.3654388",
    "source": "IEEE",
    "abstract": "Malicious Python packages make software supply chains vulnerable by exploiting trust in open-source repositories like Python Package Index (PyPI). Lack of real-time behavioral monitoring makes metadata inspection and static code analysis inadequate against advanced attack strategies such as typosquatting, covert remote access activation, and dynamic payload generation. To address these challenges, we introduce DySec, a machine learning (ML)-based dynamic analysis framework for PyPI that uses eBPF kernel and user-level probes to monitor behaviors during package installation. By capturing 36 real-time features–including system calls, network traffic, resource usage, directory access, and installation patterns–DySec detects threats like typosquatting, covert remote access activation, dynamic payload generation, and multiphase attack malware. We developed a comprehensive dataset of 14,271 Python packages, including 7,127 malicious sample traces, by executing them in a controlled isolated environment. Experimental results demonstrate that DySec achieves 96% detection accuracy with an ML inference latency of <0.5s after dynamic feature extraction, reducing false negatives by 78.65% compared to static analysis and 82.24% compared to metadata analysis. During the evaluation, DySec flagged eleven packages that PyPI classified as benign. A manual analysis, including installation behavior inspection, confirmed six of them as malicious. These findings were reported to PyPI maintainers, resulting in the removal of four packages. DySec bridges the gap between reactive traditional methods and proactive, scalable threat mitigation in open-source ecosystems by uniquely detecting malicious install-time behaviors.",
    "title_zh": "DySec：一种基于机器学习的动态分析方法，用于检测PyPI生态中的恶意软件包",
    "abstract_zh": "恶意Python包通过利用对开源仓库（如Python Package Index，PyPI）的信任，使软件供应链变得脆弱。由于缺乏实时行为监控，仅依赖元数据检查和静态代码分析已不足以应对诸如拼写错误劫持（typosquatting）、隐蔽远程访问激活以及动态载荷生成等高级攻击策略。为解决这些挑战，我们提出了DySec——一种基于机器学习（ML）的PyPI动态分析框架，该框架采用eBPF内核级与用户级探针，在包安装过程中实时监控系统行为。DySec通过捕获36个实时特征（包括系统调用、网络流量、资源使用、目录访问及安装模式等），能够有效检测拼写错误劫持、隐蔽远程访问激活、动态载荷生成以及多阶段攻击型恶意软件等威胁。\n\n我们通过在一个受控隔离环境中执行14,271个Python包，构建了一个全面的数据集，其中包含7,127个恶意样本的运行轨迹。实验结果表明，DySec在完成动态特征提取后，实现超过96%的检测准确率，且机器学习推理延迟低于0.5秒；相比传统静态分析，误报率降低78.65%；相比元数据分析，误报率降低82.24%。评估过程中，DySec共标记出11个PyPI系统判定为“良性”的包，经人工分析（包括安装行为审查）确认其中6个为恶意软件。相关发现已上报PyPI维护团队，最终促成4个恶意包被移除。\n\nDySec通过独特地识别恶意安装时行为，弥合了传统被动响应方法与主动、可扩展的威胁防护之间的差距，为开源生态系统的安全治理提供了创新性解决方案。"
  },
  {
    "date": "2026-1-14",
    "title": "Optimized SEC-OLS Code Architecture for Enhanced Area, Delay, and Power Efficiency",
    "authors": "Sayan Tripathi, Jhilam Jana, Jaydeb Bhaumik",
    "publish": "2025 5th IEEE International Conference on Applied Electromagnetics, Signal Processing, &amp;amp; Communication (AESPC)",
    "url": "https://doi.org/10.1109/aespc67542.2025.11326743",
    "source": "IEEE",
    "abstract": "The implementation of error detection and correction mechanisms play an important role for preserving data integrity in storage systems requiring high operational reliability. This work introduces a novel $(24,16)$ Single Error Correction OLS (SEC-OLS) code based on optimized H-matrix construction that simplify encoding and decoding while enhancing efficiency. ASIC synthesis results show that proposed scheme achieves up to 30.37% area, 24.18% delay, and 12.07% power reductions compared to Demirci et al., along with improvements of 26.27% in area, 14.15% in delay, and 2.24% in power over Tripathi et al.. Our scheme also outperforms Xiao et al. across all metrics. Experimental results demonstrate that the proposed SEC-OLS code provides an effective trade-off between fault tolerance, hardware efficiency, and energy savings, making it highly suitable for next-generation memory and storage systems.",
    "title_zh": "面向面积、延迟和功耗优化的SEC-OLS代码架构",
    "abstract_zh": "错误检测与纠正机制的实现对于保障高可靠性存储系统中的数据完整性起着至关重要的作用。本文提出了一种基于优化H矩阵构造的新颖$(24,16)$单错误纠正OLS（SEC-OLS）码，该方法在简化编码与解码过程的同时提升了整体效率。ASIC综合结果表明，与Demirci等人相比，所提方案在面积上最多减少30.37%，延迟降低24.18%，功耗下降12.07%；相较于Tripathi等人，面积减少26.27%，延迟降低14.15%，功耗减少2.24%；同时，在所有指标上均优于Xiao等人。实验结果表明，所提出的SEC-OLS码在容错能力、硬件效率和节能之间实现了有效的平衡，因而非常适用于下一代内存与存储系统。"
  },
  {
    "date": "2026-1-14",
    "title": "Manimatic: An AI-Powered Framework for Automated Physics Animation Generation using Deep Learning and Programmatic Visualization",
    "authors": "Gnanakumar D, Sainath Reddy C, Naga Purna Sekhar D, Hemanth Kumar B, Tarun Kumar Reddy D",
    "publish": "2025 4th International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "url": "https://doi.org/10.1109/icacrs67045.2025.11324363",
    "source": "IEEE",
    "abstract": "This paper presents Manimatic, an AI-powered framework that automates physics animation generation by converting natural language descriptions into executable Manim code and rendered visualizations. The system leverages domain-specific fine-tuning of transformer-based code generation models on a curated dataset of 1,050 physics-specific prompt-code pairs spanning mechanics, waves, optics, and electromagnetism. We employ a fine-tuned CodeGen-350M-mono model achieving validation loss of 0.21, integrated with preprocessing, code generation, validation, and rendering pipelines deployed through FastAPI and Next.js interfaces. Evaluation demonstrates 96.5% syntax validity, 94.2% execution success rate, and 91.7% visual accuracy as rated by physics educators. The system successfully generates animations for diverse physics phenomena with end-to-end latency of 18-35 seconds, enabling educators to create custom instructional animations without programming expertise. This work bridges the gap between theoretical physics education and dynamic visualization, demonstrating practical viability for educational deployment.",
    "title_zh": "Manimatic：一种基于深度学习与程序化可视化技术的AI驱动物理动画自动生成框架",
    "abstract_zh": "本文提出了一种名为Manimatic的AI驱动框架，该框架通过将自然语言描述自动转换为可执行的Manim代码及渲染后的视觉动画，实现了物理动画的自动化生成。系统基于一个精心构建的数据集，其中包含1,050个涵盖力学、波动、光学和电磁学等领域的物理专用提示-代码对，对基于Transformer的代码生成模型进行了领域特定的微调。我们采用经过微调的CodeGen-350M-mono模型，在验证集上达到0.21的损失值，并集成预处理、代码生成、验证与渲染全流程，通过FastAPI和Next.js接口进行部署。评估结果显示，代码语法正确率达到96.5%，执行成功率为94.2%，由物理教育专家评定的视觉准确性达91.7%。系统能够在18至35秒的端到端延迟内成功生成多种物理现象的动画，使教育工作者无需编程经验即可创建定制化的教学动画。本研究弥合了理论物理教育与动态可视化之间的鸿沟，展示了其在教育场景中实际应用的可行性。"
  },
  {
    "date": "2026-1-14",
    "title": "Structural Analysis of a Smart Home System in Accommodation Residence",
    "authors": "Desislava Mihaylova, Miroslav Akbatirov",
    "publish": "2025 International Conference Automatics and Informatics (ICAI)",
    "url": "https://doi.org/10.1109/icai67591.2025.11324679",
    "source": "IEEE",
    "abstract": "This report examines a smart system designed for implementation in hotel conditions. Apart from the problem of choosing technical means for the execution of the project, the posed task here is to present an original solution about the working principle of the system and to describe it by using the automation theory. Hotel room conditions propose that the \"smart\" system would be responsive to customer presence and actions. The number of states when the system waits for incoming signals from different sensors or direct impact upon input devices is a comparative criterion about the complexity of similar projects. Consequently, an optional algorithm is presented, and automaton is created referring to the general states of a group events. It facilitates the assessment of the logical composition in terms of coding constraints.",
    "title_zh": "住宿住宅中智能家居系统的结构分析",
    "abstract_zh": "本报告探讨了一种专为酒店环境设计的智能系统。除了项目实施中技术手段的选择问题外，本研究的任务还在于提出一种关于系统工作原理的原创性解决方案，并运用自动化理论对其进行描述。酒店房间的使用环境要求该“智能”系统能够对顾客的存在及行为作出响应。系统在等待来自不同传感器或输入设备直接作用的信号时所处的状态数量，可作为衡量类似项目复杂程度的比较标准。因此，本文提出了一种可选算法，并根据一组事件的总体状态构建了相应的自动机模型，从而有助于从编码约束的角度评估系统的逻辑构成。"
  },
  {
    "date": "2026-1-14",
    "title": "Function Calling in Large Language Models: Industrial Practices, Challenges, and Future Directions",
    "authors": "Maolin Wang, Yingyi Zhang, Bowen Yu, Bingguang Hao, Cunyin Peng, Yicheng Chen, Wei Zhou, Jinjie Gu, Chenyi Zhuang, Ruocheng Guo, Wanyu Wang, Xiangyu Zhao",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3788284",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型中的函数调用：工业实践、挑战与未来方向",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-14",
    "title": "Foundational Design and Transient Analysis of NAND Gate and Inverter in Cadence Virtuoso for CMOS Logic Circuits",
    "authors": "Jyotishko Chakrabotry, Bristi Hajra, Pradipta Dutta",
    "publish": "2025 5th IEEE International Conference on Applied Electromagnetics, Signal Processing, &amp;amp; Communication (AESPC)",
    "url": "https://doi.org/10.1109/aespc67542.2025.11326845",
    "source": "IEEE",
    "abstract": "This paper comprehensively analyzes the schematic design, physical layout, and transient analysis of elementary CMOS logic gates, such as the NAND and inverter, in the Cadence Virtuoso environment. Designs were implemented in the GPDK 90 nm technology node and verified on paper by intensive simulation and verification. The layouts were designed according to the standard CMOS rules, and the switching characteristics and transient analysis were done using Analog Design Environment Lite (ADE L). Functional correctness was verified via LVS checks and post layout simulations with PEX. Therefore, the comparative study focused on showing the inverter as the timing reference and the NAND gate as the most universal and efficient in design; especially when it comes to being of low power dissipation and high speed in VLSI digital applications. This paper is a reference source and a textbook guide for VLSI design beginners using EDA tools.",
    "title_zh": "基于Cadence Virtuoso的CMOS逻辑电路中NAND门与反相器的基础设计及瞬态分析",
    "abstract_zh": "本文在Cadence Virtuoso环境中，对基本CMOS逻辑门（如NAND门和反相器）的原理图设计、物理版图布局及瞬态分析进行了全面分析。设计采用GPDK 90 nm工艺节点实现，并通过大量仿真与验证在纸上完成验证。版图设计遵循标准CMOS设计规则，开关特性与瞬态分析则利用模拟设计环境轻量版（ADE L）完成。功能正确性通过LVS检查以及带有PEX的版图后仿真得到验证。因此，本研究的对比分析重点在于：以反相器作为时序参考，而将NAND门作为最通用且高效的电路结构，尤其在低功耗和高速度方面表现出色，适用于VLSI数字系统应用。本文可作为初学者使用EDA工具进行VLSI设计的参考资料和教材指南。"
  },
  {
    "date": "2026-1-14",
    "title": "LLM on FPGA: Squeezing Language Models by Quantization and Multi-Query Attention and its Efficient Hardware Architecture",
    "authors": "Seoyoon Chae, Taewook Kang",
    "publish": "2025 22nd International SoC Design Conference (ISOCC)",
    "url": "https://doi.org/10.1109/isocc66390.2025.11329964",
    "source": "IEEE",
    "abstract": "We present an on-chip implementation of a compressed Transformer-based language model on a Xilinx Artix-7 FPGA. Our contributions include: (1) combining ultra-low-precision quantization (4 bits) and multi-query attention (MQA) to compress the KV cache by 8×, enabling sequence lengths up to 256 tokens; (2) a streaming hardware architecture in Verilog that implements pre-layernorm, attention, and feed-forward sublayers using block RAM (BRAM) and DSPs; and (3) post-synthesis results demonstrating real-time throughput (4.4 K tokens/s) with BRAM and DSP utilizations of 31.9% and 85%, respectively. The prototype supports generative inference entirely on-chip, paving the way for privacy-preserving, edge-scale LLMs. Code and scripts are available at https://github.com/chae-sy/squeezing_lm",
    "title_zh": "基于FPGA的大型语言模型：通过量化与多查询注意力压缩语言模型及其高效硬件架构",
    "abstract_zh": "我们在 Xilinx Artix-7 FPGA 上实现了一种基于压缩 Transformer 的语言模型的片上部署。我们的主要贡献包括：（1）将超低精度量化（4 位）与多查询注意力（MQA）相结合，使 KV 缓存压缩达 8 倍，从而支持最长 256 个 token 的序列长度；（2）采用 Verilog 设计的流式硬件架构，利用块 RAM（BRAM）和数字信号处理单元（DSP）实现了预层归一化、注意力和前馈子层；（3）后综合结果表明，该设计实现了实时吞吐率（4.4 K tokens/s），同时 BRAM 和 DSP 的利用率分别仅为 31.9% 和 85%。该原型可完全在片上完成生成式推理，为隐私保护、边缘规模的大语言模型（LLM）开辟了新路径。代码与脚本已开源，详见 https://github.com/chae-sy/squeezing_lm"
  },
  {
    "date": "2026-1-14",
    "title": "Poster: Boosting Inter-Procedural Vulnerability Detection via Retrieval-Augmented Generation",
    "authors": "Linru Ma, Hongquan Xu, Hongyu Kuang, Feng Yang, Boyu Deng",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11323228",
    "source": "IEEE",
    "abstract": "Traditional LLM-based vulnerability detection methods face challenges like hallucinations and high false positive rates. In order to overcome these constraints, we propose an innovative RAG-based method for inter-procedural vulnerability detection named IPVRAG. The main innovation design of our IPVRAG is its multi-level feature extraction strategy: during knowledge base construction, it not only extracts functional semantics and vulnerability causes but also stores pruned Data Flow Graph structures and semantic identifier information. Evaluated on a widely-used dataset, IPVRAG outperformed many of LLM-based baselines. It achieved optimal overall performance in inter-procedural vulnerability detection, particularly demonstrating superior precision-recall balance that effectively reduced false negatives.",
    "title_zh": "海报：基于检索增强生成的跨过程漏洞检测提升方法",
    "abstract_zh": "基于传统大语言模型（LLM）的漏洞检测方法面临幻觉现象和误报率高等挑战。为克服这些局限，我们提出了一种创新的基于检索增强生成（RAG）的跨过程漏洞检测方法，命名为IPVRAG。IPVRAG的核心创新设计在于其多层次特征提取策略：在知识库构建阶段，不仅提取函数语义和漏洞成因信息，还保存经过剪枝的数据流图（Data Flow Graph）结构以及语义标识符信息。在广泛使用的数据集上进行评估的结果表明，IPVRAG优于多种基于LLM的基线方法，在跨过程漏洞检测任务中取得了最优的整体性能，尤其在精确率与召回率的平衡方面表现突出，有效降低了漏报率。"
  },
  {
    "date": "2026-1-14",
    "title": "A Review on Logic Gate Design and Layout Optimization in Cadence Virtuoso for Low-Power VLSI Applications",
    "authors": "Bristi Hajra, Jyotishko Chakrabotry, Pradipta Dutta",
    "publish": "2025 5th IEEE International Conference on Applied Electromagnetics, Signal Processing, &amp;amp; Communication (AESPC)",
    "url": "https://doi.org/10.1109/aespc67542.2025.11326799",
    "source": "IEEE",
    "abstract": "This paper reviews logic gate design and layout optimization for low-power VLSI circuits using Cadence Virtuoso. Conventional CMOS, GDI, and MGDI logic styles are compared in terms of power, delay, and area. Simulation of basic gates across $180 \\mathrm{~nm}, 90 \\mathrm{~nm}$, and 45 nm technologies shows that MGDI designs achieve up to 70% power and delay reduction with minimal transistor count. Layout level optimization through transistor sizing, diffusion sharing, and routing symmetry further enhances efficiency. Advanced implementations such as CNTFET based XOR/XNOR gates, ripple carry adders, and in-memory architectures confirm Cadence Virtuoso as an effective platform for energy efficient, high performance circuit design.",
    "title_zh": "关于在Cadence Virtuoso中用于低功耗VLSI应用的逻辑门设计与版图优化的综述",
    "abstract_zh": "本文综述了基于Cadence Virtuoso的低功耗VLSI电路中逻辑门设计与版图优化。对比了传统的CMOS、GDI及MGDI逻辑结构在功耗、延迟和面积方面的性能。在180 nm、90 nm和45 nm工艺节点下对基本逻辑门的仿真结果表明，MGDI设计可实现高达70%的功耗和延迟降低，同时保持极低的晶体管数量。通过晶体管尺寸优化、扩散区共享以及布线对称性等版图级优化手段，进一步提升了电路效率。此外，基于碳纳米管场效应晶体管（CNTFET）的XOR/XNOR门、行波进位加法器及存内计算架构等先进实现方案，验证了Cadence Virtuoso作为实现高能效、高性能电路设计的有效平台。"
  },
  {
    "date": "2026-1-14",
    "title": "CRADLE: Conversational RTL Design Space Exploration with LLM-Based Multi-Agent Systems",
    "authors": "Lukas Krupp, Maximilian Schöffel, Elias Biehl, Norbert Wehn",
    "publish": "2025 22nd International SoC Design Conference (ISOCC)",
    "url": "https://doi.org/10.1109/isocc66390.2025.11329873",
    "source": "IEEE",
    "abstract": "This paper presents CRADLE, a conversational framework for design space exploration of RTL designs using LLM-based multi-agent systems. Unlike existing rigid approaches, CRADLE enables user-guided flows with internal self-verification, correction, and optimization. We demonstrate the framework with a generator-critic agent system targeting FPGA resource minimization using state-of-the-art LLMs. Experimental results on the RTLLM benchmark show that CRADLE achieves significant reductions in resource usage with averages of 48% and 40% in LUTs and FFs across all benchmark designs.",
    "title_zh": "CRADLE：基于大语言模型多智能体系统的对话式RTL设计空间探索",
    "abstract_zh": "本文提出了CRADLE，一种基于大语言模型（LLM）多智能体系统的对话式框架，用于RTL设计的架构空间探索。与现有僵化的方法不同，CRADLE支持用户引导的设计流程，并具备内部自验证、纠错和优化能力。我们通过一个生成-批评者智能体系统，在使用前沿大语言模型的基础上，实现了针对FPGA资源最小化的目标。在RTLLM基准测试上的实验结果表明，CRADLE在所有基准设计中平均将LUT和FF资源分别减少了48%和40%，取得了显著的资源节约效果。"
  },
  {
    "date": "2026-1-14",
    "title": "Low-Power TinyML CNN Accelerator using Integrated Clock Gating for Edge Devices",
    "authors": "Shashi Kant Dargar, Akash, Antony Fedrick, Avinash Kumar",
    "publish": "2025 4th International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "url": "https://doi.org/10.1109/icacrs67045.2025.11324407",
    "source": "IEEE",
    "abstract": "In this work, a compact low-power convolutional neural network (CNN) hardware accelerator is developed for TinyML-based edge AI systems. The design applies integrated clock gating (ICG) using Synopsys EDA tools, where gating decisions are guided by real switching activity captured in SAIF files. This approach effectively reduces dynamic power without affecting timing or area efficiency. The Verilog RTL architecture includes modules such as a line buffer, adaptive multiplier supporting exact and approximate modes, ReLU, pooling, and automated clock control. When synthesized with a 45 nm standard-cell library, the proposed accelerator achieved 38.2% lower dynamic power and an improved timing slack of 3.41 ns. Functional correctness was verified through simulation and waveform inspection, confirming the design’s reliability. The overall methodology is reproducible and suitable for energy-constrained IoT and always-on microcontroller platforms.",
    "title_zh": "面向边缘设备的低功耗TinyML卷积神经网络加速器：基于集成时钟门控技术",
    "abstract_zh": "本文提出了一种面向基于TinyML的边缘AI系统的紧凑型低功耗卷积神经网络（CNN）硬件加速器。该设计采用Synopsys EDA工具实现集成时钟门控（ICG），其门控决策基于SAIF文件中捕获的实际开关活动信息，有效降低了动态功耗，同时不影响时序性能和面积效率。Verilog RTL架构包含行缓冲区、支持精确与近似两种模式的自适应乘法器、ReLU、池化模块以及自动时钟控制单元。在使用45 nm标准单元库综合后，所提出的加速器实现了38.2%的动态功耗降低，并获得了3.41 ns的改进时序余量。通过仿真与波形检查验证了功能正确性，确认了设计的可靠性。整体方法具有可复现性，适用于能源受限的物联网及始终在线的微控制器平台。"
  },
  {
    "date": "2026-1-14",
    "title": "Model Checking PLC Programs: Enhancing Formalization for Scalability",
    "authors": "Jessica Ravakambinintsoa, Emil Dumitrescu, Eric Zamaï, Denis Chalon",
    "publish": "2025 11th International Conference on Control, Decision and Information Technologies (CoDIT)",
    "url": "https://doi.org/10.1109/codit66093.2025.11321720",
    "source": "IEEE",
    "abstract": "Formal verification of PLC programs requires transforming control logic into a mathematical model. Since PLC languages lack a formal semantics, multiple transformation methods exist, based on various code interpretations. This work introduces a novel approach leveraging Single Static Assignments (SSA) to ensure a faithful PLC code transformation while enhancing model checking scalability. By systematically tracking variable assignments, the method accurately captures execution dependencies and preserves control logic. Experimental results demonstrate promising improvements in verification efficiency.",
    "title_zh": "模型检查PLC程序：提升形式化以增强可扩展性",
    "abstract_zh": "可编程逻辑控制器（PLC）程序的形式化验证需要将控制逻辑转化为数学模型。由于PLC语言缺乏形式语义，现有的转换方法基于对代码的不同解释，因而存在多种实现方式。本文提出一种新方法，利用单静态赋值（SSA）技术，在确保PLC代码转换忠实性的同时，提升模型检测的可扩展性。通过系统地追踪变量赋值，该方法能够准确捕捉执行依赖关系，并完整保留控制逻辑。实验结果表明，该方法在验证效率方面取得了显著提升。"
  },
  {
    "date": "2026-1-14",
    "title": "Comparative Study of Edge Deployment of LLM on Arm and RISC-V SBC Clusters",
    "authors": "Tay-Jyi Lin, Bo-Chen Liao, Chih-Yen Liao, Kai-Siang Shih, Chingwei Yeh, Peng-Sheng Chen, Shih-Chieh Chang, Tien-Fu Chen, Jinn-Shyan Wang",
    "publish": "2025 22nd International SoC Design Conference (ISOCC)",
    "url": "https://doi.org/10.1109/isocc66390.2025.11329552",
    "source": "IEEE",
    "abstract": "Connecting multiple low-cost single-board computers (SBCs) through network to form a computing cluster is a feasible solution for deploying large language models (LLM) at the edge. This work compares the deployment of Llama3 8B on computing clusters composed of leading-edge Arm and RISC-V SBCs. The performance numbers (as tokens/sec) are given and analyzed in correspondence to the hardware architecture & software design implementations.",
    "title_zh": "基于Arm与RISC-V单板计算机集群的大型语言模型边缘部署对比研究",
    "abstract_zh": "通过网络将多个低成本单板计算机（SBC）连接起来，构成计算集群，是实现大语言模型（LLM）在边缘端部署的一种可行方案。本文对比了在主流Arm架构和RISC-V架构SBC组成的计算集群上部署Llama3 8B模型的性能表现。文中给出了相应的性能数据（以每秒处理的token数为单位），并结合硬件架构与软件设计实现进行了分析。"
  },
  {
    "date": "2026-1-14",
    "title": "Multi-Agent Collaborative Reasoning via Cloud-Edge Framework",
    "authors": "Jiandian Zeng, Junjie Liao, Shaochen Sun, Guangxue Zhang, Changfu Xu, Huaijin Liu, Yang Li",
    "publish": "IEEE Network",
    "url": "https://doi.org/10.1109/mnet.2026.3651036",
    "source": "IEEE",
    "abstract": "Large Language Model (LLM)-based agents have significantly advanced the reasoning and problem-solving capabilities of intelligent systems. As tasks grow more complex, there is an increasing need to shift from single-agent framework to Multi-Agent Systems (MAS) for enhanced collaborative performance. Achieving better performance typically requires deploying large-scale LLMs, however, it poses significant challenges on resource-constrained edge devices. In addition, most MAS adopt a fully connected communication topology and require multiple rounds of interaction, resulting in considerable communication redundancy and increased computational overhead. To address the issues, in this paper, we propose a Directed Acyclic Graph-based Multi-Agent System (DAG-MAS) via cloud-edge framework for collaborative reasoning. Specifically, considering the limited resources on the edge, we utilize a 72B-LLM in the cloud finetunes a lightweight Small Language Model (SLM) for edge deployment. To generate a one round interaction graph, the SLM is further employed to analyze task requirements and determine optimal communication topology, minimizing overhead while enabling effective information exchange. Extensive experiments and analyses on four reasoning datasets demonstrate the superiority of our approach compared to several benchmark methods, validating the effectiveness in achieving higher reasoning performance with lower communication costs.",
    "title_zh": "基于云边框架的多智能体协作推理",
    "abstract_zh": "基于大语言模型（LLM）的智能体显著提升了智能系统在推理与问题解决方面的能力。随着任务复杂度的不断提升，从单智能体框架向多智能体系统（MAS）的转变成为提升协作性能的迫切需求。然而，实现更优性能通常需要部署大规模LLM，这在资源受限的边缘设备上带来了巨大挑战。此外，现有大多数多智能体系统采用全连接通信拓扑结构，并需进行多轮交互，导致严重的通信冗余和计算开销增加。针对上述问题，本文提出一种基于有向无环图（DAG）的多智能体系统（DAG-MAS），依托云-边协同架构实现高效协作推理。具体而言，考虑到边缘端资源有限，我们利用云端的720亿参数大模型对轻量级小语言模型（SLM）进行微调，以适配边缘部署。为进一步构建单轮交互的通信图，该SLM还被用于分析任务需求，自动确定最优通信拓扑结构，在降低系统开销的同时保障有效信息传递。在四个推理数据集上的大量实验与分析表明，所提方法在推理性能上优于多种基准方法，同时显著降低了通信成本，验证了其在高效率与高性能之间取得良好平衡的有效性。"
  },
  {
    "date": "2026-1-14",
    "title": "Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space-air-ground Integrated Networks",
    "authors": "Minrui Xu, Dusit Niyato, Hongliang Zhang, Jiawen Kang, Zehui Xiong, Shiwen Mao, Zhu Han",
    "publish": "IEEE Transactions on Networking",
    "url": "https://doi.org/10.1109/ton.2025.3649068",
    "source": "IEEE",
    "abstract": "Edge intelligence in space-air-ground integrated networks (SAGINs) can enable worldwide network coverage beyond geographical limitations for users to access ubiquitous and low-latency intelligence services. Facing global coverage and complex environments in SAGINs, edge intelligence can provision large language models (LLMs) agents for users via edge servers at ground base stations (BSs) or cloud data centers relayed by satellites. As LLMs with billions of parameters are pretrained on vast datasets, LLM agents have few-shot learning capabilities, e.g., chain-of-thought (CoT) prompting for complex tasks, which raises a new trade-off between resource consumption and performance in SAGINs. In this paper, we propose a joint caching and inference framework for edge intelligence to provision sustainable and ubiquitous LLM agents in SAGINs. We introduce “cached model-as-a-resource” for offering LLMs with limited context windows and propose a novel optimization framework, i.e., joint model caching and inference, to utilize cached model resources for provisioning LLM agent services along with communication, computing, and storage resources.We design “age of thought” (AoT) considering the CoT prompting of LLMs, and propose a least AoT cached model replacement algorithm for optimizing the provisioning cost. We propose a deep Q-network-based modified second-bid (DQMSB) auction to incentivize satellite/ground network operators in real-time, which can enhance allocation efficiency by 23% while guaranteeing strategy-proofness and being free from adverse selection.",
    "title_zh": "缓存的模型即资源：面向空-天-地一体化网络边缘智能的大语言模型代理部署",
    "abstract_zh": "在空-天-地一体化网络（SAGINs）中，边缘智能能够突破地理限制，为用户提供全球范围内的网络覆盖，实现无处不在且低延迟的智能服务。面对SAGINs中全球覆盖需求与复杂环境挑战，边缘智能可通过地面基站（BS）的边缘服务器或由卫星中继的云数据中心，向用户部署具备大规模参数量的大语言模型（LLMs）智能体。由于LLMs基于海量数据进行预训练，其智能体具备少样本学习能力，例如通过思维链（Chain-of-Thought, CoT）提示完成复杂任务，这在SAGINs中引发了资源消耗与性能之间的新权衡。本文提出一种联合缓存与推理框架，以支持在SAGINs中可持续、无处不在地提供LLM智能体服务。我们引入“缓存模型即资源”（cached model-as-a-resource）概念，针对具有有限上下文窗口的LLMs，设计了一种新型优化框架——联合模型缓存与推理，旨在协同利用缓存模型资源以及通信、计算和存储资源，高效提供LLM智能体服务。我们提出了“思维时效性”（Age of Thought, AoT）指标，以衡量LLMs在CoT提示下的时效性，并设计了最小AoT缓存模型替换算法，以优化服务提供成本。此外，本文还提出一种基于深度Q网络的改进型第二出价拍卖机制（DQMSB），可实时激励卫星与地面网络运营商，在保障策略无关性（strategy-proofness）且避免逆向选择的前提下，使资源分配效率提升23%。"
  },
  {
    "date": "2026-1-14",
    "title": "Learning-based Approach for Early Detection of Hardware Trojans in Open-Source Hardware",
    "authors": "Polepalli Bhargavi, Nukamreddy Sai Samhita, G Mahesh, Hirekurubara Narayana, Kothapu Ajay Kumar",
    "publish": "2025 4th International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "url": "https://doi.org/10.1109/icacrs67045.2025.11324305",
    "source": "IEEE",
    "abstract": "The growing popularity of open-source hardware has unfortunately made it easier for untrustworthy actors to slip hardware Trojans into designs. While we have got some decent detection methods already, they often stumble when dealing with complex stuff like RISC-V processors and cryptographic accelerators. Introducing a new framework with mixed semantic code analysis and some intelligent embedding tricks. Instead of simply depending on text-frequency methods such as TF-IDF or Bag-of-Words, we analyze the structure in depth of Verilog code and using lightweight contextual embeddings to really get a feel for both the text and how the hardware's supposed to work. We even built a dataset of 3,900 examples, pulling from standard and injecting Trojans with the help of some refined LLM-guided mutation techniques. After pitting different classifiers and transformer models against each other, we found that our hybrid embedding approach, powered by Gradient Boosting, nailed a 98% accuracy rate. Plus, with some optimized LLM prompts, we reached recall at 99% which is too high, it reduces the number undetected Trojans attacks. This new method is all about being scalable, easy to understand, and rock-solid when it comes to keeping open-source hardware secure.",
    "title_zh": "基于学习的开源硬件中硬件木马早期检测方法",
    "abstract_zh": "开源硬件日益普及，却也给不可靠的攻击者提供了可乘之机，使其更容易在设计中植入硬件木马。尽管目前已有一些较为有效的检测方法，但在面对RISC-V处理器、密码加速器等复杂系统时，往往力不从心。为此，我们提出了一种全新的框架，结合了混合语义代码分析与智能嵌入技术。不同于传统的文本频率方法（如TF-IDF或词袋模型），我们深入分析Verilog代码的结构，并利用轻量级上下文嵌入，全面理解代码内容及其所描述的硬件行为。我们还构建了一个包含3,900个样本的数据集，通过标准设计并借助经过优化的大型语言模型（LLM）引导的变异技术注入木马。在对比多种分类器与Transformer模型后，我们发现基于梯度提升（Gradient Boosting）的混合嵌入方法取得了高达98%的准确率。此外，通过优化LLM提示词，我们实现了99%的召回率——这一数值极高，显著降低了未被检测到的木马攻击数量。该新方法兼具可扩展性、易理解性与极强的可靠性，为保障开源硬件安全提供了坚实支撑。"
  },
  {
    "date": "2026-1-14",
    "title": "AACoT: Chain-of-Thought Fine-Tuning via Associative Memory and Adaptive Error Correction",
    "authors": "Ruiyue Wang, Lingyun Song, Xinbiao Gan, Yudai Pan, Xuequn Shang",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11322935",
    "source": "IEEE",
    "abstract": "Traditional Chain-of-Thought (CoT) approaches in large language models (LLMs) often miss long-range semantic dependencies. As a result, early reasoning errors may cause subsequent cascading failures. To address these issues, we introduce AACoT, a fine-tuning framework that integrates associative memory and adaptive error correction within the CoT reasoning process. The AACoT memory functions in a dualmode capacity that differentiates entity-level knowledge from relation-level knowledge, facilitating dynamic knowledge interaction and efficient retrieval for reasoning. The adaptive error correction mechanism monitors the reasoning process, backtracks upon error detection, and regenerates the corrected reasoning paths. To improve robustness, a prompt refinement module adjusts short-term memory by collecting frequent error patterns to direct future reasoning, and a memory warm-up strategy loads crucial knowledge in advance of inference to minimize dependency on additional training. In the inference process, AACoT produces several reasoning paths and employs weighted voting to determine the final result. Results from experiments conducted on mathematical reasoning benchmarks reveal significant improvements in accuracy, validating that AACoT provides a clear and effective method for enhancing complex reasoning in foundational LLMs.",
    "title_zh": "AACoT：通过关联记忆与自适应误差校正的思维链微调",
    "abstract_zh": "大型语言模型（LLMs）中的传统链式思维（CoT）方法常常忽略长距离语义依赖关系，导致早期推理错误引发后续的级联失败。为解决这些问题，我们提出AACoT，一种将联想记忆与自适应纠错机制融入CoT推理过程的微调框架。AACoT的记忆系统采用双模式运行机制，能够区分实体级知识与关系级知识，从而促进动态知识交互，并实现高效的推理检索。自适应纠错机制可实时监控推理过程，在检测到错误时进行回溯，并重新生成修正后的推理路径。为进一步提升鲁棒性，提示优化模块通过收集常见错误模式来调整短期记忆，引导未来的推理方向；同时，记忆预热策略在推理前预先加载关键知识，减少对额外训练的依赖。在推理过程中，AACoT生成多条推理路径，并通过加权投票机制确定最终结果。在数学推理基准上的实验结果表明，该方法显著提升了准确率，验证了AACoT为增强基础大模型复杂推理能力提供了一种清晰且有效的方法。"
  },
  {
    "date": "2026-1-14",
    "title": "A Blockchain-based Smart Contract Framework for Decentralized Peer-To-Peer Lending",
    "authors": "Ragavarthini. V, Maddukuri Naga Tanuja, Maddukuri Lakshmi Vanaja, Kucharlapati Gowtham Varma, Maruboina Avinash",
    "publish": "2025 4th International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "url": "https://doi.org/10.1109/icacrs67045.2025.11324430",
    "source": "IEEE",
    "abstract": "Traditional financial lending systems face ongoing issues. These include too much involvement from middlemen, limited financial inclusion, a lack of transparency, and centralized decision-making. Such problems push unbanked and underbanked populations to the margins. This paper presents a blockchain-based decentralized peer-to-peer (P2P) credit system built on the Ethereum network. It uses smart contracts and Decentralized Autonomous Organization (DAO) frameworks that are transparent, secure, and accessible worldwide. Traditional financial institutions still rely heavily on centralized models. These models involve many intermediaries, slow processes, and high operational costs. As a result, many people have restricted access to financial services. According to the World Bank's Global Findex Database, around 1.7 billion adults are unbanked and shut out from essential financial systems. This exclusion often stems from strict eligibility requirements, lack of credit history, and absence of collateral. It not only hampers individual financial growth but also limits broader economic inclusion in developing nations. The proposed model eliminates the need for centralized institutions. It speeds up transactions, increases transparency, and allows for borderless digital lending. The system architecture uses Solidity for smart contract development, Web3.js for blockchain interaction, and a React-based user interface to create a robust full-stack decentralized application (DApp). The framework features automated asset collateralization, AI-driven interest rate modeling, trust-score-based borrower assessment, and community governance mechanisms. Performance comparisons show marked improvements in transaction speed, efficiency, and financial access compared to traditional lending models. The prototype achieves a 65% reduction in infrastructure costs and an 80% faster loan settlement time across different regions.",
    "title_zh": "基于区块链的去中心化点对点借贷智能合约框架",
    "abstract_zh": "传统金融借贷体系持续面临诸多问题，包括中介环节过多、金融包容性有限、透明度不足以及决策高度集中。这些问题导致大量无银行账户和低银行账户人群被排除在金融体系之外。本文提出一种基于以太坊网络的区块链去中心化点对点（P2P）信用系统。该系统采用智能合约与去中心化自治组织（DAO）框架，具备全球范围内的透明性、安全性和可访问性。传统金融机构仍严重依赖中心化模式，这些模式涉及众多中间人、流程缓慢且运营成本高昂，致使许多人难以获得金融服务。根据世界银行《全球金融包容性数据库》的数据，全球约有17亿成年人属于无银行账户群体，无法接入基本的金融体系。这种排斥往往源于严格的准入条件、缺乏信用记录以及缺少抵押品。这不仅阻碍了个人的财务成长，也限制了发展中国家更广泛意义上的经济包容性。所提出的模型摒弃了对中心化机构的依赖，显著加快交易速度，提升透明度，并实现无国界数字借贷。系统架构采用Solidity开发智能合约，通过Web3.js实现区块链交互，并基于React构建用户界面，打造了一个功能完整的全栈去中心化应用（DApp）。该框架包含自动资产抵押机制、基于人工智能的利率建模、基于信任评分的借款人评估，以及社区治理机制。性能对比分析表明，与传统借贷模式相比，该系统在交易速度、运行效率及金融可及性方面均有显著提升。原型系统在不同地区实现了基础设施成本降低65%，贷款结算时间缩短80%的成效。"
  },
  {
    "date": "2026-1-14",
    "title": "High Performance Sobel Edge Detection using Hybrid Approximate Multiplier",
    "authors": "P.Durggashre, K.S.Neelu Kumari, R. Kavya, R.Jayaragavi, A.Kiruthika",
    "publish": "2025 4th International Conference on Automation, Computing and Renewable Systems (ICACRS)",
    "url": "https://doi.org/10.1109/icacrs67045.2025.11324377",
    "source": "IEEE",
    "abstract": "Sobel edge detection is an important image processing tool used in many applications such as vision, medical, navigation and surveillance systems using 3×3 convolution kernels to extract structural features. Convolutional operations are typically achieved using precision multipliers, but they face constraints in terms of power, area and delay, which constrain scalability of design that are limited in resources. This presents the case for introducing a Verilog Sobel design based around high-performance streaming architecture where line buffers process the pixel stream and convolution modules are computing gradients in real time. Subsequently, performance of the traditional precision segmented multipliers is compared with a hybrid approximate method. In this hybrid method, the more significant bits are illustrated as computed exactly for the precision required based on potential errors, and the less significant bits are computed approximately to save logic, power and delay. This balance is essential to manage efficient operation while maintaining errors within acceptable tolerances offers an edge detection task. This architecture was configured to provide scalability, energy savings and design flexibility. Overall, it is very amenable to practical application in the IoT, robotics and other real-time, low-power, embedded platforms.",
    "title_zh": "基于混合近似乘法器的高性能Sobel边缘检测",
    "abstract_zh": "Sobel边缘检测是一种重要的图像处理工具，广泛应用于视觉、医疗、导航和监控系统中。它利用3×3卷积核提取结构特征。传统的卷积操作通常通过高精度乘法器实现，但这类方法在功耗、面积和延迟方面存在限制，制约了资源受限场景下的设计可扩展性。为此，本文提出一种基于高性能流式架构的Verilog Sobel设计：采用行缓冲区处理像素流，卷积模块实时计算梯度。随后，将传统高精度分段乘法器的性能与一种混合近似方法进行对比。该混合方法中，根据潜在误差情况，对较高有效位进行精确计算以满足精度要求，而对较低有效位则采用近似计算，从而节省逻辑资源、降低功耗并减少延迟。这种权衡对于在保持误差在可接受范围内的同时实现高效运行至关重要，特别适用于边缘检测任务。该架构具备良好的可扩展性、节能特性和设计灵活性，整体上非常适用于物联网、机器人以及其他实时、低功耗嵌入式平台的实际应用。"
  },
  {
    "date": "2026-1-14",
    "title": "FPGA-Based Integer-Only Hardware Accelerator for YOLOv3-Tiny Model",
    "authors": "Jonghyun Kim, Jaemyung Kim, Jin-Ku Kang, Yongwoo Kim",
    "publish": "2025 22nd International SoC Design Conference (ISOCC)",
    "url": "https://doi.org/10.1109/isocc66390.2025.11330141",
    "source": "IEEE",
    "abstract": "YOLO-based networks are frequently employed in object detection tasks due to their outstanding performance. In this work, we integrate the YOLOv3-tiny network with depthwise convolution, which excels at capturing spatial features, thereby maintaining high accuracy with a reduced parameter count. We also design an FPGA-based CNN accelerator using High-Level Synthesis (HLS) that supports line buffer and plane buffer computation schemes. Trained on the Pascal VOC dataset, the proposed network's 8-bit integer model achieved a mAP@0.5 of 65.7%, while using 74% fewer parameters than the original YOLOv3-tiny network. The accelerator is implemented on Xilinx ZC706 board, utilizing 345 BRAM18k blocks, 306 DSP slices, 25.5k FFs and 17.9k LUTs.",
    "title_zh": "基于FPGA的仅支持整数运算的YOLOv3-Tiny模型硬件加速器",
    "abstract_zh": "基于YOLO的网络因其卓越的性能而被广泛应用于目标检测任务。本文将YOLOv3-tiny网络与深度可分离卷积相结合，该方法在有效捕捉空间特征的同时，显著降低了参数量，从而在保持高精度的前提下实现了轻量化。此外，我们设计了一种基于FPGA的CNN加速器，采用高层次综合（HLS）技术实现，并支持行缓冲（line buffer）与平面缓冲（plane buffer）两种计算模式。在Pascal VOC数据集上训练后，所提出的8位整数模型达到了65.7%的mAP@0.5，且参数量仅为原始YOLOv3-tiny网络的26%。该加速器在Xilinx ZC706开发板上完成实现，共使用345个BRAM18k块、306个DSP切片、25.5k个触发器（FFs）和17.9k个查找表（LUTs）。"
  },
  {
    "date": "2026-1-14",
    "title": "Write-Once, Prove-Once: A Reusable Framework for Secure Boot Verification in Rocq",
    "authors": "Minjie Fan, Qiyu Wu, Kuai Yu, Gaosong Xu, Xiaoyang Wang, Jiwu Shu",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11323130",
    "source": "IEEE",
    "abstract": "Secure boot is a fundamental mechanism for establishing a hardware-rooted chain of trust in modern computing systems. While formal verification using interactive theorem provers like Rocq offers strong correctness guarantees, existing approaches are often tightly coupled to specific hardware configurations and cryptographic algorithms, making them brittle and difficult to reuse when system components change. In this work, we present a flexible and modular framework for formally verifying secure boot processes in Rocq. Our approach introduces a three-layer abstraction model-Feature, Axiom, and Theorem-that decouples high-level security properties from lowlevel implementation details. We abstract critical components such as storage media and cryptographic primitives (e.g., encryption, signatures, hash functions) as interfaces with welldefined operators and axiomatic correctness properties. All highlevel proofs are conducted based on these axioms, without depending on concrete implementations. When specific algorithms or hardware are chosen, the axioms become proof obligations to be verified locally. This separation ensures that changes in implementation-such as switching cryptographic primitives or storage types-do not invalidate existing proofs, enabling significant proof reuse. We demonstrate the applicability of our framework in modeling a realistic secure boot chain. Our work lays the foundation for scalable and maintainable formal verification of trust-sensitive system initialization processes.",
    "title_zh": "写入一次，验证一次：Rocq 中可重复使用的安全启动验证框架",
    "abstract_zh": "安全启动是现代计算系统中建立硬件根信任链的基本机制。尽管使用交互式定理证明器（如Rocq）进行形式化验证能够提供强有力的正确性保证，但现有方法通常与特定的硬件配置和密码算法紧密耦合，导致在系统组件发生变化时变得脆弱且难以复用。本文提出了一种灵活且模块化的框架，用于在Rocq中对安全启动过程进行形式化验证。我们的方法引入了一个三层抽象模型——特性（Feature）、公理（Axiom）和定理（Theorem），将高层安全属性与底层实现细节解耦。我们将存储介质、密码原语（如加密、签名、哈希函数）等关键组件抽象为具有明确定义操作符和公理化正确性属性的接口。所有高层证明均基于这些公理展开，不依赖于具体实现。当选择特定算法或硬件时，这些公理便转化为需要本地验证的证明义务。这种分离机制确保了实现变更（如更换密码算法或存储类型）不会使已有证明失效，从而实现了显著的证明复用。我们通过建模一个真实的可信启动链来展示该框架的应用性。本工作为可扩展且可维护的形式化验证信任敏感的系统初始化过程奠定了基础。"
  },
  {
    "date": "2026-1-14",
    "title": "Developing a Method for an Optimized Static Vehicle Function Distribution",
    "authors": "Jan Ruhnau, Steffen Becker",
    "publish": "2025 11th International Conference on Control, Decision and Information Technologies (CoDIT)",
    "url": "https://doi.org/10.1109/codit66093.2025.11321909",
    "source": "IEEE",
    "abstract": "The design of automotive electric/electronic (E/E) architectures has become increasingly complex due to the integration of numerous software-controlled functions. To address this complexity, we present a generic method for developing and implementing a vehicle function distribution optimization process. Our approach involves defining the design space, gathering relevant information from various sources, solving the optimization problem, and displaying the best configurations. Two processes are described for firstly developing, and successively using a method for the optimization. The resulting method is validated through two use-cases from the series development of current Mercedes vehicles. Validation runs show that our method can effectively optimize function distributions, reduce overhead costs, and improve system quality criteria in general, therefore providing a solid foundation for enhancing the design and development process of automotive E/E architectures.",
    "title_zh": "一种优化静态车辆功能分配的方法开发",
    "abstract_zh": "由于众多软件控制功能的集成，汽车电子/电气（E/E）架构的设计日益复杂。为应对这一复杂性，本文提出了一种通用方法，用于开发和实施车辆功能分布优化流程。我们的方法包括定义设计空间、从多种来源收集相关信息、求解优化问题，并展示最优配置方案。文中描述了两个过程：首先开发该优化方法，随后在实际中逐步应用。通过当前梅赛德斯车型系列开发中的两个用例对所提方法进行了验证。验证结果表明，该方法能够有效优化功能分布，降低开销成本，并普遍提升系统质量指标，从而为改进汽车E/E架构的设计与开发流程提供了坚实基础。"
  },
  {
    "date": "2026-1-14",
    "title": "Assessing the Effectiveness of ChatGPT for Enhancing Programming Skills Among SecondYear Computer Science Students in Tunisia",
    "authors": "Noureddine Aissa, Hédia Sellami Mhiri",
    "publish": "2025 11th International Conference on Control, Decision and Information Technologies (CoDIT)",
    "url": "https://doi.org/10.1109/codit66093.2025.11321829",
    "source": "IEEE",
    "abstract": "The integration of Artificial Intelligence (AI) into everyday life, including education, is rapidly expanding but faces challenges, particularly in aligning AI tools with educational theories and roles. This study investigates ChatGPT’s use for learning programming in Tunisian secondary schools, using qualitative and quantitative methods. The research assessed AI’s impact on students’ coding and logical thinking. An experiment with three schools divided students into an AI-assisted group and a traditional instruction group, with pre-tests and post-tests measuring the impact. Results showed ChatGPT positively influences programming skills and logical reasoning. Despite limitations like small sample size and technical constraints, the study opens new research avenues. Future research should explore larger samples and various educational levels, examining long-term effects on problem-solving, emotional engagement, and readiness for complex challenges. Tailoring AI tools to specific contexts could enhance their effectiveness, marking a step toward integrating AI in education.",
    "title_zh": "评估ChatGPT在提升突尼斯大二计算机科学专业学生编程能力方面的有效性",
    "abstract_zh": "人工智能（AI）正迅速融入日常生活，包括教育领域，但其发展仍面临诸多挑战，尤其是在将AI工具与教育理论及教学角色相契合方面。本研究探讨了ChatGPT在突尼斯中学编程学习中的应用，采用定性与定量相结合的方法。研究评估了AI对学生编程能力及逻辑思维的影响。实验选取三所中学，将学生分为使用AI辅助学习的实验组和接受传统教学的对照组，并通过前测与后测来衡量效果。结果表明，ChatGPT对提升学生的编程技能和逻辑推理能力具有积极影响。尽管存在样本量较小和技术条件受限等局限性，该研究为未来探索开辟了新路径。今后的研究应扩大样本规模，覆盖不同教育阶段，深入考察AI对学生问题解决能力、情感投入以及应对复杂挑战准备度的长期影响。针对具体教育情境优化AI工具的设计，有望进一步提升其教学效能，标志着人工智能融入教育的重要一步。"
  },
  {
    "date": "2026-1-14",
    "title": "Anomaly Detection of Vehicle Data Stream Based on LSTMAM",
    "authors": "Jinfeng Zhang, Yuezhong Zhang, Yabing Peng, Zhen Zhang, Yupeng Zhang, Shaoxun Liu",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11323157",
    "source": "IEEE",
    "abstract": "During the transmission of Controller Area Network (CAN) data streams in intelligent connected vehicles, security risks such as non-compliant data reporting and cross-border data leakage inevitably arise. Traditional anomaly detection methods based on statistics and machine learning often fail to comprehensively identify irregularities in the content of transmitted data. To overcome the limitation, this paper proposes an anomaly detection approach for CAN data streams that integrates a heterogeneous Long Short-Term Memory (LSTM) model with an Attention Mechanism (AM). First, periodic characteristics at the byte level within CAN message fields are statistically analyzed, revealing distinctive inter-byte feature variations. Based on the periodicity of each byte-level data stream, a heterogeneous LSTM model incorporating varied parameters-such as time step size and network width-is designed. A corresponding detection framework leveraging heterogeneous LSTM with AM (LSTMAM) is introduced. Furthermore, a fusion strategy between LSTM and the attention mechanism is developed to weight the influence of different hidden states on prediction outcomes. Finally, comparative experiments under various attack scenarios were conducted utilizing publicly available and vehicle-collected CAN message datasets. Comparative results demonstrate that the proposed method significantly improves detection accuracy over existing approaches, validating its effectiveness at identifying anomalies in CAN data streams.",
    "title_zh": "基于LSTMAM的车辆数据流异常检测",
    "abstract_zh": "在智能网联汽车的控制器局域网络（CAN）数据流传输过程中，不可避免地会出现数据违规上报、跨域数据泄露等安全风险。传统的基于统计和机器学习的异常检测方法往往难以全面识别传输数据内容中的异常行为。为克服这一局限性，本文提出一种融合异构长短期记忆网络（LSTM）与注意力机制（AM）的CAN数据流异常检测方法。首先，对CAN消息字段中字节级别的周期性特征进行统计分析，揭示了字节间特征变化的显著差异。基于各字节级数据流的周期特性，设计了一种引入不同参数（如时间步长和网络宽度）的异构LSTM模型，并提出了一个结合异构LSTM与注意力机制（LSTMAM）的检测框架。此外，还构建了LSTM与注意力机制之间的融合策略，以加权不同隐藏状态对预测结果的影响。最后，利用公开可获取及车辆采集的CAN消息数据集，在多种攻击场景下进行了对比实验。实验结果表明，所提方法相较于现有技术显著提升了检测准确率，验证了其在识别CAN数据流异常方面的有效性。"
  },
  {
    "date": "2026-1-14",
    "title": "Test Case Enhanced Self-Iterative Code Generation Framework",
    "authors": "Tianyou Chang, Yupeng Zhang, Yujie Fang",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11322891",
    "source": "IEEE",
    "abstract": "In the field of code generation, large language models(LLMs) have made significant advancements. In addition to straightforward code generation, the latest research integrates unit testing and debuggers into the code generation process of LLMs. This approach enables the large models to self-improve the generated code by incorporating feedback from test results. However, the current method relies only on a small number of test cases for code debugging, making it difficult to cover various scenarios and edge conditions of the program, especially in cases involving complex logic or extensive data operations. To address this issue, the paper proposes a Test Case Enhanced Self-Iterative code generation framework (TEI). This is a novel solution comprising analysts, designers, developers, and testers. Analysts and designers are responsible for refining code requirements and designing structured solutions, respectively. Developers encode based on the refined requirements and design solutions. Testers are required, firstly, to design multiple comprehensive, detailed, and precise test cases based on a given test case, and secondly, to systematically verify the generated code block by block and report its correctness and any potential errors, in order to provide feedback to the analysts in the next iteration. The experimental results demonstrate that our proposed framework (TEI), when using GPT-3.5 as the agent, outperforms existing code generation models and methods significantly. For instance, our approach achieves an 88.4% pass@1 rate in the HumanEval benchmarks, surpassing the previously state-of-the-art GPT-4, which only achieved 85.4%. We also investigated the accuracy of augmented test cases and their impact on the overall quality of code generation within the framework. “Failure is simply the opportunity to begin again, this time more intelligently.” Henry Ford",
    "title_zh": "测试用例增强的自迭代代码生成框架",
    "abstract_zh": "在代码生成领域，大型语言模型（LLMs）已取得显著进展。除了直接生成代码外，最新的研究将单元测试和调试器融入到LLM的代码生成流程中。这一方法使大型模型能够通过测试结果反馈来自我优化生成的代码。然而，当前的方法仅依赖少量测试用例进行代码调试，难以覆盖程序的各种场景和边界条件，尤其是在涉及复杂逻辑或大规模数据操作的情况下。为解决这一问题，本文提出了一种测试用例增强的自迭代代码生成框架（TEI）。该框架创新性地融合了分析师、设计师、开发者与测试员的角色：分析师负责细化代码需求，设计师则负责设计结构化解决方案；开发者根据优化后的需求和设计方案进行编码；测试员则需首先基于给定的测试用例，设计出多个全面、详尽且精确的测试用例；其次，对生成的代码块逐块系统性验证，并报告其正确性及潜在错误，从而为下一轮迭代中的分析师提供反馈。实验结果表明，当以GPT-3.5作为代理时，我们提出的TEI框架在性能上显著优于现有的代码生成模型与方法。例如，在HumanEval基准测试中，我们的方法达到了88.4%的pass@1率，超越此前最先进的GPT-4（仅达到85.4%）。此外，我们还深入研究了增强测试用例的准确性及其对框架整体代码生成质量的影响。“失败只是重新开始的机会，但这一次更明智些。”——亨利·福特"
  },
  {
    "date": "2026-1-14",
    "title": "A Framework for Digital Intelligent Anomaly Control in High-End Equipment Design and Manufacturing",
    "authors": "Ruoyi Sun, Yuxiang Ma, Shiduo Ning, Jing Ma, Chao Wei, Yanjun Shi",
    "publish": "2025 6th International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE)",
    "url": "https://doi.org/10.1109/icbaie66852.2025.11326617",
    "source": "IEEE",
    "abstract": "High-end manufacturing sectors such as aerospace, marine vessels, rail transportation, energy power, and information electronics impose extremely demanding requirements on manufacturing technologies, and face challenges including multi-variety production, small batch sizes, high reliability, high consistency, and complex manufacturing processes. Meanwhile, production anomalies occur throughout the entire manufacturing flow, and traditional anomaly management methods—plagued by data fragmentation, delayed feedback, and inflexible scheduling—are increasingly inadequate to meet the practical needs of high-end equipment manufacturing. To address this bottleneck, a framework of digital-intelligent anomaly control in the design and manufacturing of high-end equipment is proposed. This framework establishes a key technological system for a collaborative closed loop of “design-scheduling-control” tailored to complex manufacturing requirements, which includes: a large language model(LLM)-driven design approach; a knowledge- and data-fusion driven proactive-reactive scheduling method for smart workshops; and a cloud-edge-device collaborative digital twin control method. By reshaping conventional anomaly management processes through digital-intelligent technologies, this model effectively supports flexible production and high-precision control in multi-variety, small-batch manufacturing scenarios, thereby enhancing the batch production capability of complex products.",
    "title_zh": "高端装备设计与制造中的数字化智能异常控制框架",
    "abstract_zh": "航空航天、船舶制造、轨道交通、能源电力、信息电子等高端制造领域对制造技术提出了极为严苛的要求，面临多品种、小批量、高可靠性、高一致性以及复杂制造工艺等诸多挑战。同时，生产过程中的异常现象贯穿于整个制造流程，而传统的异常管理方法由于存在数据割裂、反馈滞后、排程僵化等问题，已难以满足高端装备制造业的实际需求。为突破这一瓶颈，本文提出了一种面向高端装备设计与制造的数字智能异常控制框架。该框架构建了一个面向复杂制造需求的“设计-排程-控制”协同闭环关键技术体系，主要包括：基于大语言模型（LLM）驱动的设计方法；融合知识与数据的智能车间主动-响应式排程方法；以及云-边-端协同的数字孪生控制方法。通过数字智能技术重塑传统异常管理流程，该模型有效支撑了多品种、小批量制造场景下的柔性生产与高精度控制，显著提升了复杂产品的批产能力。"
  },
  {
    "date": "2026-1-14",
    "title": "Research on Software Defect Detection Method Based on Changing Location Lightweight Map Data",
    "authors": "Jingdong Wang, Guiwen Ta, Fanqi Meng",
    "publish": "2025 IEEE 31th International Conference on Parallel and Distributed Systems (ICPADS)",
    "url": "https://doi.org/10.1109/icpads67057.2025.11322990",
    "source": "IEEE",
    "abstract": "Aiming at the problems such as large memory occupation and slow speed caused by excessive data usage when using the graph-based representation method to detect defects in the software source code during the software update and maintenance process, a lightweight defect detection method for graph data based on the source code change position is proposed. The innovation point lies in that during the data preprocessing process, after fully extracting the dependency relationships between source code statements and the semantic information of the statements by constructing the program dependency graph through extracting source code data, the content and location of the source code changes in one submission are determined, thereby inferring the parts that have an impact on the source code in one change. Ultimately, the amount of data is reduced by pruning the dependency graph to remove the parts that do not participate in the change and are not affected by the change, thereby reducing the computational overhead. The processed data is more suitable for defect detection during software update and maintenance, overcoming the problem of excessive quantity caused by the original graph-based preprocessing method, and thus optimizing the effect of the model. Through experimental verification, this method reduces the data volume by approximately <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$58.91 / \\%$</tex> on the dataset constructed with jmeter, lowers the runtime memory usage by approximately 35.89 %, and increases the speed by approximately 41.87 %. And verified through the log information of the libgdx software, there are obvious changes in the above three aspects.",
    "title_zh": "基于变更位置轻量级地图数据的软件缺陷检测方法研究",
    "abstract_zh": "针对在软件更新与维护过程中，采用基于图的表示方法检测源代码缺陷时，因数据使用量过大导致内存占用高、运行速度慢等问题，本文提出一种基于源代码变更位置的轻量级图数据缺陷检测方法。其创新点在于：在数据预处理阶段，通过提取源代码数据构建程序依赖图，充分挖掘源代码语句间的依赖关系及语义信息后，确定单次提交中源代码变更的内容与位置，进而推断出受该变更影响的代码部分。最终，通过剪枝操作去除未参与变更且不受变更影响的图结构部分，有效减少数据量，降低计算开销。经过处理的数据更适用于软件更新与维护过程中的缺陷检测，克服了原有基于图的预处理方法因数据量过大带来的问题，从而优化了模型效果。实验验证表明，该方法在基于JMeter构建的数据集上，数据量减少了约58.91%，运行时内存占用降低了约35.89%，执行速度提升了约41.87%；并通过libgdx软件的日志信息验证，上述三方面均表现出显著改善。"
  },
  {
    "date": "2026-1-14",
    "title": "AI-Augmented risk mitigation framework for legacy healthcare applications lacking SAST compatibility",
    "authors": "Arpna Aggarwal, Harikrishnan Muthukrishnan, Rahul Bhatia",
    "publish": "2025 IEEE Cyber Science and Technology Congress (CyberSciTech)",
    "url": "https://doi.org/10.1109/cyberscitech68397.2025.00132",
    "source": "IEEE",
    "abstract": "In today’s regulated and digitized healthcare environment, securing legacy applications remains a critical challenge. Static Application Security Testing (SAST) tools are indispensable in modern DevSecOps pipelines; yet many healthcare systems still rely on outdated platforms that cannot integrate with these tools. This incompatibility creates blind spots that expose sensitive data and critical operations to breaches.This research addresses the urgent gap in risk assessment and mitigation where SAST integration is infeasible. We propose a fallback security framework that combines AI-augmented, human-in-the-loop vulnerability scoring with behavior-based anomaly detection, offering adaptive protection for legacy applications. Our framework also includes a comparative matrix of SAST tool compatibility with legacy technologies and compensating controls tailored to healthcare environments.Through analysis of healthcare compliance requirements, such as the Health Insurance Portability and Accountability Act (HIPAA), case studies from payer and provider systems, and mapping of control gaps, we demonstrate how legacy incompatibility amplifies exposure to cyberattacks, downtime, and regulatory failures. The findings highlight that while modernization is essential, organizations can mitigate risk through the implementation of layered governance, staff training, and phased deployment of security controls.This framework operates transformer-based code translation models and machine learning-driven behavioral anomaly detection, enabling legacy risk remediation to move from theoretical to actionable in real-time DevSecOps pipelines.",
    "title_zh": "缺乏SAST兼容性的遗留医疗应用的AI增强型风险缓解框架",
    "abstract_zh": "在当今受监管且高度数字化的医疗保健环境中，保护遗留应用程序仍是一项关键挑战。静态应用安全测试（SAST）工具在现代DevSecOps流程中不可或缺；然而，许多医疗系统仍依赖于无法与这些工具集成的过时平台。这种不兼容性造成了安全盲点，使敏感数据和关键业务操作面临被攻击的风险。\n\n本研究针对SAST集成不可行情况下的风险评估与缓解存在紧迫缺口的问题，提出了一种备用安全框架。该框架结合了AI增强的人工介入漏洞评分机制与基于行为的异常检测技术，为遗留应用程序提供自适应的安全防护。此外，框架还包含一个SAST工具与遗留技术兼容性的对比矩阵，以及专为医疗环境设计的补偿性控制措施。\n\n通过分析医疗合规要求（如《健康保险可携性和责任法案》HIPAA）、来自支付方和医疗机构系统的案例研究，以及对控制差距的映射，我们证明了遗留系统不兼容性如何加剧遭受网络攻击、系统停机和监管违规的风险。研究结果表明，尽管现代化改造至关重要，但组织可通过实施分层治理、员工培训以及分阶段部署安全控制措施来有效降低风险。\n\n该框架采用基于Transformer的代码翻译模型和由机器学习驱动的行为异常检测技术，使遗留系统风险修复从理论走向实时、可操作的DevSecOps流程，真正实现动态响应与持续防护。"
  },
  {
    "date": "2026-1-14",
    "title": "New Approach to Optimize Vulnerabilities Management of Smart Contract in Blockchain Network",
    "authors": "Z. H. Randriamiarison, H. Razafimahatratra, N. R Razafindrakoto, Y. Rhazali",
    "publish": "2025 11th International Conference on Control, Decision and Information Technologies (CoDIT)",
    "url": "https://doi.org/10.1109/codit66093.2025.11321553",
    "source": "IEEE",
    "abstract": "Blockchain technology is gaining popularity today, replacing centralized data storage on a central server with a decentralized network of ledgers, thus ensuring secure information exchange. A smart contract is a program written on the blockchain that runs autonomously within the Ethereum virtual machine: a transparent and secure program, but once deployed on the blockchain network, it cannot be modified. Despite its advantage over other technologies, smart contract has become a prime target for hackers, making it difficult for developers to eliminate all vulnerabilities before its deployment. In this paper, we propose a static analysis approach aimed at reducing vulnerabilities in smart contract. Our method builds upon PASO (Parser for Solidity) and MSmart approaches: we developed a test lifecycle model for smart contracts and created a tool based on ANTLR4's G4 grammar. It involves both syntactic and lexical analysis to effectively detect bugs and vulnerabilities in smart contract. To validate our method, we used FDR (False Discovery Rate) and FNR (False Negative Rate) as evaluation metrics, data collected from SmartBugs and Etherscan. We validated our approach compared with MSmart and SmartCheck. We got higher FDR and improved FNR, indicating enhanced detection capabilities. After thorough analysis and extensive testing, our tool has proven to be both specific and high-performing.",
    "title_zh": "区块链网络中智能合约漏洞管理的新方法优化",
    "abstract_zh": "区块链技术如今日益流行，它通过去中心化的账本网络取代了集中式数据存储于中央服务器的方式，从而确保信息交换的安全性。智能合约是编写在区块链上的程序，它在以太坊虚拟机（EVM）中自主运行：具有透明性和安全性，但一旦部署到区块链网络上便无法修改。尽管相较于其他技术具备诸多优势，智能合约却已成为黑客攻击的主要目标，使得开发者难以在部署前彻底消除所有漏洞。本文提出一种静态分析方法，旨在减少智能合约中的漏洞。我们的方法基于PASO（Solidity解析器）和MSmart方法，构建了智能合约的测试生命周期模型，并基于ANTLR4的G4语法开发了一款分析工具。该工具结合词法分析与语法分析，能够有效检测智能合约中的缺陷与安全漏洞。为验证所提方法的有效性，我们采用FDR（假阳性率）和FNR（假阴性率）作为评估指标，使用来自SmartBugs和Etherscan的数据进行测试。与MSmart和SmartCheck相比，我们的方法表现出更高的FDR值和更低的FNR值，表明其漏洞检测能力显著提升。经过全面分析与大量测试，验证了该工具具备高准确率与高性能。"
  }
]