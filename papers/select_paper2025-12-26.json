[
  {
    "date": "2025-12-26",
    "title": "Agentic AI Serverless Code Generation: Towards Autonomous Improvement of Performance, Cost, and Code Quality",
    "authors": "Xinghan Chen",
    "publish": "Proceedings of the 26th International Middleware Conference",
    "url": "https://doi.org/10.1145/3721464.3777437",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "代理式AI无服务器代码生成：迈向性能、成本与代码质量的自主优化",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-26",
    "title": "LogiDiag: Diagnostic Planner-Guided Reasoning With LLMs for Logical Anomaly Diagnosis",
    "authors": "Qirui Bai, Shuangwu Chen, Yuxing Wei, Dong Jin, Qirui Chen, Yu Guo, Xiaobin Tan, Jian Yang",
    "publish": "IEEE Transactions on Industrial Informatics",
    "url": "https://doi.org/10.1109/tii.2025.3642274",
    "source": "IEEE",
    "abstract": "Logical anomalies occur when a product's assembly violates prescribed logical rules, which widely exist in industrial assembly and packaging processes. Due to the difficulty in comprehending such complex logical relationships, a paucity of research has focused on the industrial logical anomaly diagnosis (LAD). Recently, large language models (LLMs) have demonstrated strong semantic understanding and zero-shot reasoning capabilities, making them a promising tool for LAD. However, directly applying LLMs to LAD still face two critical challenges: 1) the scarcity of abnormal samples in real-world settings, and 2) the propensity of LLMs to generate hallucinated or unreliable diagnostic conclusions. To address these challenges, we propose LogiDiag, a novel diagnostic reasoning method for LAD, to pinpoint where and why a product fails to comply with the logical rules, thereby elevating product quality and reducing remedial intervention cost. We design a visual descriptor that identifies product component attributes even in out-of-distribution abnormal images and organizes them into component descriptions for LLMs' comprehension. To mitigate hallucinations, we devise a planner to guide LLMs in diagnostic reasoning through rule orchestration, tool allocation, and chain-of-diagnosis generation. Experimental results on multiple benchmark datasets validate the competitive performance of LogiDiag.",
    "title_zh": "LogiDiag：基于诊断规划的大型语言模型逻辑异常诊断推理",
    "abstract_zh": "逻辑异常是指产品装配过程违反了预定的逻辑规则，这类问题广泛存在于工业装配与包装流程中。由于理解这些复杂逻辑关系的难度较大，针对工业逻辑异常诊断（Logical Anomaly Diagnosis, LAD）的研究相对匮乏。近年来，大语言模型（LLMs）展现出强大的语义理解能力与零样本推理能力，为LAD提供了极具前景的解决方案。然而，直接将LLMs应用于LAD仍面临两大关键挑战：1）真实场景中异常样本稀缺；2）LLMs容易生成幻觉或不可靠的诊断结论。为应对上述挑战，我们提出LogiDiag——一种新型的LAD诊断推理方法，能够精准定位产品违反逻辑规则的具体位置及其原因，从而提升产品质量并降低后续修复成本。我们设计了一种视觉描述符，能够在分布外的异常图像中识别产品组件属性，并将其组织成便于LLM理解的组件描述。为抑制幻觉现象，我们进一步设计了一个规划器，通过规则编排、工具分配以及诊断链生成，引导LLM进行系统化诊断推理。在多个基准数据集上的实验结果验证了LogiDiag具有竞争力的性能表现。"
  },
  {
    "date": "2025-12-26",
    "title": "Demo: Detecting Data-Leak Using NVIDIA Morpheus",
    "authors": "Saoni Mukherjee, Bhavesh A. Patel",
    "publish": "2025 13th Wireless Days Conference (WD)",
    "url": "https://doi.org/10.1109/wd67713.2025.11302615",
    "source": "IEEE",
    "abstract": "As Artificial Intelligence (AI) adoption accelerates across industries, the need for robust real-time cybersecurity solutions becomes increasingly critical. Traditional security frameworks that rely on static rules, signature-based detection, and threshold alerts struggle to detect sophisticated identity-based attacks that exploit behavioral anomalies rather than explicit policy violations. These limitations, combined with the growing volume of telemetry data and the latency of conventional detection methods, leave organizations vulnerable to prolonged breaches and data exfiltration. This paper presents a use case with a scalable, AI-driven approach to sensitive data leak detection using NVIDIA Morpheus, a GPU-accelerated cybersecurity framework. We demonstrate how Morpheus, in conjunction with NVIDIA BlueField DPUs and DOCA, enables high-throughput, low-latency inspection of real-time network telemetry without impacting system performance. The solution leverages a pre-trained NLP-based Sensitive Information Detection model capable of identifying ten categories of sensitive data within packet payloads, including credentials, PII, and cryptographic keys. Network-captured PCAP data serialized in JSONlines format passes through a linear, feed-forward Morpheus pipeline, configured via CLI and powered by Triton Inference Server with dynamic batching for optimized inference. The final output provides binary classification results that indicate the presence or absence of sensitive information. This case study illustrates how AI-enhanced telemetry analysis can significantly reduce detection and response times, offering a proactive defense mechanism against modern cyber threats.",
    "title_zh": "演示：使用NVIDIA Morpheus检测数据泄露",
    "abstract_zh": "随着人工智能（AI）在各行业的应用不断加速，对强大实时网络安全解决方案的需求变得日益紧迫。传统的安全框架依赖静态规则、基于签名的检测以及阈值告警，难以有效识别那些利用行为异常而非明确策略违规的身份攻击。这些局限性，加之海量遥测数据的增长和传统检测方法的延迟问题，使组织面临长期渗透和数据外泄的风险。本文提出一个典型案例，展示了一种可扩展的AI驱动方法，利用NVIDIA Morpheus——一种GPU加速的网络安全框架，实现敏感数据泄露的实时检测。我们证明，Morpheus结合NVIDIA BlueField DPU与DOCA技术，能够在不影响系统性能的前提下，对实时网络遥测数据进行高吞吐、低延迟的深度检查。该方案采用预先训练的基于自然语言处理（NLP）的敏感信息检测模型，能够识别数据包载荷中的十类敏感信息，包括凭据、个人身份信息（PII）及加密密钥等。通过JSONlines格式序列化的网络捕获PCAP数据，经由线性前馈的Morpheus处理管道，该管道通过命令行界面（CLI）配置，并由Triton推理服务器支持动态批处理以优化推理效率。最终输出为二分类结果，明确指示敏感信息是否存在。本案例研究展示了AI增强的遥测分析如何显著缩短检测与响应时间，为应对现代网络威胁提供主动防御机制。"
  },
  {
    "date": "2025-12-26",
    "title": "Scaling Inter-procedural Dataflow Analysis on the Cloud",
    "authors": "Zewen Sun, Yujin Zhang, Yueyang Wang, Duanchen Xu, Yiyu Zhang, Yun Qi, Zhaokang Wang, Yue Li, Xuandong Li, Qingda Lu, Wenwen Peng, Shengjian Guo, Zhiqiang Zuo",
    "publish": "ACM Transactions on Programming Languages and Systems",
    "url": "https://doi.org/10.1145/3786763",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "在云上扩展过程间数据流分析",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-26",
    "title": "ARM: Autonomous Remediation &amp; Management with LLM Agents for Intent-Driven Control",
    "authors": "Vasilis Avgerinos, Kostas Ramantas, Luis Alonso, Christos Verikoukis",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2025.3648858",
    "source": "IEEE",
    "abstract": "The growing complexity of cloud-native, edge, and IoT infrastructures has made manual configuration, fault remediation, and lifecycle management increasingly unsustainable. Traditional automation techniques—such as rule-based logic or bespoke machine learning pipelines—struggle with adaptability and explainability in dynamic environments. Recent advances in Large Language Models (LLMs), however, have introduced new opportunities for autonomous, intent-driven infrastructure control. In this work, we present a closed-loop framework that integrates LLM agents for automated Root Cause Analysis (RCA) and mitigation of faults within cloud-edge and IoT systems. When SLA violations are detected, the agent identifies likely root causes and selects corrective actions—such as pod rescheduling, scaling, or configuration updates—executed via a Model Context Protocol (MCP) server exposing management tool functionalities through an API. This RCA-plus-mitigation loop enables fault handling that is both explainable and adaptive. We evaluate our system on a cluster running synthetic IoT workloads under emulated stressors using a reproducible benchmarking setup. Results show that the agent identifies SLA violations with 52.9% accuracy and mitigates 70.7% of them successfully. Notably, the agent incorporates validation steps to ensure system stability after interventions. These findings highlight the feasibility of LLMs for real-time infrastructure healing and their potential role in future AIOps workflows.",
    "title_zh": "ARM：基于大语言模型代理的自主修复与管理，实现意图驱动控制",
    "abstract_zh": "云原生、边缘计算及物联网基础设施的日益复杂，使得手动配置、故障修复和生命周期管理变得越来越不可持续。传统的自动化技术——如基于规则的逻辑或定制化的机器学习流程——在动态环境中难以实现足够的适应性和可解释性。然而，大型语言模型（LLMs）的最新进展为实现自主、意图驱动的基础设施控制带来了新的机遇。本文提出一个闭环框架，将LLM智能体集成于云-边及物联网系统中，实现故障的自动根因分析（RCA）与应对。当检测到服务等级协议（SLA）违规时，智能体能够识别潜在的根本原因，并选择相应的纠正措施，如Pod重新调度、扩容或配置更新，这些操作通过Model Context Protocol（MCP）服务器执行，该服务器以API形式暴露管理工具的功能。这一“根因分析+修复”闭环机制实现了既可解释又具备自适应能力的故障处理。我们在一个运行合成物联网工作负载的集群上，采用可复现的基准测试环境对系统进行了评估。结果表明，该智能体对SLA违规的识别准确率达到52.9%，成功缓解了70.7%的违规情况。值得注意的是，智能体在干预后引入了验证步骤，以确保系统稳定性。这些发现证明了LLM在实时基础设施修复中的可行性，也凸显其在未来AIOps工作流中的巨大潜力。"
  },
  {
    "date": "2025-12-26",
    "title": "Network-Layer Differential Fuzzing for Ethereum",
    "authors": "Fudong Wu, Qianhong Wu, Jia-Ju Bai, Bo Qin, Zhenyu Guan, Willy Susilo",
    "publish": "IEEE Transactions on Information Forensics and Security",
    "url": "https://doi.org/10.1109/tifs.2025.3648565",
    "source": "IEEE",
    "abstract": "In Ethereum, DevP2P is the fundamental network-layer protocol set that supports consensus mechanisms, transaction propagation and smart contract execution. Due to the importance of DevP2P, its bugs can be exploited by the attacker to cause security problems like denial of service, leading to property loss on Ethereum. However, existing blockchain testing approaches focus on the bug detection of consensus and application layers, causing many serious DevP2P bugs to be missed. In fact, detecting DevP2P bugs has some key challenges, including how to generate effective inputs and how to detect complex bugs. This paper designs D2PFuzz, the first network-layer differential fuzzing approach of bug detection for Ethereum. It consists of two key techniques: (1) a <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">query-based fuzzing strategy</i> that dynamically generates valid DevP2P messages according to network, chain and node state changes; and (2) a <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">multi-node differential checking method</i> that identifies important differences of DevP2P response messages from multiple nodes in the same blockchain to detect semantic bugs. We have evaluated D2PFuzz on five open-source and popular Ethereum node implementations, including Geth, Erigon, Reth, Besu and Nethermind. D2PFuzz in total finds 15 unique bugs, 12 of which are previously unknown. Compared to two state-of-the-art blockchain testing approaches including LOKI and Hive, D2PFuzz improves testing coverage by 3.7x and 21.6x, respectively, and finds 13 bugs missed by these approaches.",
    "title_zh": "以太坊网络层差异模糊测试",
    "abstract_zh": "在以太坊中，DevP2P 是支持共识机制、交易传播和智能合约执行的基础网络层协议集。由于 DevP2P 的重要性，其漏洞可能被攻击者利用，引发拒绝服务等安全问题，导致以太坊上的资产损失。然而，现有的区块链测试方法主要关注共识层和应用层的缺陷检测，导致许多严重的 DevP2P 层漏洞被遗漏。事实上，检测 DevP2P 层漏洞面临若干关键挑战，包括如何生成有效的输入数据以及如何发现复杂的语义错误。本文提出 D2PFuzz，这是首个针对以太坊网络层的差分 fuzzing 漏洞检测方法。该方法包含两项核心技术：（1）一种基于查询的 fuzzing 策略，能够根据网络状态、链状态及节点状态的变化动态生成合法的 DevP2P 消息；（2）一种多节点差分校验方法，通过比较同一区块链中多个节点对相同请求的响应消息，识别出重要的差异，从而检测出语义层面的漏洞。我们在五个主流且开源的以太坊节点实现（Geth、Erigon、Reth、Besu 和 Nethermind）上对 D2PFuzz 进行了评估，共发现了 15 个独特的漏洞，其中 12 个为此前未知的漏洞。与当前最先进的区块链测试工具 LOKI 和 Hive 相比，D2PFuzz 分别将测试覆盖率提升了 3.7 倍和 21.6 倍，并发现了 13 个这两种方法所遗漏的漏洞。"
  },
  {
    "date": "2025-12-26",
    "title": "In-Context Example Ordering for LLM-Based API Sequence Generation",
    "authors": "Rahul Atul Bhope, Praveen Venkateswaran, K. R. Jayaram, Vatche Isahagian, Vinod Muthusamy, Nalini Venkatasubramanian",
    "publish": "Proceedings of the 26th International Middleware Conference",
    "url": "https://doi.org/10.1145/3721464.3777432",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于大语言模型的API序列生成中的上下文示例排序",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-26",
    "title": "A Unified Multi-Label Code Smell Dataset for Code Smell Detection at Different Granularities",
    "authors": "Haneen Alhadeaf, Mubarak Alrashoud",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3648907",
    "source": "IEEE",
    "abstract": "Code smell detection is critical for maintaining software quality and enabling effective refactoring, yet much prior work identifies only one smell at a time. This single-label framing misses the real-world complexity where a code element can exhibit multiple co-occurring smells. We address this gap by creating a unified multi-label dataset that combines four existing datasets at two levels—method-level and class-level—covering Long Method (LM), Feature Envy (FE), God Class (GC), and Data Class (DC). Our approach models correlations (co-occurrence) among these smells and links them to Feature Importance analyses to identify the metrics that drive each label. We evaluate three multi-label strategies—Binary Relevance, Label Powerset, and Classifier Chains—paired with Decision Tree and Random Forest.We used a 5-fold stratified cross-validation for each single-level dataset. To prevent data leakage, we implemented a 5-fold GroupKFold for the unified dataset, along with an in-fold grid search for hyperparameter tuning. Performance is reported via Jaccard, Hamming Loss, and Exact Match. On the unified Truth-only dataset, Classifier Chains with Random Forest achieves the highest Jaccard (0.3351), while Binary Relevance with Random Forest attains the lowest Hamming Loss (0.0288) and the highest Exact Match (0.8847). Overall, the unified dataset enables simultaneous detection of multiple smells in one model and protocol, reveals where inter-label correlations are informative (LM–FE) and where they are not (GC–DC), and maintains distribution properties for fair comparison, yielding results that are more realistic and easier to reuse.",
    "title_zh": "一种统一的多标签代码异味数据集，用于不同粒度的代码异味检测",
    "abstract_zh": "代码异味检测对于维护软件质量及实现有效重构至关重要，然而以往的许多研究仅能识别单一异味。这种单标签框架忽略了现实世界中代码元素可能同时表现出多种共现异味的复杂性。为弥补这一不足，我们构建了一个统一的多标签数据集，该数据集在方法级和类级两个层次上整合了四个现有数据集，涵盖长方法（LM）、特征依恋（FE）、上帝类（GC）和数据类（DC）四种异味。我们的方法建模了这些异味之间的相关性（共现关系），并结合特征重要性分析，识别出驱动每个标签的关键度量指标。\n\n我们评估了三种多标签策略——二元相关（Binary Relevance）、标签幂集（Label Powerset）和分类器链（Classifier Chains），分别与决策树和随机森林模型相结合。针对每个单层次数据集，采用5折分层交叉验证进行评估；为防止数据泄露，对统一数据集采用5折分组K折交叉验证（GroupKFold），并在每折内进行网格搜索以优化超参数。性能指标采用Jaccard相似系数、汉明损失（Hamming Loss）和精确匹配率（Exact Match）。\n\n在统一的“真值”数据集上，分类器链配合随机森林取得了最高的Jaccard分数（0.3351）；而二元相关配合随机森林则实现了最低的汉明损失（0.0288）和最高的精确匹配率（0.8847）。总体而言，该统一数据集使得一个模型和一套流程即可同时检测多种异味，揭示了标签间相关性的信息价值（如LM–FE之间存在显著关联），也指出了无关关联（如GC–DC之间无明显关联），同时保持了数据分布特性，便于公平比较。最终结果更加贴近实际场景，且具有更高的可复用性。"
  }
]