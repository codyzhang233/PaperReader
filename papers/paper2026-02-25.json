[
  {
    "date": "2026-02-25",
    "title": "Spreading dynamics for the Lotka-Volterra system with general initial supports: the strong competition",
    "authors": "Hongjun Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21537v1",
    "source": "arXiv",
    "abstract": "This paper studies the spreading dynamics of a high-dimensional strong competition Lotka-Volterra system where two species initially occupy disjoint measurable (possibly unbounded) subsets in $\\mathbb{R}^N$, which are called initial support. Recently, Hamel and Rossi [14] introduced some new geometric notions, such as bounded or unbounded directions and positive-distance interior, for single-species equations with general initial supports. Under these notions and appropriate assumptions, we characterize directional spreading behavior for the two-species system: precise spreading speeds and sets for both species are derived."
  },
  {
    "date": "2026-02-25",
    "title": "ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning",
    "authors": "Xiaoxuan Wang, Han Zhang, Haixin Wang, Yidan Shi, Ruoyan Li, Kaiqiao Han, Chenyi Tong, Haoran Deng, Renliang Sun, Alexander Taylor, Yanqiao Zhu, Jason Cong, Yizhou Sun, Wei Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21534v1",
    "source": "arXiv",
    "abstract": "Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines."
  },
  {
    "date": "2026-02-25",
    "title": "TM-RUGPULL: A Temporary Sound, Multimodal Dataset for Early Detection of RUG Pulls Across the Tokenized Ecosystem",
    "authors": "Fatemeh Shoaei, Mohammad Pishdar, Mozafar Bag-Mohammadi, Mojtaba Karami",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21529v1",
    "source": "arXiv",
    "abstract": "Rug-pull attacks pose a systemic threat across the blockchain ecosystem, yet research into early detection is hindered by the lack of scientific-grade datasets. Existing resources often suffer from temporal data leakage, narrow modality, and ambiguous labeling, particularly outside DeFi contexts. To address these limitations, we present TM-RugPull, a rigorously curated, leakage-resistant dataset of 1,028 token projects spanning DeFi, meme coins, NFTs, and celebrity-themed tokens. RugPull enforces strict temporal hygiene by extracting all features on chain behavior, smart contract metadata, and OSINT signals strictly from the first half of each project's lifespan. Labels are grounded in forensic reports and longevity criteria, verified through multi-expert consensus. This dataset enables causally valid, multimodal analysis of rug-pull dynamics and establishes a new benchmark for reproducible fraud detection research."
  },
  {
    "date": "2026-02-25",
    "title": "2-dimensional unit vector flows",
    "authors": "Hussein Houdrouge, Bobby Miraftab, Pat Morin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21526v1",
    "source": "arXiv",
    "abstract": "We study $2$-dimensional unit vector flows on graphs, that is, nowhere-zero flows that assign to each oriented edge a unit vector in $\\mathbb R^{3}$. We give a new geometric characterization of $\\mathbb S^{2}$-flows on cubic graphs. We also prove that the class of cubic graphs admitting an $\\mathbb S^{2}$-flow is closed under a natural composition operation, which yields further constructions; in particular, blowing up a vertex into a triangle preserves the existence of an $\\mathbb S^{2}$-flow. Our second contribution is algebraic: we extend the rank-based approach of [SIAM J. Discrete Math., 29 (2015), pp.~2166--2178] from $\\mathbb S^{1}$-flows to $\\mathbb S^{2}$-flows. More precisely, we show that if an $\\mathbb S^{2}$-flow $\\varphi$ satisfies $\\operatorname{rank}(S_{\\mathbb{Q}}(\\varphi))\\le 2$ and $S_{\\mathbb{Q}}(\\varphi)$ is odd-coordinate-free, then the graph admits a nowhere-zero $4$-flow."
  },
  {
    "date": "2026-02-25",
    "title": "Quantum Attacks Targeting Nuclear Power Plants: Threat Analysis, Defense and Mitigation Strategies",
    "authors": "Yaser Baseri, Edward Waller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21524v1",
    "source": "arXiv",
    "abstract": "The advent of Cryptographically Relevant Quantum Computers (CRQCs) presents a fundamental and existential threat to the forensic integrity and operational safety of Industrial Control Systems (ICS) and Operational Technology (OT) in critical infrastructure. This paper introduces a novel, forensics-first framework for achieving quantum resilience in high-consequence environments, with a specific focus on nuclear power plants. We systematically analyze the quantum threat landscape across the Purdue architecture (L0-L5), detailing how Harvest-Now, Decrypt-Later (HNDL) campaigns, enabled by algorithms like Shor's, can retroactively compromise cryptographic foundations, undermine evidence admissibility, and facilitate sophisticated sabotage. Through two detailed case studies, \\textsc{Quantum~Scar} and \\textsc{Quantum~Dawn}, we demonstrate multi-phase attack methodologies where state-level adversaries exploit cryptographic monoculture and extended OT lifecycles to degrade safety systems while creating unsolvable forensic paradoxes. Our probabilistic risk modeling reveals alarming success probabilities (up to 78\\% for targeted facilities under current defenses), underscoring the criticality of immediate action. In response, we propose and validate a phased, defense-in-depth migration path to Post-Quantum Cryptography (PQC), integrating hybrid key exchange, cryptographic diversity, secure time synchronization, and side-channel resistant implementations aligned with ISA/IEC 62443 and NIST standards. The paper concludes that without urgent adoption of quantum-resilient controls, the integrity of both physical safety systems and digital forensic evidence remains at severe and irreversible risk."
  },
  {
    "date": "2026-02-25",
    "title": "Energy Layers and Quasi-Superradiant Heat Engines of Schwarzschild Black Holes",
    "authors": "Wen-Xiang Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21521v1",
    "source": "arXiv",
    "abstract": "We examine Schwarzschild black holes within the framework of gravitational thermodynamics, introducing an ``energy layer'' picture for black-hole mass-energy and exploring a possible energy-extraction mechanism termed ``quasi-superradiance.'' Building on the standard relations for Hawking temperature and Bekenstein--Hawking entropy, we formalize energy layers via quasi-local radial energy accounting (e.g.\\ integrating an effective local energy density over spherical shells) and connect this bookkeeping to the free energy $\\FHelm=M-Þ\\SBH$. We then extend the entropy correction ansatz with explicit series inversion and derive higher-order expansions for $Þ(M)$ and $\\FHelm(M)$, including logarithmic and inverse-mass terms. To enhance mathematical transparency, we add intermediate derivations, lemma/theorem statements, and appendices. The quasi-superradiant mechanism is framed as a Carnot-like thought experiment powered by the Tolman temperature gradient between the near-horizon region and infinity; we show that the generalized second law enforces the Carnot bound and yields integrated maximum-work inequalities. Throughout, we stress that the proposal is heuristic and intended as a consistency-checked framework for discussion rather than a claim of definitive new physics."
  },
  {
    "date": "2026-02-25",
    "title": "I/O Optimizations for Graph-Based Disk-Resident Approximate Nearest Neighbor Search: A Design Space Exploration",
    "authors": "Liang Li, Shufeng Gong, Yanan Yang, Yiduo Wang, Jie Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21514v1",
    "source": "arXiv",
    "abstract": "Approximate nearest neighbor (ANN) search on SSD-backed indexes is increasingly I/O-bound (I/O accounts for 70--90\\% of query latency). We present an I/O-first framework for disk-based ANN that organizes techniques along three dimensions: memory layout, disk layout, and search algorithm. We introduce a page-level complexity model that explains how page locality and path length jointly determine page reads, and we validate the model empirically. Using consistent implementations across four public datasets, we quantify both single-factor effects and cross-dimensional synergies. We find that (i) memory-resident navigation and dynamic width provide the strongest standalone gains; (ii) page shuffle and page search are weak alone but complementary together; and (iii) a principled composition, OctopusANN, substantially reduces I/O and achieves 4.1--37.9\\% higher throughput than the state-of-the-art system Starling and 87.5--149.5\\% higher throughput than DiskANN at matched Recall@10=90\\%. Finally, we distill actionable guidelines for selecting storage-centric or hybrid designs across diverse concurrency levels and accuracy constraints, advocating systematic composition rather than isolated tweaks when pushing the performance frontier of disk-based ANN."
  },
  {
    "date": "2026-02-25",
    "title": "Oxygen permeability and stability in the entropy-stabilized Co-based Perovskite oxygen permeable membranes",
    "authors": "Zaichen Xiang, Rui Chen, Shuangyue Wang, Jingjun Qin, Wanyi Zhang, Yucheng Li, Lingyong Zeng, Huixia Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21511v1",
    "source": "arXiv",
    "abstract": "Oxygen transport membranes (OTMs), enabling catalytic reaction and gas separation, support crucial chemical engineering processes and decarbonization technologies, but their applications are hindered by limited oxygen permeation fluxes and inadequate long-term stability during operation. Here, a series of high-entropy perovskite OTMs based on La0.5Sr0.5CoO3 were designed and synthesized by the simple sol-gel method. The impact of varying doping ratios on the structure, surface morphology, oxygen permeability, and stability of these high-entropy OTMs was thoroughly examined. At 950 °C, the optimal composition, La0.25Sr0.25Gd0.2Nd0.2Pr0.1CoO3, achieved oxygen permeation fluxes of 1.62 mL min-1 cm-2 under air/He gradient and 1.46 mL min-1 cm-2 under air/CO2, respectively. Remarkably, all high-entropy OTMs demonstrated stable operation for over 100 h in a pure CO2 environment without a significant decline in performance. This finding paves a new way to enhance the structural and oxygen permeation stability of OTMs, and further promotes the application of OTMs in oxy-fuel combustion technologies aimed at improving CO2 capture and storage efficiency."
  },
  {
    "date": "2026-02-25",
    "title": "Can ranked-choice voting elect the least popular candidate?",
    "authors": "David McCune, Jennifer Wilson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21504v1",
    "source": "arXiv",
    "abstract": "We analyze how frequently instant runoff voting (IRV) selects the weakest (or least popular) candidate in three-candidate elections. We consider four definitions of ``weakest candidate'': the Borda loser, the Bucklin loser, the candidate with the most last-place votes, and the candidate with minimum social utility. We determine the probability that IRV selects the weakest candidate under the impartial anonymous culture and impartial culture models of voter behavior, and use Monte Carlo simulations to estimate these probabilities under several spatial models. We also examine this question empirically using a large dataset of real elections. Our results show that IRV can select the weakest candidates under each of these definitions, but such outcomes are generally rare. Across most models, the probability that IRV elects a given type of weakest candidate is at most 5\\%. Larger probabilities arise only when the electorate is extremely polarized."
  },
  {
    "date": "2026-02-25",
    "title": "A Decade-Long Increasing Mid-Infrared Luminosity in Galaxy NGC6447: a Turning-On Candidate of Active Galactic Nucleus",
    "authors": "Xinyu Dai, Nate Adams, Natalie Kovacevic, Kaitlyn Parrinello, Marko Micic, Heechan Yuk, Zijun Gao, Lorelei Starling, Francesco Shankar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21502v1",
    "source": "arXiv",
    "abstract": "It is widely expected that the obscured accretion stage can be the initial turning-on stage of active galactic nuclei from quiescent galaxies. We present mid-infrared light curves of NGC 6447 in 3.5$μ$m and 4.6 $μ$m bands observed by WISE/NEOWISE, which show an almost monotonic increasing trend of 1.2 mag over 14 years. The optical light curve from ASAS-SN during the same period is consistent with a constant showing no variability. The mid-infrared color evolution shows that the galaxy transitioned into an active galactic nucleus (AGN) in 2018. The SPHEREx spectrum reveals an increasing continuum resembling warm to hot dust emission from an AGN. NuSTAR detected an X-ray source with a 2-30 keV luminosity of $8.4\\times10^{41}$ ergs/s at the lower boundary of AGN X-ray emission range, and a factor of >7 variability in one year compared to the Swift upper limit. NGC 6447 was classified as a quiescent galaxy in the literature. The multi-wavelength timing and spectral properties of NGC 6447 are consistent with the expected AGN turning on event, where the obscuring material around the AGN central engine is gradually dispersed, revealing the central engine. This example shows that long-term infrared variability can be a powerful tool to find similar sources. Based on the sample selection statistics, we estimate the duration of the episodes of AGN accretion (duty cycle) signified by the turning-on event as $10^4$-$10^6$ yr."
  },
  {
    "date": "2026-02-25",
    "title": "A Researcher's Guide to Empirical Risk Minimization",
    "authors": "Lars van der Laan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21501v1",
    "source": "arXiv",
    "abstract": "This guide develops high-probability regret bounds for empirical risk minimization (ERM). The presentation is modular: we state broadly applicable guarantees under high-level conditions and give tools for verifying them for specific losses and function classes. We emphasize that many ERM rate derivations can be organized around a three-step recipe -- a basic inequality, a uniform local concentration bound, and a fixed-point argument -- which yields regret bounds in terms of a critical radius, defined via localized Rademacher complexity, under a mild Bernstein-type variance--risk condition. To make these bounds concrete, we upper bound the critical radius using local maximal inequalities and metric-entropy integrals, recovering familiar rates for VC-subgraph, Sobolev/Hölder, and bounded-variation classes. We also review ERM with nuisance components -- including weighted ERM and Neyman-orthogonal losses -- as they arise in causal inference, missing data, and domain adaptation. Following the orthogonal learning framework, we highlight that these problems often admit regret-transfer bounds linking regret under an estimated loss to population regret under the target loss. These bounds typically decompose regret into (i) statistical error under the estimated (optimized) loss and (ii) approximation error due to nuisance estimation. Under sample splitting or cross-fitting, the first term can be controlled using standard fixed-loss ERM regret bounds, while the second term depends only on nuisance-estimation accuracy. We also treat the in-sample regime, where nuisances and the ERM are fit on the same data, deriving regret bounds and giving sufficient conditions for fast rates."
  },
  {
    "date": "2026-02-25",
    "title": "Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information",
    "authors": "Umid Suleymanov, Zaur Rajabov, Emil Mirzazada, Murat Kantarcioglu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21496v1",
    "source": "arXiv",
    "abstract": "While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic \"Editor\" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites."
  },
  {
    "date": "2026-02-25",
    "title": "GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning",
    "authors": "Ningyuan Yang, Weihua Du, Weiwei Sun, Sean Welleck, Yiming Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21492v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) has become a central post-training paradigm for large language models (LLMs), but its performance is highly sensitive to the quality of training problems. This sensitivity stems from the non-stationarity of RL: rollouts are generated by an evolving policy, and learning is shaped by exploration and reward feedback, unlike supervised fine-tuning (SFT) with fixed trajectories. As a result, prior work often relies on manual curation or simple heuristic filters (e.g., accuracy), which can admit incorrect or low-utility problems. We propose GradAlign, a gradient-aligned data selection method for LLM reinforcement learning that uses a small, trusted validation set to prioritize training problems whose policy gradients align with validation gradients, yielding an adaptive curriculum. We evaluate GradAlign across three challenging data regimes: unreliable reward signals, distribution imbalance, and low-utility training corpus, showing that GradAlign consistently outperforms existing baselines, underscoring the importance of directional gradient signals in navigating non-stationary policy optimization and yielding more stable training and improved final performance. We release our implementation at https://github.com/StigLidu/GradAlign"
  },
  {
    "date": "2026-02-25",
    "title": "Moment bounds for condition numbers and singular values of high-dimensional Gaussian random matrices: Applications and limitations",
    "authors": "Partha Sarkar, Kshitij Khare, Sanvesh Srivastava",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21487v1",
    "source": "arXiv",
    "abstract": "Spectral properties of Gram matrices are central to high dimensional asymptotic analyses of statistical estimators in regression and covariance estimation. These properties, in turn, depend critically on the extreme singular values and condition numbers of Gaussian random matrices. For many applications, sharp positive and negative moment bounds for these quantities are required to control expected prediction risk and related performance metrics. Although extensive work provides concentration and tail bounds for extreme singular values of Gaussian random matrices, these results do not readily yield the moment bounds needed in such analyses. Motivated by this gap, we establish non asymptotic moment bounds for arbitrary positive moments of the largest singular value and arbitrary negative moments of the smallest singular value, and uniform bounds for arbitrary positive moments of the condition number of high dimensional Gaussian random matrices. We demonstrate the utility of these bounds by applying them to derive explicit risk guarantees in high dimensional regression and covariance estimation, as well as to obtain bounds on the mean iteration complexity of gradient descent for solving Gram linear systems. Finally, we present counterexamples demonstrating that the positive condition number moment bounds and negative smallest singular value moment bounds cannot, in general, be extended to the broader class of sub Gaussian random matrices."
  },
  {
    "date": "2026-02-25",
    "title": "From Awareness to Application: Strengthening Recruitment for NSF S-STEM Scholarships in Computer Science",
    "authors": "Xiaohui Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21481v1",
    "source": "arXiv",
    "abstract": "Recruiting academically strong students into NSF S-STEM scholarship programs remains a persistent challenge in computer science education. This paper presents the design and initial implementation of a suite of targeted recruitment strategies for our NSF-funded project. Our recruitment strategy leverages multiple channels. Information sessions and early outreach efforts were employed to increase awareness and reduce perceived barriers to applying. Data from our recruitment includes applicant demographics, academic performance, financial aid profiles, recruitment source tracking, and survey responses on students awareness and decision-making processes. These data provide a foundation for evaluating the reach and effectiveness of various recruitment strategies and identifying factors that influence student application decisions. Quantitative and qualitative research approaches are employed to examine the implementation and outcomes of proactive recruitment strategies. Our preliminary analysis indicates that direct information sessions and departmental emails are effective recruitment strategies, accounting for a large portion of eligible applications. Our findings emphasize the importance of early communication about the program, clearly defined eligibility criteria, and a streamlined application process. By sharing ongoing progress and lessons learned from our project, this paper contributes evidence-based insights into recruitment practices and offers strategies that can be adapted by other institutions implementing NSF S-STEM programs."
  },
  {
    "date": "2026-02-25",
    "title": "Pancake: Hierarchical Memory System for Multi-Agent LLM Serving",
    "authors": "Zhengding Hu, Zaifeng Pan, Prabhleen Kaur, Vibha Murthy, Zhongkai Yu, Yue Guan, Zhen Wang, Steven Swanson, Yufei Ding",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21477v1",
    "source": "arXiv",
    "abstract": "In this work, we identify and address the core challenges of agentic memory management in LLM serving, where large-scale storage, frequent updates, and multiple coexisting agents jointly introduce complex and high-cost approximate nearest neighbor (ANN) searching problems. We present Pancake, a multi-tier agentic memory system that unifies three key techniques: (i) multi-level index caching for single agents, (ii) coordinated index management across multiple agents, and (iii) collaborative GPU-CPU acceleration. Pancake exposes easy-to-use interface that can be integrated into memory-based agents like Mem-GPT, and is compatible with agentic frameworks such as LangChain and LlamaIndex. Experiments on realistic agent workloads show that Pancake substantially outperforms existing frameworks, achieving more than 4.29x end-to-end throughput improvement."
  },
  {
    "date": "2026-02-25",
    "title": "A Knowledge-Driven Approach to Music Segmentation, Music Source Separation and Cinematic Audio Source Separation",
    "authors": "Chun-wei Ho, Sabato Marco Siniscalchi, Kai Li, Chin-Hui Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21476v1",
    "source": "arXiv",
    "abstract": "We propose a knowledge-driven, model-based approach to segmenting audio into single-category and mixed-category chunks with applications to source separation. \"Knowledge\" here denotes information associated with the data, such as music scores. \"Model\" here refers to tool that can be used for audio segmentation and recognition, such as hidden Markov models. In contrast to conventional learning that often relies on annotated data with given segment categories and their corresponding boundaries to guide the learning process, the proposed framework does not depend on any pre-segmented training data and learns directly from the input audio and its related knowledge sources to build all necessary models autonomously. Evaluation on simulation data shows that score-guided learning achieves very good music segmentation and separation results. Tested on movie track data for cinematic audio source separation also shows that utilizing sound category knowledge achieves better separation results than those obtained with data-driven techniques without using such information."
  },
  {
    "date": "2026-02-25",
    "title": "Nonlinearity-Inhomogeneity Competition in Discrete-Time Quantum Walks",
    "authors": "N. Amaral, A. R. C. Buarque, W. S. Dias",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21474v1",
    "source": "arXiv",
    "abstract": "We investigate the interplay between nonlinearity and inhomogeneities in discrete-time quantum walks on one-dimensional lattices. Nonlinear effects are introduced through a Kerr-like, intensity-dependent local phase, while spatial and temporal inhomogeneities are implemented via random variations of the quantum gate operations. By analyzing typical quantities, such as the return probability and the participation function, we identify distinct quantum walking regimes as the nonlinear parameter $χ$ and the quantum gate parameter $θ$ are varied. Spatial inhomogeneities weaken nonlinear self-trapping and constrict the region of robust localization. In this process, partially localized regimes emerge, characterized by the coexistence of a confined core and dispersive wave-packet components. In contrast, temporal inhomogeneities act as time-dependent perturbations that continuously disrupt the phase coherence required for self-trapped excitation, thereby enhancing dispersive emission and promoting delocalization. By using $χ$ versus $θ$ diagrams, we display a comprehensive characterization of how inhomogeneities modify the stability and extent of prevailing dynamical regimes, elucidating the competition between nonlinearity and inhomogeneities in discrete-time quantum walks."
  },
  {
    "date": "2026-02-25",
    "title": "Effects of Training Data Quality on Classifier Performance",
    "authors": "Alan F. Karr, Regina Ruane",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21462v1",
    "source": "arXiv",
    "abstract": "We describe extensive numerical experiments assessing and quantifying how classifier performance depends on the quality of the training data, a frequently neglected component of the analysis of classifiers. More specifically, in the scientific context of metagenomic assembly of short DNA reads into \"contigs,\" we examine the effects of degrading the quality of the training data by multiple mechanisms, and for four classifiers -- Bayes classifiers, neural nets, partition models and random forests. We investigate both individual behavior and congruence among the classifiers. We find breakdown-like behavior that holds for all four classifiers, as degradation increases and they move from being mostly correct to only coincidentally correct, because they are wrong in the same way. In the process, a picture of spatial heterogeneity emerges: as the training data move farther from analysis data, classifier decisions degenerate, the boundary becomes less dense, and congruence increases."
  },
  {
    "date": "2026-02-25",
    "title": "VecGlypher: Unified Vector Glyph Generation with Language Models",
    "authors": "Xiaoke Huang, Bhavul Gauri, Kam Woh Ng, Tony Ng, Mengmeng Xu, Zhiheng Liu, Weiming Ren, Zhaochong An, Zijian Zhou, Haonan Qiu, Yuyin Zhou, Sen He, Ziheng Wang, Tao Xiang, Xiao Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21461v1",
    "source": "arXiv",
    "abstract": "Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools."
  },
  {
    "date": "2026-02-25",
    "title": "Intrinsic Spin Filter Effect in a $d$-wave altermagnet KV$_2$Se$_2$O with Open Fermi Surface",
    "authors": "Bin Liu, Pei-Hao Fu, Yu-Xuan Sun, Xiao-Lin Zhang, Si-Cong Zhu, Xiang-Long Yu, Hua Wu, Yuan-Zhi Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21460v1",
    "source": "arXiv",
    "abstract": "Altermagnets offer a unique pathway to functional spintronics by combining vanishing magnetization with large spin splitting. Here, we demonstrate that the canonical d-wave altermagnet KV2Se2O can deliver giant tunneling magnetoresistance through orientation-dependent spin filtering. By analyzing the crystallographic spin segregation, we show that transport along specific crystallographic axes is nearly fully spin-polarized within the symmetry-protected ballistic channels. We implement this mechanism in a lattice-matched KV2Se2O/Bi2O2Se/KV2Se2O magnetic tunnel junction, which achieves a robust half-metallic transport regime. The symmetry-protected spectral gap in the parallel/anti-parallel configuration ensures a high tunneling magnetoresistance ratio, resulting in substantial tunneling magnetoresistance, robust thermally driven spin filtering, and spin Seebeck effect at room temperature. These findings provide a path of altermagnetic heterostructures as a high-performance platform for scalable, field-free, and thermally stable spin logic."
  },
  {
    "date": "2026-02-25",
    "title": "Measuring elastic properties of granular hydrogels: Effects of capillary interaction and ionic conditions",
    "authors": "Jiayin Zhao, Haiyi Zhong, Yixiang Gan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21457v1",
    "source": "arXiv",
    "abstract": "The elastic properties of granular hydrogels are commonly characterised under wet conditions, yet the influence of capillary interactions remains unclear. In practical applications, hydrogels operate in aqueous environments containing dissolved ionic species, where swelling and elastic behaviour depend sensitively on ionic conditions. In this study, an experimental setup is developed to measure elastic responses of granular hydrogels under wet conditions. This setup directly observes liquid bridges formation and its evolution during compression. Our results show that neglecting capillary contributions leads to a systematic underestimation of the Young's modulus of hydrogels. Such an underestimation due to the capillary interaction increases as the sample size or its intrinsic stiffness decreases. In addition to the swelling ratio, the tested samples were also prepared under controlled salinity levels. The experimentally observed dependence of stiffness on swelling and salinity conditions is well captured by a modified constitutive model. The development of this study offers a robust testing protocol for measuring elastic properties of hydrogels under various environmental conditions."
  },
  {
    "date": "2026-02-25",
    "title": "Constructive Vector Fields for Path Following in Fully-Actuated Systems on Matrix Lie Groups",
    "authors": "Felipe Bartelt, Vinicius M. Gonçalves, Luciano C. A. Pimenta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21450v1",
    "source": "arXiv",
    "abstract": "This paper presents a novel vector field strategy for controlling fully-actuated systems on connected matrix Lie groups, ensuring convergence to and traversal along a curve defined on the group. Our approach generalizes our previous work (Rezende et al., 2022) and reduces to it when considering the Lie group of translations in Euclidean space. Since the proofs in Rezende et al. (2022) rely on key properties such as the orthogonality between the convergent and traversal components, we extend these results by leveraging Lie group properties. These properties also allow the control input to be non-redundant, meaning it matches the dimension of the Lie group, rather than the potentially larger dimension of the space in which the group is embedded. This can lead to more practical control inputs in certain scenarios. A particularly notable application of our strategy is in controlling systems on SE(3) -- in this case, the non-redundant input corresponds to the object's mechanical twist -- making it well-suited for controlling objects that can move and rotate freely, such as omnidirectional drones. In this case, we provide an efficient algorithm to compute the vector field. We experimentally validate the proposed method using a robotic manipulator to demonstrate its effectiveness."
  },
  {
    "date": "2026-02-25",
    "title": "Quadric surfaces of revolution in the 3-sphere as Weingarten surfaces",
    "authors": "Ildefonso Castro, Daniel López-López",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21785v1",
    "source": "arXiv",
    "abstract": "The study of quadric surfaces of revolution is a cornerstone of classical Euclidean geometry, but its extension to the three-dimensional sphere $\\mathbb{S}^3$ has not been sufficiently explored. This article addresses this important gap by providing a rigorous classification and characterization of non-degenerate quadric surfaces of revolution in $\\mathbb{S}^3$, namely spherical ellipsoids, hyperboloids and paraboloids, generated by the rotation of spherical conics around a geodesic axis containing their foci or is orthogonal to them. Using the concept of spherical angular momentum as a prominent geometric invariant, we discover that these surfaces constitute a remarkable class of Weingarten surfaces and prove that they are uniquely characterised by a specific cubic functional relation between their principal curvatures. This result not only provides a unified description of spherical quadric surfaces of revolution, but also highlights a profound geometric universality, reflecting exactly the same cubic Weingarten relations observed in their Euclidean and Lorentzian counterparts."
  },
  {
    "date": "2026-02-25",
    "title": "Therapist-Robot-Patient Physical Interaction is Worth a Thousand Words: Enabling Intuitive Therapist Guidance via Remote Haptic Control",
    "authors": "Beatrice Luciani, Alex van den Berg, Matti Lang, Alexandre L. Ratschat, Laura Marchal-Crespo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21783v1",
    "source": "arXiv",
    "abstract": "Robotic systems can enhance the amount and repeatability of physically guided motor training. Yet their real-world adoption is limited, partly due to non-intuitive trainer/therapist-trainee/patient interactions. To address this gap, we present a haptic teleoperation system for trainers to remotely guide and monitor the movements of a trainee wearing an arm exoskeleton. The trainer can physically interact with the exoskeleton through a commercial handheld haptic device via virtual contact points at the exoskeleton's elbow and wrist, allowing intuitive guidance. Thirty-two participants tested the system in a trainer-trainee paradigm, comparing our haptic demonstration system with conventional visual demonstration in guiding trainees in executing arm poses. Quantitative analyses showed that haptic demonstration significantly reduced movement completion time and improved smoothness, while speech analysis using large language models for automated transcription and categorization of verbal commands revealed fewer verbal instructions. The haptic demonstration did not result in higher reported mental and physical effort by trainers compared to the visual demonstration, while trainers reported greater competence and trainees lower physical demand. These findings support the feasibility of our proposed interface for effective remote human-robot physical interaction. Future work should assess its usability and efficacy for clinical populations in restoring clinicians' sense of agency during robot-assisted therapy."
  },
  {
    "date": "2026-02-25",
    "title": "Heads Up!: Towards In Situ Photogrammetry Annotations and Augmented Reality Visualizations for Guided Backcountry Skiing",
    "authors": "Christoph Albert Johns, László Kopácsi, Michael Barz, Daniel Sonntag",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21771v1",
    "source": "arXiv",
    "abstract": "Backcountry skiing is an activity where a group of skiers navigate challenging environmental conditions to ski outside of managed areas. This activity requires careful monitoring and effective communication around the current weather and terrain conditions to ensure skier safety. We aim to support and facilitate this communication by providing backcountry guides with a set of in situ spatial annotation tools to communicate hazards and appropriate speeds to the ski recreationalists. A guide can use a tablet application to annotate a photogrammetry-based map of a mountainside, for example, one collected using a commercial camera drone, with hazard points, slow-down zones, and safe zones. These annotations are communicated to the skiers via visual overlays in augmented reality heads-up displays. We present a prototype consisting of a web application and a virtual reality display that mirror the guide's and skier's perspectives, enabling participatory interaction design studies in a safe environment."
  },
  {
    "date": "2026-02-25",
    "title": "SAPNet++: Evolving Point-Prompted Instance Segmentation with Semantic and Spatial Awareness",
    "authors": "Zhaoyang Wei, Xumeng Han, Xuehui Yu, Xue Yang, Guorong Li, Zhenjun Han, Jianbin Jiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21762v1",
    "source": "arXiv",
    "abstract": "Single-point annotation is increasingly prominent in visual tasks for labeling cost reduction. However, it challenges tasks requiring high precision, such as the point-prompted instance segmentation (PPIS) task, which aims to estimate precise masks using single-point prompts to train a segmentation network. Due to the constraints of point annotations, granularity ambiguity and boundary uncertainty arise the difficulty distinguishing between different levels of detail (eg. whole object vs. parts) and the challenge of precisely delineating object boundaries. Previous works have usually inherited the paradigm of mask generation along with proposal selection to achieve PPIS. However, proposal selection relies solely on category information, failing to resolve the ambiguity of different granularity. Furthermore, mask generators offer only finite discrete solutions that often deviate from actual masks, particularly at boundaries. To address these issues, we propose the Semantic-Aware Point-Prompted Instance Segmentation Network (SAPNet). It integrates Point Distance Guidance and Box Mining Strategy to tackle group and local issues caused by the point's granularity ambiguity. Additionally, we incorporate completeness scores within proposals to add spatial granularity awareness, enhancing multiple instance learning (MIL) in proposal selection termed S-MIL. The Multi-level Affinity Refinement conveys pixel and semantic clues, narrowing boundary uncertainty during mask refinement. These modules culminate in SAPNet++, mitigating point prompt's granularity ambiguity and boundary uncertainty and significantly improving segmentation performance. Extensive experiments on four challenging datasets validate the effectiveness of our methods, highlighting the potential to advance PPIS."
  },
  {
    "date": "2026-02-25",
    "title": "Learning from Yesterday's Error: An Efficient Online Learning Method for Traffic Demand Prediction",
    "authors": "Xiannan Huang, Quan Yuan, Chao Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21757v1",
    "source": "arXiv",
    "abstract": "Accurately predicting short-term traffic demand is critical for intelligent transportation systems. While deep learning models achieve strong performance under stationary conditions, their accuracy often degrades significantly when faced with distribution shifts caused by external events or evolving urban dynamics. Frequent model retraining to adapt to such changes incurs prohibitive computational costs, especially for large-scale or foundation models. To address this challenge, we propose FORESEE (Forecasting Online with Residual Smoothing and Ensemble Experts), a lightweight online adaptation framework that is accurate, robust, and computationally efficient. FORESEE operates without any parameter updates to the base model. Instead, it corrects today's forecast in each region using yesterday's prediction error, stabilized through exponential smoothing guided by a mixture-of-experts mechanism that adapts to recent error dynamics. Moreover, an adaptive spatiotemporal smoothing component propagates error signals across neighboring regions and time slots, capturing coherent shifts in demand patterns. Extensive experiments on seven real-world datasets with three backbone models demonstrate that FORESEE consistently improves prediction accuracy, maintains robustness even when distribution shifts are minimal (avoiding performance degradation), and achieves the lowest computational overhead among existing online methods. By enabling real-time adaptation of traffic forecasting models with negligible computational cost, FORESEE paves the way for deploying reliable, up-to-date prediction systems in dynamic urban environments. Code and data are available at https://github.com/xiannanhuang/FORESEE"
  },
  {
    "date": "2026-02-25",
    "title": "LiREC-Net: A Target-Free and Learning-Based Network for LiDAR, RGB, and Event Calibration",
    "authors": "Aditya Ranjan Dash, Ramy Battrawy, René Schuster, Didier Stricker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21754v1",
    "source": "arXiv",
    "abstract": "Advanced autonomous systems rely on multi-sensor fusion for safer and more robust perception. To enable effective fusion, calibrating directly from natural driving scenes (i.e., target-free) with high accuracy is crucial for precise multi-sensor alignment. Existing learning-based calibration methods are typically designed for only a single pair of sensor modalities (i.e., a bi-modal setup). Unlike these methods, we propose LiREC-Net, a target-free, learning-based calibration network that jointly calibrates multiple sensor modality pairs, including LiDAR, RGB, and event data, within a unified framework. To reduce redundant computation and improve efficiency, we introduce a shared LiDAR representation that leverages features from both its 3D nature and projected depth map, ensuring better consistency across modalities. Trained and evaluated on established datasets, such as KITTI and DSEC, our LiREC-Net achieves competitive performance to bi-modal models and sets a new strong baseline for the tri-modal use case."
  },
  {
    "date": "2026-02-25",
    "title": "A Robust Analysis of QU-fitting Behavior for 800-1088 MHz and 1296-1440 MHz",
    "authors": "Lindsey Oberhelman, Cameron L. Van Eck, N. M. McClure-Griffiths, Yik Ki Ma, Alec J. M. Thomson, Jason M. Price, Shinsuke Ideguchi, Craig S. Anderson, Marijke Haverkorn, Denis Leahy, Takuya Akahori, Jennifer West",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21739v1",
    "source": "arXiv",
    "abstract": "QU-fitting is a powerful tool for interpreting spectro-polarimetric radio continuum observations by linking them to physical models, enabling estimates of the magnetic fields in, for example, the Milky Way, galaxy clusters, and radio jets. We present a comprehensive investigation into the effectiveness and limitations of QU-fitting within the ASKAP POSSUM survey frequency ranges (800-1088 MHz and 1296-1440 MHz) with projections to other spectro-polarimetric radio observations. We simulate different physical polarization sources: Faraday simple, Burn slab, internal turbulence, external turbulence, and two-component models in the POSSUM frequencies, and assess their observational degeneracies and fit accuracies. Our results highlight the model-dependent nature of reliable fitting and identify specific regions of parameter space where model selection, and therefore characterization of the physical medium, becomes ambiguous. For QU-fitting we find the Bayes factor, computed using the marginal likelihood, outperforms more traditionally used goodness-of-fit metrics such as Bayesian Information Criterion (BIC), Akaike Information Criterion (AIC), and chi-squared for model selection. We provide empirical relationships to delineate the boundaries where model distinguishability is impossible. Finally, we evaluate how accurately QU-fitting recovers model parameters and their associated uncertainties, thereby assessing its ability to correctly characterize the Faraday-rotating medium in both point and extended sources in Faraday depth space."
  },
  {
    "date": "2026-02-25",
    "title": "Implementation and transition to post-quantum cryptography of the Minimal IKE protocol",
    "authors": "Davide De Zuane, Paolo Santini, Marco Baldi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21737v1",
    "source": "arXiv",
    "abstract": "This paper concerns the Minimal Internet Key Exchange (IKE) protocol, which has received little attention to date, despite its potential to make the best-known IKE protocol sufficiently lightweight to be also applied in contexts where it is currently prohibitive, due to its large footprint. First, we introduce and describe Colibri, an efficient, open-source implementation of the Minimal IKE protocol, which allows us to quantitatively assess its real advantages in terms of lightness. Then we introduce a post-quantum variant of the Minimal IKE protocol, which is essential to make it contemporary, and assess it through Colibri. We demonstrate that the protocol performance remains excellent even in such a more challenging context, making it suitable for deploying pervasive and quantum-resistant virtual private networks."
  },
  {
    "date": "2026-02-25",
    "title": "Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild",
    "authors": "Hao Luo, Ye Wang, Wanpeng Zhang, Haoqi Yuan, Yicheng Feng, Haiweng Xu, Sipeng Zheng, Zongqing Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21736v1",
    "source": "arXiv",
    "abstract": "Despite progress, Vision-Language-Action models (VLAs) are limited by a scarcity of large-scale, diverse robot data. While human manipulation videos offer a rich alternative, existing methods are forced to choose between small, precisely-labeled datasets and vast in-the-wild footage with unreliable hand tracking labels. We present JALA, a pretraining framework that learns Jointly-Aligned Latent Actions. JALA bypasses full visual dynamic reconstruction, instead learns a predictive action embedding aligned with both inverse dynamics and real actions. This yields a transition-aware, behavior-centric latent space for learning from heterogeneous human data. We scale this approach with UniHand-Mix, a 7.5M video corpus (>2,000 hours) blending laboratory and in-the-wild footage. Experiments demonstrate that JALA generates more realistic hand motions in both controlled and unconstrained scenarios, significantly improving downstream robot manipulation performance in both simulation and real-world tasks. These results indicate that jointly-aligned latent actions offer a scalable pathway for VLA pretraining from human data."
  },
  {
    "date": "2026-02-25",
    "title": "SigVLP: Sigmoid Volume-Language Pre-Training for Self-Supervised CT-Volume Adaptive Representation Learning",
    "authors": "Jiayi Wang, Hadrien Reynaud, Ibrahim Ethem Hamamci, Sezgin Er, Suprosanna Shit, Bjoern Menze, Bernhard Kainz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21735v1",
    "source": "arXiv",
    "abstract": "Large-scale, volumetric medical imaging datasets typically aggregate scans from different vendors and devices, resulting in highly variable resolution, slice thicknesses, and numbers of slices per study. Consequently, training representation models usually requires cropping or interpolating along the z-axis to obtain fixed-size blocks, which inevitably causes information loss. We propose a new training approach to overcome this limitation. Instead of absolute position embeddings, we interpret volumes as sequences of 3D chunks and adopt Rotary Position Embeddings, allowing us to treat the z-axis as an unconstrained temporal dimensions. Building on this idea, we introduce a new vision-language model: SigVLP. In SigVLP, we implement Rotary Position Embedding as the positional encoding method, which is applied directly within the attention operation, generating input-conditioned sine and cosine weights on the fly. This design ensures consistent alignment between query and key projections and adapts to any input sizes. To allow for variable input size during training, we sample Computed Tomography volumes in chunks and pair them with localized organ-wise textual observations. Compared to using entire reports for conditioning, chunkwise alignment provides finer-grained supervision, enabling the model to establish stronger correlations between the text and volume representations, thereby improving the precision of text-to-volume alignment. Our models are trained with the Muon optimizer and evaluated on a diverse set of downstream tasks, including zero-shot abnormality and organ classification, segmentation, and retrieval tasks."
  },
  {
    "date": "2026-02-25",
    "title": "Prime-Weighted Interference Patterns Inspired by the Euler Product",
    "authors": "Jouni J. Takalo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21719v1",
    "source": "arXiv",
    "abstract": "We study a prime-weighted oscillatory model inspired by structural aspects of the Euler product of the Riemann zeta function. The model defines finite superpositions of prime-frequency modes and exhibits zero-like crossings produced by destructive interference. We analyze how the weight exponent $x$ controls amplitude growth, slope scaling, and stability of crossings. A heuristic asymptotic argument identifies $x=\\tfrac12$ as a distinguished balance regime separating high-energy and over-damped behavior. The results concern the defined model itself."
  },
  {
    "date": "2026-02-25",
    "title": "TranX-Adapter: Bridging Artifacts and Semantics within MLLMs for Robust AI-generated Image Detection",
    "authors": "Wenbin Wang, Yuge Huang, Jianqing Xu, Yue Yu, Jiangtao Yan, Shouhong Ding, Pan Zhou, Yong Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21716v1",
    "source": "arXiv",
    "abstract": "Rapid advances in AI-generated image (AIGI) technology enable highly realistic synthesis, threatening public information integrity and security. Recent studies have demonstrated that incorporating texture-level artifact features alongside semantic features into multimodal large language models (MLLMs) can enhance their AIGI detection capability. However, our preliminary analyses reveal that artifact features exhibit high intra-feature similarity, leading to an almost uniform attention map after the softmax operation. This phenomenon causes attention dilution, thereby hindering effective fusion between semantic and artifact features. To overcome this limitation, we propose a lightweight fusion adapter, TranX-Adapter, which integrates a Task-aware Optimal-Transport Fusion that leverages the Jensen-Shannon divergence between artifact and semantic prediction probabilities as a cost matrix to transfer artifact information into semantic features, and an X-Fusion that employs cross-attention to transfer semantic information into artifact features. Experiments on standard AIGI detection benchmarks upon several advanced MLLMs, show that our TranX-Adapter brings consistent and significant improvements (up to +6% accuracy)."
  },
  {
    "date": "2026-02-25",
    "title": "Out-of-time-ordered correlators for turbulent fields: a quantum-classical correspondence",
    "authors": "Motoki Nakata",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21710v1",
    "source": "arXiv",
    "abstract": "An extended formulation of out-of-time-ordered correlators (OTOCs), which quantify noncommutative operator growth and information scrambling in quantum many-body systems, is developed for turbulence dynamics as a representative of non-canonical Hamiltonian systems. Based on the Wigner-Weyl transform and the Moyal bracket formalism, the semiclassical limit of OTOC for turbulent plasmas governed by the Hasegawa-Mima equation is derived as an ensemble-averaged squared Lie-Poisson bracket between two chosen functionals of the turbulent fields. The classical-limit OTOC provides a quantitative measure of how a variational perturbation applied to one functional propagates across scales in the turbulent dynamics and how it affects another functional at a later time, thereby capturing scale-dependent or field-dependent transfer processes. In a quasilinear approximation with a strong zonal flow, we derive an inverse-square decay of the OTOC with the time lag, indicating an algebraic suppression of the zonal-mode response to perturbations of the non-zonal fields. This behavior is attributed to zonal-flow shearing, which rapidly scrambles the non-zonal perturbation toward higher wavenumbers, and consequently reduces the low-wavenumber non-zonal content that can feed back onto large-scale zonal modes."
  },
  {
    "date": "2026-02-25",
    "title": "Assessing airborne laser scanning and aerial photogrammetry for deep learning-based stand delineation",
    "authors": "Håkon Næss Sandum, Hans Ole Ørka, Oliver Tomic, Terje Gobakken",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21709v1",
    "source": "arXiv",
    "abstract": "Accurate forest stand delineation is essential for forest inventory and management but remains a largely manual and subjective process. A recent study has shown that deep learning can produce stand delineations comparable to expert interpreters when combining aerial imagery and airborne laser scanning (ALS) data. However, temporal misalignment between data sources limits operational scalability. Canopy height models (CHMs) derived from digital photogrammetry (DAP) offer better temporal alignment but may smoothen canopy surface and canopy gaps, raising the question of whether they can reliably replace ALS-derived CHMs. Similarly, the inclusion of a digital terrain model (DTM) has been suggested to improve delineation performance, but has remained untested in published literature. Using expert-delineated forest stands as reference data, we assessed a U-Net-based semantic segmentation framework with municipality-level cross-validation across six municipalities in southeastern Norway. We compared multispectral aerial imagery combined with (i) an ALS-derived CHM, (ii) a DAP-derived CHM, and (iii) a DAP-derived CHM in combination with a DTM. Results showed comparable performance across all data combinations, reaching overall accuracy values between 0.90-0.91. Agreement between model predictions was substantially larger than agreement with the reference data, highlighting both model consistency and the inherent subjectivity of stand delineation. The similar performance of DAP-CHMs, despite the reduced structural detail, and the lack of improvements of the DTM indicate that the framework is resilient to variations in input data. These findings indicate that large datasets for deep learning-based stand delineations can be assembled using projects including temporally aligned ALS data and DAP point clouds."
  },
  {
    "date": "2026-02-25",
    "title": "SF3D-RGB: Scene Flow Estimation from Monocular Camera and Sparse LiDAR",
    "authors": "Rajai Alhimdiat, Ramy Battrawy, René Schuster, Didier Stricker, Wesam Ashour",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21699v1",
    "source": "arXiv",
    "abstract": "Scene flow estimation is an extremely important task in computer vision to support the perception of dynamic changes in the scene. For robust scene flow, learning-based approaches have recently achieved impressive results using either image-based or LiDAR-based modalities. However, these methods have tended to focus on the use of a single modality. To tackle these problems, we present a deep learning architecture, SF3D-RGB, that enables sparse scene flow estimation using 2D monocular images and 3D point clouds (e.g., acquired by LiDAR) as inputs. Our architecture is an end-to-end model that first encodes information from each modality into features and fuses them together. Then, the fused features enhance a graph matching module for better and more robust mapping matrix computation to generate an initial scene flow. Finally, a residual scene flow module further refines the initial scene flow. Our model is designed to strike a balance between accuracy and efficiency. Furthermore, experiments show that our proposed method outperforms single-modality methods and achieves better scene flow accuracy on real-world datasets while using fewer parameters compared to other state-of-the-art methods with fusion."
  },
  {
    "date": "2026-02-25",
    "title": "Isotope-Resolved Ba and Xe Yields in Actinide Fission and Correlated Heavy--Light Fragment Systematics",
    "authors": "K. Pomorski, A. Augustyn, T. Cap, Y. J. Chen, M. Kowal, B. Nerlo-Pomorska, M. Warda, Z. G. Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21692v1",
    "source": "arXiv",
    "abstract": "Isotope-resolved post-neutron fission yields in the Ba and Xe chains are calculated and benchmarked against evaluated reference data, with emphasis on element-resolved isotopic chains $Y(N_f)$ at fixed fragment charge $Z$ and on the consistency of heavy--light fragment correlations. Calculations are performed within a four-dimensional (4D) Langevin framework employing Fourier-over-Spheroid shape parametrization. The benchmark covers spontaneous fission of selected Cm and Cf isotopes (including $^{244,246}$Cm and $^{250}$Cf) as well as neutron-induced fission at thermal and 14-MeV energies for representative actinides in the Th--Pu region (including $^{229}$Th, $^{235}$U, $^{239}$Pu, and $^{249}$Cf). The dominant neutron-number maxima are reproduced for a large fraction of the isotopic chains considered, indicating that the mean charge partition and the average neutron content of the main fission channels are described consistently. A systematic residual discrepancy is observed in the isotopic widths: the calculated yields often fall off too rapidly on the distribution tails, producing distributions that are narrower than the evaluated data, most notably for heavy-fragment chains."
  },
  {
    "date": "2026-02-25",
    "title": "Trajectory Generation with Endpoint Regulation and Momentum-Aware Dynamics for Visually Impaired Scenarios",
    "authors": "Yuting Zeng, Manping Fan, You Zhou, Yongbin Yu, Zhiwen Zheng, Jingtao Zhang, Liyong Ren, Zhenglin Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21691v1",
    "source": "arXiv",
    "abstract": "Trajectory generation for visually impaired scenarios requires smooth and temporally consistent state in structured, low-speed dynamic environments. However, traditional jerk-based heuristic trajectory sampling with independent segment generation and conventional smoothness penalties often lead to unstable terminal behavior and state discontinuities under frequent regenerating. This paper proposes a trajectory generation approach that integrates endpoint regulation to stabilize terminal states within each segment and momentum-aware dynamics to regularize the evolution of velocity and acceleration for segment consistency. Endpoint regulation is incorporated into trajectory sampling to stabilize terminal behavior, while a momentum-aware dynamics enforces consistent velocity and acceleration evolution across consecutive trajectory segments. Experimental results demonstrate reduced acceleration peaks and lower jerk levels with decreased dispersion, smoother velocity and acceleration profiles, more stable endpoint distributions, and fewer infeasible trajectory candidates compared with a baseline planner."
  },
  {
    "date": "2026-02-25",
    "title": "Hierarchical Lead Critic based Multi-Agent Reinforcement Learning",
    "authors": "David Eckel, Henri Meeß",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21680v1",
    "source": "arXiv",
    "abstract": "Cooperative Multi-Agent Reinforcement Learning (MARL) solves complex tasks that require coordination from multiple agents, but is often limited to either local (independent learning) or global (centralized learning) perspectives. In this paper, we introduce a novel sequential training scheme and MARL architecture, which learns from multiple perspectives on different hierarchy levels. We propose the Hierarchical Lead Critic (HLC) - inspired by natural emerging distributions in team structures, where following high-level objectives combines with low-level execution. HLC demonstrates that introducing multiple hierarchies, leveraging local and global perspectives, can lead to improved performance with high sample efficiency and robust policies. Experimental results conducted on cooperative, non-communicative, and partially observable MARL benchmarks demonstrate that HLC outperforms single hierarchy baselines and scales robustly with increasing amounts of agents and difficulty."
  },
  {
    "date": "2026-02-25",
    "title": "Trie-Aware Transformers for Generative Recommendation",
    "authors": "Zhenxiang Xu, Jiawei Chen, Sirui Chen, Yong He, Jieyu Yang, Chuan Yuan, Ke Ding, Can Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21677v1",
    "source": "arXiv",
    "abstract": "Generative recommendation (GR) aligns with advances in generative AI by casting next-item prediction as token-level generation rather than score-based ranking. Most GR methods adopt a two-stage pipeline: (i) \\textit{item tokenization}, which maps each item to a sequence of discrete, hierarchically organized tokens; and (ii) \\textit{autoregressive generation}, which predicts the next item's tokens conditioned on the tokens of user's interaction history. Although hierarchical tokenization induces a prefix tree (trie) over items, standard autoregressive modeling with conventional Transformers often flattens item tokens into a linear stream and overlooks the underlying topology. To address this, we propose TrieRec, a trie-aware generative recommendation method that augments Transformers with structural inductive biases via two positional encodings. First, a \\textit{trie-aware absolute positional encoding} aggregates a token's (node's) local structural context (\\eg depth, ancestors, and descendants) into the token representation. Second, a \\textit{topology-aware relative positional encoding} injects pairwise structural relations into self-attention to capture topology-induced semantic relatedness. TrieRec is also model-agnostic, efficient, and hyperparameter-free. In our experiments, we implement TrieRec within three representative GR backbones, achieving notably improvements of 8.83\\% on average across four real-world datasets."
  },
  {
    "date": "2026-02-25",
    "title": "AVID: A Near-Major Post-Merger of Late-Type Dwarfs beneath a Regularly Rotating HI Disk (VCC 693)",
    "authors": "Fujia Li, Hong-Xin Zhang, Elias Brinks, Se-Heon Oh, Rory Smith, Zesen Lin, Weibin Sun, Yu-Zhu Sun, Tie Li, Minsu Kim, Jaebeom Kim, Lijun Chen, Lanyue Zhang, Patrick Côté, Alessandro Boselli, Pierre-Alain Duc, Laura Ferrarese, Matteo Fossati, Stephen Gwyn, Xu Kong, Sanjaya Paudel, Eric W. Peng, Thomas H. Puzia, Rubén Sánchez-Janssen, Matthew Taylor, Yinghe Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21676v1",
    "source": "arXiv",
    "abstract": "On the periphery of galaxy clusters, moderately high galaxy densities and velocity dispersions favour interactions and mergers that influence galaxy evolution prior to cluster infall. Observational studies of this phase in dwarfs remain rare. We present a high-resolution study of the merger remnant VCC 693 in the outskirts of Virgo cluster, using observations from the Atomic gas in Virgo Interacting Dwarf galaxies (AVID) project. We explore the origin of VCC 693 and the consequences of the merger on its star formation and structure through a joint analysis of VLA and FAST HI emission line observations, together with complementary optical imaging and spectroscopy. We employ hydrodynamical simulations to help interpret the observations. Our analysis favours a near-major merger between two dwarfs with a stellar mass ratio of 3:1-4:1, with one likely gas-poor progenitor (i.e., a damp merger). The optical appearance of VCC 693 is dominated by complex tidal structures throughout the system, whereas the HI gas has settled to a regular rotating disk. Compared with similar-mass dwarfs, the central star formation and gas-phase metallicity are moderately enhanced. The global star formation rate, HI gas content, and HI-to-optical size ratio of VCC 693 are broadly consistent with those of typical dwarfs of similar mass, albeit somewhat lower. Decomposition of the HI rotation curve into baryonic and dark matter indicates a high halo concentration, suggesting post-merger relaxation into a more centrally peaked configuration. Together with two recent studies of AVID post-merger systems, these results support the view that even major dwarf mergers can produce remnants with overall stellar structures indistinguishable from ordinary dwarfs, and that the environmental effects in cluster outskirts can promote damp or mixed mergers, constituting an integral part of galactic pre-processing."
  },
  {
    "date": "2026-02-25",
    "title": "Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping",
    "authors": "Junmyeong Lee, Hoseung Choi, Minsu Cho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21668v1",
    "source": "arXiv",
    "abstract": "Forecasting dynamic scenes remains a fundamental challenge in computer vision, as limited observations make it difficult to capture coherent object-level motion and long-term temporal evolution. We present Motion Group-aware Gaussian Forecasting (MoGaF), a framework for long-term scene extrapolation built upon the 4D Gaussian Splatting representation. MoGaF introduces motion-aware Gaussian grouping and group-wise optimization to enforce physically consistent motion across both rigid and non-rigid regions, yielding spatially coherent dynamic representations. Leveraging this structured space-time representation, a lightweight forecasting module predicts future motion, enabling realistic and temporally stable scene evolution. Experiments on synthetic and real-world datasets demonstrate that MoGaF consistently outperforms existing baselines in rendering quality, motion plausibility, and long-term forecasting stability. Our project page is available at https://slime0519.github.io/mogaf"
  },
  {
    "date": "2026-02-25",
    "title": "Crossing Numbers of Knots on Closed Surfaces",
    "authors": "Makoto Ozawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21659v1",
    "source": "arXiv",
    "abstract": "Let $c(K;F)$ denote the surface crossing number of a knot $K$ with respect to a closed surface $F \\subset S^{3}$. We establish the lower bound \\[ c(K;F) \\ge 2\\bigl(t(K)-δ(F)\\bigr)+1, \\] where $t(K)$ is the tunnel number of $K$ and $δ(F)$ is the Heegaard deficiency of $F$. In particular, for any fixed closed surface $F$, the surface crossing number $c(K;F)$ is unbounded over all knots $K$. Furthermore, we construct a family of knots $K_m$ demonstrating that $c(K_m;F) = Θ(t(K_m))$, which shows that this lower bound is asymptotically sharp."
  },
  {
    "date": "2026-02-25",
    "title": "Following the Diagnostic Trace: Visual Cognition-guided Cooperative Network for Chest X-Ray Diagnosis",
    "authors": "Shaoxuan Wu, Jingkun Chen, Chong Ma, Cong Shen, Xiao Zhang, Jun Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21657v1",
    "source": "arXiv",
    "abstract": "Computer-aided diagnosis (CAD) has significantly advanced automated chest X-ray diagnosis but remains isolated from clinical workflows and lacks reliable decision support and interpretability. Human-AI collaboration seeks to enhance the reliability of diagnostic models by integrating the behaviors of controllable radiologists. However, the absence of interactive tools seamlessly embedded within diagnostic routines impedes collaboration, while the semantic gap between radiologists' decision-making patterns and model representations further limits clinical adoption. To overcome these limitations, we propose a visual cognition-guided collaborative network (VCC-Net) to achieve the cooperative diagnostic paradigm. VCC-Net centers on visual cognition (VC) and employs clinically compatible interfaces, such as eye-tracking or the mouse, to capture radiologists' visual search traces and attention patterns during diagnosis. VCC-Net employs VC as a spatial cognition guide, learning hierarchical visual search strategies to localize diagnostically key regions. A cognition-graph co-editing module subsequently integrates radiologist VC with model inference to construct a disease-aware graph. The module captures dependencies among anatomical regions and aligns model representations with VC-driven features, mitigating radiologist bias and facilitating complementary, transparent decision-making. Experiments on the public datasets SIIM-ACR, EGD-CXR, and self-constructed TB-Mouse dataset achieved classification accuracies of 88.40%, 85.05%, and 92.41%, respectively. The attention maps produced by VCC-Net exhibit strong concordance with radiologists' gaze distributions, demonstrating a mutual reinforcement of radiologist and model inference. The code is available at https://github.com/IPMI-NWU/VCC-Net."
  },
  {
    "date": "2026-02-25",
    "title": "Score-Based Conditional Flow Models for MIMO Receiver Design with Superimposed Pilots",
    "authors": "Ruhao Zhang, Yupeng Li, Yitong Liu, Shijian Gao, Jing Jin, Hongwen Yang, Jiangzhou Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21654v1",
    "source": "arXiv",
    "abstract": "Accurate channel state information (CSI) is vital for multiple-input multiple-output (MIMO) systems. However, superimposed pilots (SIP), which reduce overhead, introduce severe pilot contamination and data interference, complicating joint channel estimation and data detection. This paper proposes a conditional flow matching receiver (CFM-Rx), an unsupervised generative framework that learns directly from received signals, eliminating the need for labeled data and improving adaptability across diverse system settings. By leveraging flow-based generative modeling, CFM-Rx enables deterministic, low-latency inference and exploits model invertibility to capture the bidirectional nature of signal propagation. This framework unifies flow matching with score-based diffusion modeling via a moment-consistent ordinary differential equation (ODE), replacing stochastic differential equation (SDE) sampling with a deterministic and efficient process. Furthermore, it integrates receiver-side priors to ensure stable, data-consistent inference. Extensive simulation results across various MIMO configurations demonstrate that CFM-Rx consistently outperforms conventional estimators and state-of-the-art data-driven receivers, achieving notable gains in channel estimation accuracy and symbol detection robustness, particularly under severe pilot contamination."
  },
  {
    "date": "2026-02-25",
    "title": "Sparsity Induction for Accurate Post-Training Pruning of Large Language Models",
    "authors": "Minhao Jiang, Zhikai Li, Xuewen Liu, Jing Zhang, Mengjuan Chen, Qingyi Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21652v1",
    "source": "arXiv",
    "abstract": "Large language models have demonstrated capabilities in text generation, while their increasing parameter scales present challenges in computational and memory efficiency. Post-training sparsity (PTS), which reduces model cost by removing weights from dense networks, is an effective approach. However, native dense matrices lack high sparsity, making existing approaches that directly remove weights disrupt model states, resulting in unsatisfactory performance recovery even with post-tuning. We propose Sparsity Induction, which promotes models toward higher sparsity at both distribution and feature levels before pruning, to push the limits of PTS. At the distribution level, we enhance distributional sparsity through mathematically equivalent scaling transformations, which are fully absorbable and incur no extra parameters or inference-time overhead. At the feature level, we introduce Spectral Norm Loss to promote feature sparsity from a low-rank perspective. Experiments across diverse model architectures and tasks demonstrate that our method further enhances sparsity-friendliness, achieving superior pruning performance over existing approaches."
  },
  {
    "date": "2026-02-25",
    "title": "PPCR-IM: A System for Multi-layer DAG-based Public Policy Consequence Reasoning and Social Indicator Mapping",
    "authors": "Zichen Song, Weijia Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21650v1",
    "source": "arXiv",
    "abstract": "Public policy decisions are typically justified using a narrow set of headline indicators, leaving many downstream social impacts unstructured and difficult to compare across policies. We propose PPCR-IM, a system for multi-layer DAG-based consequence reasoning and social indicator mapping that addresses this gap. Given a policy description and its context, PPCR-IM uses an LLM-driven, layer-wise generator to construct a directed acyclic graph of intermediate consequences, allowing child nodes to have multiple parents to capture joint influences. A mapping module then aligns these nodes to a fixed indicator set and assigns one of three qualitative impact directions: increase, decrease, or ambiguous change. For each policy episode, the system outputs a structured record containing the DAG, indicator mappings, and three evaluation measures: an expected-indicator coverage score, a discovery rate for overlooked but relevant indicators, and a relative focus ratio comparing the systems coverage to that of the government. PPCR-IM is available both as an online demo and as a configurable XLSX-to-JSON batch pipeline."
  },
  {
    "date": "2026-02-25",
    "title": "Mechanics and thermodynamics: A link between the two theories",
    "authors": "Henri Gouin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21649v1",
    "source": "arXiv",
    "abstract": "In this note, we analyze the relationships that should govern the use of thermodynamics in fluid mechanics in a way that we believe is understandable to mathematicians. We also aim to better define the reasons why mechanics and thermodynamics must be correctly linked by showing that the principle of virtual work expressed using a specific internal energy is perfectly suited to fluid mechanics problems, provided that a well-chosen internal energy is proposed."
  },
  {
    "date": "2026-02-25",
    "title": "Multimodal Survival Modeling and Fairness-Aware Clinical Machine Learning for 5-Year Breast Cancer Risk Prediction",
    "authors": "Toktam Khatibi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21648v1",
    "source": "arXiv",
    "abstract": "Clinical risk prediction models often underperform in real-world settings due to poor calibration, limited transportability, and subgroup disparities. These challenges are amplified in high-dimensional multimodal cancer datasets characterized by complex feature interactions and a p >> n structure. We present a fully reproducible multimodal machine learning framework for 5-year overall survival prediction in breast cancer, integrating clinical variables with high-dimensional transcriptomic and copy-number alteration (CNA) features from the METABRIC cohort. After variance- and sparsity-based filtering and dimensionality reduction, models were trained using stratified train/validation/test splits with validation-based hyperparameter tuning. Two survival approaches were compared: an elastic-net regularized Cox model (CoxNet) and a gradient-boosted survival tree model implemented using XGBoost. CoxNet provides embedded feature selection and stable estimation, whereas XGBoost captures nonlinear effects and higher-order interactions. Performance was assessed using time-dependent area under the ROC curve (AUC), average precision (AP), calibration curves, Brier score, and bootstrapped 95 percent confidence intervals. CoxNet achieved validation and test AUCs of 98.3 and 96.6, with AP values of 90.1 and 80.4. XGBoost achieved validation and test AUCs of 98.6 and 92.5, with AP values of 92.5 and 79.9. Fairness diagnostics showed stable discrimination across age groups, estrogen receptor status, molecular subtypes, and menopausal state. This work introduces a governance-oriented multimodal survival framework emphasizing calibration, fairness auditing, robustness, and reproducibility for high-dimensional clinical machine learning."
  },
  {
    "date": "2026-02-25",
    "title": "Semi-classical limit of an attractive Fermi gas in one or two dimensions",
    "authors": "Thomas Gamet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21640v1",
    "source": "arXiv",
    "abstract": "We study the ground-state of a Fermi gas with short range attrative interactions in one or two dimensions. N fermions are placed in a confining potential, and interact with each other through a negative potential, whose range is larger than the typical distance between particles. We show the convergence of the ground state energy of the Hamiltonian to a Thomas-Fermi energy in the large N limit. Furthermore, we prove convergence of the ground states, in the sense of their Husimi functions."
  },
  {
    "date": "2026-02-25",
    "title": "RuCL: Stratified Rubric-Based Curriculum Learning for Multimodal Large Language Model Reasoning",
    "authors": "Yukun Chen, Jiaming Li, Longze Chen, Ze Gong, Jingpeng Li, Zhen Qin, Hengyu Chang, Ancheng Xu, Zhihao Yang, Hamid Alinejad-Rokny, Qiang Qu, Bo Zheng, Min Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21628v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a prevailing paradigm for enhancing reasoning in Multimodal Large Language Models (MLLMs). However, relying solely on outcome supervision risks reward hacking, where models learn spurious reasoning patterns to satisfy final answer checks. While recent rubric-based approaches offer fine-grained supervision signals, they suffer from high computational costs of instance-level generation and inefficient training dynamics caused by treating all rubrics as equally learnable. In this paper, we propose Stratified Rubric-based Curriculum Learning (RuCL), a novel framework that reformulates curriculum learning by shifting the focus from data selection to reward design. RuCL generates generalized rubrics for broad applicability and stratifies them based on the model's competence. By dynamically adjusting rubric weights during training, RuCL guides the model from mastering foundational perception to tackling advanced logical reasoning. Extensive experiments on various visual reasoning benchmarks show that RuCL yields a remarkable +7.83% average improvement over the Qwen2.5-VL-7B model, achieving a state-of-the-art accuracy of 60.06%."
  },
  {
    "date": "2026-02-25",
    "title": "Tokenizing Semantic Segmentation with RLE",
    "authors": "Abhineet Singh, Justin Rozeboom, Nilanjan Ray",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21627v1",
    "source": "arXiv",
    "abstract": "This paper presents a new unified approach to semantic segmentation in both images and videos by using language modeling to output the masks as sequences of discrete tokens. We use run length encoding (RLE) to discretize the segmentation masks and then train a modified version of Pix2Seq \\cite{p2s} to output these RLE tokens through autoregression. We propose novel tokenization strategies to compress the length of the token sequence to make it practicable to extend this approach to videos. We also show how instance information can be incorporated into the tokenization process to perform panoptic segmentation. We evaluate our proposed models on two datasets to show that they are competitive with the state of the art in spite of being bottlenecked by our limited computational resources."
  },
  {
    "date": "2026-02-25",
    "title": "AT2024lhc and AT2024kmq in the landscape of featureless tidal disruption events",
    "authors": "Yuhan Yao, Ryan Chornock, Andrew Mummery, Raffaella Margutti, Marat Gilfanov, Muryel Guolo, Eric R. Coughlin, Wenbin Lu, Joheen Chakraborty, Dheeraj R. Pasham, Kate D. Alexander, Olivia Aspegren, Charlotte R. Angus, Xinze Guo, Xander J. Hall, Erica Hammerstein, K. -Ryan Hinds, Anna Y. Q. Ho, Xiaoshan Huang, Elias Kammoun, Natalie LeBaron, Matteo Lucchini, Zoë McGrath, Matt Nicholl, Daniel A. Perley, R. Michael Rich, Genevieve Schroeder, Xinyue Sheng, Jesper Sollerman, Jean Somalwar, Jacob R. Wise, Michael W. Coughlin, Andrew Drake, Matthew J. Graham, George Helou, Joahan C. Jaimes, Mansi M. Kasliwal, Ashish A. Mahabal, Pavel Medvedev, Josiah Purdum, Ben Rusholme, Rashid Sunyaev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21624v1",
    "source": "arXiv",
    "abstract": "We study AT2024kmq and AT2024lhc, two tidal disruption events (TDEs) with blue featureless spectra associated with high-mass black holes ($M_{\\rm BH}\\sim 10^8\\,M_\\odot$). Both events show optical precursors consistent with shock dissipation from stream self-intersection. Their X-ray emission is luminous ($L_{\\rm X}\\sim 10^{44}\\,{\\rm erg\\,s^{-1}}$), highly variable (with minimum observed variability timescales of 1.3\\,hr and 4.8\\,hr for factor of $\\sim3$ flux changes), long-lasting ($>1\\,\\rm yr$), emerging no later than the optical peak, and well characterized by power-laws with $1.7<Γ<3$ (where $f_ν\\propto ν^{1-Γ}$). The X-ray properties and radio non-detections support a compact corona ($\\lesssim 10 r_{\\rm g}$) producing Comptonized X-ray emission. Using all published featureless TDEs, we find statistically significant bimodality in the distribution of their peak UV/optical blackbody luminosities and radii. We assemble a comparison TDE sample with early-time X-ray observations with eROSITA, in which we find different $M_{\\rm BH}$ distributions in TDEs with different X-ray spectral evolution properties: low-mass black holes ($M_{\\rm BH} \\sim 10^6 M_\\odot$) remain soft ($Γ>4$) within $t\\lesssim 2$\\,yr, intermediate masses ($\\sim 10^7 M_\\odot$) transition from soft to hard at $\\sim$1 yr, while high masses ($\\sim 10^8 M_\\odot$) are hard ($1.5<Γ\\lesssim 3$) from the outset. We interpret this result as evidence that the soft-to-hard state transition in TDEs occurs at the critical threshold of $\\dot{M}_{\\rm acc} \\sim 0.03 \\dot M_{\\rm Edd}$ (similar to X-ray binaries), using the fact that the transition timescale predicted by simple disk theory scales with black hole mass as $t_{\\rm tr}\\propto M_{\\rm BH}^{-3/4}$."
  },
  {
    "date": "2026-02-25",
    "title": "ADM-DP: Adaptive Dynamic Modality Diffusion Policy through Vision-Tactile-Graph Fusion for Multi-Agent Manipulation",
    "authors": "Enyi Wang, Wen Fan, Dandan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21622v1",
    "source": "arXiv",
    "abstract": "Multi-agent robotic manipulation remains challenging due to the combined demands of coordination, grasp stability, and collision avoidance in shared workspaces. To address these challenges, we propose the Adaptive Dynamic Modality Diffusion Policy (ADM-DP), a framework that integrates vision, tactile, and graph-based (multi-agent pose) modalities for coordinated control. ADM-DP introduces four key innovations. First, an enhanced visual encoder merges RGB and point-cloud features via Feature-wise Linear Modulation (FiLM) modulation to enrich perception. Second, a tactile-guided grasping strategy uses Force-Sensitive Resistor (FSR) feedback to detect insufficient contact and trigger corrective grasp refinement, improving grasp stability. Third, a graph-based collision encoder leverages shared tool center point (TCP) positions of multiple agents as structured kinematic context to maintain spatial awareness and reduce inter-agent interference. Fourth, an Adaptive Modality Attention Mechanism (AMAM) dynamically re-weights modalities according to task context, enabling flexible fusion. For scalability and modularity, a decoupled training paradigm is employed in which agents learn independent policies while sharing spatial information. This maintains low interdependence between agents while retaining collective awareness. Across seven multi-agent tasks, ADM-DP achieves 12-25% performance gains over state-of-the-art baselines. Ablation studies show the greatest improvements in tasks requiring multiple sensory modalities, validating our adaptive fusion strategy and demonstrating its robustness for diverse manipulation scenarios."
  },
  {
    "date": "2026-02-25",
    "title": "GW070605: An Undisclosed Binary Neutron Star Hardware Injection in LIGO's Fifth Science Run",
    "authors": "Heather Fong, Kipp Cannon, Chi-Wai Chan, Richard N. George, Alvin K. Y. Li, Soichiro Kuwahara, Hiroaki Ohta, Minori Shikauchi, Leo Tsukada, Takuya Tsutsui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21615v1",
    "source": "arXiv",
    "abstract": "The authors wished to document the sensitivity improvement that has been contributed to the GW detection rate by detection algorithm research and development efforts, and set about re-analyzing S5 and S6 to determine the sensitive time-volumes of a modern pipeline and compare them to that of analysis algorithms of the day. To our surprise, this effort led to the discovery of GW070605, what at first appeared to be a previously unreported high significance binary neutron star merger at a time when only the Livingston detector (L1) was operating -- data that could not have been analyzed and a signal that could not have been discovered previously because the algorithms of the day required coincidence between two or more detectors. GW070605's end time occurs in LIGO's L1 detector at 2007-06-05 18:37:02 UTC, and is estimated to be a merger with component masses of 1.82$M_\\odot$ and 1.24$M_\\odot$. The GstLAL detection algorithm estimates that noise processes produce false positives at least as significant as GW070605 at a rate of $8.6\\times10^{-10}$ per year. Disappointingly, subsequent investigations revealed the presence of a previously undocumented hardware injection in the L1 detector's Y arm end test mass' excitation channel, whose time and properties match that of GW070605. The injection does not appear in the Gravitational Wave Open Science Center list of hardware injections. We determined that while there is no sensitivity improvement between GstLAL and previous algorithms at the null-result threshold, there is marked improvement at above null-result thresholds; specifically, an approximately 55-times detection rate increase from initial-era algorithms at a FAR threshold of 1 per 7000 years."
  },
  {
    "date": "2026-02-25",
    "title": "Jumping Control for a Quadrupedal Wheeled-Legged Robot via NMPC and DE Optimization",
    "authors": "Xuanqi Zeng, Lingwei Zhang, Linzhu Yue, Zhitao Song, Hongbo Zhang, Tianlin Zhang, Yun-Hui Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21612v1",
    "source": "arXiv",
    "abstract": "Quadrupedal wheeled-legged robots combine the advantages of legged and wheeled locomotion to achieve superior mobility, but executing dynamic jumps remains a significant challenge due to the additional degrees of freedom introduced by wheeled legs. This paper develops a mini-sized wheeled-legged robot for agile motion and presents a novel motion control framework that integrates the Nonlinear Model Predictive Control (NMPC) for locomotion and the Differential Evolution (DE) based trajectory optimization for jumping in quadrupedal wheeled-legged robots. The proposed controller utilizes wheel motion and locomotion to enhance jumping performance, achieving versatile maneuvers such as vertical jumping, forward jumping, and backflips. Extensive simulations and real-world experiments validate the effectiveness of the framework, demonstrating a forward jump over a 0.12 m obstacle and a vertical jump reaching 0.5 m."
  },
  {
    "date": "2026-02-25",
    "title": "An application of Fontaine's monoidal maps to perfectoid towers",
    "authors": "Kazuki Hayashi, Shinnosuke Ishiro, Kazuma Shimomoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21605v1",
    "source": "arXiv",
    "abstract": "To connect arithmetic and ring-theoretic properties of rings of mixed characteristic with those of positive characteristic, we introduce monoidal maps for perfectoid towers. Using these maps, we discuss the almost integrality of perfectoid towers and of their tilts. We also show that the towers constructed by F. Andreatta via ramification theory become perfectoid towers, and we apply the monoidal maps to deduce the normality of their small tilts."
  },
  {
    "date": "2026-02-25",
    "title": "Retrieval Challenges in Low-Resource Public Service Information: A Case Study on Food Pantry Access",
    "authors": "Touseef Hasan, Laila Cure, Souvika Sarkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21598v1",
    "source": "arXiv",
    "abstract": "Public service information systems are often fragmented, inconsistently formatted, and outdated. These characteristics create low-resource retrieval environments that hinder timely access to critical services. We investigate retrieval challenges in such settings through the domain of food pantry access, a socially urgent problem given persistent food insecurity. We develop an AI-powered conversational retrieval system that scrapes and indexes publicly available pantry data and employs a Retrieval-Augmented Generation (RAG) pipeline to support natural language queries via a web interface. We conduct a pilot evaluation study using community-sourced queries to examine system behavior in realistic scenarios. Our analysis reveals key limitations in retrieval robustness, handling underspecified queries, and grounding over inconsistent knowledge bases. This ongoing work exposes fundamental IR challenges in low-resource environments and motivates future research on robust conversational retrieval to improve access to critical public resources."
  },
  {
    "date": "2026-02-25",
    "title": "SPOC: Safety-Aware Planning Under Partial Observability And Physical Constraints",
    "authors": "Hyungmin Kim, Hobeom Jeon, Dohyung Kim, Minsu Jang, Jeahong Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21595v1",
    "source": "arXiv",
    "abstract": "Embodied Task Planning with large language models faces safety challenges in real-world environments, where partial observability and physical constraints must be respected. Existing benchmarks often overlook these critical factors, limiting their ability to evaluate both feasibility and safety. We introduce SPOC, a benchmark for safety-aware embodied task planning, which integrates strict partial observability, physical constraints, step-by-step planning, and goal-condition-based evaluation. Covering diverse household hazards such as fire, fluid, injury, object damage, and pollution, SPOC enables rigorous assessment through both state and constraint-based online metrics. Experiments with state-of-the-art LLMs reveal that current models struggle to ensure safety-aware planning, particularly under implicit constraints. Code and dataset are available at https://github.com/khm159/SPOC"
  },
  {
    "date": "2026-02-25",
    "title": "ABM-UDE: Developing Surrogates for Epidemic Agent-Based Models via Scientific Machine Learning",
    "authors": "Sharv Murgai, Utkarsh Utkarsh, Kyle C. Nguyen, Alan Edelman, Erin C. S. Acquesta, Christopher Vincent Rackauckas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21588v1",
    "source": "arXiv",
    "abstract": "Agent-based epidemic models (ABMs) encode behavioral and policy heterogeneity but are too slow for nightly hospital planning. We develop county-ready surrogates that learn directly from exascale ABM trajectories using Universal Differential Equations (UDEs): mechanistic SEIR-family ODEs with a neural-parameterized contact rate $κ_φ(u,t)$ (no additive residual). Our contributions are threefold: we adapt multiple shooting and an observer-based prediction-error method (PEM) to stabilize identification of neural-augmented epidemiological dynamics across intervention-driven regime shifts; we enforce positivity and mass conservation and show the learned contact-rate parameterization yields a well-posed vector field; and we quantify accuracy, calibration, and compute against ABM ensembles and UDE baselines. On a representative ExaEpi scenario, PEM-UDE reduces mean MSE by 77% relative to single-shooting UDE (3.00 vs. 13.14) and by 20% relative to MS-UDE (3.75). Reliability improves in parallel: empirical coverage of ABM $10$-$90$% and $25$-$75$% bands rises from 0.68/0.43 (UDE) and 0.79/0.55 (MS-UDE) to 0.86/0.61 with PEM-UDE and 0.94/0.69 with MS+PEM-UDE, indicating calibrated uncertainty rather than overconfident fits. Inference runs in seconds on commodity CPUs (20-35 s per $\\sim$90-day forecast), enabling nightly ''what-if'' sweeps on a laptop. Relative to a $\\sim$100 CPU-hour ABM reference run, this yields $\\sim10^{4}\\times$ lower wall-clock per scenario. This closes the realism-cadence gap, supports threshold-aware decision-making (e.g., maintaining ICU occupancy $<75$%), preserves mechanistic interpretability, and enables calibrated, risk-aware scenario planning on standard institutional hardware. Beyond epidemics, the ABM$\\to$UDE recipe provides a portable path to distill agent-based simulators into fast, trustworthy surrogates for other scientific domains."
  },
  {
    "date": "2026-02-25",
    "title": "Magnetic anisotropic pinning and symmetric breaking induced by interfacial coupling in topological-like ruthenate superlattices",
    "authors": "Zhongyuan Jiang, Zhiwei Zhang, Kesen Zhao, Wenjie Meng, Yuanyuan Zhao, Yubin Hou, Zhangzhang Cui, Jian Zhang, Zheling Shan, Haoliang Huang, Qingyou Lu, Yalin Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21582v1",
    "source": "arXiv",
    "abstract": "Interfacial engineering enables various emergent effects such as spin reorientations and transport anisotropy. Noncollinear spin textures are essential for realizing many emergent quantum transport phenomena. However, driving such spin structures requires precise control of the interfacial magnetic coupling in complex oxide heterostructures. Here, by utilizing competing exchange interactions at the interface between ferromagnetic metal SrRuO3 and ferromagnetic insulator LaCoO3, we discovered a noncollinear spin configuration in SrRuO3 sublayers. Magnetic stripes were induced by out-of-plane rather than in-plane magnetic fields, indicating strong anisotropy pinning in our superlattices. The observed magneto-transport anisotropy is well explained by our proposed spin configurations, accounting for contributions from both bulk and interface of the SrRuO3 layers. More interestingly, magnetic skymionic textures were absent even at high magnetic fields. The interfacial exchange interaction overwhelms the Dzyaloshinskii-Moriya interaction (DMI) that stabilizes skyrmions, featuring a higher exchange coupling energy than that for the topological spin textures. Our work highlights the potential of interfacial engineering in tuning the spintronic properties by designing proper interfacial interactions."
  },
  {
    "date": "2026-02-25",
    "title": "MultiAnimate: Pose-Guided Image Animation Made Extensible",
    "authors": "Yingcheng Hu, Haowen Gong, Chuanguang Yang, Zhulin An, Yongjun Xu, Songhua Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21581v1",
    "source": "arXiv",
    "abstract": "Pose-guided human image animation aims to synthesize realistic videos of a reference character driven by a sequence of poses. While diffusion-based methods have achieved remarkable success, most existing approaches are limited to single-character animation. We observe that naively extending these methods to multi-character scenarios often leads to identity confusion and implausible occlusions between characters. To address these challenges, in this paper, we propose an extensible multi-character image animation framework built upon modern Diffusion Transformers (DiTs) for video generation. At its core, our framework introduces two novel components-Identifier Assigner and Identifier Adapter - which collaboratively capture per-person positional cues and inter-person spatial relationships. This mask-driven scheme, along with a scalable training strategy, not only enhances flexibility but also enables generalization to scenarios with more characters than those seen during training. Remarkably, trained on only a two-character dataset, our model generalizes to multi-character animation while maintaining compatibility with single-character cases. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in multi-character image animation, surpassing existing diffusion-based baselines."
  },
  {
    "date": "2026-02-25",
    "title": "Bulk and turbulent gas motions in the interacting galaxy cluster Abell 3395 South observed with XRISM",
    "authors": "Naomi Ota, Angie Veronica, Jakob Dietl, Anri Yanagawa, Thomas H. Reiprich, Veronica Biffi, Klaus Dolag, Marcus Brüggen, Esra Bulbul, Florian Pacaud, Yoshiki Toba",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21580v1",
    "source": "arXiv",
    "abstract": "We investigate the gas motions in the core region of the Abell~3395 South subcluster (A3395S) using high-resolution X-ray spectroscopy with XRISM/Resolve. By analyzing the Fe~XXV He$α$ emission line, we directly measure the line-of-sight bulk and turbulent velocities of the intracluster medium. We find that the one-dimensional turbulent velocity is low, at the level of $124\\pm21~{\\rm km\\,s^{-1}}$, while a significant line-of-sight bulk velocity of $263\\pm23~{\\rm km\\,s^{-1}}$ is detected. The coexistence of low turbulence and finite bulk motion suggests that A3395S has not yet reached a dynamically relaxed state. These results are consistent with the non-detection of a radio halo in A3395S, implying that turbulent particle reacceleration is currently inefficient in the cluster core. This study demonstrates that high-resolution X-ray spectroscopy with XRISM provides a powerful means to directly constrain intracluster medium dynamics in merging galaxy clusters, and it provides a reference for future comparative studies of A3395N and A3391 within the same large-scale structure."
  },
  {
    "date": "2026-02-25",
    "title": "Equivariant log concavity and the $\\operatorname{FI^\\sharp}$-module structure on $H^i(\\operatorname{Conf}(n,\\mathbb{R}^d))$",
    "authors": "Benjamin Homan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21578v1",
    "source": "arXiv",
    "abstract": "Previous work has conjectured that the graded $\\mathfrak{S}_n$-representations $H^\\bullet(\\operatorname{Conf}(n,\\mathbb{R}^d);\\mathbb{Q})$ are strongly equivariantly log concave, and has proven this conjecture in low degrees. By leveraging the theory of representation stability, we are able instead prove a stronger statement about the $\\operatorname{FI^\\sharp}$-module structure on $H^i(\\operatorname{Conf}(n,\\mathbb{R}^d);\\mathbb{Q})$ which implies the original conjecture up to degree 19. We conjecture that this equivariant log concavity-like property holds in all degrees for the $\\operatorname{FI^\\sharp}$-modules $H^i(\\operatorname{Conf}(n,\\mathbb{R}^d);\\mathbb{Q})$."
  },
  {
    "date": "2026-02-25",
    "title": "Diagnosis-Driven Co-planning of Network Reinforcement and BESS for Distribution Grid with High Penetration of Electric Vehicles",
    "authors": "Linhan Fang, Elias Raffoul, Xingpeng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21567v1",
    "source": "arXiv",
    "abstract": "While the rapid proliferation of electric vehicles (EVs) accelerates net-zero goals, uncoordinated charging activities impose severe operational challenges on distribution grids, including exacerbated peak loads, thermal overloading, and voltage violations. To overcome the computational intractability of jointly optimizing grid infrastructure reinforcements and battery energy storage system (BESS) installations, this paper proposes a novel three-stage diagnosis-driven co-planning (DDCP) framework. The methodology integrates a violation detection and quantification (VDQ) model to systematically identify system breaches, and a violation-mitigated BESS planning (VMBP) model for optimal BESS sitting and sizing. Specifically, Stage I of the DDCP framework diagnoses critical bottleneck lines that render standalone BESS solutions infeasible. Stage II targets cable upgrades exclusively at the Top-N prioritized bottleneck lines and Stage III then executes the optimal BESS deployment using a network-enhanced VMBP model. Furthermore, this study quantifies the EV hosting capacity thresholds before and after BESS integration across varying EV adoption rates and base voltages. Finally, a comprehensive comparative analysis evaluates four mitigation approaches: the VDQ-driven cable upgrade (VCU) model, the VMBP model, system-wide voltage uprating, and the proposed DDCP framework. The results demonstrate that the DDCP framework not only resolves the complex joint-optimization hurdle but also achieves the high techno-economic superiority in addressing high-EV-penetration challenges."
  },
  {
    "date": "2026-02-25",
    "title": "Entanglement recovery by reversing the effect of noise in quantum repeater",
    "authors": "Sewon Jeong, Shrobona Bagchi, Jaehak Lee, Hyang-Tag Lim, Yong-Su Kim, Taeyoung Choi, Seung-Woo Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21563v1",
    "source": "arXiv",
    "abstract": "We propose a method to directly recover the degree of entanglement distributed by entanglement swapping in the presence of noise. Our approach introduces a reversing operation that probabilistically undoes the effect of amplitude damping or photon loss on a single entangled pair, enabling heralded recovery of entanglement. We demonstrate that entanglement can be substantially recovered even under strong noise, including parameter regimes where the distributed entanglement would otherwise vanish due to entanglement sudden death. We analyze the effectiveness of the protocol in two representative repeater models, i.e.,~two-way and one-way architectures and identify the optimal reversing strategy. Due to its heralded and single-copy nature, our protocol is readily compatible with other entanglement recovery techniques such as entanglement purification and distillation. Our work provides a practical and experimentally feasible way toward robust entanglement distribution in current and near-term quantum repeater architectures."
  },
  {
    "date": "2026-02-25",
    "title": "Passive Environment-Assisted Quantum Communication",
    "authors": "Evelyn Voss, Bikun Li, Zhaoyou Wang, Liang Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21549v1",
    "source": "arXiv",
    "abstract": "As quantum information systems mature, efficient and coherent transfer of quantum information through noisy channels becomes increasingly important. We examine how passive environment-assisted quantum communication enhances direct quantum information transfer efficiency. A bosonic pure-loss channel, modeled as transmission through a beam splitter with a vacuum input state at the dark port, has zero quantum capacity when transmissivity is below 50%. Quantum communication through the channel can be enhanced by passive environment assistance, achieved via the selection of an appropriate input state for the ancilla port. Although ideal Gottesman-Kitaev-Preskill (GKP) states enable perfect quantum information transmission at arbitrarily small transmissivity, they are challenging to realize experimentally. We therefore explore more experimentally accessible non-Gaussian ancilla states, such as Fock, cat, and squeezed cat states, and numerically determine the optimal encoding and decoding strategies. We also construct analytical schemes that yield high-fidelity transmission and good information rates."
  },
  {
    "date": "2026-02-25",
    "title": "Muon+: Towards Better Muon via One Additional Normalization Step",
    "authors": "Ruijie Zhang, Yequan Zhao, Ziyue Liu, Zhengyang Wang, Zheng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21545v1",
    "source": "arXiv",
    "abstract": "The Muon optimizer has demonstrated promising performance in pre-training large language models through gradient (or momentum) orthogonalization. In this work, we propose a simple yet effective enhancement to Muon, namely Muon+, which introduces an additional normalization step after orthogonalization. We demonstrate the effectiveness of Muon+ through extensive pre-training experiments across a wide range of model scales and architectures. Our evaluation includes GPT-style models ranging from 130M to 774M parameters and LLaMA-style models ranging from 60M to 1B parameters. We comprehensively evaluate the effectiveness of Muon+ in the compute-optimal training regime and further extend the token-to-parameter (T2P) ratio to an industrial level of $\\approx 200$. Experimental results show that Muon+ provides a consistent boost on training and validation perplexity over Muon. We provide our code here: https://github.com/K1seki221/MuonPlus."
  },
  {
    "date": "2026-02-25",
    "title": "Efficient time-series prediction on NISQ devices via time-delayed quantum extreme learning machine",
    "authors": "Mio Kawanabe, Saud Cindrak, Kathy Luedge, Jun-ichi Shirakashi, Tetsuo Shibuya, Hiroshi Imai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21544v1",
    "source": "arXiv",
    "abstract": "We proposed a time-delayed quantum extreme learning machine (TD-QELM) for efficient time-series prediction on noisy intermediate-scale quantum (NISQ) devices. By encoding multiple past inputs simultaneously, TD-QELM achieves shallow circuit depth independent of sequence length, thereby, mitigating noise accumulation and reducing computational complexity. Experiments using the NARMA benchmark on both noiseless simulations and IBM's 127-qubit processor demonstrate that TD-QELM consistently outperforms conventional quantum reservoir computing in prediction accuracy and noise robustness. These results highlight TD-QELM as a practical and scalable framework for time-series learning on current NISQ hardware."
  },
  {
    "date": "2026-02-25",
    "title": "TG-ASR: Translation-Guided Learning with Parallel Gated Cross Attention for Low-Resource Automatic Speech Recognition",
    "authors": "Cheng-Yeh Yang, Chien-Chun Wang, Li-Wei Chen, Hung-Shin Lee, Hsin-Min Wang, Berlin Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22039v1",
    "source": "arXiv",
    "abstract": "Low-resource automatic speech recognition (ASR) continues to pose significant challenges, primarily due to the limited availability of transcribed data for numerous languages. While a wealth of spoken content is accessible in television dramas and online videos, Taiwanese Hokkien exemplifies this issue, with transcriptions often being scarce and the majority of available subtitles provided only in Mandarin. To address this deficiency, we introduce TG-ASR for Taiwanese Hokkien drama speech recognition, a translation-guided ASR framework that utilizes multilingual translation embeddings to enhance recognition performance in low-resource environments. The framework is centered around the parallel gated cross-attention (PGCA) mechanism, which adaptively integrates embeddings from various auxiliary languages into the ASR decoder. This mechanism facilitates robust cross-linguistic semantic guidance while ensuring stable optimization and minimizing interference between languages. To support ongoing research initiatives, we present YT-THDC, a 30-hour corpus of Taiwanese Hokkien drama speech with aligned Mandarin subtitles and manually verified Taiwanese Hokkien transcriptions. Comprehensive experiments and analyses identify the auxiliary languages that most effectively enhance ASR performance, achieving a 14.77% relative reduction in character error rate and demonstrating the efficacy of translation-guided learning for underrepresented languages in practical applications."
  },
  {
    "date": "2026-02-25",
    "title": "Quantitative propagation of chaos for 2D stochastic vortex model on the whole space under moderate interactions",
    "authors": "Alexandre B. de Souza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22038v1",
    "source": "arXiv",
    "abstract": "We derive the stochastic 2D vortex model on the whole Euclidean space from stochastic particle systems driven by individual and environmental noises, obtaining pathwise quantitative bounds in the sense of relative entropy. The main novelty is the application of the Donsker-Varadhan inequality in the context of moderately interacting particles to handle the nonlinearity, as well as the use of localization techniques combined with the probabilistic data setting, to derive estimates for the quadratic variation terms. Moreover, we prove the existence of a suitable solution to the aforementioned model."
  },
  {
    "date": "2026-02-25",
    "title": "Ab initio calculations of nuclear charge radii across and beyond ${}^{132}$Sn: Putting chiral EFT nuclear interactions to the test",
    "authors": "Pepijn Demol, Urban Vernik, Thomas Duguet, Alexander Tichai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22030v1",
    "source": "arXiv",
    "abstract": "Charge radii are investigated along the Tin isotopic chain via ab initio Bogoliubov coupled cluster calculations at the singles and doubles level. In addition to the reproduction of absolute radii, the parabolic behavior of isotopic shifts between the N = 50 and N = 82 magic numbers and the kink through ${}^{132}$Sn are shown to provide stringent tests for state-of-the-art chiral effective field theory ($χ$EFT) inter-nucleon interactions. Indeed, none of the employed fine-tuned interactions can capture all such key characteristics. Eventually, the pronounced sensitivity of the results to the employed Hamiltonian beyond ${}^{132}$Sn provides a unique playground to pin down critical attributes of $χ$EFT inter-nucleon interactions in the future. This calls for measuring isotopic shifts both towards ${}^{100}$Sn and beyond ${}^{134}$Sn, as well as for performing high-accuracy ab initio calculations of mean-square radii in heavy open-shell nuclei by adding both triples corrections to the many-body wave function and the two-body charge density correction to the operator"
  },
  {
    "date": "2026-02-25",
    "title": "Disease Progression and Subtype Modeling for Combined Discrete and Continuous Input Data",
    "authors": "Sterre de Jonge, Elisabeth J. Vinke, Meike W. Vernooij, Daniel C. Alexander, Alexandra L. Young, Esther E. Bron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22018v1",
    "source": "arXiv",
    "abstract": "Disease progression modeling provides a robust framework to identify long-term disease trajectories from short-term biomarker data. It is a valuable tool to gain a deeper understanding of diseases with a long disease trajectory, such as Alzheimer's disease. A key limitation of most disease progression models is that they are specific to a single data type (e.g., continuous data), thereby limiting their applicability to heterogeneous, real-world datasets. To address this limitation, we propose the Mixed Events model, a novel disease progression model that handles both discrete and continuous data types. This model is implemented within the Subtype and Stage Inference (SuStaIn) framework, resulting in Mixed-SuStaIn, enabling subtype and progression modeling. We demonstrate the effectiveness of Mixed-SuStaIn through simulation experiments and real-world data from the Alzheimer's Disease Neuroimaging Initiative, showing that it performs well on mixed datasets. The code is available at: https://github.com/ucl-pond/pySuStaIn."
  },
  {
    "date": "2026-02-25",
    "title": "IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs",
    "authors": "Chris Egersdoerfer, Arnav Sareen, Jean Luca Bez, Suren Byna, Dongkuan, Xu, Dong Dai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22017v1",
    "source": "arXiv",
    "abstract": "As the complexity of the HPC storage stack rapidly grows, domain scientists face increasing challenges in effectively utilizing HPC storage systems to achieve their desired I/O performance. To identify and address I/O issues, scientists largely rely on I/O experts to analyze their I/O traces and provide insights into potential problems. However, with a limited number of I/O experts and the growing demand for data-intensive applications, inaccessibility has become a major bottleneck, hindering scientists from maximizing their productivity. Rapid advances in LLMs make it possible to build an automated tool that brings trustworthy I/O performance diagnosis to domain scientists. However, key challenges remain, such as the inability to handle long context windows, a lack of accurate domain knowledge about HPC I/O, and the generation of hallucinations during complex interactions.In this work, we propose IOAgent as a systematic effort to address these challenges. IOAgent integrates a module-based pre-processor, a RAG-based domain knowledge integrator, and a tree-based merger to accurately diagnose I/O issues from a given Darshan trace file. Similar to an I/O expert, IOAgent provides detailed justifications and references for its diagnoses and offers an interactive interface for scientists to ask targeted follow-up questions. To evaluate IOAgent, we collected a diverse set of labeled job traces and released the first open diagnosis test suite, TraceBench. Using this test suite, we conducted extensive evaluations, demonstrating that IOAgent matches or outperforms state-of-the-art I/O diagnosis tools with accurate and useful diagnosis results. We also show that IOAgent is not tied to specific LLMs, performing similarly well with both proprietary and open-source LLMs. We believe IOAgent has the potential to become a powerful tool for scientists navigating complex HPC I/O subsystems in the future."
  },
  {
    "date": "2026-02-25",
    "title": "World Guidance: World Modeling in Condition Space for Action Generation",
    "authors": "Yue Su, Sijin Chen, Haixin Shi, Mingyu Liu, Zhengshen Zhang, Ningyuan Huang, Weiheng Zhong, Zhengbang Zhu, Yuxiao Liu, Xihui Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22010v1",
    "source": "arXiv",
    "abstract": "Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is available at: https://selen-suyue.github.io/WoGNet/"
  },
  {
    "date": "2026-02-25",
    "title": "Universal Transport Properties of Continuous quantum gases",
    "authors": "Zi-yang Liu, Xiangguo Yin, Yunbo Zhang, Shizhong Zhang, Xi-Wen Guan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.22009v1",
    "source": "arXiv",
    "abstract": "The Drude weight characterizes ballistic transport in quantum many-body systems, yet a comprehensive understanding and exact analytical results for it remain elusive, especially in multi-component quantum gases. In this work, we leverage Generalized Hydrodynamics and the Thermodynamic Bethe Ansatz method to precisely compute the Drude weights of one-dimensional continuous integrable systems, such as the Lieb-Liniger model and the Bose-Fermi mixture model. We establish an exact, universal relationship between components of the Drude weight matrix and fundamental thermodynamic quantities (e.g., particle, enthalpy, and entropy densities) for the constituent particles with distinct statistics undergo dynamic coupling. For both models, we further derive analytical approximations of the Drude weight in distinct physical regimes and identify universal scaling laws for the Drude weight near quantum phase transitions.Finally, to connect theory with experiment, we propose and simulate two feasible measurement protocols--a linear potential quench and a bipartitioning setup-verifying that they can reliably extract the Drude weights. Our results establish a direct link between macroscopic transport phenomena and microscopic quasiparticle structure, furnishing critical theoretical benchmarks for future ultracold atomic gas experiments."
  },
  {
    "date": "2026-02-25",
    "title": "Intrusive and Non-Intrusive Model Order Reduction for Airborne Contaminant Transport: Comparative Analysis and Uncertainty Quantification",
    "authors": "Lisa Kühn, Jacopo Bonari, Max von Danwitz, Alexander Popp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21996v1",
    "source": "arXiv",
    "abstract": "Numerical simulations of contaminant dispersion, as after a gas leakage incident on a chemical plant, can provide valuable insights for both emergency response and preparedness. Simulation approaches combine incompressible Navier-Stokes (INS) equations with advection-diffusion (AD) processes to model wind and concentration field. However, the computational cost of such high-fidelity simulations increases rapidly for complex geometries like urban environments, making them unfeasible in time-critical or multi-query \"what-if\" scenarios. Therefore, this study focuses on the application of model order reduction (MOR) techniques enabling fast yet accurate predictions. To this end, a thorough comparison of intrusive and non-intrusive MOR methods is performed for the computationally more demanding parametric INS problem with varying wind velocities. Based on these insights, a non-intrusive reduced-order model (ROM) is constructed accounting for both wind velocity and direction. The study is conducted on a two-dimensional domain derived from real-world building footprints, preserving key features for analyzing the dispersion of, for instance, denser contaminants. The resulting ROM enables faster than real-time predictions of spatio-temporal contaminant dispersion from an instantaneous source under varying wind conditions. This capability allows assessing wind measurement uncertainties through a Monte Carlo analysis. To demonstrate the practical applicability, an interactive dashboard provides intuitive access to simulation results."
  },
  {
    "date": "2026-02-25",
    "title": "Outpatient Appointment Scheduling Optimization with a Genetic Algorithm Approach",
    "authors": "Ana Rodrigues, Rui Rego",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21995v1",
    "source": "arXiv",
    "abstract": "The optimization of complex medical appointment scheduling remains a significant operational challenge in multi-center healthcare environments, where clinical safety protocols and patient logistics must be reconciled. This study proposes and evaluates a Genetic Algorithm (GA) framework designed to automate the scheduling of multiple medical acts while adhering to rigorous inter-procedural incompatibility rules. Using a synthetic dataset encompassing 50 medical acts across four healthcare facilities, we compared two GA variants, Pre-Ordered and Unordered, against deterministic First-Come, First-Served (FCFS) and Random Choice baselines. Our results demonstrate that the GA framework achieved a 100% constraint fulfillment rate, effectively resolving temporal overlaps and clinical incompatibilities that the FCFS baseline failed to address in 60% and 40% of cases, respectively. Furthermore, the GA variants demonstrated statistically significant improvements (p < 0.001) in patient-centric metrics, achieving an Idle Time Ratio (ITR) frequently below 0.4 and reducing inter-healthcenter trips. While the GA (Ordered) variant provided a superior initial search locus, both evolutionary models converged to comparable global optima by the 100th generation. These findings suggest that transitioning from manual, human-mediated scheduling to an automated metaheuristic approach enhances clinical integrity, reduces administrative overhead, and significantly improves the patient experience by minimizing wait times and logistical burdens."
  },
  {
    "date": "2026-02-25",
    "title": "PatchDenoiser: Parameter-efficient multi-scale patch learning and fusion denoiser for medical images",
    "authors": "Jitindra Fartiyal, Pedro Freire, Sergei K. Turitsyn, Sergei G. Solovski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21987v1",
    "source": "arXiv",
    "abstract": "Medical images are essential for diagnosis, treatment planning, and research, but their quality is often degraded by noise from low-dose acquisition, patient motion, or scanner limitations, affecting both clinical interpretation and downstream analysis. Traditional filtering approaches often over-smooth and lose fine anatomical details, while deep learning methods, including CNNs, GANs, and transformers, may struggle to preserve such details or require large, computationally expensive models, limiting clinical practicality. We propose PatchDenoiser, a lightweight, energy-efficient multi-scale patch-based denoising framework. It decomposes denoising into local texture extraction and global context aggregation, fused via a spatially aware patch fusion strategy. This design enables effective noise suppression while preserving fine structural and anatomical details. PatchDenoiser is ultra-lightweight, with far fewer parameters and lower computational complexity than CNN-, GAN-, and transformer-based denoisers. On the 2016 Mayo Low-Dose CT dataset, PatchDenoiser consistently outperforms state-of-the-art CNN- and GAN-based methods in PSNR and SSIM. It is robust to variations in slice thickness, reconstruction kernels, and HU windows, generalizes across scanners without fine-tuning, and reduces parameters by ~9x and energy consumption per inference by ~27x compared with conventional CNN denoisers. PatchDenoiser thus provides a practical, scalable, and computationally efficient solution for medical image denoising, balancing performance, robustness, and clinical deployability."
  },
  {
    "date": "2026-02-25",
    "title": "Fractal dimension of singular times for SPDEs: Energy bounds, criticality, and weak-strong uniqueness",
    "authors": "Antonio Agresti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21981v1",
    "source": "arXiv",
    "abstract": "For several physically relevant SPDEs, it is known that global weak solutions coexist with local strong ones. Typically, weak-strong uniqueness results are known, and ensure that the global and strong solutions coincide as long as the latter exist. Times at which a weak solution does not coincide with a strong one are called singular times. Determining their fractal dimension is fundamental to capturing the regularity of weak solutions. We define singular times for a wide class of semilinear SPDEs. We show that sets of singular times have fractal dimension (i.e., Hausdorff and/or Minkowski) at most $ 1-\\ell\\, \\mathsf{Exc}$, where $\\ell$ and $\\mathsf{Exc}$ are the time integrability and the excess of spatial regularity compared to the critical regularity of the energy bound associated with weak solutions, respectively. Moreover, their corresponding $(1-\\ell\\,\\mathsf{Exc} )$-dimensional measure is zero. We formulate and apply our theory to quenched strong Leray-Hopf solutions of 3D Navier-Stokes equations (NSEs) with physically relevant noises, including rough Kraichnan and Lie transport. In particular, we extend the fundamental $1/2$-dimensional bound of Leray and Scheffer on singular times for 3D NSEs to the stochastic setting, and we prove new conditional results under supercritical Serrin's conditions, irrespective of the roughness of the noise. Our framework is new even in the deterministic case, and provides the first partial regularity results for weak solutions to SPDEs with multiplicative noise."
  },
  {
    "date": "2026-02-25",
    "title": "Autobidding Equilibria in Sponsored Shopping",
    "authors": "Paul Dütting, Renato Paes Leme, Yuhao Li, Kelly Spendlove, Yifeng Teng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21966v1",
    "source": "arXiv",
    "abstract": "As commerce shifts to digital marketplaces, platforms increasingly monetize traffic through Sponsored Shopping auctions. Unlike classic ``Sponsored Search\", where an advertiser typically bids for a single link, these settings involve advertisers with broad catalogs of distinct products. In these auctions, a single advertiser can secure multiple slots simultaneously to promote different items within the same query. This creates a fundamental complexity: the allocation is combinatorial, as advertisers simultaneously win a bundle of slots rather than a single position. We study this setting through the lens of autobidding, where value-maximizing agents employ uniform bidding strategies to optimize total value subject to Return-on-Investment (ROI) constraints. We analyze two prevalent auction formats: Generalized Second-Price (GSP) and Vickrey-Clarke-Groves (VCG). Our first main contribution is establishing the universal existence of an Autobidding Equilibrium for both settings. Second, we prove a tight Price of Anarchy (PoA) of 2 for both mechanisms."
  },
  {
    "date": "2026-02-25",
    "title": "Compact Circulant Layers with Spectral Priors",
    "authors": "Joseph Margaryan, Thomas Hamelryck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21965v1",
    "source": "arXiv",
    "abstract": "Critical applications in areas such as medicine, robotics and autonomous systems require compact (i.e., memory efficient), uncertainty-aware neural networks suitable for edge and other resource-constrained deployments. We study compact spectral circulant and block-circulant-with-circulant-blocks (BCCB) layers: FFT-diagonalizable circular convolutions whose weights live directly in the real FFT (RFFT) half (1D) or half-plane (2D). Parameterizing filters in the frequency domain lets us impose simple spectral structure, perform structured variational inference in a low-dimensional weight space, and calculate exact layer spectral norms, enabling inexpensive global Lipschitz bounds and margin-based robustness diagnostics. By placing independent complex Gaussians on the Hermitian support we obtain a discrete instance of the spectral representation of stationary kernels, inducing an exact stationary Gaussian-process prior over filters on the discrete circle/torus. We exploit this to define a practical spectral prior and a Hermitian-aware low-rank-plus-diagonal variational posterior in real coordinates. Empirically, spectral circulant/BCCB layers are effective compact building blocks in both (variational) Bayesian and point estimate regimes: compact Bayesian neural networks on MNIST->Fashion-MNIST, variational heads on frozen CIFAR-10 features, and deterministic ViT projections on CIFAR-10/Tiny ImageNet; spectral layers match strong baselines while using substantially fewer parameters and with tighter Lipschitz certificates."
  },
  {
    "date": "2026-02-25",
    "title": "Optimal Trajectories in Discrete Space with Acceleration Constraints",
    "authors": "Arnaud Casteigts, Matteo De Francesco, Pierre Leone",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21964v1",
    "source": "arXiv",
    "abstract": "In the racetrack acceleration model, proposed by Martin Gardner in 1973, each step consists of changing the position of the vehicle by a vector in $\\mathbb{Z}^2$, with the constraints that two consecutive vectors differ by at most one unit in each dimension. We investigate three problems related to this model in arbitrary dimension in open space (no obstacles), where a configuration of the vehicle consists of its current position and the last-used vector. The three problems are the following. In Branching Cost (BC), given two configurations, the goal is to compute the minimum number of intermediate configurations (length of a trajectory) between the two configurations. Branching Trajectory (BT) has the same input and asks for a description of the corresponding trajectory. Multipoint Trajectory (MT) asks for an optimal trajectory that visits given points $p_1,\\dots,p_n$ in a prescribed order, starting and ending with zero-speed configurations.\\\\ We revisit known approaches to solve BC in 2D, showing that this problem can be solved in constant time in any fixed number of dimensions $d$ (more generally, in $O(d \\log d)$ time). We show that BT can also be solved in constant time for any fixed $d$, despite the fact that the length of the trajectory is not constant, by leveraging the fact that there always exists \\emph{one} optimal trajectory compactly represented by $O(1)$ intermediate configurations. For MT, we collect theoretical and experimental evidence that the speed cannot be trivially bounded; local decisions may be impacted by points that are arbitrarily far in the visit order; and an optimal trajectory may require significant excursions out of the convex hull of the points. We still establish conservative speed bounds that a natural dynamic programming (DP) algorithm can exploit to solve reasonably large instances efficiently."
  },
  {
    "date": "2026-02-25",
    "title": "Analysis of eigenvalue clustering leads to optimal scaling in numerical radiative transfer",
    "authors": "Pietro Benedusi, Simone Riva, Luca Belluzzi, Stefano Serra-Capizzano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21958v1",
    "source": "arXiv",
    "abstract": "We consider a multidimensional polychromatic radiative transfer (RT) problem, accounting for scattering processes in a general form, i.e. anisotropic (dipole) scattering with partial frequency redistribution. Given a discrete ordinates discretization, we report the corresponding matrix structures, depending on model and discretization parameters. Despite the possibly dense nature of these matrices, the use of Krylov methods is effective (especially in the matrix-free context) and robust. We propose a theoretical analysis, using the spectral tools of the symbol theory, explaining why Krylov convergence is robust w.r.t. all the discretization parameters, even in the unpreconditioned case. In fact, the compactness of the continuous operators used in the modeling leads to zero-clustered dense matrix sequences plus identity, so that the clustering at the unity of the spectra is deduced. Numerical experiments confirm the theoretical results, which have a direct application, for example, in the simulation of radiative transfer in stellar atmospheres, a key problem in astrophysical research. In general, we demonstrate that optimal scaling with respect to RT discretization parameters is expected for Krylov solution strategies."
  },
  {
    "date": "2026-02-25",
    "title": "Geometric oscillations of local Hall and Nernst effects in ballistic graphene at weak magnetic fields",
    "authors": "Z. Z. Alisultanov, A. V. Kavokin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21934v1",
    "source": "arXiv",
    "abstract": "We predict a novel class of magnetotransport oscillations in ballistic graphene specific for a ring-shape geometry. Using the Büttiker-Landauer formalism, we analytically obtain the local Hall and Nernst coefficients in the weak-field ballistic regime. These coefficients exhibit pronounced oscillations as functions of both the magnetic field and the angular positions of the measurement probes. The oscillations originate from the discrete set of skipping orbits that geometrically connect the contacts, with resonances occurring when the angular separation between contacts times the radius of the disk equals an integer number of cyclotron diameters. Unlike conventional quantum oscillations in conductivity, this effect is robust at room temperature and can dominate local thermoelectric signals. This geometric control of ballistic flow provides a platform for studying electron hydrodynamics and engineering phase-coherent devices, with potential applications in sensitive terahertz detectors and thermal management systems."
  },
  {
    "date": "2026-02-25",
    "title": "Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context",
    "authors": "JiaKui Hu, Jialun Liu, Liying Yang, Xinliang Zhang, Kaiwen Li, Shuang Zeng, Yuanwei Li, Haibin Huang, Chi Zhang, Yanye Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21929v1",
    "source": "arXiv",
    "abstract": "Scene-consistent video generation aims to create videos that explore 3D scenes based on a camera trajectory. Previous methods rely on video generation models with external memory for consistency, or iterative 3D reconstruction and inpainting, which accumulate errors during inference due to incorrect intermediary outputs, non-differentiable processes, and separate models. To overcome these limitations, we introduce ``geometry-as-context\". It iteratively completes the following steps using an autoregressive camera-controlled video generation model: (1) estimates the geometry of the current view necessary for 3D reconstruction, and (2) simulates and restores novel view images rendered by the 3D scene. Under this multi-task framework, we develop the camera gated attention module to enhance the model's capability to effectively leverage camera poses. During the training phase, text contexts are utilized to ascertain whether geometric or RGB images should be generated. To ensure that the model can generate RGB-only outputs during inference, the geometry context is randomly dropped from the interleaved text-image-geometry training sequence. The method has been tested on scene video generation with one-direction and forth-and-back trajectories. The results show its superiority over previous approaches in maintaining scene consistency and camera control."
  },
  {
    "date": "2026-02-25",
    "title": "Bridging Through Absence: How Comeback Researchers Bridge Knowledge Gaps Through Structural Re-emergence",
    "authors": "Somyajit Chakraborty, Angshuman Jana, Avijit Gayen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21926v1",
    "source": "arXiv",
    "abstract": "Understanding the role of researchers who return to academia after prolonged inactivity, termed \"comeback researchers\", is crucial for developing inclusive models of scientific careers. This study investigates the structural and semantic behaviors of comeback researchers, focusing on their role in cross-disciplinary knowledge transfer and network reintegration. Using the AMiner citation dataset, we analyze 113,637 early-career researchers and identify 1,425 comeback cases based on a three-year-or-longer publication gap followed by renewed activity. We find that comeback researchers cite 126% more distinct communities and exhibit 7.6% higher bridging scores compared to dropouts. They also demonstrate 74% higher gap entropy, reflecting more irregular yet strategically impactful publication trajectories. Predictive models trained on these bridging- and entropy-based features achieve a 97% ROC-AUC, far outperforming the 54% ROC-AUC of baseline models using traditional metrics like publication count and h-index. Finally, we substantiate these results via a multi-lens validation. These findings highlight the unique contributions of comeback researchers and offer data-driven tools for their early identification and institutional support."
  },
  {
    "date": "2026-02-25",
    "title": "Real analytic solutions to the divergence equation",
    "authors": "Chi Hin Chan, Jun-Shuo Chen, Cheng-Fang Su",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21925v1",
    "source": "arXiv",
    "abstract": "In this paper, we develop a differential-topological method to yield explicit real analytic solutions $v$ to the divergence equation $div_{\\mathbb{R}^n} v = f$ on any annali $A(R_1 ,R_2) = \\{ x \\in \\mathbb{R}^n : R_1 < |x| < R_2\\}$, with $n \\geq 2$, and $0 < R_1 < R_2 < \\infty$. The prescribed source term $f$ is supposed to be real analytic on $\\overline{A(R_1 , R_2)} = \\{ x \\in \\mathbb{R}^n : R_1 \\leq |x| \\leq R_2\\}$ satisfying the zero integral condition on $A(R_1, R_2)$. The resulting solution $v$ is a real analytic vector field on $\\overline{A(R_1 , R_2)}$, which vanishes on $\\partial \\big( A(R_1, R_2 ) \\big )$. The method which we develop here is different from the standard Bogovski approach and the Kapitanskii-Pileckas approach. The first main step our method is a clever differential-topological argument, which we develop under the inspiration and guidance of the standard proof of the cohomological statement $H_c^n \\big ( \\mathbb{R}^n\\big ) = \\mathbb{R}$ in Spviak book A Comprehensive Introduction to Differential Geometry, Vol I. This allows us to reduce the problem to that of solving a linear algebra problem."
  },
  {
    "date": "2026-02-25",
    "title": "Comparison of Linear Systems Across Time Domains: Continuous-time vs. Discrete-time",
    "authors": "Armin Pirastehzad, Bart Besselink",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21924v1",
    "source": "arXiv",
    "abstract": "We develop a formal framework for the behavioral comparison of linear systems across different time domains. We accomplish this by introducing the notion of system interpolation, which determines whether the input-state trajectories of a continuous-time system can be realized as piecewise polynomial interpolations of the input-state trajectories of a discrete-time system. In this context, a piecewise polynomial interpolation of a discrete-time signal is characterized as a continuous-time function that coincides with the discrete-time signal at given sampling instants and can be realized as a polynomial of a prescribed degree over intervals between these instants. By representing piecewise polynomial functions as linear combinations of shifted Legendre polynomials, we characterize system interpolation as a subspace inclusion that is completely in terms of system parameters. This therefore allows for a computationally efficient comparison of the input-state behavior of a continuous-time system with that of a discrete-time one. We then exploit this characterization to discretize a given continuous-time system into a discrete-time one. Lastly, given a control specification, we exploit system interpolation to synthesize controllers that ensure satisfaction at each given sampling instant, while they measure the extent of (possible) violation over intervals between these instants."
  },
  {
    "date": "2026-02-25",
    "title": "Learning in the Null Space: Small Singular Values for Continual Learning",
    "authors": "Cuong Anh Pham, Praneeth Vepakomma, Samuel Horváth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21919v1",
    "source": "arXiv",
    "abstract": "Alleviating catastrophic forgetting while enabling further learning is a primary challenge in continual learning (CL). Orthogonal-based training methods have gained attention for their efficiency and strong theoretical properties, and many existing approaches enforce orthogonality through gradient projection. In this paper, we revisit orthogonality and exploit the fact that small singular values correspond to directions that are nearly orthogonal to the input space of previous tasks. Building on this principle, we introduce NESS (Null-space Estimated from Small Singular values), a CL method that applies orthogonality directly in the weight space rather than through gradient manipulation. Specifically, NESS constructs an approximate null space using the smallest singular values of each layer's input representation and parameterizes task-specific updates via a compact low-rank adaptation (LoRA-style) formulation constrained to this subspace. The subspace basis is fixed to preserve the null-space constraint, and only a single trainable matrix is learned for each task. This design ensures that the resulting updates remain approximately in the null space of previous inputs while enabling adaptation to new tasks. Our theoretical analysis and experiments on three benchmark datasets demonstrate competitive performance, low forgetting, and stable accuracy across tasks, highlighting the role of small singular values in continual learning. The code is available at https://github.com/pacman-ctm/NESS."
  },
  {
    "date": "2026-02-25",
    "title": "Traffic-aware Hierarchical Integrated Thermal and Energy Management for Connected HEVs",
    "authors": "Jie Han, Arash Khalatbarisoltani, Hai L. Vu, Xiaosong Hu, Jun Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21914v1",
    "source": "arXiv",
    "abstract": "The energy and thermal management systems of hybrid electric vehicles (HEVs) are inherently interdependent. With the ongoing deployment of intelligent transportation systems (ITSs) and increasing vehicle connectivity, the integration of traffic information has become crucial for improving both energy efficiency and thermal comfort in modern vehicles. To enhance fuel economy, this paper proposes a novel traffic-aware hierarchical integrated thermal and energy management (TA-ITEM) strategy for connected HEVs. In the upper layer, global reference trajectories for battery state of charge (SOC) and cabin temperature are planned using traffic flow speed information obtained from ITSs. In the lower layer, a real-time model predictive control (MPC)-based ITEM controller is developed, which incorporates a novel Transformer-based speed predictor with driving condition recognition (TF-DCR) to enable anticipatory tracking of the reference trajectories. Numerical simulations are conducted under various driving cycles and ambient temperature conditions. The results demonstrate that the proposed TA-ITEM approach outperforms conventional rule-based and MPC-SP approaches, with average fuel consumption reductions of 56.36\\% and 5.84\\%, respectively, while maintaining superior thermal regulation and cabin comfort. These findings confirm the effectiveness and strong generalization capability of TA-ITEM and underscore the advantages of incorporating traffic information."
  },
  {
    "date": "2026-02-25",
    "title": "Deep Learning-Enabled Invisible Electromagnetic Scattering Amplifier",
    "authors": "Qike Xie, Qin Liao, Xiaofan Ji, Yichao Liu, Fei Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21908v1",
    "source": "arXiv",
    "abstract": "With the rapid development of micro-electro-mechanical systems, electrically small micro-targets, such as subwavelength micro unmanned aerial vehicles and bionic mosquito robots, exhibit ultra-low scattering cross section, which brings severe challenges to their effective detection. To address this problem, an Invisible Electromagnetic Scattering Amplifier (IESA) is designed by combining finite-element electromagnetic simulation with a forward lossless tandem neural network. The IESA realizes the dual-functional integration of intrinsic electromagnetic invisibility (near-zero scattering) for itself and significant scattering amplification for subwavelength targets entering its air sensing region. Electromagnetic simulations verify that the designed IESA can achieve a stable scattering amplification effect on subwavelength targets with a characteristic size of approximately 0.1λ0, regardless of their spatial positions or geometric shapes, with a maximum scattering cross section amplification factor of 8.58. The IESA breaks the technical bottleneck of the separate design of electromagnetic invisibility and scattering amplification functions. It shows potential for applications in the fields of radar detection, anti-terrorism security, micro-target monitoring, and adaptive electromagnetic sensing."
  },
  {
    "date": "2026-02-25",
    "title": "Betti numbers of skeletons of a class of squarefree monomial rings with l,inear resolution",
    "authors": "Ralf Fröberg",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21907v1",
    "source": "arXiv",
    "abstract": "The starting point is the class of the following simplicial complexes $Δ$ with 2-linear resolutions. The facets of $Δ$ are $F_1,\\ldots,F_n$, and we demand that for each $i$ $F_i\\cap (F_1\\cup \\cdots\\cup F_{i-1}\\cup F_{i+1}\\cdots\\cup F_n)$ be a point. We will determine the Betti numbers, and thus the projective dimension, the depth, and the regularity of the Stanley-Reisner rings of all skeletons of such complexes. It follows that we know when these complexes are Cohen-Macaulay. Also, there are two ways to determine the Hilbert series of $Δ$, giving sequences of identities for binomial coefficients."
  },
  {
    "date": "2026-02-25",
    "title": "TIRAuxCloud: A Thermal Infrared Dataset for Day and Night Cloud Detection",
    "authors": "Alexis Apostolakis, Vasileios Botsos, Niklas Wölki, Andrea Spichtinger, Nikolaos Ioannis Bountos, Ioannis Papoutsis, Panayiotis Tsanakas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21905v1",
    "source": "arXiv",
    "abstract": "Clouds are a major obstacle in Earth observation, limiting the usability and reliability of critical remote sensing applications such as fire disaster response, urban heat island monitoring, and snow and ice cover mapping. Therefore, the ability to detect clouds 24/7 is of paramount importance. While visible and near-infrared bands are effective for daytime cloud detection, their dependence on solar illumination makes them unsuitable for nighttime monitoring. In contrast, thermal infrared (TIR) imagery plays a crucial role in detecting clouds at night, when sunlight is absent. Due to their generally lower temperatures, clouds emit distinct thermal signatures that are detectable in TIR bands. Despite this, accurate nighttime cloud detection remains challenging due to limited spectral information and the typically lower spatial resolution of TIR imagery. To address these challenges, we present TIRAuxCloud, a multi-modal dataset centered around thermal spectral data to facilitate cloud segmentation under both daytime and nighttime conditions. The dataset comprises a unique combination of multispectral data (TIR, optical, and near-infrared bands) from Landsat and VIIRS, aligned with auxiliary information layers. Elevation, land cover, meteorological variables, and cloud-free reference images are included to help reduce surface-cloud ambiguity and cloud formation uncertainty. To overcome the scarcity of manual cloud labels, we include a large set of samples with automated cloud masks and a smaller manually annotated subset to further evaluate and improve models. Comprehensive benchmarks are presented to establish performance baselines through supervised and transfer learning, demonstrating the dataset's value in advancing the development of innovative methods for day and night time cloud detection."
  },
  {
    "date": "2026-02-25",
    "title": "Endpoint Variation and jump inequalities for rough singular integrals",
    "authors": "Ankit Bhojak, Saurabh Shrivastava",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21888v1",
    "source": "arXiv",
    "abstract": "In this article, we prove weak type $(1,1)$ bounds for the variation and jump operators corresponding to the family of truncations of singular integrals with rough kernels. This resolves an open question raised by Jones, Seeger and Wright (Trans. Amer. Math. Soc. (2008)). Moreover, as an immediate consequence of the variational estimate, we recover the weak type $(1,1)$ boundedness of the maximal truncation operator corresponding to singular integrals with rough kernels."
  },
  {
    "date": "2026-02-25",
    "title": "SND@LHC Upgrade for the High-Luminosity LHC: Physics Reach and Installation Scenarios",
    "authors": "SND@LHC Collaboration",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21881v1",
    "source": "arXiv",
    "abstract": "The SND@LHC experiment is currently taking data at the Large Hadron Collider (LHC), exploring the unique forward region at pseudorapidities from 7.2 to 8.4. Its physics programme covers neutrinos originating from heavy-flavour decays and feebly interacting particles produced in proton proton collisions. Building upon the successful operation of the present detector, this paper presents the physics reach of the approved SND@LHC upgrade for Run4 of the LHC, and compares it with an alternative installation scenario. Lowering the detector by approximately 40 cm and shifting it horizontally by about 30 cm, while keeping it off-axis, increases the total neutrino interaction rate by a factor of five. The paper describes the design of the upgraded detector and compare the physics performance in both installation scenarios."
  },
  {
    "date": "2026-02-25",
    "title": "Interactive Augmented Reality-enabled Outdoor Scene Visualization For Enhanced Real-time Disaster Response",
    "authors": "Dimitrios Apostolakis, Georgios Angelidis, Vasileios Argyriou, Panagiotis Sarigiannidis, Georgios Th. Papadopoulos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21874v1",
    "source": "arXiv",
    "abstract": "A user-centered AR interface for disaster response is presented in this work that uses 3D Gaussian Splatting (3DGS) to visualize detailed scene reconstructions, while maintaining situational awareness and keeping cognitive load low. The interface relies on a lightweight interaction approach, combining World-in-Miniature (WIM) navigation with semantic Points of Interest (POIs) that can be filtered as needed, and it is supported by an architecture designed to stream updates as reconstructions evolve. User feedback from a preliminary evaluation indicates that this design is easy to use and supports real-time coordination, with participants highlighting the value of interaction and POIs for fast decision-making in context. Thorough user-centric performance evaluation demonstrates strong usability of the developed interface and high acceptance ratios."
  },
  {
    "date": "2026-02-25",
    "title": "Study of the $Ω_{ccc}Ω_{ccc}$ and $Ω_{bbb}Ω_{bbb}$ dibaryons in QCD Sum Rules",
    "authors": "Xu-Liang Chen, Jin-Peng Zhang, Zi-Xi Ou-Yang, Wei Chen, Jia-Jun Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2602.21872v1",
    "source": "arXiv",
    "abstract": "The recent observation of a family of fully-charm tetraquark states by the LHCb, ATLAS and CMS Collaborations suggests the possible existence of fully-heavy dibaryons. In this work, we investigate the $Ω_{ccc}Ω_{ccc}$ and $Ω_{bbb}Ω_{bbb}$ dibaryons in both the $^1S_0$ and $^5S_2$ channels using the method of QCD sum rules. We employ the iterative dispersion relation (IDR) method to efficiently compute the massive five-loop banana diagrams that appear in these systems, and properly address the tricky small-circle divergence problem in the nonperturbative terms. Our analyses reveal that for both charm and bottom systems, the scalar dibaryon lies lower than its tensor counterpart. The mass of the scalar $Ω_{ccc}Ω_{ccc}$ dibaryon is found to be slightly above the $2Ω_{ccc}$ mass threshold, while the $Ω_{bbb}Ω_{bbb}$ systems may form bound states."
  },
  {
    "date": "2026-2-25",
    "title": "Design of an Intelligent TCM Diagnostic Model for Pattern Differentiation and Treatment in Liver Cancer",
    "authors": "Kexin Sun",
    "publish": "Proceedings of the 2025 4th International Conference on Health Big Data and Intelligent Healthcare",
    "url": "https://doi.org/10.1145/3792746.3792770",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-25",
    "title": "Integrating Traditional Statistical Analysis and Machine Learning to Explore the Relationship Between Academic Achievement and Physical Education Performance of Middle School Students in rural area in China",
    "authors": "Lei Huang, Zikang Zhang, Wei Peng, Shaoming Sun, Fangwen Zhang, Peixiao Lu",
    "publish": "Proceedings of the 2025 4th International Conference on Health Big Data and Intelligent Healthcare",
    "url": "https://doi.org/10.1145/3792746.3792759",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-25",
    "title": "Capacitive Crosstalk Model Between RF Probes in On-Wafer Measurements at Sub-THz/THz Frequencies",
    "authors": "Ahmad Raza Awan, Aleksi Maanselkä, Sumit Pratap Singh, Olli Kursu, Aarno Pärssinen, Marko E. Leinonen",
    "publish": "2025 50th International Conference on Infrared, Millimeter, and Terahertz Waves (IRMMW-THz)",
    "url": "https://doi.org/10.1109/irmmw-thz61557.2025.11406078",
    "source": "IEEE",
    "abstract": "Accurate characterization of devices in the sub-THz/THz frequency ranges is crucial for advancing next generation communication and sensing technologies. At these higher frequencies, factors such as RF leakage between probes and calibration transfer errors across different substrates can introduce significant inaccuracies in measurements. To address these challenges, a DUT consisting of balun and transformer is designed and optimized for 220 to 330 GHz frequencies in a 130 nm SiGe BiCMOS process. Discrepancies are observed between the measured and simulated S21 results. This work investigates RF capacitive crosstalk between the RF probes and its modeling in the simulation environment to improve the alignment of the measurement and simulation results. After incorporating the capacitive crosstalk model, a better agreement is achieved between the measured and simulated results. The findings provide valuable information to improve the alignment between the simulated and measured results."
  },
  {
    "date": "2026-2-25",
    "title": "2025 International Conference on Advances in Technology and Computing (ICATC)",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/icatc68823.2025",
    "source": "IEEE",
    "abstract": ""
  },
  {
    "date": "2026-2-25",
    "title": "Gauss–Newton Temporal Difference Learning With Nonlinear Function Approximation",
    "authors": "Zhifa Ke, Junyu Zhang, Zaiwen Wen",
    "publish": "IEEE Transactions on Neural Networks and Learning Systems",
    "url": "https://doi.org/10.1109/tnnls.2026.3661291",
    "source": "IEEE",
    "abstract": "In this article, a Gauss–Newton temporal difference (GNTD) learning method is proposed to solve the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$Q$</tex-math> </inline-formula>-learning problem with nonlinear function approximations. In each iteration, our method takes one Gauss–Newton (GN) step to optimize a variant of mean-squared Bellman error (MSBE), where target networks are adopted to avoid double sampling. Inexact GN steps are analyzed so that one can safely and efficiently compute the GN updates by cheap matrix iterations. Under mild conditions, nonasymptotic finite-sample convergence to the globally optimal <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$Q$</tex-math> </inline-formula> function is derived for various nonlinear function approximations. In particular, for neural network parameterization with ReLU activation, GNTD achieves an improved sample complexity of <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\tilde {\\mathcal {O}}(\\varepsilon ^{-1})$</tex-math> </inline-formula>, as opposed to the <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\mathcal {\\mathcal {O}}(\\varepsilon ^{-2})$</tex-math> </inline-formula> sample complexity of the existing neural temporal difference (TD) methods. An <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\tilde {\\mathcal {O}}(\\varepsilon ^{-1.5})$</tex-math> </inline-formula> sample complexity of GNTD is also established for general smooth function approximations. We validate our method via extensive experiments on several reinforcement learning (RL) benchmarks, where GNTD exhibits both higher rewards and faster convergence than TD-type methods."
  },
  {
    "date": "2026-2-25",
    "title": "Inertial Trajectory Estimation Using Low-Cost Inertial Measurement Units and Edge Computing",
    "authors": "Bor-Shyh Lin, Chih-Wei Peng, Shing Hin Hui, Bor-Shing Lin",
    "publish": "IEEE Journal of Biomedical and Health Informatics",
    "url": "https://doi.org/10.1109/jbhi.2026.3668114",
    "source": "IEEE",
    "abstract": "Trajectory estimation is often used in applications such as rehabilitation assessment and indoor navigation. Although various sensors can be used to estimate trajectories, inertial measurement units (IMUs) are both easy to implement and can be used in both indoor and outdoor environments. This study proposes a system in which trajectory estimation models are integrated into an edge computing platform with a neural processing unit to provide estimations without transmission delays. The system is secure, is private, and has low power consumption. A motion dataset comprising walking and hand movement data was collected, and a model with convolutional and temporal layers was trained and tested. Various tests were used to identify a suitable model structure and parameters; Res2Net, a convolutional block attention module, and a temporal convolutional network were ultimately used for the proposed model. Experiments were conducted to investigate the model's accuracy and inference time. The model's accuracy was high, with an average root mean-square error of 0.364 m, exceeding that of a previously proposed model. Moreover, the model's inference time was 0.234 s for 20 s of input IMU data, which was >20% faster than that of a comparable ResNet bidirectional long short-term memory model. The model's performance was also evaluated on various platforms to demonstrate that it could provide accurate real-time trajectory estimation on an edge computing platform."
  },
  {
    "date": "2026-2-25",
    "title": "D2S-RSG-SSD: Dual Double-Sampling with Random Sub-Samples Generation for Self-Supervised Real Image Denoising_supp1-3665610.pdf",
    "authors": "Chao Ren",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tpami.2026.3665610/mm1",
    "source": "IEEE",
    "abstract": "Recent advances in self-supervised image denoising have highlighted the potential of Blind-Spot Networks (BSNs). However, existing methods suffer from three major limitations: (1) Their effectiveness in real-world scenarios is limited by strong assumptions, such as noise independence, which rarely hold in practice. (2) While sampling-based strategies can partially improve performance, BSNs inherently suffer from information loss caused by centroid masking, and removing the blind spot leads to noise overfitting, both of which hinder denoising performance. (3) Sampling-based methods often introduce checkerboard artifacts, yet existing studies typically overlook the fundamental differences between these artifacts and real noise. To address these issues, we propose a novel self-supervised denoising framework, Dual Double-Sampling with Random Sub-samples Generation (D2S-RSG-SSD). To address Limitation 1, we introduce a sampling-based framework that breaks noise dependence by combining Random Sub-samples Generation (RSG) with a cross-paired loss <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$\\mathcal {L}_{RSG}$</tex-math></inline-formula>. RSG generates diverse sub-samples with inherent variance, referred to as sampling differences, which serve as natural perturbations to augment training data and disrupt spatial noise correlations. The proposed loss function ensures full utilization of these sub-samples while stabilizing optimization. To address Limitation 2, we propose a Dual Double-Sampling (D2S) strategy with fixed sampling patterns and a dual-branch architecture. This design reduces reliance on pixel-level information and leverages complementary features to mitigate both noise overfitting and information loss. A key advantage is its compatibility with various advanced denoising networks, lifting the constraint of using BSNs in self-supervised settings. Additionally, we introduce a fixed sub-image sampling strategy to prevent pattern collapse during inference and ensure stability. To address Limitation 3, we explicitly differentiate checkerboard artifacts from real noise and develop a dedicated artifact remover to correct pixel discontinuities caused by sampling-based operations. This design preserves fine image details while reducing over-smoothing. Experiments on benchmark real-noise datasets and self-captured noisy images demonstrate the robustness and generalizability of our framework, achieving better performance over existing methods."
  },
  {
    "date": "2026-2-25",
    "title": "SPIRE: A 28nm Memory-Efficient Multi-Reservoir LSM Accelerator for Adaptive and Flexible Time-series Classification",
    "authors": "Darío Fernández-Khatiboun, Simon Richter, Yasser Rezaeiyan, Maryam Sadeghi, Corentin Piozin, Farshad Moradi",
    "publish": "IEEE Transactions on Biomedical Circuits and Systems",
    "url": "https://doi.org/10.1109/tbcas.2026.3668521",
    "source": "IEEE",
    "abstract": "Spiking Neural Networks are widely studied for their brain-inspired ability to process sequential information, yet their memory limitations often hinder the extraction of long-term dependencies. Reservoir computing, and in particular liquid state machines (LSM), has gained attention within this context for its ability to separate the recurrence and classification components into a recurrent reservoir liquid followed by a feedforward layer. However, existing LSM hardware suffers from significant design trade-offs, including large memory demands or performance degradation due to restrictive connectivity and weight precision. Inspired by these findings, we introduce SPIRE, a compact 1.13mm<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> core area, fully digital multi-reservoir LSM with online learning adaptation. Implemented in TSMC 28nm CMOS technology, SPIRE is a memory-efficient multi-reservoir LSM tailored for time-series classification and edge deployment. By organizing up to eight reservoir ensembles into four parallelized cores, SPIRE enhances synaptic density and computational efficiency. Furthermore, SPIRE leverages on-the-fly generation of reservoir weights, reducing even further the memory footprint while supporting both sequential and parallelized dual operation modes. Benchmark results demonstrate that these design choices improve SPIRE’s synaptic density by up to 18.46× over prior works. SPIRE achieves 3.56 GSOPs/mm<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> with just 4.91 pJ/SOP in sequential inference and up to 76.05 GSOPs/mm<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup> with 0.1 pJ/SOP in parallel configurations running at 55 MHz and 0.55 V."
  },
  {
    "date": "2026-2-25",
    "title": "A Convex Phased Array Ultrasonic Inspection Gauge for Small-Diameter Pipelines with Enhanced Resolution and Sensitivity",
    "authors": "Christian Peyton, Dayi Zhang, Mehrab Zamanian, Nick Bettley, Hugh Lewis, Ehsan Mohseni, David Lines, Gordon Dobie",
    "publish": "IEEE Transactions on Instrumentation and Measurement",
    "url": "https://doi.org/10.1109/tim.2026.3667349",
    "source": "IEEE",
    "abstract": "Accurate measurement of wall thickness and defect detection is essential for pipeline integrity. Small-diameter pipelines (4-6 inches), common in distribution networks, flowlines, and process systems, are difficult to inspect because they are often buried, insulated, or otherwise inaccessible. Ultrasonic pipeline inspection gauges (PIGs) provide a solution, but to navigate the tight bends found in traditional ”unpiggable lines” a short form factor unibody PIG is required. Conventional unibody PIGs rely on multiple carriages and large transducer elements that achieve high signal-to-noise ratio (SNR) with fewer channels at the expense of spatial resolution. Conversely, reducing element size increases resolution but also raises the inactive fraction of the aperture, weakening signals and reducing beam uniformity. To address these limitations, this paper presents a proof-of-concept inspection instrument based on a convex phased array with small elements. Compensation is applied through coherent transmit sub-apertures and multi-element receive beamforming. Simulations using Huygens modelling show that a 128-element convex array achieves full circumferential coverage in 4-6′′ pipes. Importantly, the 128-element design provides approximately four times the resolution of a 32-element array while maintaining comparable SNR, thereby overcoming the traditional tradeoff. Two industrial-focused experiments confirmed the benefits of compensation. In the 4′′ pipe, compensation achieved an SNR improvement of 15.34 dB compared with uncompensated operation, along with a reduction in wall-thickness measurement error by 0.59 mm and in measurement uncertainty by 1.43 mm. In the 6′′ pipe, tests further demonstrated reliable detection of 2 mm flat-bottom holes, which equivalent to 0.8% of the pipe’s circumference. Together, these findings demonstrate that phased-array compensation overcomes the traditional trade-off between resolution and sensitivity, enabling compact ultrasonic PIG tools to inspect 4–6′′ pipelines with high reliability."
  },
  {
    "date": "2026-2-25",
    "title": "Radiation Induced Leakage Current in 3-D NAND Technology",
    "authors": "Mondol Anik Kumar, Matchima Buddhanoy, Justin Bell, Alexander Brandl, Indranil Chatterjee, Biswajit Ray",
    "publish": "IEEE Transactions on Nuclear Science",
    "url": "https://doi.org/10.1109/tns.2026.3667975",
    "source": "IEEE",
    "abstract": "This work provides an experimental characterization of radiation-induced leakage current (RILC) in 3-D NAND Triple-Level Cell (TLC) technologies. Commercial 64-layer devices from floating-gate (FG) and charge-trap (CT) technology were irradiated with γ-rays up to 30 krad(Si) and monitored over extended retention periods. Results reveal that FG NAND exhibits pronounced vulnerability to RILC, with degradation most severe in the highest program state (L<sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">7</sub>) of the TLC memory, in the bottom layers of the vertical stack, and particularly within the lower deck of dual-deck architecture. In contrast, CT NAND demonstrates negligible RILC under identical irradiation conditions. Strong cell-to-cell variability in RILC was observed among FG NAND cells. Notably, the leakage rate slows over time, suggesting partial neutralization of oxide traps and a possible self-healing effect in some cells. A comparison with stress-induced leakage current (SILC) on non-irradiated FG devices further indicates that 30 krad(Si) irradiation is equivalent to ~100 program/erase (P/E) cycles, leading to ~6.67% lifetime reduction."
  },
  {
    "date": "2026-2-25",
    "title": "BTS-I2C 2025 Cover Page",
    "authors": "N/A",
    "publish": "2025 2nd Beyond Technology Summit on Informatics International Conference (BTS-I2C)",
    "url": "https://doi.org/10.1109/bts-i2c67944.2025.11399456",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-2-25",
    "title": "VishBox: An AI-Agent-Based Adaptive Voice Phishing Simulation Framework for Cybersecurity Education",
    "authors": "Yoonmo Yang, Daon Choi, Yunyi Hong, Jee-Won Park, Jae-Yong Yu, Hee-Dou Kim, Sungmi Park",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3667823",
    "source": "IEEE",
    "abstract": "Voice phishing has grown increasingly sophisticated, employing a range of deceptive tactics and social engineering skills to exploit individual and institutional vulnerabilities. In South Korea, countermeasures usually rely on static educational scenarios that fail to capture the dynamic, psychologically adaptive nature of real-time manipulation. This study introduces VishBox, an AI agent-orchestrated simulation framework that enables ethically safe reproduction of attacker-victim interactions through coordinated autonomous agents. VishBox generates high-fidelity synthetic crime dialogues and integrates empirically calibrated victim profiles parameterized by demographics, digital financial literacy, and personality traits, grounded in South Korean empirical studies. The system further incorporates an autonomous risk evaluation process to model escalation and derive personalized prevention strategies. Validation using national crime statistics and a survey with 102 participants shows that VishBox produces psychologically plausible deception patterns that are difficult for humans to distinguish from authentic cases. Simulated vulnerability distributions broadly align with real-world victimization patterns across age groups, while also revealing personality-driven risk scenarios that are underrepresented in incident statistics. Human risk ratings also mirrored the system’s turn-level estimates, confirming the realism of its escalation modeling. By providing a controlled, scalable environment for observing real-time manipulation, VishBox establishes a foundation for behavioral cybersecurity research, adaptive educational design, and evidence-driven policy development against evolving phishing threats."
  },
  {
    "date": "2026-2-25",
    "title": "Extending Memory-Based Obfuscated Malware Detection with Network Behavior",
    "authors": "Jhon F. Mercado, Josue Genaro Almaraz-Rivera, Sergio Armando Gutierrez, Jesus Arturo Perez-Diaz, Luis A. Fletscher, Jose Antonio Cantoral-Ceballos, Juan Felipe Botero",
    "publish": "IEEE Open Journal of the Communications Society",
    "url": "https://doi.org/10.1109/ojcoms.2026.3667851",
    "source": "IEEE",
    "abstract": "Obfuscated and fileless malware families evade traditional detection systems by residing exclusively in memory and employing stealthy techniques such as process injection and encrypted communication. Although memory-based detection methods have demonstrated strong performance using host-based features alone, the contribution of network-level information remains underexplored. This study addresses this gap by leveraging the recently released WinMal25 dataset, which comprises approximately 2 TB of ground-truth Windows memory dumps collected under realistic benign activity and obfuscated malicious execution. We extract a small set of socket- and connection-level variables directly from RAM and evaluate their contribution to malware detection using Random Forest and XGBoost classifiers under multiple feature configurations. The experimental results show that network-related structures preserved in memory are highly discriminative on their own and further enhance detection performance when combined with traditional system-level features. These findings demonstrate that communication-related structures preserved in memory constitute a robust and complementary forensic signal, supporting the development of interpretable and generalizable memory-based malware detection systems capable of operating under heavy obfuscation."
  },
  {
    "date": "2026-2-25",
    "title": "Quantitative analysis of the impact of region of interest information on deep learning algorithms for thyroid ultrasound imaging_supp1-3667415.doc",
    "authors": "Eun Jung Lee",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/ojemb.2026.3667415/mm1",
    "source": "IEEE",
    "abstract": ""
  },
  {
    "date": "2026-2-25",
    "title": "Secured and Standardized Intelligent Zero-Touch 6G Framework for Edge-AI Applications",
    "authors": "Md Rayhan Hassan Mahin, Partha Chakraborty, Niropam Das, Harleen Kaur, Hemayet Uddin Himel, Jobanpreet Kaur, Ambarish G. Mohapatra",
    "publish": "IEEE Communications Standards Magazine",
    "url": "https://doi.org/10.1109/mcomstd.2026.3660159",
    "source": "IEEE",
    "abstract": "The shift to the sixth-generation networks (6G) presents new demands of automation and intelligence and trust of heterogeneously linked edge worlds. This paper describes a proposed framework of the Secured and Standardized Zero-Touch 6G (SS-ZT6G) incorporating Zero-Trust concepts, blockchain-security audit and AI-driven orchestration to allow autonomous, resilient and standards-compliant edge services management. The framework uses closed-loop automation and predictive orchestration as well as standardized APIs, in alignment with ETSI ZSM, 3GPP MANO, and O-RAN specifications, to achieve interoperability and compatibility of service provisioning. Empirical tests indicate a 44.9% decrease in latency, an increase of 9.8% in efficiency of automation, and 97.5% security detection accuracy as compared to reference architectures. The findings confirm that SS-ZT6G has the potential to deliver a secure, interoperable, and self-optimizing backbone of Edge-AI-based 6G ecosystems, which will create the possibility of sustainable and intelligent network autonomy."
  },
  {
    "date": "2026-2-25",
    "title": "Development of An Innovative Control &amp; Monitoring System (ICMS) for Battery Energy Storage System (BESS) to Spearhead Malaysia's National Energy Transition Roadmap (NETR)",
    "authors": "Mohamed Fuad Faisal, Chin Kim Lo",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403378",
    "source": "IEEE",
    "abstract": "In 2023 the Malaysian Government launched the National Energy Transition Roadmap (NETR) as a comprehensive strategic plan to steer the Malaysian energy systems away from fossil-fuel-based sources towards cleaner, more sustainable alternatives. The NETR sets to achieve net-zero emissions by 2050. The plan is comprehensive and outlines a gradual increase in renewable energy shares, targeting 31% by 2025, 40% by 2035, and an impressive 70% by 2050.To help expediate the decarbonization of the Malaysian energy sector, TNB foresee a need to install Battery Energy Storage System (BESS) to prevent the excess power, generated from the Solar PV installation that are not being consumed, from flowing reversely from the LV system (400 Volt) to the MV system (11 kV). Based on literature reviews, reverse power flow can have a negative impact on distribution transformers [1]. The existing Energy Management System (EMS) in the BESS functions primarily to control the operation of the BESS. The EMS sends an input signal to either charge or discharge the batteries, depending on the control logic requirement, and the State of Charge (SOC) or State of Health (SOH) of the battery system. However, the functionality of the EMS to prevent the occurrence of reverse power flow in the power system/ transformer is not defined.In this paper, an innovative control scheme and monitoring system to ensure optimal operation of TNB’s Battery Energy Storage Systems (BESS) in storing all the excess power generated by the Solar PV installation and preventing the occurrence of reverse power flow in the power system is presented. The results of this project have proven that this innovative control and monitoring system can directly enhance the integration of more solar PV installation and indirectly spearhead the Malaysia's National Energy Transition Roadmap (NETR)."
  },
  {
    "date": "2026-2-25",
    "title": "Revolutionising Learning: The Impact of Digital Transformation on Education Systems",
    "authors": "Harshil Sharma, Shipra Agarwal, Mousmi Goel, Riya Sharma",
    "publish": "2025 5th International Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU)",
    "url": "https://doi.org/10.1109/iot-siu65919.2025.11402748",
    "source": "IEEE",
    "abstract": "The role of digital game in education is the most consistent in the way it reorganizes teaching, learning and knowledge that includes digital. In the last two decades, with a rapid technological development in the size of internet, mobile devices, cloud computing and artificial intelligence, more streamlined methods of traditional teaching have emerged. This infection has also unlocked new opportunities to improve the quality, access and inclusion of education worldwide. For digital technology, it facilitates personal learning, collaboration in geographical distance, and access to a series of historical materials that students and teachers could only dream. With educational institutions around the world, education has been developed at a stunning rate, which is rapidly accepted by globalization and digital age. While covering various aspects of digital changes of education systems, it examines paper, provides new education opportunities, how to increase both experiences in recent times, provide new education opportunities, grapes with challenges of equal rights. While covering various aspects of digital changes of education systems, it examines paper, provides new education opportunities, how to increase both experiences in recent times, provide new education opportunities, grapes with challenges of equal rights. This highlights the important methods in which digital tools changed education, from personal learning to global platforms to reach resources and competent cooperation. It also underlines the challenges of the infrastructure, resistance to various levels of digital literacy such as successful implementation and changes for obstacles. This paper provides recommendations for future proofing education systems that enable inclusive and equitable digital changes based on the analysis of emerging trends, case studies and best practices."
  },
  {
    "date": "2026-2-25",
    "title": "Automated Patient Treatment Classification Using Decision Tree Models and Healthcare Data Analytics",
    "authors": "M. Saranya, C Srinivasan, S. Sasikumar, M. P. Revathi, Sujatha T, Akshay L",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403066",
    "source": "IEEE",
    "abstract": "Effective classification of patient therapy is essential for enhancing healthcare delivery and optimizing resource allocation. This paper introduces an automated methodology using decision tree (DT) models to categorize patients as either inpatient or outpatient, utilizing clinical and demographic features. The proposed model exhibited exceptional prediction performance, with an accuracy of 99.22%, signifying dependable and resilient classification capacity. The analysis of feature significance indicated that haemoglobin, haematocrit, and erythrocyte levels were the most critical determinants affecting therapy classification. The DT model utilizes structured healthcare data to assist physicians in making evidence-based choices, minimizing human mistakes, and enhancing patient management. Health care providers can understand the rationale behind each categorisation because to the DT's interpretability, which makes the decision-making process transparent. This automated system provides a scalable solution for hospitals and clinics aiming to optimize treatment allocation, improve operational efficiency, and provide personalized patient care. The study illustrates that the amalgamation of healthcare data analytics with machine learning (ML) approaches may markedly improve clinical procedures and patient outcomes."
  },
  {
    "date": "2026-2-25",
    "title": "Dynamic Budgeting with AI: Balancing Health Outcomes and Inflation",
    "authors": "Soumyajit Hazra, Saptarshi Banerjee, Samit Karmakar",
    "publish": "2025 International Conference on Artificial Intelligence for Computing, Astronomy and Renewable Energy (AICARE)",
    "url": "https://doi.org/10.1109/aicare66005.2025.11402814",
    "source": "IEEE",
    "abstract": "The governments of developing economies confront a challenge in striking a balance between the social outcomes and macroeconomic stability. This paper presents an end-to-end reinforcement-learning-based decision system that allocates state-level development budgets across health, education, and rural sectors, reduces Infant Mortality Rate, and at the same time sustains price stability. Using new data for Bihar, Jharkhand, and West Bengal over 2015-2025, the model trains an agent to minimize IMR while penalizing deviation in inflation. A forward-looking view to policy choices is provided by an LSTM network that predicts future inflation. Compared to the historical spending pattern, the learned policy results in up to $\\mathbf{1 1. 5 \\%}$ lower IMR in Bihar, besides a $\\mathbf{1 2}$-point moderation in the Consumer Price Index. These findings suggest that adaptive and data-driven budgeting may improve health outcomes without compromising fiscal discipline. This approach is a support instrument for the governments rather than a substitute for policymakers themselves."
  },
  {
    "date": "2026-2-25",
    "title": "Breaking Development Traps: Synthetic Household Simulations for Poverty Alleviation in Rural West Bengal",
    "authors": "Soumyajit Hazra, Saptarshi Banerjee, Samit Karmakar",
    "publish": "2025 International Conference on Artificial Intelligence for Computing, Astronomy and Renewable Energy (AICARE)",
    "url": "https://doi.org/10.1109/aicare66005.2025.11402828",
    "source": "IEEE",
    "abstract": "In rural India, poverty encompasses more than just low income; it also includes overlapping disadvantages in social inclusion, employment prospects, education, and health. Many households in West Bengal experience these limitations at the same time; seasonal work, landlessness, and a lack of public services all work together to create development traps that are hard to break. This study uses a simulation approach that combines synthetic household representations with public data to investigate those mechanisms. Examining the interactions between particular policy tools-MNREGA employment, access to Primary Health Centers (PHC), school-retention incentives, and social security pensions-at the household level is the goal. How much, for instance, can a family’s ability to consume be altered by a forty-day MNREGA guarantee or reduced medical costs? Which support combinations have the biggest impact on welfare over the long run? The primary welfare metric is Monthly Per-Capita Consumption Expenditure (MPCE), which is based on the Tendulkar Committee’s benchmark for rural poverty. Real purchasing power is captured by MPCE, which shows how households translate public services, transfers, and income into daily well-being. The analysis uses information from the NFHS-5, MNREGA performance statistics, Rural Health and Education Reports, and the 2023-24 Household Consumption Expenditure Survey. The model simulates the trajectories of individual households rather than just generating aggregate state figures. It makes it possible to observe how the impact of policy bundles is shaped by structural factors such as gender, caste, and land tenure. As a result, the work adds an applied, scenario-based perspective on policy design for rural development to traditional econometric studies."
  },
  {
    "date": "2026-2-25",
    "title": "IEC 61850 Conformance Testing for Intelligent Electronic Devices for Edition 2.1",
    "authors": "Shivendra Kumar Sinha, Pradish M, Dinesh J, Shailesh Kapoor, Shivakumar V",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11393983",
    "source": "IEEE",
    "abstract": "The deployment of the IEC 61850 communication protocol in smart grid systems requires stringent conformance testing of Intelligent Electronic Devices (IEDs) to ensure both interoperability and reliability. This paper deliberates a thorough analysis of IEC 61850 Edition 2 with Amendment 1 (Edition 2.1) conformance testing for IEDs, incorporating the newly introduced features of the standard. The paper provides the protocol testing requirements and configurations necessary for compliance while highlighting the practical challenges during IED testing such as managing data models, validating the ICD file, ensuring synchronization accuracy, and facilitating interoperability among devices from various vendors. This paper discusses the conformance testing of server devices that are integral to substation automation systems in accordance with Edition 2.1 and Challenges."
  },
  {
    "date": "2026-2-25",
    "title": "A Quantum-Inspired Cybersecurity System for Post-Breach Data Control",
    "authors": "Sunil Kumar Peela, Ramadan Abdunabi",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393737",
    "source": "IEEE",
    "abstract": "Data breaches increasingly leave organizations unable to assert control over sensitive information once it is exfiltrated. Existing defenses, such as zero-trust security, encryption, monitoring, and recovery mechanisms, remain largely preventive or reactive and provide no means to influence data after a compromise. This paper presents EntangleX, a quantuminspired post-breach data-control framework that replaces exposed content with two logically linked instances: an authoritative copy under defender control and a non-authoritative replica in the adversary-facing environment. A one-way transfer path securely vaults the original, while policy-driven updates applied to the authoritative Entangle B instance propagate to the nonauthoritative Entangle A replica. We implement a complete classical prototype across three virtual machines demonstrating automatic vaulting, transparent file replacement on Windows, real-time synchronization, and low operational overhead. Security analysis shows that EntangleX enables post-breach data sovereignty, one-way control, and strong auditability, while providing a foundation for future quantum-enhanced variants."
  },
  {
    "date": "2026-2-25",
    "title": "Towards Trustworthy Autonomous Vehicles: Explainable AI for Self-Driving Cars",
    "authors": "Aashna Khurana, Tarandeep Kaur Bhatia, Kaashif Matto, Hridyansh Lakhan",
    "publish": "2025 5th International Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU)",
    "url": "https://doi.org/10.1109/iot-siu65919.2025.11402690",
    "source": "IEEE",
    "abstract": "Autonomous vehicles (AVs) are rapidly relying on newset and the advanced deep learning models and their architectures to drive and decide in real-time situations on road. No doubt their potential is incredible but, the blackboxed nature of these AI systems are causing huge concerns about the safety, responsibility, and trust. The failure of these models to offer interpretability for AV decisionmaking hinders fault diagnosis, complicates regulatory compliance, and undermines user confidence which all are very crucial to large-scale and real time adoption of autonomous systems. Explainable Artificial Intelligence (XAI) is one of the core solutions to problems like these a XAI systems have transparency, interpretability, and explainability of AI results. Our paper presents some leading XAI methods, such as SHAP (SHapley Additive exPlanations), LIME (Local Interpretable Model-agnostic Explanations), and Grad- CAM (Gradient-weighted Class Activation Mapping), with implementations in autonomous vehicle systems. The above mentioned approaches provide meaningful insights into model behavior, identify potential biases, and provide greater transparency. The integration of XAI in AV systems consistently improves system safety, user trust and ethical decision-making Our paper also reviews recent research advances, compares proposed XAI frameworks for AVs, and finally concludes their implications for future autonomous transportation. This paper briefly discusses practical problems with using realtime XAI models, such as computational overhead and latency maintenance of decisions with other problems. Future directions in our proposed research aim to improve the systems and the gaps found in the performance to explainability in models towards advancing safer, transparent, and more socially acceptable automated vehicle systems."
  },
  {
    "date": "2026-2-25",
    "title": "Stored-Reference LMS Filtering on FPGA for Low- Latency Acoustic Feedback Cancellation in Live Audio Systems",
    "authors": "W.S.C.Rodrigo, R.A.Prabhath Buddhika, W.C.Nirmal, A.C.Ranasinghe, S.L.Mallawathanthri",
    "publish": "2025 International Conference on Advances in Technology and Computing (ICATC)",
    "url": "https://doi.org/10.1109/icatc68823.2025.11407788",
    "source": "IEEE",
    "abstract": "Acoustic feedback, often perceived as howling, remains a major challenge in live audio environments. This paper presents a real-time feedback suppression system based on a Stored-Reference LMS filtering strategy implemented on an FPGA. The proposed design captures a reference feedback signal during a short detection phase and reuses it during operation for adaptive cancellation. The system was developed on a Zynq-7010 platform with a WM8960 codec and evaluated using both simulation and hardware tests. Objective measurements across multiple audio samples, including music with high-frequency noise and guitar signals containing 600–900 Hz howling show consistent SNR improvement compared to unfiltered audio and a conventional notch-filter baseline. Among the evaluated algorithms, LMS offered the best balance of stability and computational efficiency for FPGA deployment. Results confirm that the stored-reference LMS approach effectively suppresses feedback while preserving audio quality. Future extensions include multi-channel support and dynamic reference adaptation for more complex acoustic environments."
  },
  {
    "date": "2026-2-25",
    "title": "Agentic Retrieval for Conversational Memory in LLM-Based Chatbots",
    "authors": "Volkan Turgut, Qusay H. Mahmoud",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393694",
    "source": "IEEE",
    "abstract": "Large language model (LLM)–based conversational systems are constrained by fixed context windows, limiting their ability to retain and retrieve information from extended dialogue histories. While context window expansion and memory injection approaches have been proposed, they incur significant computational costs and lack mechanisms for selective, intent-aware recall. Existing retrieval-augmented generation (RAG) systems are primarily designed for document retrieval and fail to address the structural and temporal characteristics of conversational memory. This paper presents an agentic RAG system that overcomes these limitations through dual retrieval pathways tailored to different query intents. A query routing agent directs exploratory queries to topic-based cluster navigation and routes targeted queries to hybrid semantic-lexical retrieval over exchange-based conversational units with LLM-powered context enrichment. Topic discovery is performed automatically using UMAP dimensionality reduction and HDBSCAN clustering without predefined categories. Evaluation on real-world conversational data demonstrates strong performance, including high query classification accuracy and perfect hit rates with high recall for targeted queries. The system integrates with an open chatbot interface (Open WebUI), supports multi-user deployment with access control, and operates without model fine-tuning."
  },
  {
    "date": "2026-2-25",
    "title": "Parkinson's Disease Detection",
    "authors": "Rahul Vibhakar M R, Kousthub D G, Nidish, Karthik S",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11394389",
    "source": "IEEE",
    "abstract": "This paper presents a diagnostic platform based on machine learning for the early detection of Parkinson's Disease (PD) from the analysis of multimodal data that includes both visual and acoustic biomarkers. The proposed system utilizes hand-written spiral and wave pictures for the evaluation of motor control, in combination with patient vocal recordings for investigating speech irregularities that mark PD progression. An Integration and Prediction (MIP) model is defined to ensure uniformity in data recording, preprocessing and feature extraction for multiple modalities. Stroke smoothness, pressure variability, and tremor frequency convey spatial-temporal descriptors from the handwriting representation, while acoustic analysis focuses on jitter, shimmer, and Mel-Frequency Cepstral Coefficients (MFCCs) for identifying vocal instability. MobileNetV2 achieves 86% accuracy on spiral images, InceptionV3 obtains 81% accuracy for wave patterns, and KNN reaches 92% accuracy on speech samples. Experimental evaluations show that the hybrid MIP approach outperforms unimodal baselines in accuracy and robustness performance. The experiments verify that the proposed multimodal approach provides a quick, non- invasive, and an interpretable diagnostic device to enable medical practitioners to identify and treat Parkinson's Disease."
  },
  {
    "date": "2026-2-25",
    "title": "Application of Discrete-Time Unknown Input Observers for Cyberattack Detection in Connected CACC Vehicles",
    "authors": "S. Bougherara, Q.H. Nguyen, M. Haddad, H. Rafaralahy, A. Zemouche",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401358",
    "source": "IEEE",
    "abstract": "This study addresses the increasing security challenges faced by Cooperative Adaptive Cruise Control (CACC) systems due to cyberattacks. These systems, which rely on real-time data processing and critical decision-making, necessitate effective cyberattack detection methods. We propose the appli-cation of unknown input observers (UIOs) to simultaneously estimate system states and detect cyberattacks. A significant challenge in implementing UIOs is satisfying the matrix rank condition necessary for their existence. Traditional discretization methods often fail to meet the required performance and accuracy for effective threat detection. Our contribution lies in employing an exact discretization method that overcomes these limitations, ensuring the rank condition is satisfied. This approach enhances the robustness of CACC systems against cyberattacks, allowing for more accurate tracking and quicker threat response, thereby improving security and traffic flow in modern transportation systems."
  },
  {
    "date": "2026-2-25",
    "title": "Traffic Congestion Control in Smart Cities using Advanced Machine Learning Techniques with Explainable Artificial Intelligence",
    "authors": "Mudassar Imran Haider, Bilal Shoaib Khan, Abdul Hannan Khan, Muhammad Asghar Khan, Muhammad Adnan Khan",
    "publish": "2025 International Conference on AI-Driven STEM Education and Learning Technologies (AISTEMEDU)",
    "url": "https://doi.org/10.1109/aistemedu67077.2025.11403868",
    "source": "IEEE",
    "abstract": "Traffic control is widely acknowledged as one of the most significant problems in smart cities due to the increase in vehicle traffic. The main focus of the study is on traffic jams and how an intelligent traffic control system can help. In this research, traffic monitoring and congestion management will be handled by a number of ML algorithms. In this research work, a model is proposed for intelligent traffic congestion control system that gathers information from various sensors and analyzes in order to predict traffic congestion in smart cities. The proposed research manages traffic congestion using machine learning model. A pre-processing layer for handling missing values, out layer, normalization is introduced. Artificial Neural Network (ANN), Random Forest (RF), Linear Regression (LR), Support Vector Machine (SVM) and Naïve Bayes (NB) were applied to anticipate congestion. The simulation's results showed that the proposed model performed significantly better than the earlier strategies. This study main objective is to control traffic on the road in its early phases through the employment of ANN, RF, LR, SVM and NB. Random Forest algorithm perform well in comparison with others and give the accuracy 0.998, F1 Score 0.998, Precision 0.996, Sensitivity 1.0, Specificity 0.995 and Recall 1.0."
  },
  {
    "date": "2026-2-25",
    "title": "Deep Learning-Based Real-Time Crop Monitoring and Weed Detection",
    "authors": "Anushri Adapawar, Anushka Poshattiwar, Tanvi Bandebuche, Sandeep Kumar, Priya Dasarwar, Dipesh Dalal",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11393986",
    "source": "IEEE",
    "abstract": "Precision agriculture, which uses deep learning and artificial intelligence (AI) to enable real-time crop monitoring and management, has completely changed contemporary farming. This study presents a deep learningbased weed detection algorithm that classifies agricultural imagery into crop and weed categories using the InceptionV3 architecture. To improve model dependability, the Kaggle dataset was restructured into a structured directory format and divided into subsets for training (70%) validation (15%) and testing <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$(15 \\%)$</tex>. Training was conducted using a binary classification method with a sigmoid activation function, yielding an astounding 98.46% accuracy on the test set. GradCAM visualization was used to pinpoint important areas impacting grouping results in order to put light on model predictions. Grad-CAM visualization was used to identify important areas impacting categorization results in order to shed light on model predictions. The model is able to effectively identify weeds and crops by using the main morphological, textual, and color components to assist precision farming by using drones or robotic sprayers to apply the necessary herbicides. The paper provides a foundation to real-time surveillance, and the next round of investigation will be to implement it in the field and add more diseases and pests to the list."
  },
  {
    "date": "2026-2-25",
    "title": "Artificial Neural Network Model for Obesity Prediction Using Physical Activity Data",
    "authors": "Ariya S. Kurup, S Murugan, R. Vijayakumar, R. Jagadeesh Kannan, E. Hemavathi, Pruno Suson W",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403783",
    "source": "IEEE",
    "abstract": "Obesity constitutes an important issue for society, resulting in chronic conditions such as heart failure, diabetes, and metabolism syndrome. Accurate prediction of obesity prevalence utilizing lifestyle and physical activity information is essential for prompt management. This study develops an Artificial Neural Network (ANN) algorithm to predict obesity risks utilizing 17 characteristics from the publicly available Obesity Dataset, comprising gender, age, weight, height, family history, eating habits, and regular exercise. This database categorizes individuals based on obesity classifications. The suggested ANN model achieves an effective accuracy of 99.57%, demonstrating its strong capability to effectively classify individuals into their respective obesity categories. The enhanced precision highlights the effectiveness of ANN in clarifying intricate relationships involving dietary choices and the effects of being overweight. The findings indicate that ANN-driven estimates utilizing active lifestyle information may efficiently identify individuals at risk promptly and offer targeted preventive strategies for preventing obesity-related physiological issues."
  },
  {
    "date": "2026-2-25",
    "title": "Analysis on the operation scenarios and test procedure of green island microgrid moving towards a zero-carbon island",
    "authors": "Chen-Yu Chien",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403123",
    "source": "IEEE",
    "abstract": "To support Green Island Power System's transition towards becoming a zero-carbon island through the construction of a 2MW renewable energy system and a 4MW/10MWh energy storage system, a study was conducted involving an on-site survey of the Green Island Power System and an introduction to the IEEE 2030.7, IEEE 2030.8, and IEEE 2030.9 international standards. Based on these findings, this study proposes operating scenarios and system function verification test procedures for the Green Island microgrid system. This is to comprehensively verify the functions of the microgrid controller and energy storage, address the impact of high penetration of inverter-based resources (IBR) on the Green Island system, and enhance the resilience of the power grid system. The aim is to reduce carbon emissions from the power generation system, advance energy storage systems, and establish an integrated microgrid management system, with the goal of creating a demonstration microgrid system that can serve as a model for the construction of outlying islands in Taiwan."
  },
  {
    "date": "2026-2-25",
    "title": "The Zone Promotion using Binaural Beats",
    "authors": "Masayuki Itoh, Kazuki Mochida, Aoi Hichiwa",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401360",
    "source": "IEEE",
    "abstract": "Music is widely used in daily life and is essential for commuting, relaxation, and concentration. Especially in sports and learning, music has the effect of increasing concentration and motivation, contributing to improved performance. On the other hand, binaural beats using \"swells,\" which are certain pattern sounds, are also said to have healing effects and enhance cognitive abilities. Therefore, we examined the effects of listening to music on concentration from biometric measurements. In particular, we created a pseudo \"the zone\" (a hyper-concentration state: a state of high concentration and a sense of immersion) using binaural beats and verified its effects. Two female and four male subjects in their early 20s were evaluated by acquiring biological data (electroencephalogram (EEG) and electrocardiogram (ECG)) while performing an exercise task (cards tower: making a tower of playing cards) and a thinking task (Kraepelin test) that required concentration while listening to various types of music, and then evaluating the subjects in their lowest concentrated state. The binaural beats were applied to the state in which the subjects were least able to concentrate, and their state was examined to see if it changed. EEG analysis showed an increase in the ratio of the characteristic frequency band, Sensory Motor Rhythm (SMR): (αβ12-15 Hz), and a decrease in the stress level (β intensity/α intensity) in four of the six subjects to whom binaural beats were applied. In addition, the Poincaré plot of R-R interval (RRI) showed a reduction in area (increased density). From these experimental results, we confirmed the possibility that the binaural beats applied and evaluated in the lowest concentrated state promote an exquisite balance state and the zone of the autonomic nervous system."
  },
  {
    "date": "2026-2-25",
    "title": "AI-Based Candidate Recommendation for Company Vacancies: Emphasizing Soft Skills and Competencies",
    "authors": "K.T.A.D.K Kasthurirathna, R.S.K De Silva, B.D.A.M Kumara, S.U.D.A Gunasekara, Samantha Thellijjagoda, Poorna Panduwawala",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11394424",
    "source": "IEEE",
    "abstract": "Historically, the recruitment process relies predominantly on resumes, academic achievement, and technical testing, but these can overlook significant soft skills for workplace success. Soft skills such as confidence, communication, adaptability, and stress tolerance have direct influence on the performance of employees but are tested subjectively and non-systematically in an interview. This paper introduces a multimodal approach of an AI-recommended candidate system that objectively evaluates the soft skills of candidates through a multimodal approach. The framework integrates four modules: (i) speech and tone analysis for verbal confidence, (ii) hand movement recognition for confidence estimation, (iii) eye-contact detection for self-confidence and attentiveness, and (iv) facial expression analysis for stress. All the modules output binary decisions Confident/Non-Confident or Stress/Non-Stress, which are integrated to present a holistic perspective of the candidate. Minimum decision-making assessment is also offered to optimize evaluation. The application is implemented as a web app recording candidate interview, processing multimodal signals with machine learning models, and providing real-time recommendations to recruiters through an interactive dashboard. Experimental outcomes demonstrate superb accuracy from all modules and superb user acceptance, confirming the feasibility of applying multimodal AI to enhance fairness and richness in hiring. This study illustrates the potential of AI to reduce bias, increase transparency, and support data-driven decision-making that is more subtle than résumé-based assessment."
  },
  {
    "date": "2026-2-25",
    "title": "Neural Observer-Based Learning for Robust State Estimation",
    "authors": "Q.H. Nguyen, S. Meng, M. Haddad, H. Rafaralahy, A. Zemouche",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401369",
    "source": "IEEE",
    "abstract": "This work introduces a state estimation approach that combines physics-based modeling with data-driven learning. The proposed estimator combines a PI observer and neural network to improve learning for the unknown parts of the system using gradient-based methods. The gradient is obtained using sensitivity propagation. Additionally, we develop a model-based policy gradient algorithm to learn directly from trajectory tracking errors without the need for ground truth. To enhance adaptiveness, a framework is developed to continually improve the accuracy of the dynamic model during deployment. Finally, we demonstrate the effectiveness of the proposed method through the simulation of vehicle tracking trajectories."
  },
  {
    "date": "2026-2-25",
    "title": "Unveiling the Merits and Defects of LLMs in Automatic Review Generation for Scientific Papers",
    "authors": "Ruochi Li, Haoxuan Zhang, Edward Gehringer, Ting Xiao, Junhua Ding, Haihua Chen",
    "publish": "2025 IEEE International Conference on Data Mining (ICDM)",
    "url": "https://doi.org/10.1109/icdm65498.2025.00146",
    "source": "IEEE",
    "abstract": "The surge in scientific submissions has placed increasing strain on the traditional peer-review process, prompting the exploration of large language models (LLMs) for automated review generation. While LLMs demonstrate competence in producing structured and coherent feedback, their capacity for critical reasoning, contextual grounding, and quality sensitivity remains limited. To systematically evaluate these aspects, we propose a comprehensive evaluation framework that integrates semantic similarity analysis and structured knowledge graph metrics to assess LLM-generated reviews against human-written counterparts. We construct a large-scale benchmark of 1,683 papers and 6,495 expert reviews from ICLR and NeurIPS in multiple years, and generate reviews using five LLMs. Our findings show that LLMs perform well in descriptive and affirmational content, capturing the main contributions and methodologies of the original work, with GPT-4o highlighted as an illustrative example, generating 15.74% more entities than human reviewers in the strengths section of good papers in ICLR 2025. However, they consistently underperform in identifying weaknesses, raising substantive questions, and adjusting feedback based on paper quality. GPT-4o produces 59.42% fewer entities than real reviewers in the weaknesses and increases node count by only 5.7% from good to weak papers, compared to 50% in human reviews. Similar trends are observed across all conferences, years, and models, providing empirical foundations for understanding the merits and defects of LLM-generated reviews and informing the development of future LLM-assisted reviewing tools. Data, code, and more detailed results are publicly available at https://github.com/RichardLRC/Peer-Review."
  },
  {
    "date": "2026-2-25",
    "title": "Enhanced Explainable Diagnosis of Alzheimer’s Disease",
    "authors": "Prasad kolhapure, Shravani Wadikar, Giridhar Hebbale",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403046",
    "source": "IEEE",
    "abstract": "Alzheimer’s disease (AD) is a progressive brain disorder that affects the memory, thinking, and daily activities. So, early diagnosis is difficult for treatment, but traditional methods take time and often lack consistency. This paper presents a simple hybrid frame-work that combines a Convolutional Neural Network (CNN) for MRI feature extraction with a Random Forest (RF) classifier to improve the accuracy and understanding. The framework was trained on a publicly available MRI dataset containing 6,400 brain images divided into four groups: Non-Demented, Very-Mild Demented, Mild Demented, and Moderate Demented. After preprocessing, augmentation, and balancing with SMOTE, the model achieved an overall accuracy of 83.06%. The per-class F1-scores were 0.74 for Non-Demented, 0.67 for Very-Mild Demented, 0.85 for Mild Demented, and 0.98 for Moderate Demented. Saliency maps highlighted the hippocampal and medial-temporal regions, which align with known clinical markers and enhance model clarity. The results indicate that the CNN-RF hybrid framework balances performance and under-standing, making it suitable for use in healthcare settings with limited resources."
  },
  {
    "date": "2026-2-25",
    "title": "Integrating Ultrasound Imaging with Structured State Space Models for Hormonal Pattern forecasting in Polycystic Ovary Syndrome",
    "authors": "Dr.S.Elavarasan, Dr.E.Rathnasabapathi, Vilma D Souz, Gomathy",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403475",
    "source": "IEEE",
    "abstract": "Polycystic Ovary Syndrome (PCOS) is a common endocrine condition that profoundly affects hormonal control and reproductive health. Precise prediction of hormonal rhythms is crucial for prompt diagnosis and efficient therapeutic therapy. This study presents an innovative approach that combines ultrasound imaging with Structured State Space Models (SSMs) to include both spatial and temporal dynamics in the diagnosis of PCOS. The dataset, obtained from Figshare, consists of 12,680 ultrasound scans classified into two classifies such as infected and non-infected. Preprocessing included normalization and balancing procedures to guarantee uniformity across the dataset. SSM’s were used to identify temporal correlations in hormonal pattern predictions, whereas imaging characteristics improved classification robustness. The suggested model demonstrated exceptional performance, with an accuracy of 99.46%, precision of 98.66%, recall of 98.66%, and F1-Score of 98.66%. These results validate the efficacy of integrating ultrasonic imaging with state-space representations for accurate classification. The method delineates a potential path for the use of sophisticated deep learning frameworks into medical diagnostics for PCOS."
  },
  {
    "date": "2026-2-25",
    "title": "Lenke Scoliosis classification In X-Ray Images Using PSO-Based Multi Thresholding Segmentation and Resnet-50",
    "authors": "Anna Nur Nazilah Chamim, Hasimah Ali, Yessi Jusman, Muhammad Ariffudin, Karisma Trinanda Putri, Devy Putri Mantikha",
    "publish": "2025 2nd Beyond Technology Summit on Informatics International Conference (BTS-I2C)",
    "url": "https://doi.org/10.1109/bts-i2c67944.2025.11399395",
    "source": "IEEE",
    "abstract": "Lenke scoliosis presents a significant clinical challenge due to its complex three-dimensional spinal deformity and the demand for precise classification for treatment planning. The widely applied Lenke classification system serves as an important guideline, but manual typing of X-ray images is laborious and prone to interobserver variability. This study proposes a novel automated framework integrating a biology-inspired optimization algorithm and deep residual learning to classify Lenke scoliosis types from posterior-anterior spine X-ray images. First, a multithresholding segmentation method based on Particle Swarm Optimization (PSO) is used to improve vertebral structure isolation by adaptively selecting an optimal threshold level, thereby enhancing structural clarity. Next, a ResNet-50 deep convolutional neural network, pretrained on ImageNet and fine-tuned on the segmented dataset, is used to extract hierarchical curvature features and perform multiclass classification. Experiments show training accuracy approaching 100% and validation accuracy of approximately 72% at epoch 97, with F1 scores per class of 0.81 for Lenke 3 and 0.49 for Lenke 6. These results demonstrate a clear improvement over traditional models without segmentation and confirm that combining PSO-based segmentation with deep residual networks significantly improves classification reliability. Finally, this study addresses limitations such as class imbalance, limited dataset size, and image quality variability and outlines future directions, including expanding Lenke types, integrating attention mechanisms, and incorporating multimodal clinical data. The proposed approach contributes to more efficient and robust computer-aided diagnosis for scoliosis management."
  },
  {
    "date": "2026-2-25",
    "title": "Self-Healing by Remote Terminal Unit of SCADA",
    "authors": "Ho Man Ho, Yau Sang Mo, Leo Ho Kwan Tang",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403520",
    "source": "IEEE",
    "abstract": "There are various considerations for power system resiliency during the network planning and design stage, such as closed ring network configurations. Critical customer substations under ring circuit would require a higher level of resiliency due to their significant impact on grid stability, high demand areas they serve or their role in supplying essential services. Thus, there would be an alternative source feed from another ring circuit or primary substation for those substations, to ensure continuity in case of cable faults on both ring-in and ring-out feeders.This paper specifically discusses the localised self-healing control for distribution substations with alternative sources from other ring circuits or primary substations. Regarding the automation control for the closed-ring distribution substations to achieve the millisecond grade power restoration for the critical distribution substation, we examine the use of the Remote Terminal Unit (RTU) of distribution substation to integrate the self-healing function.Integrating RTUs with self-healing capabilities not only alleviates spatial constraints in distribution substation but also optimises the asset utilisation. Furthermore, this paper discusses the technical approaches of such automation control integration in distribution RTUs, highlighting its advantages, limitations and potential challenges."
  },
  {
    "date": "2026-2-25",
    "title": "Object Detection and Location Tracking on Water Surface Using Edge Computing",
    "authors": "Ankitha K, Swaroop S, Anagha Tantry, Anusha Nayak, Sweekritha K C",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11394393",
    "source": "IEEE",
    "abstract": "Object detection and location tracking on water surfaces are critical to improve safety and automation in applications like small boats, autonomous cars, and environmental surveillance. This survey paper compares and examines existing methods for object detection and tracking in aquatic settings, with emphasis on those that use Convolutional Neural Networks (CNNs) and the NVIDIA Jetson Orin Nano Developer Kit. This study explores key phases of system development, such as data collection, preprocessing methods, CNN-based detection techniques, and approaches for determining object position and distance and provides a detailed review of current technologies that are being used in detecting and tracking objects on water surfaces. In addition, the study addresses obstacle avoidance strategies and real-time navigation adjustment mechanisms. Through a critical evaluation of current approaches, the review identifies core challenges such as fluctuating lighting conditions, dynamic backgrounds, and the need for dependable edge computing capabilities. The findings are intended to guide future developments in designing more accurate and efficient real-time systems for water-based environments."
  },
  {
    "date": "2026-2-25",
    "title": "Ray - An Offline Multimodal Desktop Assistant with Integrated Voice and Gesture Recognition",
    "authors": "Tanushree B Indresh, Amoolya M Shanbhag, Sneha K R, Darshan Yadav, Manjunath EC",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11393991",
    "source": "IEEE",
    "abstract": "This paper introduces RAY, an offline multimodal desktop assistant designed to enhance human-computer interaction through the integration of voice commands, text input, and real-time hand-gesture recognition. Developed using Python and the PyQt5 framework, RAY provides responsive interaction without relying on cloud services, ensuring strong privacy and consistent performance in low-connectivity environments. The system incorporates a lightweight speech-to-text and textto-speech pipeline, rule-based intent detection, and sentiment analysis using TextBlob for context-aware responses. Gesture recognition is implemented using OpenCV and MediaPipe to detect hand landmarks and classify predefined gestures in real time. A ruledriven multimodal fusion mechanism coordinates voice and gesture inputs to execute system-level commands reliably with low latency. Experimental evaluation demonstrates high gestureclassification accuracy, rapid response times, and strong usability scores, validating RAY as an effective, privacy preserving assistant for desktop automation."
  },
  {
    "date": "2026-2-25",
    "title": "Proactive Cybersecurity Threat Prediction Engine Using Hybrid AI and Multi-Source Intelligence",
    "authors": "M R Vishnupriya, Arun Karthik S, Veerapandian V R, Aluru Raghavendra Akshaya, Jackson Ajay J",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11393966",
    "source": "IEEE",
    "abstract": "As suggested in this paper, a proactive cybersecurity threat prediction engine that integrates hybrid artificial intelligence methods and information intelligence based on various data sources is proposed. The framework combines the organizational system logs and historical vulnerability data with external sources of threat intelligence including Common Vulnerabilities and Exposures (CVE) information, VirusTotal, and the MITRE Adversarial Tactics, Techniques, and Common Knowledge (ATT&CK) data into a single dataset. The analytics core implements a hybrid of anomaly detection (Isolation Forest algorithm) and risk typing (Random Forest and Extreme Gradient Boosting (XGBoost) and time series forecasting using the Prophet model and contextualization of textual threat reports using Bidirectional Encoder Representations from Transformers (BERT) language model. The combination will allow detecting zero-day in real-time and predicting future window of attack. Actionable insights in the form of an interactive risk dashboard provide risk scores, forecast vulnerabilities, anomaly alerts, and prescriptive recommendations. Through their efforts to convert tricky algorithms into a viable forecasting tool, this paper example shows how sophisticated AI techniques can be operationalised to develop a complete predictive cybersecurity framework."
  },
  {
    "date": "2026-2-25",
    "title": "GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction",
    "authors": "Narges Ghasemi, Amir Ziashahabi, Salman Avestimehr, Cyrus Shahabi",
    "publish": "2025 IEEE International Conference on Data Mining (ICDM)",
    "url": "https://doi.org/10.1109/icdm65498.2025.00130",
    "source": "IEEE",
    "abstract": "Image geolocalization-the task of determining an image's geographic origin-poses significant challenges, largely due to visual similarities across disparate locations and the large search space. To address these issues, we propose a hierarchical sequence prediction approach inspired by how humans narrow down locations from broad regions (e.g., country) to specific addresses (e.g., street name and house number). Analogously, our model predicts geographic tokens hierarchically, first identifying a general region and then sequentially refining predictions to increasingly precise locations. Rather than relying on explicit semantic partitions (e.g., country, city), our method uses S2 cells, a nested, multiresolution global grid, and sequentially predicts finer-level cells conditioned on visual inputs and previous predictions. This procedure mirrors autoregressive text generation in large language models. Much like in language modeling, final performance depends not only on training but also on inference-time strategy. We investigate multiple top-down traversal methods for autoregressive sampling, incorporating techniques from test-time compute scaling used in language models. Specifically, we integrate beam search and multi-sample inference while exploring various selection strategies to determine the final output. This approach enables the model to manage uncertainty by exploring multiple plausible paths through the hierarchy. We evaluate our method on the Im2GPS3k and YFCC4k datasets against two distinct sets of baselines: those that operate without a Multimodal Large Language Model (MLLM) and those that leverage one. In the MLLM-free setting, our model surpasses other comparable baselines on nearly all metrics, achieving state-of-the-art performance with accuracy gains of up to 13.9%. When augmented with an MLLM, our model again outperforms all baselines, setting a new state of the art across every metric. The source code is available at https://github.com/NNargesNN/GeoToken."
  },
  {
    "date": "2026-2-25",
    "title": "Identification and Replacement of High Energy-Consuming Home Appliances",
    "authors": "Li-Hsin Chang, YuHsuan Wu, Yi-Hong Fu, Chieh-Yu Lin",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403067",
    "source": "IEEE",
    "abstract": "To enhance customer satisfaction, Taiwan Power Company (Taipower) has set up two experimental services. First, this service analyzes household electricity usage by utilizing smart meter data and a neural network model to estimate the energy consumption shares for selected home appliances in a single household. Through visualization methods, it provides an easy way for customers to understand which home appliances consume more energy. Together with the energy consumption shares estimation service, Taipower has developed an experimental business model with home appliance retailers for households equipped with smart meters in Taiwan through the Taipower APP. The experimental business model encourages customers to purchase high-energy-efficiency home appliances to enhance their energy efficiency. A survey conducted through online questionnaires indicated that the satisfaction rate for these two services exceeded 88%."
  },
  {
    "date": "2026-2-25",
    "title": "Federated Graph Out-of-Distribution Generalization via Representation Propagation and Scattering",
    "authors": "Yukai Zhu, He Sun, Mingjun Xiao",
    "publish": "2025 IEEE International Conference on Data Mining (ICDM)",
    "url": "https://doi.org/10.1109/icdm65498.2025.00107",
    "source": "IEEE",
    "abstract": "Federated Graph Learning (FGL) enables collab-orative model training across decentralized graph data while preserving privacy. However, FGL faces severe performance degradation under out-of-distribution (OOD) shifts due to both feature distribution divergence and structural heterogeneity among clients. To address this, we propose FGOOD, a lightweight and effective framework that improves OOD generalization in FGL. FGOOD integrates two key components: (1) representation propagation, which enhances structural robustness by aggregating multi-hop topology while preserving local features, and (2) representation scattering, which regularizes node embeddings toward a uniformly dispersed distribution on the hypersphere, improving inter-class separation without requiring contrastive pairs. The theoretical analysis provides an upper bound on the generalization error under distribution shifts. Extensive experiments on three real-world datasets demonstrate that FGOOD outperforms existing state-of-the-art baselines, improving OOD accuracy by up to 5% while remaining lightweight and scalable."
  },
  {
    "date": "2026-2-25",
    "title": "PG3D-ViT: A Prompt-Guided 3D Vision Transformer for Medical Image Classification",
    "authors": "Gong Juan., Zuo Ke, Wang Qinglin, Wang Siqi, Mao Xiaoguang, Liu Jie",
    "publish": "2025 IEEE International Conference on Data Mining (ICDM)",
    "url": "https://doi.org/10.1109/icdm65498.2025.00037",
    "source": "IEEE",
    "abstract": "3D medical image classification is challenging due to small, subtle lesions and substantial irrelevant context, which often mislead deep models. Inspired by the top-down diagnos-tic process of clinicians—first identifying anatomical context, then locating anomalies—we propose Prompt-Guided 3D Vision Transformer (PG 3D- ViT), a framework that simulates clinical reasoning through prompt-driven attention. To address limited 3D training data, PG3D- ViT leverages 2D masked auto encoder (MAE) pretraining to learn transferable image features. Through the prompt generation module, consistency difference analysis is performed between normal and abnormal samples to extract anatomical structure and global spatial prompt information related to the lesion context. These prompts are injected as query into a cross-attention mechanism, guiding the model to focus on lesion-relevant regions across the 3D volume. Evaluated on 7 public datasets spanning multiple modalities and pathologies, PG3D-ViT achieves a 1.88% average AUC improvement over state-of-the-art methods. The attention map visualizations demonstrate that the model can accurately localize lesion regions, validating the effectiveness of the clinical prompting mechanism in enhancing both the performance and interpretability of 3D medical image classification. The code is available at the provided link<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup><sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>https://github.comJUMED-P/PG3D-ViT"
  },
  {
    "date": "2026-2-25",
    "title": "Toward Youth-Centered Privacy-by-Design in Smart Devices: A Systematic Review",
    "authors": "Molly Campbell, Mohamad Sheikho Al Jasem, Ajay Kumar Shrestha",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393846",
    "source": "IEEE",
    "abstract": "This literature review evaluates privacy-by-design frameworks, tools, and policies intended to protect youth in AI-enabled smart devices using a PRISMA-guided workflow. Sources from major academic and grey-literature repositories from the past decade were screened. The search identified 2,216 records; after deduplication and screening, 645 articles underwent eligibility assessment, and 122 were included for analysis. The corpus was organized along three thematic categories: technical solutions, policy/regulatory measures, and education/awareness strategies. Findings reveal that while technical interventions such as on-device processing, federated learning, and lightweight encryption significantly reduce data exposure, their adoption remains limited. Policy frameworks, including the EU's GDPR, the UK Age-Appropriate Design Code, and Canada's PIPEDA, provide important baselines but are hindered by gaps in enforcement and age-appropriate design obligations, while educational initiatives are rarely integrated systematically into curricula. Overall, the corpus skews toward technical solutions (67%) relative to policy (21 %) and education (12%), indicating an implementation gap outside the technical domain. To address these challenges, we recommend a multi-stakeholder model in which policymakers, manufacturers, and educators co-develop inclusive, transparent, and context-sensitive privacy ecosystems. This work advances discourse on youth data protection by offering empirically grounded insights and actionable recommendations for the design of ethical, privacy-preserving AI systems tailored to young users."
  },
  {
    "date": "2026-2-25",
    "title": "Centralized On-Line Monitoring System (COMS) as Operations &amp; Maintenance tool in Equipment Maintenance Management",
    "authors": "Dennis Jose L. Gan, Johannes Carl N. Ramos, Gregorio F. Jasareno, Rameses C. Oloya, Jayson R. Makalintal",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403382",
    "source": "IEEE",
    "abstract": "National Grid Corporation of the Philippines (NGCP) consistently desires to provide a reliable and continuous transmission of electricity throughout the country. The Philippines, being an archipelago, faces a challenge in ensuring that the power transmission is reliable. Its organizational structure adapts a regionalized and district concept to closely manage the assets scattered across the country. With its organizational structure, its maintenance implementation of high voltage substation equipment (HVE) is being directly managed by its regions and districts. This, however, offers challenges in providing timely and accurate equipment information that ultimately affects the effectiveness in developing O&M’s yearly maintenance program.With its desire to further improve the HVE maintenance implementation strategy, NGCP, through its Operation and Maintenance (O&M) Group introduced a system that will improve its equipment maintenance management through centralized data collection and management. The system intends to provide a readily available source of information focusing on the health condition of substation equipment and the maintenance requirement.This paper aims to discuss the development of the system and its alignment to a condition-based approach in maintaining the substation equipment. The system is a web-based application designed to reinforce NGCP’s Asset Management System. Parallel with the introduction of this system is the development of equipment condition evaluation guidelines that will be used in determining the health status of the equipment including the maintenance recommendation.Overall, the system is a combination of data analytics developed to consolidate all asset information such as records of electrical tests, inspection data including operational performance and the application of equipment health assessment guidelines.This system serves as the monitoring dashboard platform that converts the information collected into codes that are easy to understand for effective monitoring of the status of substation high voltage equipment.In its early application, improvements in the equipment maintenance were observed particularly on the resource’s optimization and maintenance planning."
  },
  {
    "date": "2026-2-25",
    "title": "Our Initiatives to Visualization of Cybersecurity Skills and Penetration Testing for Control Systems",
    "authors": "Kakeru Kashima, Hiroyuki Hasegawa",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403286",
    "source": "IEEE",
    "abstract": "This paper introduces our initiatives to strengthen the overall cybersecurity of the organization through the visualization of security personnel skills and the insource implementation of penetration testing for control systems. By creating a skill map, we have organized ideas for strategic talent development, and through the internalization of the testing team, we have enabled risk assessments that ensure the confidentiality of information."
  },
  {
    "date": "2026-2-25",
    "title": "Fake News Detection in Academic Platforms Using NLP and ML",
    "authors": "K. Priyanka, Harmeet Kaur Kochhar, Romica Bhat, V. Purushothama Raju, Mogulla Archana, Anand Pandey",
    "publish": "2025 World Conference on Cutting-Edge Science and Technology (WCCEST)",
    "url": "https://doi.org/10.1109/wccest66994.2025.11389935",
    "source": "IEEE",
    "abstract": "Digitalization The paper examines the means through which fake news can be prevented in academic websites using Natural Language Processing (NLP) as well as Machine Learning (ML). Some of the models we have tried on the Kaggle data include Support Vector Machines (SVM), Long Short-Term Memory (LSTM) networks and BERT. To detect the indicators of fake news, these models have been trained with the help of the following algorithms TF-IDF, word embeddings and contextual analysis. SVM has the highest very high accuracy of 99.48. It was nearly close to LSTM with a 99.39 value. The results suggest that the deep learning algorithms are superior to the simple ML algorithms in the process of detecting fake materials. The paper will contribute to enhancing the degree of online academic safety by providing more effective tools of identifying fake or misleading data and guaranteeing research credibility."
  },
  {
    "date": "2026-2-25",
    "title": "Modular Top Level Architecture Synthesis and Signal Routing in a 32-Bit RISC Processor",
    "authors": "Parinith M, Manjunath G. Asuti, Sudarshan, Rekha. P",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11394596",
    "source": "IEEE",
    "abstract": "The RISC-V instruction set architecture (ISA) is gaining wide adoption in domains such as IoT, embedded systems, and academic research due to its open-source, modular, and flexible design. A CPU core that is both efficient and easily verified is a basic prerequisite for such applications. In this work, we present the design and implementation of a Verilog HDL-based 32-bit single-cycle RISC-V processor that supports the RV32I instruction set. The processor integrates an Arithmetic Logic Unit (ALU), Register File, Control Unit, and Memory into a structured and modular datapath. Simulation and functional verification were performed using Eda Playground, where the correctness of instruction execution was confirmed through waveform analysis. The result of ALU operations is governed by the opcode and operands, where arithmetic operations (e.g., addition) perform A+B, logical operations (e.g., AND) perform <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathrm{A} \\wedge \\mathrm{B}$</tex>, and memory instructions handle load/store between registers and memory. Status flags such as zero, carry, negative, and overflow are updated accordingly. The proposed design demonstrates improved efficiency through optimized control logic and reduced critical path delay, ensuring faster instruction execution in single-cycle operation. This processor serves as a foundational model for future enhancements such as pipelined or low-power architectures aimed at increasing performance and energy efficiency. The proposed modular top-level architectural synthesis approach improves scalability, verification simplicity, and enables seamless extension toward pipelined RISC-V architectures."
  },
  {
    "date": "2026-2-25",
    "title": "Motor Imagery With Ai Integrated Rehabilitation In Neurological And Pediatric Rehabilitation",
    "authors": "Avisha Jaysingpure, Sharath Hullumani",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403212",
    "source": "IEEE",
    "abstract": "Serious motor impairments that restrict independence and quality of life are frequently the outcome of neurological diseases like stroke, cerebral palsy (CP), traumatic brain injury (TBI), and spinal cord injury (SCI). These conditions are among the main causes of long-term disability. Conventional rehabilitation methods offer some recovery, but they have drawbacks such as decreased therapy intensity, patient weariness, and therapist availability. Through the promotion of neuroplasticity and cortical reconfiguration, motor imagining (MI), a cognitive technique that stimulates brain networks involved in actual movement without physical execution, has become a viable augment therapy. By using artificial intelligence (AI) in conjunction with brain-computer interfaces (BCIs) to decode electroencephalography (EEG) signals in real time and provide adaptive feedback via robotics, virtual reality (VR), and functional electrical stimulation (FES), MI-based rehabilitation has advanced even further. While preliminary data suggest potential advantages for children with CP and SCI, especially when interventions are gamified and age-appropriate, clinical trials show notable gains in upper limb function, coordination, and motivation among adult stroke and SCI patients. Notwithstanding obstacles such EEG noise, the unpredictability of juvenile MI ability, and the high processing requirements of AI models, research is still being done to develop portable, reasonably priced, and easily navigable BCI systems that are appropriate for telerehabilitation. MI in conjunction with AI-powered BCI technology is a next-generation neurorehabilitation strategy that has the potential to revolutionize patient-centred recovery by improving accessibility, engagement, and efficacy in both adult and paediatric populations."
  },
  {
    "date": "2026-2-25",
    "title": "A Review on Classification of Lymph Nodes in benign, and malignant classes using Deep Learning Techniques",
    "authors": "Rahul Dattatray Ghode, Saroj Kumar Pandey, Manoj Kumar Ojha",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403411",
    "source": "IEEE",
    "abstract": "The lymphatic system comprises tissues, organs, lymphatic vessels, and lymph nodes (LN). It performs the major function of filtering out toxic substances, waste products, and other unwanted materials from the human body. The lymph fluid is collected by lymphatic capillaries, thereby forming lymphatic fluid. Lymph nodes act as filtration checkpoints and filter this fluid. This system supplies aid to circulatory and immune functions. Cancer is essentially characterized by its metastatic potential. Tumor cells usually spread through the lymphatic system. LN are the initial sites of metastasis. The classification of lymph nodes into benign or malignant is of paramount importance for treatment planning and evaluation of efficacy. Invasive techniques such as biopsy and FNAC are the current standard methods for the detection of malignant tumors in lymph nodes. These techniques have disadvantages like pain, bleeding, nerve damages, anesthesia risks, and also require special knowledge. There is therefore an urgent need for less invasive, faster, and safer methods to be developed. Imaging methods can therefore answer such needs: computed tomography is widely used for tumor assessment and has high reliability, but manual image analysis is very time-consuming, laborious, and requires specialized knowledge. Challenges in the detection and classification of LN include significant variations in the image appearance, indistinct boundaries, and low contrast with class imbalance. So, in order to handle such challenges, this paper discusses an automated deep learning-based approach which will handle LN detection and malignant tumor classification in computed tomography images. This study analyzes several CNN-based architectures for LN classification and discusses their challenges, performance analysis, and future research directions."
  },
  {
    "date": "2026-2-25",
    "title": "Leveraging Blockchain for Secure and Transparent Patient Case Data Management: Insights from System Implementation and Use Cases",
    "authors": "Maheswari. S, Sumaiya Thaseen, Varun Dev Sahu, Pritish Dipak Divate, Yashrajesh Akolu",
    "publish": "2025 2nd International Conference on Artificial Intelligence, Metaverse, and Cybersecurity (ICAMAC)",
    "url": "https://doi.org/10.1109/icamac67779.2025.11398625",
    "source": "IEEE",
    "abstract": "The safe handling of patient information is essential in the healthcare industry, particularly as the quantity and sensitivity of health records increase. Present systems frequently depend on centralized databases that are susceptible to unauthorized access and data manipulation, thereby restricting transparency and security. Furthermore, these systems lack the traceability required for efficient patient data management, making them prone to errors and inefficiencies in data processing. This paper proposes a patient data ledger built on blockchain technology, incorporating decentralized data management and secure transactions via Ethereum to enhance patient data handling. By leveraging blockchain, we achieve immutable records and ensure transparent, secure, and tamperresistant data storage. Unlike conventional systems that depend heavily on intermediaries for trust, our blockchain-based ledger minimizes human intervention and employs smart contracts to automate data security and access. Utilizing Ethereum's blockchain along with Web3 and MetaMask, the system enables secure, user-friendly access and effective data logging. This approach provides a reliable and scalable solution, ensuring real-time transparency and efficient handling of patient information while significantly enhancing security."
  },
  {
    "date": "2026-2-25",
    "title": "Time-Complexity Characterization of the NIST Lightweight Cryptography Finalists",
    "authors": "Najmul Hasan, Prashanth BusiReddyGari",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393752",
    "source": "IEEE",
    "abstract": "Lightweight cryptography is becoming essential as emerging technologies in digital identity systems and Internet of Things verification continue to demand strong cryptographic assurance on devices with limited processing power, memory, and energy resources. As these technologies move into routine use, they demand cryptographic primitives that maintain strong security and deliver predictable performance by clear theoretical models of time complexity. Although NIST's lightweight cryptography project provides empirical evaluations of the ten finalist algorithms, a unified theoretical understanding of their time-complexity behavior remains absent. This work introduces a symbolic model that decomposes each scheme into initialization, data-processing, and finalization phases, enabling formal time-complexity derivation for all ten finalists. The results clarify how design parameters shape computational scaling on constrained mobile and embedded environments. The framework provides a foundation needed to distinguish algorithmic efficiency and guides the choice of primitives capable of supporting security systems in constrained environments."
  },
  {
    "date": "2026-2-25",
    "title": "Risk Management in AI-Driven Sustainable E-Commerce Transformations: A Comprehensive Framework for Digital Business Resilience",
    "authors": "Karan Kumar Ratra, Pabitra Saikia, Liyaqatali Nadaf",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393855",
    "source": "IEEE",
    "abstract": "The convergence of artificial intelligence (AI) and sustainable e-commerce represents a transformative paradigm in digital commerce, promising enhanced operational efficiency, personalized customer experiences, and reduced environmental impact. However, this integration introduces a complex, multidimensional risk landscape that threatens both commercial viability and sustainability objectives. This paper presents a comprehensive analysis of risk management challenges in AI-driven sustainable e-commerce transformations through systematic examination of technological, ethical, environmental, and operational dimensions. Informed by the recent literature and current practices in the respective realms, we construct an inclusive framework for risk management that focuses on challenges of bias, cybersecurity, data protection, carbon footprint, and resilient value chains, which would be applicable to the context of e-commerce businesses seeking to navigate the complex landscape while creating resilient, trustworthy, and sustainable digital ecosystems effectively. However, the article will conclude by pointing towards the vital areas of future research work, which would be the standardizing of Green AI, utilizing AI to create an optimized circular economy, or studying risk perceptions across different cultures, which would help advance the landscape with its focus on the sustainable dynamics of the digital world effectively."
  },
  {
    "date": "2026-2-25",
    "title": "Development and Implementation of Smart Environmental and Safety Monitoring System Using CANBus and MQTT with Real-Time Visualization",
    "authors": "Arko Djajadi, Moeljono Widjaja, Vincent Marlino, Izdihar Dhawy Tasdid, Bonifasius Martin Wibawa, Hafizh Kumara Widyadhana",
    "publish": "2025 2nd Beyond Technology Summit on Informatics International Conference (BTS-I2C)",
    "url": "https://doi.org/10.1109/bts-i2c67944.2025.11399311",
    "source": "IEEE",
    "abstract": "Modern smart buildings require deterministic monitoring systems to ensure environmental quality and occupant safety. Conventional wireless protocols like Wi-Fi, ZigBee, and LoRa often suffer from latency and instability, limiting their use in safety-critical applications. Similarly, standard wired protocols like Modbus often lack priority messaging capabilities. This study presents a hybrid monitoring architecture integrating the Controller Area Network (CANBus) and Message Queuing Telemetry Transport (MQTT) protocol. An Arduino Mega transmitter node, interfaced with a multi-modal sensor suite (gas, sound, vibration, temperature, and light), transmits data via CANBus to an ESP32 IoT gateway. The ESP32 aggregates data over 2-second intervals and publishes structured JSON payloads to an MQTT broker for web visualization. Experimental results demonstrate robust performance with a 100% frame capture rate over the local CANBus link, confirming the reliability of the wired protocol for deterministic acquisition. The aggregation mechanism effectively reduced network load while producing stable data streams. The proposed platform offers a cost-effective, scalable, and reliable foundation for smart building monitoring while highlighting the trade-off between data smoothing and transient event detection."
  },
  {
    "date": "2026-2-25",
    "title": "Deep Learning Techniques for Automated Medical Diagnosis and Drug Interaction Prediction",
    "authors": "Anurag Shrivastava, Layth Hussein, Ginni Nijhawan, Sarvesh Kumar Mishra, Ashwini Kumar, Ajitesh Kumar",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403741",
    "source": "IEEE",
    "abstract": "The application of artificial intelligence in the healthcare is transforming the conventional diagnostic and treatment regimes. Deep learning, which is a branch of AI and is marked by its multi-layered neural networks, has been found to be exceptionally skilled in interpreting complex and high-dimensional medical data. The current paper offers a thorough overview of modern deep learning methods used in two vital and interconnected fields, namely, automated medical diagnosis and prediction of drug interactions. We discuss how convolutional neural networks have been modified into more complex recursive architecture and transformers to analyze sequential data in electronic health records. Moreover, the article also explores the use of graph neural networks in the modeling of the complex interactions among biological systems to forecast adverse drug-drug interactions, which is a major problem in pharmacovigilance. The analysis summarizes the most recent developments to reveal the potential of these technologies to transform, making them more accurate in diagnosing, more individualized in treatment, and safer to patients. The discussion also covers some of the challenges that have continued to exist such as a lack of data, the interpretability of models and the integration of the models into clinical practice and offers future research directions to close the gap between algorithmic innovation and clinical implementation."
  },
  {
    "date": "2026-2-25",
    "title": "Supply Chain Finance Risk Prediction Using Temporal Fusion Transformer on Transaction Time-Series",
    "authors": "Shyam Maurya, Utkarsh Anand, Dadabaev Saidbek Samatovich, Preethi S, T. Thirugnanasambandham, Ali Abbas Hadi",
    "publish": "2025 International Conference on AI-Driven STEM Education and Learning Technologies (AISTEMEDU)",
    "url": "https://doi.org/10.1109/aistemedu67077.2025.11403894",
    "source": "IEEE",
    "abstract": "Supply Chain Finance (SCF) is a process of controlling the flow of capital between the stakeholders in a supply chain, and correct prediction of risk is necessary to maintain financial stability and safety of investments. Utilizing transaction time-series information is also a useful way to get the time-related patterns that can be used to predict financial risk. Nevertheless, the current techniques like classical statistical models and simple machine learning techniques are not able to explain long-range correlations and dynamic time, resulting in low risks prediction accuracy. In order to overcome these drawbacks, we introduce a new model, namely SCF-TFT (Supply Chain Finance - Temporal Fusion Transformer), which combines a Temporal Fusion Transformer model with more effective feature selection and time-related attention. The methods used in the proposed SCF-TFT framework include variable selection networks, gating mechanisms, and explainable multi-horizon forecasting, which will adequately model complex temporal relationships and enhance robustness of predictions. In the supply chain field, this technique is used on actual data on transaction time-series to detect possible default risks and examine the financial condition of suppliers over a period of time. The experimental findings indicate that SCF-TFT is superior to baseline models and can be more precise, superior in recall, and F1-scores in risk prediction. Also, the model gives interpretable outputs that identify critical time drivers to affect financial risk, and therefore the model is useful in decision-making of those in finance and supply chain management."
  },
  {
    "date": "2026-2-25",
    "title": "Dimensionality increase for error correction in the interaction between information space and the physical world",
    "authors": "Tatyana Barron",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11400770",
    "source": "IEEE",
    "abstract": "The evolution of human intelligence led to the huge amount of data in the information space. Accessing and processing this data helps in finding solutions to applied problems based on finite-dimensional models. We argue, that formally, such a mathematical model can be embedded into a higher-dimensional model inside of which a desired solution will exist. In our model, the physical world and the information space are submanifolds of infinite-dimensional Hilbert spaces, and the processes, including information transmission, are maps between the submanifolds of the physical world or of the information space. We discuss how our perspective fits in the context of existing literature. Our theorem states that a submanifold in the parameter space of the physical world can be deformed to a target submanifold outside that space, with an appropriate count of the deformation parameters. We interpret this assertion as an existence result for a class of problems and we discuss further steps."
  },
  {
    "date": "2026-2-25",
    "title": "Design and Development of UART Communication Over RSA Encryption",
    "authors": "Vasudeva G, Mallikarjun P Y, Mahadev S, Tripti R Kulkarni, Bharathi Gururaj, Hemanth Kumar M. M, Abhishek H. J",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401365",
    "source": "IEEE",
    "abstract": "UART (Universal Asynchronous Receiver-Transmitter) is a widely adopted serial communication protocol in embedded systems, but its lack of inherent encryption exposes data to security vulnerabilities. This paper presents a hardware-level solution to secure UART communication by implementing the RSA encryption algorithm directly on an FPGA. The proposed architecture incorporates RSA key generation, encryption, and decryption along with UART interfacing in Verilog HDL, synthesized using the Xilinx ISE suite. Synthesis results on a Spartan-3 FPGA demonstrate the design’s area-efficiency and suitability for real-time secure communication. The encryption and decryption operations are validated with UART testbenches, and the successful round-trip of plaintext data confirms the system’s functional correctness and feasibility for IoT, automation, and secure embedded systems."
  },
  {
    "date": "2026-2-25",
    "title": "Peer-to-Peer Based Indoor Localization Using Smartphones: A Wi-Fi RSSI and Fingerprinting Algorithm Approach",
    "authors": "Madikana S. Sediela, Moses L. Gadebe, Okuthe P. Kogeda",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401353",
    "source": "IEEE",
    "abstract": "The evolution of smartphones with advanced wireless communication network capabilities has accelerated the adoption of Indoor Positioning Systems (IPS). These IPS desire to predict the position or location of various wireless devices. The Global Positioning System (GPS) remains the widely adopted Location-Based Services (LBS) application for positioning and navigation in an outdoor setting. However, GPS is inefficient indoors due to the line-of-sight requirements to the satellites. The indoor environment is harsh with multipath effects that cause occlusion between the GPS receiver and transmitter. Shortrange technologies such as Wi-Fi are gaining popularity indoors to alleviate GPS as an alternative technology. However, Wi-Fi infrastructure can be costly. This paper presents a cost-effective localization solution that utilizes Android smartphones as the sole requirement, eliminating the need for additional hardware. The proposed IPS solution uses a fingerprinting algorithm and employs a Peer-to-Peer (P2P) localization approach to reduce the cost implications of Wi-Fi. Only the received signal strength indicator (RSSI) measurements from Wi-Fi Direct and allied devices are used as input during both the offline and online stages of the fingerprinting process. The proposed IPS developed an Android mobile application in Java programming using Android Studio, with SQLite and Firebase real-time Database for storage. We have tested the system in real-time and evaluated its performance; the system produced a high accuracy of 93.33% for monitoring."
  },
  {
    "date": "2026-2-25",
    "title": "Innovative Electromyography System for Continuous Stress Detection Using Advanced Signal Processing and Classification Algorithms",
    "authors": "R. Kishore Kanna, Anjaney Nigam, Vinay Kumar Sharma, Jishu Varshney, Rama Kant, Alok Singh Chauhan",
    "publish": "2025 5th International Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU)",
    "url": "https://doi.org/10.1109/iot-siu65919.2025.11402781",
    "source": "IEEE",
    "abstract": "How to mitigate mental strain impacts of which accordingly to myriads of health professionals has been detrimental to public health becomes an integral focal within society.As such, this inquiry focuses on the development of a portable electro-myograph (EMG) powered multifunctional system meant to streamline the continuous monitoring and evaluation of an individual’s level of psychophysiological stress. EMG detects activity and specifically tension of the trapezius and the erector spinae muscle. A combination of the most recent neural network models and advanced signal processing techniques such as adaptive signal processing and regression analysis will be used to develop the system to quantify the stress symptomatic neurophysiological modality accessed via EMG and to identify the patterns of the psychophysiological response to stress. EMG stress detection, as evidenced by most of our studies, is significantly more accurate. Being able to identify various individual stress levels at an almost double the accuracy i.e. 96.2% is a major breakthrough as traditional systems employ 50% at best. Sections of the field of EMG that have real-time processing abilities, low system power consumption, and a supply presence of the Internet provide new opportunities in healthcare, occupational safety, and individual well-being for the continuous system monitoring of EMGs."
  },
  {
    "date": "2026-2-25",
    "title": "Harnessing Machine Learning for Climate Action, Sustainable EV Ecosystems, and Healthcare Innovation",
    "authors": "Jaspreet Singh, Rajinder Singh Kaundal, Ramandeep Sandhu, Pritpal Singh, Prikshat Kumar Angra, Ashwani Kumar",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403020",
    "source": "IEEE",
    "abstract": "Machine learning (ML), having already proven to be a game changer in the battle of environmental protection and restoration, offers new methods capable of combating the direst challenges — climate change, deforestation, pollution, biodiversity and maintaining EV ecosystem as Electronic vehicle also is important to maintain environmental sustainability. This paper elaborates on several ML models to predict and adapt the consequences of environmental change through floods forecast, air and water quality monitoring/control, energy optimization, waste management schedule and its link with healthcare innovation, wildlife preservation etc maintaining electronic vehicle ecosystem is very important and this paper discussed strategies to maintain Ev ecosystem. This model employed Random Forest (RF) classifier to predict flood occurrences with an 85 percent predictive accuracy based on rainfall and River flow data from ten years earlier. Similarly, DNN had a significant prediction of climate change, as the R 2 statistic was 0.92 and an infinite value = than World climate models. Convolutional Neural Networks (CNN) and Support Vector Machines (SVM) were employed for real-time monitoring air and water quality pollutant detection with high accuracy and precision. Moreover, Gradient Boosting Machines (GBM) was utilized in smart grids to save energy waste by 12 percent whereas CNN based automated waste separation allowed for a risen recycling efficiency of 25 percent. It also covers the use of ML in Q as well as C with CNN models getting an accuracy 93% on identification of species, a DL model finding a 25% increase in deforestation rate within next ten years"
  },
  {
    "date": "2026-2-25",
    "title": "Technology-Driven Needle-Free Injection Systems: Accuracy, Safety and Sustainable Drug Delivery",
    "authors": "R. Sridevi, P. Thiruvalar Selvan",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403721",
    "source": "IEEE",
    "abstract": "Needle-Free Injection Systems (NFIS) are rapidly emerging as transformative alternatives to conventional needle-based and auto-injector drug delivery devices. By eliminating hypodermic needles, NFIS enhances patient comfort, minimizes pain, and significantly reduces contamination risks and medical waste. This study presents a comparative analysis of NFIS, needle-based syringes, and auto-injectors, focusing on key performance metrics such as dose accuracy, pain level, injection velocity, contamination risk, waste generation, and smart integration. The results indicate that NFIS achieves higher dose precision (<2%), minimal pain (0–1 VAS), and faster administration (<1 second) compared to traditional syringes (5–10% error, 3–6 VAS, 5–15 seconds). Moreover, NFIS offers precise skin penetration control, negligible contamination risk, and low waste due to the absence of sharps, whereas needle-based methods remain dependent on manual variability and generate high disposal requirements. Future research directions emphasize adaptive jet velocity control, AI-driven penetration sensing, biodegradable or retractable needle designs, and IoT-enabled smart monitoring for improved treatment adherence. By integrating fluid dynamics modeling, pressure-impulse analyses, and simulation-based validation, this paper highlights the potential of NFIS to deliver vaccines, insulin, and biologics across diverse anatomical sites with enhanced safety and efficiency. The findings underscore NFIS as a scalable, technology-driven solution for painless, accurate, and sustainable drug administration, particularly valuable for large-scale immunization in remote and resource-limited healthcare settings."
  },
  {
    "date": "2026-2-25",
    "title": "Foundations of FinTechSec++: A Framework for Future Data Security Solutions in Financial Ecosystems",
    "authors": "Ruchin Kumar, Sharvan Kumar Garg",
    "publish": "2025 World Conference on Cutting-Edge Science and Technology (WCCEST)",
    "url": "https://doi.org/10.1109/wccest66994.2025.11389858",
    "source": "IEEE",
    "abstract": "With the rapid digitalization of financial services-spanning mobile wallets, peer-to-peer lending, central bank digital currencies (CBDCs), and decentralized finance (DeFi)-security architectures must evolve to counter diverse and emerging threats. Building on our earlier FinTechSec++ design for FinTechs and CBDCs, this paper reconceives the framework as a [Simplified] foundational platform for wider financial ecosystems. The framework introduces: (i) modular cryptographic plugins tailored to domain-specific data, (ii) a policy orchestration engine for reconciling multi-jurisdictional rules, (iii) audit logs optimized for external analytics tools, and (iv) automated retraining pipelines for anomaly detection. [Simplified long sentence] Benchmarks on three prototypes (Micro Payment App, CBDC Sandbox, and DeFi DEX) demonstrate threat detection rates of 94-97%, encryption throughput gains of 1.7x-1.9x, and policy enforcement latencies below 60 ms. These findings establish FinTechSec++ as a practical foundation for future financial data security solutions."
  },
  {
    "date": "2026-2-25",
    "title": "Comparative Analysis of AI Models for Fast Food Image Classification",
    "authors": "Alicia Hong, Jeng-Shiuan Ma, Srikar Bellur",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401344",
    "source": "IEEE",
    "abstract": "This paper presents a comprehensive evaluation of AI models for fast food image classification, comparing traditional computer vision approaches with modern multimodal systems. We hypothesize that modern AI technologies, including large language models with multimodal capabilities, surpass traditional approaches in accuracy and robustness. Our study compares six models: ResNet-18 and Vision Transformer (ViT-B/16) representing traditional approaches, CLIP as a multimodal encoder, and three large language models (GPT-4o-mini, Claude 3.5 Sonnet, and Gemma-3) with vision capabilities. We evaluate these models using the Fast-Food Classification Dataset V2 containing 20,000 images across nine fast-food categories. The experimental results demonstrate that modern AI models substantially outperform traditional approaches. Among traditional models, a two-stage unfreezing strategy for ResNet-18 achieved the best performance at 93.93% accuracy, exceeding head-only training (84.79%) and full fine-tuning (92.75%). Among multimodal systems, Gemma-3 reached 98.90% in zero-shot classification, further improved to 99.13% with LoRA-based fine-tuning. Finally, an ensemble of top-performing models achieved the highest overall accuracy of 99.29%."
  },
  {
    "date": "2026-2-25",
    "title": "Indoor Virtual Reality Navigation Incorporating Inclusion, Diversity, Equity, and Accessibility",
    "authors": "Zihua Zhu, Aiden Evans, Andrew J. Park, Eunju Hwang, Alyssa Fenuta",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393805",
    "source": "IEEE",
    "abstract": "This paper presents the development of a Virtual Reality (VR) indoor navigation system for a university building that incorporates the principles of Inclusion, Diversity, Equity, and Accessibility (IDEA). The system integrates 3D modeling, VR interactions, navigation, and user interface design to create an immersive and accessible experience for students, faculty, and visitors. The system supports detailed indoor modeling, searchbased navigation, and accessibility-focused pathways to facilitate orientation, virtual campus tours, and future virtual events or classes. Key components include 3D environment modeling using Rhino and Blender, VR integration and interaction in Unity, and a map-based navigation and search system with accessibility features for wheelchair users. The project contributes to inclusive digital campus experiences, offering both standard and wheelchair-accessible modes, and demonstrates how VR can improve orientation and accessibility in higher education environments."
  },
  {
    "date": "2026-2-25",
    "title": "Forecasting Solar Power Production using Deep Learning Approach",
    "authors": "Mehran Mohammad Rashidi, Mohamed Labib Awad, AbdulRahman Younis, Dawood Al Ali, Hyder Abdallah",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401263",
    "source": "IEEE",
    "abstract": "Trends in renewable energy sector show that energy production from solar photovoltaic (PV) has received a significant boost in recent years. Due to variable nature of PV generation, solar power forecast is becoming an essential factor for effective integration and successful operation of utility scale solar PV plants. Energy production from solar PV plant depends on several factors like sunlight, clouds, fog, temperature, etc. These factors themselves are forecasted using weather forecasting techniques; thereby, they are always biased with some degree of uncertainties in their values. Furthermore, the availability and accuracy of forecasted weather data, which is the main input for the solar PV generation forecast, is unique for each utility and depends on several factors. Thus, for effective planning and operation of solar and conventional generation fleet and grid operations, a unique and robust solar power forecasting system is required to reasonably forecast solar power generation. This paper presents a hybrid model based on multi-layer framework using artificial neural network (ANN), k-nearest neighbors (KNN) classification and k-means clustering algorithms for solar power forecast. The accuracy of the hybrid model is evaluated using a real world utility-scale solar PV plant of 1000MW."
  },
  {
    "date": "2026-2-25",
    "title": "Demystifying Carbon Capture, Utilization and Storage: A Power Utility Corporate Academy Journey of Energy Transition Capability Uplifting",
    "authors": "Mohd Iqbal Ridwan, Mohd Firdaus Mad Karim",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403045",
    "source": "IEEE",
    "abstract": "The power industry stands as the predominant source of Greenhouse Gases (GHG), with a substantial portion of emissions originating from fossil fuel (coal and gas) power plants. Effective management of these emissions is critical to achieving clean power generation and realizing the Net Zero 2050 ambitions. Within Malaysia's National Energy Transition Roadmap (NETR), Carbon Capture, Utilization, and Storage (CCUS) is identified as a pivotal technology for mitigating carbon emissions at upstream power generation facilities. However, the capital-intensive nature, advancing technological maturity, and complexity in business models across its value chain pose significant challenges to the large-scale deployment of CCUS in power generation plantsDespite these uncertainties, it is essential to ensure that the current workforce, particularly within power utilities such as Tenaga Nasional Berhad (TNB), remains well-informed about CCUS advancements while pilot projects are conducted on a small scale. As the Corporate Academy of TNB, TNB ILSAS plays a crucial role in fostering continuous competency development and uplifting the TNB workforce's capabilities in energy transition technologiesThis paper elucidates TNB’s journey in bolstering its workforce's capabilities in Energy Transition, focusing on the intricacies of CCUS technologies. It aims to bridge the gap between ambition and reality, particularly from the perspective of learning and development."
  },
  {
    "date": "2026-2-25",
    "title": "Real-Time EMG Signal Classification for 3D-Printed Prosthetic Arm Control Using Machine Learning and Deep Learning Models",
    "authors": "Sayand K K, Jishnu Vijayan, Venkitesh Sasikumar, Hema P Menon, Davidson Devasia",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11394633",
    "source": "IEEE",
    "abstract": "The analysis of EMG signals for muscle activity detection has gained a lot of prominence in recent years. These signals can be used to control prosthetics. For this the signals are obtained from the biceps of a person. In this work we investigate the application of machine learning / deep learning based models for real-time prosthetic arm control for EMG-based muscle activity classification. The models such as K-Nearest Neighbors (KNN), Naive Bayes, Linear Discriminant Analysis (LDA), Support Vector Machine (SVM), Random Forest (RF), Convolutional Neural Network (CNN), and Long Short Term Memory (LSTM) were compared. It was found that Random Forest gave the best results in terms of accuracy and responsiveness. For effective EMG signal processing and prosthetic movement execution, the system combines servo motors, surface electrodes, and Arduino UNO. For experiment purpose we used a customized 3D printed prosthetic arm. This study supports the development of cost-effective, high-performance prosthetics for use in myoelectrical rehabilitation systems."
  },
  {
    "date": "2026-2-25",
    "title": "Improving Heart Disease Diagnosis with Aquila-Optimized Feature Selection and XGBoost Classification",
    "authors": "Shilpa Sardesai, Paril Ghori",
    "publish": "2025 World Conference on Cutting-Edge Science and Technology (WCCEST)",
    "url": "https://doi.org/10.1109/wccest66994.2025.11390018",
    "source": "IEEE",
    "abstract": "Problems with heart disease can now be considered critical to the global health as the disease remains the primary cause of death in the whole world. XGBoost ensemble classifiers have proved to be an important tool in predictive healthcare analytics due to its applicability in machine learning. The efficiency of the models suffers in case of huge high-dimensional healthcare datasets combined with overlapping features. The authors examine the ways into which Aquila-Optimized Feature Selection (AOFS) can be used along with XGBoost to enhance both the speed and predictive accuracy in heart disease prediction. The result of testing reveals that AOFS is able to select the relevant features successfully causing an accuracy of 98.12% as compared to that of 96.35% upon the absence of feature selection. The standard feature selection methods do not perform well compared to AOFS which optimizes heart disease prediction models and they improve both precision and recall scores and AUC-ROC values and therefore exhibit better performance."
  },
  {
    "date": "2026-2-25",
    "title": "A CNN-BiLSTM Distribution Network Ground Fault Phase Selection Method Incorporating Attention Mechanisms",
    "authors": "Xianglun Nie, Yu Wu, Yi Li, Jianglan Shen, Xiaohu Zheng, Fangxue Li",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403410",
    "source": "IEEE",
    "abstract": "Accurately identifying the faulty phase is an important means to achieve rapid fault isolation and restoration. To improve the precision of fault phase selection, the Convolutional Neural Network-Bidirectional Long and Short Term Memory Network (CNN-BiLSTM) distribution network ground fault phase selection method integrating the attention mechanism is proposed. Firstly, the three-phase currents of the feeder are converted into 2D images through the signal-to-image conversion method and mapped to the R, G, and B channels to generate RGB images. Then, the generated RGB images are input into the CNN-BiLSTM fault phase selection model integrating CBAM. The local features of the RGB image are extracted by CNN, and the temporal features embedded in the RGB image are extracted by BiLSTM. Further, the Convolutional Block Attention Module (CBAM) is utilized to adaptively focus and mine the key feature information contained in the RGB images, thereby achieving high-precision fault phase selection. The results demonstrate that the proposed method exhibits high phase selection precision and robust performance under variations in network topology, neutral point operating modes, and noise interference."
  },
  {
    "date": "2026-2-25",
    "title": "A Privacy-Preserving Cybersecurity Framework for AI-Driven Green Mobility Ecosystems",
    "authors": "Rafael Abreu, Alexandre Sousa, Luís Correia, Arsénio Reis, Carlos Serôdio, Frederico Branco, Manuel J. C. S. Reis",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401363",
    "source": "IEEE",
    "abstract": "The integration of Artificial Intelligence (AI), Internet of Things (IoT), and Vehicle-to-Everything (V2X) technologies in green mobility systems introduces new cybersecurity and privacy challenges. This paper proposes a lightweight cybersecurity framework that integrates compact convolutional neural networks (CNNs) for real-time anomaly detection at the edge, federated learning for decentralized model training, and blockchain-based decentralized identity management with zero-knowledge proofs. These mechanisms collectively ensure sub-100 ms threat detection latency, reduced communication overhead, and GDPR-compliant privacy preservation. Simulation results demonstrate a 60% reduction in latency, 45% lower communication costs, 30% energy savings at edge nodes, and a detection accuracy of 93.4% compared to traditional cloud-centric models."
  },
  {
    "date": "2026-2-25",
    "title": "Exploration and Practice of Digital Twin Engineering Education for Complex Equipment",
    "authors": "Jiayu Yuan, Xudong Pan, Yuefeng Li, Ruoqiao Zhuang",
    "publish": "2025 IEEE 14th International Conference on Engineering Education (ICEED)",
    "url": "https://doi.org/10.1109/iceed66794.2025.11400233",
    "source": "IEEE",
    "abstract": "Aiming at the multidisciplinary and crossintegration nature of digital twin technology for complex equipment, as well as the current challenges in cultivating digital twin talents in higher education, this study draws on practical engineering cases of digital twin systems to explore the application of the Project-Based Learning (PBL) teaching model in related engineering education. It demonstrates how the PBL approach helps develop students' practical skills, innovation capacity, and ability to solve complex engineering problems, thereby achieving the talent development goal of shifting the emphasis from knowledge transmission and skill training to mindset cultivation. This research provides a valuable practical case and contributes to the reform of engineering education in universities."
  },
  {
    "date": "2026-2-25",
    "title": "IoT-Based Crab Aquaculture Monitoring System",
    "authors": "Aliah Chadun, Raj Kishen Moloo",
    "publish": "2026 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)",
    "url": "https://doi.org/10.1109/iitcee67948.2026.11394174",
    "source": "IEEE",
    "abstract": "This paper presents the design and implementation of an IoT-based monitoring system for crab aquaculture in Mauritius. The system tracks real-time water quality parameters such as temperature, <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{p H}$</tex>, salinity, and dissolved oxygen using sensors connected to an Arduino Uno R4 WiFi. Data is processed and transmitted to the cloud for real-time monitoring via a mobile application. The proposed system aims to improve water quality management, reducing mortality rates in crab farming and enhancing overall productivity. Besides, the system incorporates and AI predictive analytics using historical water quality data to forecast potential risks and mitigate them. Testing has shown that the system provides farmers with real-time insights, alerts and forecast leading to better decision-making in maintaining optimal pond conditions."
  },
  {
    "date": "2026-2-25",
    "title": "An Intelligent Real-Time Bus Occupancy Monitoring System Using Sensor Fusion and Computer Vision for Smart Public Transport",
    "authors": "Manisha Mehtre, Supriya Sutar, Suyash Bhavalkar, Rounk Sondawale, Swaraj Sontakke, Avishkar Suryawanshi",
    "publish": "2025 5th International Conference on Internet of Things: Smart Innovation and Usages (IoT-SIU)",
    "url": "https://doi.org/10.1109/iot-siu65919.2025.11402676",
    "source": "IEEE",
    "abstract": "Throughout this paper, we have elucidated our concept of a smart bus monitoring system that operates under the IoT (Internet of Things) paradigm, thereby allowing the provision of real-time data for the determination of the number of people occupying seats as well as the overall count of passengers. We intend to determine occupancy by means of HX711 load cells which will provide a clear indication of the seat and the person’s weight. On the other hand, by using a Raspberry Pi Camera Module 3 together with OpenCV, we will be able to detect a human and our proposal is that once the detection is done, an alert will be raised instantly if the bus is overloaded with passengers. A combination of sensor data and vision data is the basis of our system, and the information is processed via a Raspberry Pi 4B microcontroller. The processing of data in real time this way makes it possible to set the rates for or counts of seated capacity; also, the counts of boarding and disembarking will be used for the automatic pricing of fares during bus journeys. This hybrid approach allows us to not only correct errors that arise from only using single input monitoring, but it improves the reliability of total occupancy or seated capacity detection in order to limit potentially false events. Our unified data will also support predictive analysis and optimal route planning, as well as providing a dynamically scheduled or resourced operation based on real-time occupancy counts. Our history information will be used to learn people’s changing behavioural traffic patterns, and improve fleet management. We will want the system to be affordable, easy to scale, deployable in any public transport network, while increasing the efficiency and safety of transport, while improving the opportunities for enjoyment of travel, as well as helping to further urban mobility into smart cities. Raspberry Pi’s integration with platforms like Firebase allows for low latency transfer of data and live dashboards related to analysis on occupancy and fares. The inclusion of GPS tags on data allows us to forecast demand based on some location data. Anomaly Detection helps to find mechanical problems or unforeseen circumstances."
  },
  {
    "date": "2026-2-25",
    "title": "Performance Evaluation of YOLOv4 and ResNet50 in UAV-Based Weed Detection Systems",
    "authors": "Ledile Mathipa, Uchechi Ukaegbu, Lagouge Tartibu",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401348",
    "source": "IEEE",
    "abstract": "This study focuses on the development of an Unmanned Aerial Vehicle (UAV) based system for real-time weed detection in agricultural fields using Deep Learning (DL) techniques. Two models, ResNet50 and YOLOv4, were employed for weed detection and classification due to their proven effectiveness and differing architectures. The system was built using cost-efficient components and utilized a publicly available Kaggle dataset, with annotations created using the MakeSense.ai tool. Training was conducted on the Darknet framework in Google Collaboratory, leveraging Graphics Processing Unit (GPU) acceleration for improved efficiency. Among the models, YOLOv4 outperformed ResNet50, achieving a mean Average Precision (mAP@0.50) of 91%, F1 score of 88%, accuracy of 89%, recall of 82%, and an average detection time of 347ms. These results highlight YOLOv4's superior speed and accuracy, making it well-suited for practical applications in weed management. The overall system enhances agricultural productivity and cost-effectiveness by enabling timely and precise weed eradication, showcasing the transformative role of deep learning in modern agriculture."
  },
  {
    "date": "2026-2-25",
    "title": "An Effective Modelling of Optimized High-Speed VLSI Analog Circuit Layout using Fine-Tuned Deep Reinforcement Learning Framework",
    "authors": "Kavya Gaddipati",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11401285",
    "source": "IEEE",
    "abstract": "High-speed VLSI refers to the implementation and design of very large scale integration circuits improved for fast signal processing and minimum delay, allowing them to work at higher clock frequencies or process faster analog signals. In such models, millions (or still billions) of transistors are incorporated onto a single chip, and attaining higher speed needs particular focus on parasitic reduction, device sizing, power distribution, and interconnect design. Higher-speed VLSI is important in applications like higher-performance processors, signal processing units, communication systems, and higher-frequency analog/mixed-signal circuits. High-speed VLSI analog circuit layout concentrates on the design and real-world implementation of analog incorporated circuits able to work at higher frequencies with reduced signal degradation. It includes a thorough examination of parasitic inductances, capacitances, and resistances, as these can considerably influence performance at higher speeds. Major aspects consist of improved floorplanning to reduce interconnected length, symmetrical layout for balanced modules, guard and shielding rings to lower noise coupling, and the usage of differential routing for enhanced signal integrity. Optimization methods—like reducing interconnected length, utilizing common-centroid layouts to match, balancing trade-offs among speed and area, and using automatic or AI-assisted design tools—are applied for adjusting parameters for lowered power consumption, enhanced bandwidth, and better stability. This study presents an Effective Modeling of Optimized High-Speed VLSI Analog Circuit Layout using the Marine Predators Algorithm with Deep Reinforcement Learning (MPA-DRL) framework. The MPA-DRL technique is mainly designed to decrease the bottlenecks faced in the phase of the VLSI analog circuit design. The proposed model focused on two major phases: floorplanning and routing processes. Initially, the floorplanning problem can be framed as a Markov Decision Process (MDP) and exploited by deep reinforcement learning (DRL) to automatically perform placement generation under customary topological constraints. The hyperparameters of the DRL model can be optimized using the marine predators algorithm (MPA). Besides, Rectilinear Minimum Spanning Tree (RMST) is used for the global routing process and creates guiding paths for linking all circuit blocks. At last, by incorporating the solution into the procedural generation architecture, we propose a unified pipeline that bridges the boundary between circuit design and verification stages. A series of experiments was made, and the comparison study highlighted the betterment of the proposed model over existing studies."
  },
  {
    "date": "2026-2-25",
    "title": "An Explainable Artificial Intelligence Approach to Health Insurance Claim Fraud Detection",
    "authors": "Janapati Malathi, Talari Srinivasa Rao, Myneedi Chetan Viswa Kumar, Shaik Mujahid",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403401",
    "source": "IEEE",
    "abstract": "Health insurance fraud is a serious problem in today's health care system that results in a drain on monetary resources and delays in claim payments. This work introduces an intelligent, explainable health insurance claim verification system leveraging Optical Character Recognition (OCR) and Natural Language Processing (NLP) for an automated fraud detection process. The medical key features were extracted from claim text using the BioGPT embeddings and utilizing a Transformer-based classifier (RoBERTa Model). Deep contextual classification was performed to evaluate whether a claim was a legitimate or fraudulent claim. To tackle the class imbalance for the data, hybrid sampling was done using SMOTE and random undersampling, while interpretability was delivered using SHAP (Shapley Additive exPlanations) to clarify features that had influence in each decision. A chatbot powered by GPT responded in real time to any questions related to the claim, giving transparency and clarity using web scraping to pull updated policy data. The web-based platform will allow the claims be uploaded for user flexibility and to visualize fraud probability. The model was able to achieve an accuracy of 0.9848 and offered balanced performance, reliability, and trust in automated claim verification."
  },
  {
    "date": "2026-2-25",
    "title": "Naive Bayes Classifier for Prostate Cancer Risk Prediction Using Patient Records",
    "authors": "Shaini G.S, Ramesh S, D.Yobu, B. Shadaksharappa, S Murugan, Gokul G",
    "publish": "2025 2nd International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)",
    "url": "https://doi.org/10.1109/icaiihi67124.2025.11403257",
    "source": "IEEE",
    "abstract": "In order to decrease mortality and improve treatment outcomes, early risk assessment is crucial for prostate cancer, one of the most common tumours affecting men worldwide. This research presents a Naive Bayes classification algorithm to forecast prostate cancer risk utilizing the publicly accessible Prostate Cancer Risk & Lifestyle Synthetic Dataset from Kaggle. The collection comprises 1,000 synthetic patient records that encompass attributes including age, PSA level, familial history, race, Gleason score, digital rectal exam (DRE) outcomes, and lifestyle factors. After the preprocessing and encoding of categorical data, a Gaussian Naive Bayes classifier was trained and assessed utilizing a stratified 80/20 train-test division. The model achieved a testing accuracy of 91.2%, a precision of 89.5%, a recall of 92.1%, and an F1-score of 90.8%. The area under the ROC curve (AUC) was measured at 0.94, signifying exceptional discriminative performance. The results indicate that Naive Bayes, despite its simplicity, may accurately predict prostate cancer risk based on both lifestyle and clinical characteristics. The method shows potential as a streamlined decision-support instrument for initial risk assessment in healthcare settings."
  },
  {
    "date": "2026-2-25",
    "title": "STQS: A Unified System Architecture for Spatial Temporal Quantum Sensing",
    "authors": "Anastashia Jebraeilli, Chenxu Liu, Keyi Yin, Samuel Stein, Erik Lentz, Yufei Ding, Ang Li",
    "publish": "ACM Transactions on Quantum Computing",
    "url": "https://doi.org/10.1145/3795881",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-25",
    "title": "Utilizing Internet of Things in Human-Building Interaction to Support Sustainable Built Environments",
    "authors": "Suhas Prakash Devmane, Rana Omer, Charith Perera",
    "publish": "ACM Computing Surveys",
    "url": "https://doi.org/10.1145/3796536",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-2-25",
    "title": "Reinforcement Learning-Based Fuzzy Control for Nonlinear Systems With Unknown Dynamics via Parallel Composite Policy Iteration Scheme",
    "authors": "Yiqun Liu, Lifei Dai, Changzhu Zhang, Hao Zhang, Zhuping Wang, Hak-Keung Lam",
    "publish": "IEEE Transactions on Cybernetics",
    "url": "https://doi.org/10.1109/tcyb.2026.3665244",
    "source": "IEEE",
    "abstract": "The problem of reinforcement learning (RL)-based fuzzy control for nonlinear systems with unknown dynamics via parallel composite policy iteration (PCPI) scheme is studied in this article. The main objective of this article is to solve the fuzzy algebraic Riccati equation (FARE), which is inherently complex and cannot be easily solved by traditional mathematical formulas. Policy iteration (PI) and value iteration (VI) algorithms proposed have been widely used to address this problem. However, these algorithms have the disadvantages of an initial stabilizing control policy, the persistent excitation (PE) condition, and huge amounts of data. To effectively alleviate these drawbacks, a novel PCPI algorithm is proposed in this article. Specifically, for each fuzzy subsystem, an adaptive parameter is designed to eliminate the requirement of an initial stabilizing control policy. In addition, an online model-free PCPI algorithm is proposed for the situation where the dynamic information of the fuzzy system is difficult to obtain. By substituting the stored historical data with online data, the PE condition is relaxed to the initial excitation (IE) condition. Concurrently, the corresponding algorithm can be executed independently and concurrently under each fuzzy rule, thereby fully exploiting the available computational resources. Finally, the effectiveness of the algorithms set forth in this article is verified through a single-link robot arm and quarter-car active suspension (QCAS) experiment."
  },
  {
    "date": "2026-2-25",
    "title": "Extending the Spectral Integral Method to Solving 3-D Electromagnetic Scattering From a Smooth Sphere",
    "authors": "Zhen Guan, Jiawen Li, Falin Liu, Feng Han",
    "publish": "IEEE Transactions on Microwave Theory and Techniques",
    "url": "https://doi.org/10.1109/tmtt.2026.3663207",
    "source": "IEEE",
    "abstract": "Previous works have shown that due to its high-order accuracy with exponential convergence, the spectral integral method (SIM) significantly outperforms the traditional surface integral equation (SIE) for computing electromagnetic (EM) scattering from 2-D homogeneous objects with smooth boundaries (e.g., infinitely long circular cylinders) in terms of memory and time cost. This work extends SIM to the computation of EM scattering from smooth 3-D spheres filled with metal or homogeneous dielectric materials. Starting from the traditional SIE, the unknown spatial-domain equivalent electric and magnetic currents on the sphere surface are expanded by truncated vector spherical harmonics (VSH) series with unknown coefficients. Then the dyadic Green’s functions (DGFs) directly interact with VSH and thus are transformed into their spherical-harmonic spectral coefficients by surface integrals. Consequently, the conventional spatial-domain convolutional integrals in the SIE are transformed into multiplications of VSH spectral coefficients. Finally, to maintain the reliability of the SIM solution, the discretized equations are constructed by sampling the field values at the perturbed spherical Fibonacci grids (SFGs). To justify the computation accuracy and implementation efficiency of SIM applied to EM scattering from metal and dielectric spheres, a few numerical experiments were conducted, comparing it to the traditional SIE method. It is found that SIM only needs the spatial sampling density (SD) of 4 points per wavelength (PPW) to achieve reliable computation results while the traditional SIE usually requires an SD of 25 PPW to reach the same accuracy. In addition, the dependence of the required number of VSH modes to accurately represent the scattered fields on the distance between the excitation source and the scatterer is also studied."
  },
  {
    "date": "2026-2-25",
    "title": "Fog/Edge-Aware State Space Models for Multi-Task Chest X-ray Report Generation and Lesion Detection",
    "authors": "Wenbin Feng, Yu Lu, Xiaoqing Li, Kai Leung Yung, Wai Hung Ip",
    "publish": "IEEE Journal of Biomedical and Health Informatics",
    "url": "https://doi.org/10.1109/jbhi.2026.3667969",
    "source": "IEEE",
    "abstract": "Artificial intelligence (AI) is transforming radiology, particularly in automating medical report generation and abnormality detection. Although recent AI systems have shown clear potential in reducing radiologists' workloads and improving diagnostic accuracy, they still suffer from high computational cost and limited efficiency when modeling long-range dependencies. To address these challenges, we propose two state spacemodel (SSM) based frameworks: MambaXray-CTL for medical report generation, and MambaXray-MTL for unified report generation and abnormality localization. Both frameworks integrate a lightweight Mamba-based vision encoder with a large language model (LLM) decoder and incorporate multi-stage contrastive learning to align visual and textual representations. MambaXray-CTL achieves state-of-the-art performance on the IU X-ray and CheXpertPlus datasets while substantially reducing computational overhead compared with Vision Transformer models. MambaXray-MTL further extends this capability through a multi-task learning design that produces clinically coherent reports and accurately localizes abnormalities. Experimental results demonstrate the effectiveness of combining state space models with contrastive learning to deliver efficient, interpretable, and deployable AI solutions for chest radiograph analysis."
  },
  {
    "date": "2026-2-25",
    "title": "Winsor-CAM: Human-Tunable Visual Explanations from Deep Networks via Layer-Wise Winsorization",
    "authors": "Casey Wall, Longwei Wang, Rodrigue Rizk, KC Santosh",
    "publish": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
    "url": "https://doi.org/10.1109/tpami.2026.3668075",
    "source": "IEEE",
    "abstract": "Interpreting Convolutional Neural Networks (CNNs) is critical for safety-sensitive applications such as healthcare and autonomous systems. Popular visual explanation methods like Grad-CAM use a single convolutional layer, potentially missing multi-scale cues and producing unstable saliency maps. We introduce Winsor-CAM, a single-pass gradient-based method that aggregates Grad-CAM maps from all convolutional layers and applies percentile-based Winsorization to attenuate outlier contributions. A user-controllable percentile parameter <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$p$</tex-math></inline-formula> enables semantic-level tuning from low-level textures to high-level object patterns. We evaluate Winsor-CAM on six CNN architectures using PASCAL VOC 2012 and PolypGen, comparing localization (IoU, center-of-mass distance) and fidelity (insertion/deletion AUC) against seven baselines including Grad-CAM, Grad-CAM++, LayerCAM, ScoreCAM, AblationCAM, ShapleyCAM, and FullGrad. On DenseNet121 with a subset of Pascal VOC 2012, Winsor-CAM achieves 46.8% IoU and 0.059 CoM distance versus 39.0% and 0.074 for Grad-CAM, with improved insertion AUC (0.656 vs. 0.623) and deletion AUC (0.197 vs. 0.242). Notably, even the worst-performing fixed <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$p$</tex-math></inline-formula>-value configuration outperforms FullGrad across all metrics. An ablation study confirms that incorporating earlier layers improves localization. Similar evaluation on PolypGen polyp segmentation further validates Winsor-CAM's effectiveness in medical imaging contexts. Winsor-CAM provides an efficient, robust, and human-tunable explanation tool for expert-in-the-loop analysis."
  },
  {
    "date": "2026-2-25",
    "title": "A Retrospective Walk Down the “Processing in Memory” Lane",
    "authors": "Peter M. Kogge",
    "publish": "IEEE Micro",
    "url": "https://doi.org/10.1109/mm.2026.3667414",
    "source": "IEEE",
    "abstract": "Processing in Memory (PIM) and similar terms have gained attention recently as a potentially “revolutionary new” technique. The truth, however, is that many examples of the technology go back over 50 years. This paper provides a retrospective review of such systems, with an attempt to develop a rational categorization for the spectrum of approaches that have been explored."
  },
  {
    "date": "2026-2-25",
    "title": "Exploring Implicit Sentiment Analysis Through Progressive Prompting Strategies",
    "authors": "Chang Liu, Chen Gao, Yong Li, Meng Wang",
    "publish": "IEEE Transactions on Computational Social Systems",
    "url": "https://doi.org/10.1109/tcss.2026.3658513",
    "source": "IEEE",
    "abstract": "Aspect-based sentiment analysis (ABSA) aims to identify aspects and their associated sentiments from text. It can be categorized into explicit sentiment analysis (ESA) and implicit sentiment analysis (ISA). Unlike ESA, ISA lacks explicit sentiment indicators, requiring deeper contextual understanding and multilevel reasoning to infer underlying opinions. To address this challenge, we propose a progressive chain-of-thought-based reasoning framework (P-CoR) inspired by advanced prompt engineering in large language models (LLMs). P-CoR consists of three progressive prompting strategies: chain-of-thought-based reasoning (CoR), chain self-consistency-based reasoning (CSCR), and tree-of-thought-based reasoning (ToR). In CoR, we adopt a three-step reasoning process to identify fine-grained aspects, infer aspect-level opinions, and predict sentiment polarity. ToR involves identifying all aspect terms and subsequently determining the intensity of sentiment and the underlying reasons for opinions associated with each aspect, while CSCR enhances robustness by selecting candidate answers through voting consistency across inferred aspects and opinions. Experimental results on two benchmark datasets show that all proposed strategies outperform traditional neural models, with ToR achieving the best overall performance. Specifically, ToR attains 86.12% accuracy and 79.22% Macro-F1 on the restaurant dataset and 83.09% accuracy with 83.90% Macro-F1 on the laptop dataset. These results highlight the importance of ISA and validate the effectiveness of progressive prompting strategies for sentiment inference using LLMs."
  },
  {
    "date": "2026-2-25",
    "title": "A Soft Fabric-Based Thermal Haptic Device for Virtual Reality",
    "authors": "Rui Chen, Xianlong Mai, Domenico Chiaradia, Antonio Frisoli, Daniele Leonardis",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2026.3667732",
    "source": "IEEE",
    "abstract": "This paper presents a novel fabric-based thermal-haptic interface for virtual reality. It integrates pneumatic actuation and conductive fabric with an innovative ultra-lightweight design, achieving only 2 g for each finger unit. By embedding heating elements within textile pneumatic chambers, the system delivers modulated pressure and thermal stimuli to fingerpads through a fully soft, wearable interface. Comprehensive characterization demonstrates rapid thermal modulation with heating rates up to 3°C/s, enabling dynamic thermal feedback for virtual interactions. The pneumatic subsystem generates forces up to 8.93 N at 50 kPa, while optimization of fingerpad-actuator clearance enhances cooling efficiency with minimal force reduction. Experimental validation conducted with two different user studies shows high temperature identification accuracy (0.98 overall) across three thermal levels and significant manipulation improvements in a virtual pick-and-place task. Results show enhanced success rates (88.5% to 96.4%, p = 0.029) and improved force control precision (p = 0.013) when haptic feedback is enabled, validating the effectiveness of the integrated thermal-haptic approach for advanced human-machine interaction applications."
  },
  {
    "date": "2026-2-25",
    "title": "Analysis and Compensation of Intrinsic Position Error in Resolvers for High-Accuracy Applications",
    "authors": "R. Azami, M. A. Razavi, Z. Nasiri-Gheidari, F. Tootoonchian",
    "publish": "IEEE Sensors Journal",
    "url": "https://doi.org/10.1109/jsen.2026.3665933",
    "source": "IEEE",
    "abstract": "Resolvers are essential components for precise position sensing in demanding industrial and automotive applications. Their accuracy is fundamentally limited by inherent imperfections. A significant challenge in both design and compensation is the difficulty in decoupling the position error originating from the magnetic structure from the velocity-induced error (rotational voltage). This paper proposes a new framework to address this challenge. The key innovations of this work are twofold: first, the introduction of a new analytical metric for quantifying the error caused purely by the magnetic structure, and second, the development of an effective compensation algorithm based on this analysis. We introduce the concept of \"Intrinsic Position Error,\" which is isolated by analyzing induced voltages at the zero-crossing of the excitation current, showing it is a direct function of inductance harmonics. Based on this, a novel compensation algorithm is proposed which utilizes the harmonic characteristics of the error signal for a precise position correction. Finite Element Analysis (FEA) were performed to validate the proposed method. The results demonstrate the algorithm’s effectiveness, showing the average absolute position error is reduced by 92%. Experimental validation was conducted on a fabricated sensor prototype. The results showed a strong correlation with simulations, confirming the feasibility and effectiveness of the proposed compensation algorithm. This research provides a valuable tool for designers to optimize magnetic structures and a practical method for achieving high-accuracy position sensing."
  },
  {
    "date": "2026-2-25",
    "title": "Cover",
    "authors": "N/A",
    "publish": "2026 IEEE 16th Annual Computing and Communication Workshop and Conference (CCWC)",
    "url": "https://doi.org/10.1109/ccwc67433.2026.11393643",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-2-25",
    "title": "ICECER 2025 Cover Page",
    "authors": "N/A",
    "publish": "2025 International Conference on Electrical and Computer Engineering Researches (ICECER)",
    "url": "https://doi.org/10.1109/icecer65523.2025.11400943",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-2-25",
    "title": "Implementation of a Blackstart cranking path sequence operation through PMU",
    "authors": "Chirag Mistry, Carlos Aguilar, Dorin Patroiu, Charles Adewole",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403331",
    "source": "IEEE",
    "abstract": "The complexity of the interactions due to the integration of inverter-based resources and changes in generation mix is forcing utilities to focus on identifying blackstart cranking path sequences to restore the power system in the shortest period of time. This requires the use of an on-site generation unit or blackstart resources to start up and produce power without the need for an external (off-site) power source when recovering from a blackout event that involves the loss of many generation units.This paper presents a blackstart approach by Southern California Edison (SCE) using a subregional island methodology that is comprised of a self-starting unit used to start a larger generating unit(s) through energization of few generator step-up transformers, transmission line(s), and starting of motors and other auxiliary loads needed to restart non-blackstart generating units. Energization of the unloaded transmission line(s) during a blackstart is a critical step, as the charging current causes a voltage rise along the transmission line. The charging current could be significantly high that the blackstart generation unit will absorb reactive power. Regular studies are performed to verify that the proposed blackstart restoration plans are compliant with voltage and frequency operation limits, as well as to ensure that the blackstart generating unit is capable of absorbing reactive power within its limits under the lightly-loaded blackstart condition. Also, it is important to ensure that the magnitude, duration, and harmonic content of the transformer inrush current will not cause resonance issues. Also, a key concern is ensuring that abnormal system conditions and faults are detected during transmission line energization, and other steps of power system restoration. This is especially true for transmission lines that transverse through wildfire prone areas. Energization of a downed conductor could ignite a wildfire and is a concern for public safety. During the broken conductor condition and lightly-loaded line conditions, the expected performance of the protection system may be compromised, as the current magnitude may be below the relay set threshold or a pickup current.In order to facilitate the restoration process, a synchrophasor-based wide area scheme is used to guide the operator during the blackstart cranking path sequence, using the line protection relays to send the real-time current and voltage measurements to a central controller for monitoring the line health, as well as any failing conductor conditions. Additional relays in critical locations are also used to obtain node voltage and current measurement points required to avoid any switching error. The architecture of the restoration system used is presented in this paper, including the topology, sequence logic and steps followed, as well as the HMI for the blackstart restoration process."
  },
  {
    "date": "2026-2-25",
    "title": "Author Index",
    "authors": "N/A",
    "publish": "2025 International Conference on Advances in Machine Intelligence, and Cybersecurity Technologies (AMICT)",
    "url": "https://doi.org/10.1109/amict65811.2025.11402765",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-2-25",
    "title": "Ganoderma Detection on Oil Palm Stem using YOLO Approach",
    "authors": "Anindita Septiarini, Hamdani Hamdani, Encik Akhmad Syaifudin, Fazri Rahmad Nor Gading, Novianti Puspita, Masna Wati",
    "publish": "2025 2nd Beyond Technology Summit on Informatics International Conference (BTS-I2C)",
    "url": "https://doi.org/10.1109/bts-i2c67944.2025.11399519",
    "source": "IEEE",
    "abstract": "Ganoderma is the primary pathogenic fungus infecting oil palm stems and poses a serious threat to the palm oil industry, as it has the potential to cause significant economic losses. Accurate and timely detection is crucial for effectively controlling its spread. This study investigates the application of deep learning-based object detection to enable automated, precise, and rapid identification of Ganoderma infections. Specifically, it evaluates and compares the detection performance of medium variants of three models: YOLOv8, YOLOv9, and YOLOv10, each fine-tuned using pre-trained weights on a custom dataset of 354 annotated images containing instances of Ganoderma and Primordium (the early fruiting body). Through image augmentation, the dataset was expanded to 798 training images, 70 validation images, and 18 test images. Experimental results on the test set show that each model achieved mAP50 scores of 95.41%, 94.54%, and 95.10%, mAP50:95 scores of 74.40%, 69.74%, and 67.71%, and Mean Recall values of 93.93%, 92.91%, and 91.21%, respectively. These findings demonstrate that YOLOv8m strikes the optimal balance between detection accuracy and robustness, making it a strong candidate for deployment in early detection systems for oil palm plantations."
  },
  {
    "date": "2026-2-25",
    "title": "Coordinated Optimal Scheduling Method for Distribution Systems Based on the Analytic Target Cascading Method",
    "authors": "Nan Ning, Min Xie, Guohong Wang, Yun Rao, Keyang Chen",
    "publish": "2025 25th Conference of the Electric Power Supply Industry (CEPSI)",
    "url": "https://doi.org/10.1109/cepsi66359.2025.11403419",
    "source": "IEEE",
    "abstract": "With the development of distributed energy technology and the in-depth promotion of power system reform, the distribution network presents the characteristics of multiple stakeholders. Distribution network operators, distributed energy providers, combined cooling, heating and power (CCHP) load integrators and other distribution network entities have different interest needs. In order to describe the model of these stakeholders, realize the energy balance of cooling, heating and power in the distribution network, and maintain the safe and stable operation of the power system, a collaborative optimization scheduling method of distribution system based on analytic target cascading (ATC) is proposed. The distribution network operators, distributed energy providers and CCHP load integrators under the distribution network environment are modeled and the distribution system collaborative optimal scheduling is carried out. Each subject coordinates by exchanging contact variable information, and finally obtains the optimal collaborative optimal scheduling strategy. Finally, the proposed model and algorithm are simulated and verified based on an example of ieee33 distribution network system. It is shown that the coordinated optimal scheduling of the distribution system based on the ATC algorithm decouples and parallelly solves the liaison variables between each stakeholder and the distribution network operator, which greatly improves the calculation efficiency."
  },
  {
    "date": "2026-2-25",
    "title": "Dynamic Brightest Intensity ROI for Smartphone-Based PPG: A Comparative Analysis of Frame Selection Methods for Hemoglobin Estimation and Anemia Classification",
    "authors": "Nipuni Vithana, Rasika Rajapaksha",
    "publish": "2025 International Conference on Advances in Technology and Computing (ICATC)",
    "url": "https://doi.org/10.1109/icatc68823.2025.11407836",
    "source": "IEEE",
    "abstract": "Smartphone photoplethysmography (sPPG) has become one of the promising non-invasive methods of estimating hemoglobin and screening for anemia, especially where resources are limited. However, extracting PPG signals from smartphone fingertip videos is extremely sensitive to frame quality, changes in illumination and motion artifacts. This study fills a literature gap by introducing a frame selection algorithm, Dynamic Brightest Intensity Region of Interest (ROI) and compares its performance with five existing algorithms namely Fixed Center ROI, Right to Left ROI, Temporal Difference ROI, Template Matching ROI and Frame Adaptive ROI. The latter methodology uses a set of data augmentation and preprocessing techniques to improve the quality of PPG signals obtained based on fingertip videos. The signals are then processed by physiologically-informed feature extraction and then refined by systematic feature selection to accurately estimate hemoglobin and classify anemia severity by using XGBoost and Artificial Neural Networks.In this study, Frame Adaptive ROI method gave the best predictive performance; however, it involves intensive pixel-level operations and dynamic masking, which makes the method time-consuming and more computationally intensive. Conversely, the suggested Dynamic Brightest Intensity ROI algorithm showed a desirable trade-off between accuracy and efficiency with a high level of hemoglobin regression (RMSE = 0.5043) and anemia severity classification (accuracy = 0.9783). It has a reduced computational complexity, and thus is better applicable in real-time or mobile deployment environments where processing time is a key factor. These results indicate that the dynamic selection of the frame is significant in enhancing the quality of the signal."
  },
  {
    "date": "2026-2-25",
    "title": "Economic Time Series Decomposition Using Seasonal ARIMA in Macro-Level Planning Models",
    "authors": "Gayrat Bekbergenov, K.Bhargava Triveni Nandana, Mamasidikova Naima Tokhirjon Kizi, Sureka M, Mariyam Ahmed",
    "publish": "2025 International Conference on AI-Driven STEM Education and Learning Technologies (AISTEMEDU)",
    "url": "https://doi.org/10.1109/aistemedu67077.2025.11403934",
    "source": "IEEE",
    "abstract": "The macro-level indicators, including Gross Domestic Product (GDP), inflation, and employment, cannot be explained without economic time series decomposition. SARIMA models provide an efficient statistical methodology that can be used to trace such conditional seasonal economic trends. Nevertheless, the current procedures tend to ignore the complex seasonal correlations and cannot differentiate between transient and enduring economic shifts, which result in the inadvisory policy decisions. The current paper suggests a model of GDP growth pattern decomposition by the use of SARIMA to improve the accuracy of macroeconomic planning. The suggested approach is able to provide more accurate trend, seasonal, and residual separation, which is a major weakness of the previous models. The SARIMA-based decomposition can help the policymakers to develop data-based strategies of fiscal and monetary policies by exposing the economic dynamic that may have been supported by seasonal changes under the surface. SARIMA in the experimental results has a forecast accuracy of 6.5, an error rate of 11.5, the data processing time is 95 seconds and moderate computational complexity (5/10). These values prove that SARIMA is better than the available models in terms of accuracy and the efficiency of operation."
  },
  {
    "date": "2026-2-25",
    "title": "Review of a Specialised Civil Engineering Technology (Construction) Course: Outcome-Based Learning Approach",
    "authors": "Chee-Ming Chan, Alina Shamsuddin, Azeanita Suratkon",
    "publish": "2025 IEEE 14th International Conference on Engineering Education (ICEED)",
    "url": "https://doi.org/10.1109/iceed66794.2025.11399964",
    "source": "IEEE",
    "abstract": "Shifting the focus from traditional content delivery to student-centered learning, Outcome-Based Education (OBE) is widely adopted in technology-based programmes, where it prioritizes what students are expected to achieve by the end of a learning experience as measurable outcomes. The teaching methodologies, assessment strategies and learning activities are deliberately aligned to ensure that every component of the curriculum supports the attainment of these predetermined outcomes. Specifically in the context of engineering technology, this encompasses designing curricula that equip students with not only theoretical understanding but also practical, hands-on skills relevant to real-world engineering challenges. With the iterative progression of ‘learning’ steadily reinforcing their comprehension and mastery of the subject matter, students are progressively nurtured to transition seamlessly into successive phases of learning. This ongoing refinement of knowledge functions as a launchpad, allowing learners to build upon the solid ground of newly constructed ‘learned’ knowledge and skill. The efficiency of this process lies in the student's ability to internalize and apply previously acquired concepts, effectively leveraging their cumulative knowledge base. This outcomedriven approach fosters a culture of continuous improvement, in turn creating a dynamic educational environment that empowers students to meet the demands of a complex, innovation-driven market with confidence and capability via reflective practices. The paper reviews a core discipline Civil Engineering Technology course, through the course structure and contents, learning outcomes, delivery and activities, and finally the evaluation of learning outcomes."
  }
]