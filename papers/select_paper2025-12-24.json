[
  {
    "date": "2025-12-24",
    "title": "AegisAgent: An Autonomous Defense Agent Against Prompt Injection Attacks in LLM-HARs",
    "authors": "Yihan Wang, Huanqi Yang, Shantanu Pal, Weitao Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20986v1",
    "source": "arXiv",
    "abstract": "The integration of Large Language Models (LLMs) into wearable sensing is creating a new class of mobile applications capable of nuanced human activity understanding. However, the reliability of these systems is critically undermined by their vulnerability to prompt injection attacks, where attackers deliberately input deceptive instructions into LLMs. Traditional defenses, based on static filters and rigid rules, are insufficient to address the semantic complexity of these new attacks. We argue that a paradigm shift is needed -- from passive filtering to active protection and autonomous reasoning. We introduce AegisAgent, an autonomous agent system designed to ensure the security of LLM-driven HAR systems. Instead of merely blocking threats, AegisAgent functions as a cognitive guardian. It autonomously perceives potential semantic inconsistencies, reasons about the user's true intent by consulting a dynamic memory of past interactions, and acts by generating and executing a multi-step verification and repair plan. We implement AegisAgent as a lightweight, full-stack prototype and conduct a systematic evaluation on 15 common attacks with five state-of-the-art LLM-based HAR systems on three public datasets. Results show it reduces attack success rate by 30\\% on average while incurring only 78.6 ms of latency overhead on a GPU workstation. Our work makes the first step towards building secure and trustworthy LLM-driven HAR systems.",
    "title_zh": "AegisAgent：一种针对大语言模型-人类-自动化系统（LLM-HARs）中提示注入攻击的自主防御代理",
    "abstract_zh": "将大型语言模型（LLMs）融入可穿戴传感技术，正在催生一类能够深入理解人类活动的新型移动应用。然而，这些系统在可靠性方面面临严峻挑战，其根源在于对提示注入攻击的高度脆弱性——攻击者通过向LLM输入具有欺骗性的指令来操控系统行为。传统的防御机制依赖于静态过滤和僵化规则，难以应对这类攻击所蕴含的复杂语义特征。我们主张必须实现范式转变：从被动过滤转向主动防护与自主推理。为此，我们提出AegisAgent，一种专为保障LLM驱动的人体活动识别（HAR）系统安全而设计的自主代理系统。AegisAgent不仅被动地拦截威胁，更扮演着认知守护者的角色：它能自主感知潜在的语义不一致，通过调用动态记忆中的历史交互记录来推断用户的真实意图，并主动生成并执行多步骤的验证与修复方案。我们构建了一个轻量级、全栈式的AegisAgent原型，并在三个公开数据集上，针对五种先进的LLM驱动HAR系统，对15种常见攻击进行了系统性评估。实验结果表明，该系统平均可将攻击成功率降低30%，同时在GPU工作站上仅引入78.6毫秒的延迟开销。本研究迈出了构建安全、可信的LLM驱动HAR系统的坚实第一步。"
  },
  {
    "date": "2025-12-24",
    "title": "One Tool Is Enough: Reinforcement Learning for Repository-Level LLM Agents",
    "authors": "Zhaoxi Zhang, Yitong Duan, Yanzhi Zhang, Yiming Xu, Jiyan He, Yunfang Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20957v1",
    "source": "arXiv",
    "abstract": "Locating the files and functions requiring modification in large open-source software (OSS) repositories is challenging due to their scale and structural complexity. Existing large language model (LLM)-based methods typically treat this as a repository-level retrieval task and rely on multiple auxiliary tools, which overlook code execution logic and complicate model control. We propose RepoNavigator, an LLM agent equipped with a single execution-aware tool-jumping to the definition of an invoked symbol. This unified design reflects the actual flow of code execution while simplifying tool manipulation. RepoNavigator is trained end-to-end via Reinforcement Learning (RL) directly from a pretrained model, without any closed-source distillation. Experiments demonstrate that RL-trained RepoNavigator achieves state-of-the-art performance, with the 7B model outperforming 14B baselines, the 14B model surpassing 32B competitors, and even the 32B model exceeding closed-source models such as Claude-3.7. These results confirm that integrating a single, structurally grounded tool with RL training provides an efficient and scalable solution for repository-level issue localization.",
    "title_zh": "一个工具足矣：面向仓库级大语言模型代理的强化学习",
    "abstract_zh": "在大型开源软件（OSS）仓库中定位需要修改的文件和函数极具挑战性，这主要源于其规模庞大和结构复杂。现有的基于大语言模型（LLM）的方法通常将此任务视为仓库级别的检索问题，并依赖多个辅助工具，却忽视了代码执行逻辑，且使模型控制变得复杂。为此，我们提出了RepoNavigator——一种配备单一“执行感知”工具的LLM智能体，该工具可直接跳转至被调用符号的定义处。这种统一设计真实反映了代码的实际执行流程，同时简化了工具操作。RepoNavigator通过强化学习（RL）从预训练模型端到端地进行训练，无需任何闭源知识蒸馏。实验结果表明，经RL训练的RepoNavigator达到了当前最佳性能：7B模型超越14B基线，14B模型优于32B竞争对手，甚至32B模型也超过了诸如Claude-3等闭源模型。这些结果证实，结合单一、结构化基础工具与强化学习训练，为仓库级问题定位提供了一种高效且可扩展的解决方案。"
  },
  {
    "date": "2025-12-24",
    "title": "Uncovering Hierarchical Structure in LLM Embeddings with $δ$-Hyperbolicity, Ultrametricity, and Neighbor Joining",
    "authors": "Prakash Chourasia, Sarwan Ali, Murray Patterson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20926v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of large language models (LLMs) has enabled significant strides in various fields. This paper introduces a novel approach to evaluate the effectiveness of LLM embeddings in the context of inherent geometric properties. We investigate the structural properties of these embeddings through three complementary metrics $δ$-hyperbolicity, Ultrametricity, and Neighbor Joining. $δ$-hyperbolicity, a measure derived from geometric group theory, quantifies how much a metric space deviates from being a tree-like structure. In contrast, ultrametricity characterizes strictly hierarchical structures where distances obey a strong triangle inequality. While Neighbor Joining quantifies how tree-like the distance relationships are, it does so specifically with respect to the tree reconstructed by the Neighbor Joining algorithm. By analyzing the embeddings generated by LLMs using these metrics, we uncover to what extent the embedding space reflects an underlying hierarchical or tree-like organization. Our findings reveal that LLM embeddings exhibit varying degrees of hyperbolicity and ultrametricity, which correlate with their performance in the underlying machine learning tasks.",
    "title_zh": "利用δ-双曲性、超度量性与邻接连接法揭示大语言模型嵌入中的层次结构",
    "abstract_zh": "大型语言模型（LLMs）的快速发展在多个领域取得了显著进展。本文提出了一种新方法，用于评估大型语言模型嵌入在固有几何特性背景下的有效性。我们通过三种互补的度量——δ-双曲性、超度量性和邻接法（Neighbor Joining），研究了这些嵌入的结构特性。δ-双曲性是一种源自几何群论的度量，用于量化一个度量空间偏离树状结构的程度；相比之下，超度量性描述的是严格分层的结构，其中距离满足一种强三角不等式。而邻接法则专门衡量距离关系在邻接法所重建的树形结构中的树状程度。通过使用这些度量分析由大型语言模型生成的嵌入，我们揭示了嵌入空间在多大程度上反映了潜在的层次化或树状组织。研究结果表明，大型语言模型的嵌入表现出不同程度的双曲性和超度量性，且这些特性与它们在底层机器学习任务中的表现密切相关。"
  },
  {
    "date": "2025-12-24",
    "title": "C2LLM Technical Report: A New Frontier in Code Retrieval via Adaptive Cross-Attention Pooling",
    "authors": "Jin Qin, Zihan Liao, Ziyin Zhang, Hang Yu, Peng Di, Rui Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21332v1",
    "source": "arXiv",
    "abstract": "We present C2LLM - Contrastive Code Large Language Models, a family of code embedding models in both 0.5B and 7B sizes. Building upon Qwen-2.5-Coder backbones, C2LLM adopts a Pooling by Multihead Attention (PMA) module for generating sequence embedding from token embeddings, effectively 1) utilizing the LLM's causal representations acquired during pretraining, while also 2) being able to aggregate information from all tokens in the sequence, breaking the information bottleneck in EOS-based sequence embeddings, and 3) supporting flexible adaptation of embedding dimension, serving as an alternative to MRL. Trained on three million publicly available data, C2LLM models set new records on MTEB-Code among models of similar sizes, with C2LLM-7B ranking 1st on the overall leaderboard.",
    "title_zh": "C2LLM 技术报告：通过自适应交叉注意力池化实现代码检索的新前沿",
    "abstract_zh": "我们提出 C2LLM——对比代码大语言模型，这是一个包含 0.5B 和 7B 两种规模的代码嵌入模型家族。基于 Qwen-2.5-Coder 的骨干网络，C2LLM 采用多头注意力池化（Pooling by Multihead Attention, PMA）模块，从标记嵌入中生成序列嵌入，有效实现了以下三点：1）充分利用预训练阶段获得的大语言模型因果表示；2）能够聚合序列中所有标记的信息，突破传统以 EOS 结尾的序列嵌入所存在的信息瓶颈；3）支持灵活调整嵌入维度，可作为 MRL 的替代方案。在三百万条公开可用数据上进行训练后，C2LLM 模型在与同类规模模型相比的 MTEB-Code 基准测试中创下新纪录，其中 C2LLM-7B 在整体排行榜中位列第一。"
  },
  {
    "date": "2025-12-24",
    "title": "RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic",
    "authors": "Le Wang, Zonghao Ying, Xiao Yang, Quanchen Zou, Zhenfei Yin, Tianlin Li, Jian Yang, Yaodong Yang, Aishan Liu, Xianglong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21220v1",
    "source": "arXiv",
    "abstract": "Embodied agents powered by vision-language models (VLMs) are increasingly capable of executing complex real-world tasks, yet they remain vulnerable to hazardous instructions that may trigger unsafe behaviors. Runtime safety guardrails, which intercept hazardous actions during task execution, offer a promising solution due to their flexibility. However, existing defenses often rely on static rule filters or prompt-level control, which struggle to address implicit risks arising in dynamic, temporally dependent, and context-rich environments. To address this, we propose RoboSafe, a hybrid reasoning runtime safeguard for embodied agents through executable predicate-based safety logic. RoboSafe integrates two complementary reasoning processes on a Hybrid Long-Short Safety Memory. We first propose a Backward Reflective Reasoning module that continuously revisits recent trajectories in short-term memory to infer temporal safety predicates and proactively triggers replanning when violations are detected. We then propose a Forward Predictive Reasoning module that anticipates upcoming risks by generating context-aware safety predicates from the long-term safety memory and the agent's multimodal observations. Together, these components form an adaptive, verifiable safety logic that is both interpretable and executable as code. Extensive experiments across multiple agents demonstrate that RoboSafe substantially reduces hazardous actions (-36.8% risk occurrence) compared with leading baselines, while maintaining near-original task performance. Real-world evaluations on physical robotic arms further confirm its practicality. Code will be released upon acceptance.",
    "title_zh": "RoboSafe：通过可执行的安全逻辑保护具身智能体",
    "abstract_zh": "由视觉-语言模型（VLMs）驱动的具身智能体在执行复杂现实任务方面的能力日益增强，但仍容易受到危险指令的影响，可能引发不安全行为。运行时安全防护机制通过在任务执行过程中拦截危险动作，提供了一种灵活且有前景的解决方案。然而，现有的防御方法通常依赖于静态规则过滤或提示层面的控制，难以应对动态、时间依赖且上下文丰富的环境中产生的隐性风险。为此，我们提出 RoboSafe——一种基于可执行谓词的安全逻辑的混合推理运行时防护系统，用于具身智能体。RoboSafe 在“混合长短时安全记忆”框架上整合了两种互补的推理过程：首先，我们设计了**反向反思推理模块**，持续回顾短期记忆中的近期轨迹，推断出时间相关的安全谓词，并在检测到违规时主动触发重规划；其次，我们提出了**前向预测推理模块**，通过从长期安全记忆和智能体的多模态观测中生成情境感知的安全谓词，提前预判潜在风险。这两个组件共同构成一种自适应、可验证的安全逻辑，兼具可解释性与代码可执行性。在多个智能体上的大量实验表明，与现有领先基线相比，RoboSafe 显著降低了危险行为的发生率（风险降低36.8%），同时保持了接近原始任务性能的表现。在物理机器人手臂上的真实世界评估进一步验证了其实际应用价值。代码将在论文被接受后公开发布。"
  },
  {
    "date": "2025-12-24",
    "title": "AutoBaxBuilder: Bootstrapping Code Security Benchmarking",
    "authors": "Tobias von Arx, Niels Mündler, Mark Vero, Maximilian Baader, Martin Vechev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21132v1",
    "source": "arXiv",
    "abstract": "As LLMs see wide adoption in software engineering, the reliable assessment of the correctness and security of LLM-generated code is crucial. Notably, prior work has demonstrated that security is often overlooked, exposing that LLMs are prone to generating code with security vulnerabilities. These insights were enabled by specialized benchmarks, crafted through significant manual effort by security experts. However, relying on manually-crafted benchmarks is insufficient in the long term, because benchmarks (i) naturally end up contaminating training data, (ii) must extend to new tasks to provide a more complete picture, and (iii) must increase in difficulty to challenge more capable LLMs. In this work, we address these challenges and present AutoBaxBuilder, a framework that generates tasks and tests for code security benchmarking from scratch. We introduce a robust pipeline with fine-grained plausibility checks, leveraging the code understanding capabilities of LLMs to construct functionality tests and end-to-end security-probing exploits. To confirm the quality of the generated benchmark, we conduct both a qualitative analysis and perform quantitative experiments, comparing it against tasks constructed by human experts. We use AutoBaxBuilder to construct entirely new tasks and release them to the public as AutoBaxBench, together with a thorough evaluation of the security capabilities of LLMs on these tasks. We find that a new task can be generated in under 2 hours, costing less than USD 10.",
    "title_zh": "AutoBaxBuilder：代码安全基准测试的自举方法",
    "abstract_zh": "随着大型语言模型（LLMs）在软件工程领域的广泛应用，对 LLM 生成代码的正确性与安全性进行可靠评估变得至关重要。值得注意的是，已有研究揭示，安全问题常常被忽视，表明 LLM 容易生成存在安全漏洞的代码。这些发现得益于由安全专家通过大量人工努力精心设计的专用基准测试。然而，长期依赖人工构建的基准测试存在局限性：（i）基准测试不可避免地会污染训练数据，（ii）必须不断扩展以覆盖新任务，从而提供更全面的评估视角，（iii）必须不断提升难度，以挑战日益强大的 LLMs。针对上述挑战，本文提出 AutoBaxBuilder——一个从零开始自动生成代码安全基准测试任务与测试用例的框架。我们设计了一个鲁棒的流水线，包含细粒度的真实性验证机制，利用 LLM 的代码理解能力来构建功能测试和端到端的安全探测攻击。为验证生成基准的质量，我们进行了定性分析，并开展了定量实验，将其与人类专家构建的任务进行对比。我们使用 AutoBaxBuilder 构建了全新的任务集，并将其公开发布为 AutoBaxBench，同时对 LLM 在这些任务上的安全能力进行了全面评估。实验结果表明，单个新任务的生成可在两小时内完成，成本低于 10 美元。"
  },
  {
    "date": "2025-12-24",
    "title": "Beyond Context: Large Language Models Failure to Grasp Users Intent",
    "authors": "Ahmed M. Hussain, Salahuddin Salahuddin, Panos Papadimitratos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21110v1",
    "source": "arXiv",
    "abstract": "Current Large Language Models (LLMs) safety approaches focus on explicitly harmful content while overlooking a critical vulnerability: the inability to understand context and recognize user intent. This creates exploitable vulnerabilities that malicious users can systematically leverage to circumvent safety mechanisms. We empirically evaluate multiple state-of-the-art LLMs, including ChatGPT, Claude, Gemini, and DeepSeek. Our analysis demonstrates the circumvention of reliable safety mechanisms through emotional framing, progressive revelation, and academic justification techniques. Notably, reasoning-enabled configurations amplified rather than mitigated the effectiveness of exploitation, increasing factual precision while failing to interrogate the underlying intent. The exception was Claude Opus 4.1, which prioritized intent detection over information provision in some use cases. This pattern reveals that current architectural designs create systematic vulnerabilities. These limitations require paradigmatic shifts toward contextual understanding and intent recognition as core safety capabilities rather than post-hoc protective mechanisms.",
    "title_zh": "超越上下文：大型语言模型无法理解用户意图",
    "abstract_zh": "当前大型语言模型（LLMs）的安全策略主要聚焦于显性有害内容的过滤，却忽视了一个关键漏洞：模型无法理解上下文，难以识别用户的真实意图。这一缺陷使得恶意用户能够系统性地利用，绕过安全机制。我们对多个最先进的LLM进行了实证评估，包括ChatGPT、Claude、Gemini和DeepSeek。分析表明，攻击者可通过情感化表述、渐进式披露以及学术化论证等手段，成功规避可靠的安全防护。值得注意的是，具备推理能力的配置不仅未降低攻击效果，反而增强了攻击的精准度——在提升事实准确性的同时，未能有效质疑其背后的潜在意图。唯一例外是Claude Opus 4.1，在某些场景下更注重意图识别而非信息输出。这一现象揭示出，当前架构设计存在系统性漏洞。因此，必须实现范式转变，将上下文理解与意图识别作为核心安全能力，而非事后附加的保护措施。"
  },
  {
    "date": "2025-12-24",
    "title": "Parallel Token Prediction for Language Models",
    "authors": "Felix Draxler, Justus Will, Farrin Marouf Sofian, Theofanis Karaletsos, Sameer Singh, Stephan Mandt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21323v1",
    "source": "arXiv",
    "abstract": "We propose Parallel Token Prediction (PTP), a universal framework for parallel sequence generation in language models. PTP jointly predicts multiple dependent tokens in a single transformer call by incorporating the sampling procedure into the model. This reduces the latency bottleneck of autoregressive decoding, and avoids the restrictive independence assumptions common in existing multi-token prediction methods. We prove that PTP can represent arbitrary autoregressive sequence distributions. PTP is trained either by distilling an existing model or through inverse autoregressive training without a teacher. Experimentally, we achieve state-of-the-art speculative decoding performance on Vicuna-7B by accepting over four tokens per step on Spec-Bench. The universality of our framework indicates that parallel generation of long sequences is feasible without loss of modeling power.",
    "title_zh": "语言模型的并行标记预测",
    "abstract_zh": "我们提出了并行标记预测（Parallel Token Prediction, PTP），这是一种适用于语言模型中并行序列生成的通用框架。PTP通过将采样过程融入模型，在单次Transformer调用中联合预测多个相互依赖的标记，从而缓解自回归解码带来的延迟瓶颈，并避免了现有多标记预测方法中常见的严格独立性假设。我们证明了PTP能够表示任意的自回归序列分布。PTP可通过蒸馏已有模型进行训练，也可通过无需教师模型的逆自回归训练方式进行训练。实验结果表明，在Spec-Bench测试中，我们基于Vicuna-7B实现了业界领先的推测性解码性能，每步可接受超过四个标记。我们框架的普适性表明，无需牺牲建模能力即可实现长序列的并行生成。"
  },
  {
    "date": "2025-12-24",
    "title": "Verification of E-Voting Algorithms in Dafny",
    "authors": "Robert Büttner, Fabian Franz Dießl, Patrick Janoschek, Ivana Kostadinovic, Henrik Oback, Kilian Voß, Franziska Alber, Roland Herrmann, Sibylle Möhle, Philipp Rümmer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21084v1",
    "source": "arXiv",
    "abstract": "Electronic voting procedures are implementations of electoral systems, making it possible to conduct polls or elections with the help of computers. This paper reports on the development of an open-source library of electronic voting procedures, which currently covers Score Voting, Instant-Runoff Voting, Borda Count, and Single Transferable Vote. The four procedures, of which two are discussed in detail, have been implemented in Dafny, formally verifying the consistency with functional specifications and key correctness properties. Using code extraction from the Dafny implementation, the library has been used to set up a voting web service.",
    "title_zh": "Dafny中电子投票算法的验证",
    "abstract_zh": "电子投票程序是选举制度的实现方式，使得在计算机的帮助下进行民意调查或选举成为可能。本文报告了一种开源电子投票程序库的开发进展，该库目前涵盖了评分投票、即时决选投票、波达计数和单记可转移投票四种方法。其中两种方法被详细讨论，它们已在Dafny语言中实现，并通过形式化验证确保了与功能规范及关键正确性属性的一致性。利用从Dafny实现中提取的代码，该库已被用于搭建一个投票网络服务系统。"
  },
  {
    "date": "2025-12-24",
    "title": "Declarative distributed broadcast using three-valued modal logic and semitopologies",
    "authors": "Murdoch J. Gabbay",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21137v1",
    "source": "arXiv",
    "abstract": "We demonstrate how to formally specify distributed algorithms as declarative axiomatic theories in a modal logic. We exhibit the method on a simple voting protocol, a simple broadcast protocol, and a simple agreement protocol. The methods scale well and have been used to find errors in a proposed industrial protocol. The key novelty is to use modal logic to capture a declarative, high-level representation of essential system properties -- the logical essence of the algorithm -- while abstracting away from transitions of an abstract machine that implements it. It is like the difference between specifying code in a functional or logic programming language, versus specifying code in an imperative one. A logical axiomatisation in the style we propose provides a precise, compact, human-readable specification that abstractly captures essential system properties, while eliding low-level implementation details; it is more precise than a natural language description, yet more abstract than source code or a logical specification thereof. This creates new opportunities for reasoning about correctness, resilience, and failure, and could serve as a foundation for human- and machine verification efforts, design improvements, and even alternative protocol implementations.",
    "title_zh": "使用三值模态逻辑和半拓扑的声明式分布式广播",
    "abstract_zh": "我们展示了如何在模态逻辑中将分布式算法形式化地指定为声明式公理理论。我们以一个简单的投票协议、一个简单的广播协议和一个简单的共识协议为例，演示了该方法。该方法具有良好的可扩展性，并已被用于发现一个提议的工业协议中的错误。其关键创新之处在于，利用模态逻辑来捕捉系统核心属性的声明式、高层次表示——即算法的逻辑本质——同时抽象掉实现它的抽象机器的状态转换细节。这类似于在函数式或逻辑编程语言中描述代码，与在命令式语言中描述代码之间的区别。我们所提出的逻辑公理化方法提供了一种精确、紧凑且易于理解的规格说明，能够抽象地刻画系统的核心属性，同时忽略低层次的实现细节；它比自然语言描述更精确，但又比源代码或其逻辑规格更为抽象。这种方法为正确性、鲁棒性和容错性的推理开辟了新的可能性，可作为人类与机器验证工作、设计改进乃至替代协议实现的基础。"
  },
  {
    "date": "2025-12-24",
    "title": "Assessing the Software Security Comprehension of Large Language Models",
    "authors": "Mohammed Latif Siddiq, Natalie Sekerak, Antonio Karam, Maria Leal, Arvin Islam-Gomes, Joanna C. S. Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21238v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly used in software development, but their level of software security expertise remains unclear. This work systematically evaluates the security comprehension of five leading LLMs: GPT-4o-Mini, GPT-5-Mini, Gemini-2.5-Flash, Llama-3.1, and Qwen-2.5, using Blooms Taxonomy as a framework. We assess six cognitive dimensions: remembering, understanding, applying, analyzing, evaluating, and creating. Our methodology integrates diverse datasets, including curated multiple-choice questions, vulnerable code snippets (SALLM), course assessments from an Introduction to Software Security course, real-world case studies (XBOW), and project-based creation tasks from a Secure Software Engineering course. Results show that while LLMs perform well on lower-level cognitive tasks such as recalling facts and identifying known vulnerabilities, their performance degrades significantly on higher-order tasks that require reasoning, architectural evaluation, and secure system creation. Beyond reporting aggregate accuracy, we introduce a software security knowledge boundary that identifies the highest cognitive level at which a model consistently maintains reliable performance. In addition, we identify 51 recurring misconception patterns exhibited by LLMs across Blooms levels.",
    "title_zh": "评估大型语言模型的软件安全理解能力",
    "abstract_zh": "大型语言模型（LLMs）在软件开发中的应用日益广泛，但其在软件安全领域的专业能力水平仍不明确。本研究以布卢姆认知分类学（Bloom's Taxonomy）为框架，系统评估了五款主流大模型——GPT-4o-Mini、GPT-5-Mini、Gemini-2.5-Flash、Llama-3.1 和 Qwen-2.5——在软件安全理解方面的表现。我们从六个认知维度进行评估：记忆、理解、应用、分析、评价和创造。研究方法融合了多种数据集，包括精心筛选的多选题、存在漏洞的代码片段（SALLM）、《软件安全导论》课程的考核试题、真实世界案例研究（XBOW），以及《安全软件工程》课程中的项目式创作任务。\n\n结果显示，尽管大模型在较低层次的认知任务中表现良好，如事实回忆和已知漏洞识别，但在需要推理、架构评估和安全系统设计等高阶任务上，其表现显著下降。除了报告整体准确率外，本文还提出了“软件安全知识边界”的概念，用以识别模型在各认知层级中持续保持可靠性能的最高水平。此外，我们还识别出大模型在不同布卢姆层级中普遍存在的51种重复性误解模式。"
  },
  {
    "date": "2025-12-24",
    "title": "Casting a SPELL: Sentence Pairing Exploration for LLM Limitation-breaking",
    "authors": "Yifan Huang, Xiaojun Jia, Wenbo Guo, Yuqiang Sun, Yihao Huang, Chong Wang, Yang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21236v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have revolutionized software development through AI-assisted coding tools, enabling developers with limited programming expertise to create sophisticated applications. However, this accessibility extends to malicious actors who may exploit these powerful tools to generate harmful software. Existing jailbreaking research primarily focuses on general attack scenarios against LLMs, with limited exploration of malicious code generation as a jailbreak target. To address this gap, we propose SPELL, a comprehensive testing framework specifically designed to evaluate the weakness of security alignment in malicious code generation. Our framework employs a time-division selection strategy that systematically constructs jailbreaking prompts by intelligently combining sentences from a prior knowledge dataset, balancing exploration of novel attack patterns with exploitation of successful techniques. Extensive evaluation across three advanced code models (GPT-4.1, Claude-3.5, and Qwen2.5-Coder) demonstrates SPELL's effectiveness, achieving attack success rates of 83.75%, 19.38%, and 68.12% respectively across eight malicious code categories. The generated prompts successfully produce malicious code in real-world AI development tools such as Cursor, with outputs confirmed as malicious by state-of-the-art detection systems at rates exceeding 73%. These findings reveal significant security gaps in current LLM implementations and provide valuable insights for improving AI safety alignment in code generation applications.",
    "title_zh": "施法：突破大语言模型局限的句子配对探索",
    "abstract_zh": "大型语言模型（LLMs）通过AI辅助编程工具彻底改变了软件开发，使编程经验有限的开发者也能构建复杂的应用程序。然而，这种易用性也为恶意行为者提供了可乘之机，他们可能利用这些强大工具生成有害软件。现有的越狱研究主要集中在针对LLMs的一般性攻击场景，对恶意代码生成作为越狱目标的探索仍十分有限。为填补这一空白，我们提出了SPELL——一个专门用于评估恶意代码生成中安全对齐脆弱性的综合性测试框架。该框架采用时间分段选择策略，通过智能地从先验知识数据集中组合句子，系统化地构建越狱提示，从而在探索新型攻击模式与复用已验证有效技术之间取得平衡。在三个先进的代码生成模型（GPT-4.1、Claude-3.5 和 Qwen2.5-Coder）上的广泛评估表明，SPELL表现出显著效果，分别在八个恶意代码类别中实现了83.75%、19.38%和68.12%的攻击成功率。所生成的提示在真实AI开发工具（如Cursor）中成功生成了恶意代码，且其输出被最先进的检测系统识别为恶意代码的比例超过73%。这些发现揭示了当前LLM实现中存在的重大安全漏洞，并为提升代码生成类AI应用中的安全对齐能力提供了宝贵洞见。"
  },
  {
    "date": "2025-12-24",
    "title": "When LLMs fall short in Deductive Coding: Model Comparison and Human AI Collaboration Workflow Design",
    "authors": "Zijian Li, Luzhen Tang, Mengyu Xia, Xinyu Li, Naping Chen, Dragan Gašević, Yizhou Fan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21041v1",
    "source": "arXiv",
    "abstract": "With generative artificial intelligence driving the growth of dialogic data in education, automated coding is a promising direction for learning analytics to improve efficiency. This surge highlights the need to understand the nuances of student-AI interactions, especially those rare yet crucial. However, automated coding may struggle to capture these rare codes due to imbalanced data, while human coding remains time-consuming and labour-intensive. The current study examined the potential of large language models (LLMs) to approximate or replace humans in deductive, theory-driven coding, while also exploring how human-AI collaboration might support such coding tasks at scale. We compared the coding performance of small transformer classifiers (e.g., BERT) and LLMs in two datasets, with particular attention to imbalanced head-tail distributions in dialogue codes. Our results showed that LLMs did not outperform BERT-based models and exhibited systematic errors and biases in deductive coding tasks. We designed and evaluated a human-AI collaborative workflow that improved coding efficiency while maintaining coding reliability. Our findings reveal both the limitations of LLMs -- especially their difficulties with semantic similarity and theoretical interpretations and the indispensable role of human judgment -- while demonstrating the practical promise of human-AI collaborative workflows for coding.",
    "title_zh": "当大语言模型在归纳编码中表现不足时：模型比较与人机协作工作流程设计",
    "abstract_zh": "随着生成式人工智能推动教育领域对话数据的快速增长，自动化编码成为提升学习分析效率的有前景方向。这一趋势凸显了理解学生与AI互动中细微差异的重要性，尤其是那些罕见但至关重要的互动模式。然而，由于数据分布不平衡，自动化编码难以捕捉这些稀有类别；而人工编码则耗时且劳动强度大。本研究探讨了大型语言模型（LLMs）在演绎性、理论驱动型编码任务中替代或逼近人类编码的潜力，同时探索了人机协作模式在大规模编码任务中的应用可能。我们比较了小型Transformer分类器（如BERT）与LLMs在两个数据集上的编码表现，特别关注对话编码中常见的“长尾”分布问题。研究结果表明，LLMs并未优于基于BERT的模型，并在演绎性编码任务中表现出系统性错误和偏见。为此，我们设计并评估了一种人机协同工作流程，该流程在保持编码可靠性的同时显著提升了编码效率。研究发现揭示了LLMs的局限性——尤其是在语义相似性判断和理论阐释方面存在困难——同时也凸显了人类判断不可替代的作用。与此同时，本研究也展示了人机协同工作流程在实际应用中的巨大潜力。"
  },
  {
    "date": "2025-12-24",
    "title": "Artificial or Just Artful? Do LLMs Bend the Rules in Programming?",
    "authors": "Oussama Ben Sghaier, Kevin Delcourt, Houari Sahraoui",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21028v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are widely used for automated code generation, yet their apparent successes often mask a tension between pretraining objectives and alignment choices. While pretraining encourages models to exploit all available signals to maximize success, alignment, whether through fine-tuning or prompting, may restrict their use. This conflict is especially salient in agentic AI settings, for instance when an agent has access to unit tests that, although intended for validation, act as strong contextual signals that can be leveraged regardless of explicit prohibitions. In this paper, we investigate how LLMs adapt their code generation strategies when exposed to test cases under different prompting conditions. Using the BigCodeBench (Hard) dataset, we design five prompting conditions that manipulate test visibility and impose explicit or implicit restrictions on their use. We evaluate five LLMs (four open-source and one closed-source) across correctness, code similarity, program size, and code churn, and analyze cross-model consistency to identify recurring adaptation strategies. Our results show that test visibility dramatically alters performance, correctness nearly doubles for some models, while explicit restrictions or partial exposure only partially mitigate this effect. Beyond raw performance, we identify four recurring adaptation strategies, with test-driven refinement emerging as the most frequent. These results highlight how LLMs adapt their behavior when exposed to contextual signals that conflict with explicit instructions, providing useful insight into how models reconcile pretraining objectives with alignment constraints.",
    "title_zh": "人工还是巧妙？大语言模型在编程中是否突破了规则？",
    "abstract_zh": "大型语言模型（LLMs）在自动化代码生成中得到了广泛应用，但其表面的成功往往掩盖了预训练目标与对齐策略之间的内在矛盾。尽管预训练阶段鼓励模型充分利用所有可用信号以最大化成功率，但对齐过程（无论是通过微调还是提示工程）却可能限制这些信号的使用。这种冲突在代理型人工智能（agentic AI）场景中尤为显著——例如，当一个智能体能够访问单元测试时，尽管这些测试本意是用于验证，却会成为强大的上下文线索，即使存在明确禁止，模型仍可能加以利用。\n\n本文研究了在不同提示条件下，LLMs面对测试用例时如何调整其代码生成策略。我们基于BigCodeBench（Hard）数据集设计了五种提示条件，通过操控测试可见性，并施加显式或隐式的使用限制，系统地考察模型行为。我们在五个LLM（四个开源模型和一个闭源模型）上评估了代码正确性、代码相似度、程序规模以及代码变更量（code churn），并分析跨模型的一致性，以识别出反复出现的适应策略。\n\n结果表明，测试可见性对性能具有决定性影响：某些模型的代码正确率几乎翻倍；而显式限制或部分暴露测试信息仅能部分缓解这一效应。除了性能指标外，我们识别出四种常见的适应策略，其中“基于测试驱动的迭代优化”（test-driven refinement）最为普遍。\n\n这些发现揭示了LLMs在面对与明确指令相冲突的上下文信号时的行为适应机制，为理解模型如何在预训练目标与对齐约束之间寻求平衡提供了重要洞见。"
  },
  {
    "date": "2025-12-24",
    "title": "Optimizing Decoding Paths in Masked Diffusion Models by Quantifying Uncertainty",
    "authors": "Ziyu Chen, Xinbei Jiang, Peng Sun, Tao Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21336v1",
    "source": "arXiv",
    "abstract": "Masked Diffusion Models (MDMs) offer flexible, non-autoregressive generation, but this freedom introduces a challenge: final output quality is highly sensitive to the decoding order. We are the first to formalize this issue, attributing the variability in output quality to the cumulative predictive uncertainty along a generative path. To quantify this uncertainty, we introduce Denoising Entropy, a computable metric that serves as an internal signal for evaluating generative process. Leveraging this metric, we propose two algorithms designed to optimize the decoding path: a post-hoc selection method and a real-time guidance strategy. Experiments demonstrate that our entropy-guided methods significantly improve generation quality, consistently boosting accuracy on challenging reasoning, planning, and code benchmarks. Our work establishes Denoising Entropy as a principled tool for understanding and controlling generation, effectively turning the uncertainty in MDMs from a liability into a key advantage for discovering high-quality solutions.",
    "title_zh": "通过量化不确定性优化掩码扩散模型中的解码路径",
    "abstract_zh": "掩码扩散模型（Masked Diffusion Models, MDMs）提供了灵活的非自回归生成方式，但这种自由也带来了挑战：最终输出的质量高度依赖于解码顺序。我们首次正式提出了这一问题，并将输出质量的波动归因于生成路径上累积的预测不确定性。为量化这种不确定性，我们引入了“去噪熵”（Denoising Entropy）这一可计算的度量指标，作为评估生成过程的内部信号。基于该指标，我们提出了两种优化解码路径的算法：一种是事后选择方法，另一种是实时引导策略。实验表明，我们的熵引导方法显著提升了生成质量，在具有挑战性的推理、规划和代码生成基准测试中均持续提高了准确率。本研究确立了“去噪熵”作为一种原理性工具，用于理解与控制生成过程，成功地将MDMs中的不确定性从劣势转化为发现高质量解的关键优势。"
  },
  {
    "date": "2025-12-24",
    "title": "Policy-Conditioned Policies for Multi-Agent Task Solving",
    "authors": "Yue Lin, Shuhui Zhu, Wenhao Li, Ang Li, Dan Qiao, Pascal Poupart, Hongyuan Zha, Baoxiang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21024v1",
    "source": "arXiv",
    "abstract": "In multi-agent tasks, the central challenge lies in the dynamic adaptation of strategies. However, directly conditioning on opponents' strategies is intractable in the prevalent deep reinforcement learning paradigm due to a fundamental ``representational bottleneck'': neural policies are opaque, high-dimensional parameter vectors that are incomprehensible to other agents. In this work, we propose a paradigm shift that bridges this gap by representing policies as human-interpretable source code and utilizing Large Language Models (LLMs) as approximate interpreters. This programmatic representation allows us to operationalize the game-theoretic concept of \\textit{Program Equilibrium}. We reformulate the learning problem by utilizing LLMs to perform optimization directly in the space of programmatic policies. The LLM functions as a point-wise best-response operator that iteratively synthesizes and refines the ego agent's policy code to respond to the opponent's strategy. We formalize this process as \\textit{Programmatic Iterated Best Response (PIBR)}, an algorithm where the policy code is optimized by textual gradients, using structured feedback derived from game utility and runtime unit tests. We demonstrate that this approach effectively solves several standard coordination matrix games and a cooperative Level-Based Foraging environment.",
    "title_zh": "多智能体任务求解的策略条件策略",
    "abstract_zh": "在多智能体任务中，核心挑战在于策略的动态适应性。然而，在主流的深度强化学习范式下，直接根据对手策略进行条件化是不可行的，其根本原因在于一个“表示瓶颈”：神经网络策略是难以理解的高维参数向量，其他智能体无法解读。本文提出一种范式转变，通过将策略表示为人类可读的源代码，并利用大型语言模型（LLM）作为近似解释器，从而弥合这一鸿沟。这种程序化表示使我们能够实现博弈论中的“程序均衡”概念。我们通过使用LLM在程序化策略空间中直接执行优化，重新构建了学习问题。LLM充当逐点最优响应算子，迭代地合成并改进自我智能体的策略代码，以应对对手的策略。我们将这一过程形式化为**程序化迭代最优响应（Programmatic Iterated Best Response, PIBR）**，该算法通过游戏效用和运行时单元测试所生成的结构化反馈，利用文本梯度对策略代码进行优化。实验表明，该方法能够有效解决多个标准协调矩阵博弈以及一个合作型分层觅食环境。"
  },
  {
    "date": "2025-12-24",
    "title": "RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks",
    "authors": "Ningyuan Liu, Jing Yang, Kaitong Cai, Keze Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20920v1",
    "source": "arXiv",
    "abstract": "Full parameter fine tuning is a key technique for adapting large language models (LLMs) to downstream tasks, but it incurs substantial memory overhead due to the need to cache extensive intermediate activations for backpropagation. This bottleneck makes full fine tuning of contemporary large scale LLMs challenging in practice. Existing distributed training frameworks such as DeepSpeed alleviate this issue using techniques like ZeRO and FSDP, which rely on multi GPU memory or CPU offloading, but often require additional hardware resources and reduce training speed. We introduce RevFFN, a memory efficient fine tuning paradigm for mixture of experts (MoE) LLMs. RevFFN employs carefully designed reversible Transformer blocks that allow reconstruction of layer input activations from outputs during backpropagation, eliminating the need to store most intermediate activations in memory. While preserving the expressive capacity of MoE architectures, this approach significantly reduces peak memory consumption for full parameter fine tuning. As a result, RevFFN enables efficient full fine tuning on a single consumer grade or server grade GPU.",
    "title_zh": "RevFFN：基于可逆块的高效内存专家混合大型语言模型全参数微调",
    "abstract_zh": "全参数微调是将大型语言模型（LLM）适配到下游任务的关键技术，但由于需要缓存大量中间激活值以进行反向传播，因此带来了显著的内存开销。这一瓶颈使得当前大规模LLM的全参数微调在实际应用中面临挑战。现有的分布式训练框架（如DeepSpeed）通过ZeRO和FSDP等技术缓解该问题，这些方法依赖多GPU内存或CPU卸载，但通常需要额外的硬件资源，并降低训练速度。我们提出RevFFN，一种针对混合专家（MoE）LLM的高效内存微调范式。RevFFN采用精心设计的可逆Transformer模块，在反向传播过程中能够从输出重建层输入激活值，从而无需在内存中存储大部分中间激活值。该方法在保持MoE架构表达能力的同时，显著降低了全参数微调的峰值内存消耗。因此，RevFFN实现了仅使用单张消费级或服务器级GPU即可高效完成全参数微调。"
  },
  {
    "date": "2025-12-24",
    "title": "A Plan Reuse Mechanism for LLM-Driven Agent",
    "authors": "Guopeng Li, Ruiqi Wu, Haisheng Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21309v1",
    "source": "arXiv",
    "abstract": "Integrating large language models (LLMs) into personal assistants, like Xiao Ai and Blue Heart V, effectively enhances their ability to interact with humans, solve complex tasks, and manage IoT devices. Such assistants are also termed LLM-driven agents. Upon receiving user requests, the LLM-driven agent generates plans using an LLM, executes these plans through various tools, and then returns the response to the user. During this process, the latency for generating a plan with an LLM can reach tens of seconds, significantly degrading user experience. Real-world dataset analysis shows that about 30% of the requests received by LLM-driven agents are identical or similar, which allows the reuse of previously generated plans to reduce latency. However, it is difficult to accurately define the similarity between the request texts received by the LLM-driven agent through directly evaluating the original request texts. Moreover, the diverse expressions of natural language and the unstructured format of plan texts make implementing plan reuse challenging. To address these issues, we present and implement a plan reuse mechanism for LLM-driven agents called AgentReuse. AgentReuse leverages the similarities and differences among requests' semantics and uses intent classification to evaluate the similarities between requests and enable the reuse of plans. Experimental results based on a real-world dataset demonstrate that AgentReuse achieves a 93% effective plan reuse rate, an F1 score of 0.9718, and an accuracy of 0.9459 in evaluating request similarities, reducing latency by 93.12% compared with baselines without using the reuse mechanism.",
    "title_zh": "一种用于大语言模型驱动智能体的计划复用机制",
    "abstract_zh": "将大型语言模型（LLMs）集成到个人助手（如小爱同学和蓝心V）中，能够有效提升其与人类交互、解决复杂任务以及管理物联网设备的能力。这类助手也被称为基于LLM的智能体（LLM-driven agents）。当接收到用户请求时，LLM驱动的智能体利用大语言模型生成执行计划，通过多种工具执行该计划，并最终将结果返回给用户。然而，在此过程中，仅生成计划这一环节所消耗的延迟可能达到数十秒，显著影响用户体验。真实世界数据集的分析表明，LLM驱动智能体接收到的约30%的请求是相同或相似的，这为复用先前生成的计划以降低延迟提供了可能。然而，直接通过原始请求文本评估请求之间的相似性存在困难，因为自然语言表达形式多样，且计划文本本身结构不固定，使得计划复用的实现极具挑战性。\n\n针对上述问题，我们提出并实现了一种面向LLM驱动智能体的计划复用机制——AgentReuse。AgentReuse通过挖掘请求语义间的相似性与差异性，并结合意图分类技术，对请求之间的相似性进行评估，从而实现计划的有效复用。基于真实世界数据集的实验结果表明，AgentReuse在请求相似性判断方面达到了93%的有效计划复用率，F1分数为0.9718，准确率为0.9459，相较于未采用复用机制的基线方法，延迟降低了93.12%。"
  },
  {
    "date": "2025-12-24",
    "title": "SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance",
    "authors": "Divij Dudeja, Mayukha Pal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21280v1",
    "source": "arXiv",
    "abstract": "The user of Engineering Manuals (EM) finds it difficult to read EM s because they are long, have a dense format which includes written documents, step by step procedures, and standard parameter lists for engineering equipment. Off the shelf transformers, especially compact ones, treat this material as a flat stream of tokens. This approach leads to confident but incorrect numeric answers and forces the models to memorize separate facts inefficiently. SMART (Structured Memory and Reasoning Transformer) offers a different and practical solution to the above problem. SMART structures its processing by using a hierarchical approach, and is based upon three main job categories (1) A syntax-aware Fact Extractor (Grammarian) Tree LSTM which extracts facts as subject relation object relations from EM sentences (2) A compact indexed memory MANN (Memory Augmented Neural Network) that indexes these Rational Subject Relation Objects as 384 dimensional vectors that are associated with the source of the information, and (3) A 6 layer Transformer that learns to fuse the previously retrieved facts into its generated response. The entire SMART model utilizes 45.51M parameters, which is 64% less than GPT-2 (124M) and 69% less than BERT (133M), and it achieves a 21.3% higher accuracy than GPT-2, indicating that SMART fits the data better with the least amount of processing requirements. SMART employs dual modes of inference an indexed fast path for known documents (sub-second answer times) and an indexed dynamic path assisted by RAGs for new uploads (FAISS Top 20 results with memory severed at 64 slots). In real world deployment, this framework leads to more well supported results with reduced hallucinations than comparable small transformer models.",
    "title_zh": "SMART SLM：结构化记忆与推理Transformer，一种用于精准文档辅助的小型语言模型",
    "abstract_zh": "工程手册（EM）的使用者发现阅读这些手册非常困难，因为它们内容冗长、格式密集，包含书面文档、分步操作流程以及工程设备的标准参数列表。市面上现有的变压器模型，尤其是紧凑型模型，通常将这类材料视为一连串扁平的词元流，这种处理方式导致模型生成自信但错误的数值答案，并迫使模型以低效的方式逐一记忆独立的事实。SMART（结构化记忆与推理Transformer）为上述问题提供了一种新颖且实用的解决方案。SMART通过采用分层处理机制，基于三大核心任务构建：（1）一个语法感知的事实提取器（语法学家）树LSTM，能够从EM语句中提取出“主语-关系-对象”形式的事实；（2）一个紧凑的索引式记忆模块MANN（记忆增强神经网络），将这些“理性主语-关系-对象”以384维向量的形式进行索引，并关联到信息来源；（3）一个六层Transformer，负责学习如何将先前检索到的事实融合进其生成的回答中。\n\n整个SMART模型仅使用4550万参数，比GPT-2（1.24亿参数）少64%，比BERT（1.33亿参数）少69%，却实现了比GPT-2高出21.3%的准确率，表明SMART在最小化计算开销的同时，能更有效地拟合数据。SMART采用双模式推理机制：对于已知文档，采用索引化的快速路径，实现亚秒级响应；对于新上传的内容，则借助RAGs（检索增强生成）技术，通过FAISS检索Top 20结果，并将记忆容量限制在64个槽位，实现动态索引路径。在真实场景部署中，该框架相比同类小型Transformer模型，能够生成更具依据性的结果，显著减少幻觉现象。"
  },
  {
    "date": "2025-12-24",
    "title": "CoTDeceptor:Adversarial Code Obfuscation Against CoT-Enhanced LLM Code Agents",
    "authors": "Haoyang Li, Mingjin Li, Jinxin Zuo, Siqi Li, Xiao Li, Hao Wu, Yueming Lu, Xiaochuan He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21250v1",
    "source": "arXiv",
    "abstract": "LLM-based code agents(e.g., ChatGPT Codex) are increasingly deployed as detector for code review and security auditing tasks. Although CoT-enhanced LLM vulnerability detectors are believed to provide improved robustness against obfuscated malicious code, we find that their reasoning chains and semantic abstraction processes exhibit exploitable systematic weaknesses.This allows attackers to covertly embed malicious logic, bypass code review, and propagate backdoored components throughout real-world software supply chains.To investigate this issue, we present CoTDeceptor, the first adversarial code obfuscation framework targeting CoT-enhanced LLM detectors. CoTDeceptor autonomously constructs evolving, hard-to-reverse multi-stage obfuscation strategy chains that effectively disrupt CoT-driven detection logic.We obtained malicious code provided by security enterprise, experimental results demonstrate that CoTDeceptor achieves stable and transferable evasion performance against state-of-the-art LLMs and vulnerability detection agents. CoTDeceptor bypasses 14 out of 15 vulnerability categories, compared to only 2 bypassed by prior methods. Our findings highlight potential risks in real-world software supply chains and underscore the need for more robust and interpretable LLM-powered security analysis systems.",
    "title_zh": "CoTDeceptor：针对基于思维链增强的大型语言模型代码智能体的对抗性代码混淆方法",
    "abstract_zh": "基于大语言模型（LLM）的代码智能体（如 ChatGPT Codex）正越来越多地被用于代码审查与安全审计任务。尽管增强思维链（CoT）的大语言模型漏洞检测器被认为能提升对混淆恶意代码的鲁棒性，但我们发现其推理链条和语义抽象过程存在可被利用的系统性弱点。这使得攻击者能够隐蔽地嵌入恶意逻辑，绕过代码审查，并将带有后门的组件传播至真实世界的软件供应链中。\n\n为深入研究这一问题，我们提出了 CoTDeceptor——首个针对 CoT 增强型 LLM 检测器的对抗性代码混淆框架。CoTDeceptor 能自主构建动态演化、难以逆向的多阶段混淆策略链，有效干扰基于 CoT 的检测逻辑。我们获取了来自安全企业的恶意代码样本，实验结果表明，CoTDeceptor 在对抗当前最先进的 LLM 及漏洞检测智能体时，展现出稳定且具备良好迁移能力的逃逸性能。相比以往方法仅能绕过 2 类漏洞，CoTDeceptor 成功绕过了 14 种（共 15 类）漏洞类型。\n\n我们的研究揭示了现实软件供应链中潜在的重大安全风险，也凸显了亟需发展更稳健、更具可解释性的基于大语言模型的安全分析系统。"
  },
  {
    "date": "2025-12-24",
    "title": "Semantic Refinement with LLMs for Graph Representations",
    "authors": "Safal Thapaliya, Zehong Wang, Jiazheng Li, Ziming Li, Yanfang Ye, Chuxu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.21106v1",
    "source": "arXiv",
    "abstract": "Graph-structured data exhibit substantial heterogeneity in where their predictive signals originate: in some domains, node-level semantics dominate, while in others, structural patterns play a central role. This structure-semantics heterogeneity implies that no graph learning model with a fixed inductive bias can generalize optimally across diverse graph domains. However, most existing methods address this challenge from the model side by incrementally injecting new inductive biases, which remains fundamentally limited given the open-ended diversity of real-world graphs. In this work, we take a data-centric perspective and treat node semantics as a task-adaptive variable. We propose a Data-Adaptive Semantic Refinement framework DAS for graph representation learning, which couples a fixed graph neural network (GNN) and a large language model (LLM) in a closed feedback loop. The GNN provides implicit supervisory signals to guide the semantic refinement of LLM, and the refined semantics are fed back to update the same graph learner. We evaluate our approach on both text-rich and text-free graphs. Results show consistent improvements on structure-dominated graphs while remaining competitive on semantics-rich graphs, demonstrating the effectiveness of data-centric semantic adaptation under structure-semantics heterogeneity.",
    "title_zh": "基于大语言模型的图表示语义精炼",
    "abstract_zh": "图结构数据在预测信号的来源上表现出显著的异质性：在某些领域，节点级别的语义信息起主导作用，而在其他领域，结构模式则更为关键。这种结构与语义之间的异质性表明，任何具有固定归纳偏置的图学习模型都无法在多样化的图数据域中实现最优泛化。然而，目前大多数方法仍从模型角度出发，通过逐步引入新的归纳偏置来应对这一挑战，但鉴于现实世界图数据的开放性和多样性，这种方法本质上存在局限。在本工作中，我们采取以数据为中心的视角，将节点语义视为一种任务自适应的变量。为此，我们提出了一种数据自适应语义精炼框架 DAS（Data-Adaptive Semantic Refinement），该框架通过一个闭环反馈回路，将固定的图神经网络（GNN）与大型语言模型（LLM）相结合。其中，GNN 提供隐式的监督信号，引导 LLM 进行语义精炼；而经过优化的语义信息又被反馈回 GNN，用于更新同一图学习器。我们在富含文本和缺乏文本的图数据上对所提方法进行了评估。实验结果表明，在以结构为主导的图上，DAS 均实现了稳定提升；而在语义丰富的图上也保持了竞争力，充分验证了在结构-语义异质性背景下，以数据为中心的语义自适应策略的有效性。"
  },
  {
    "date": "2025-12-24",
    "title": "PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects",
    "authors": "Ahmed Aljohani, Hyunsook Do",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756976",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "提示债务：对大型语言模型项目中技术债务的全面研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models",
    "authors": "Hangzhan Jin, Mohammad Hamdaqa",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756954",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CCCI：基于上下文信息的代码补全方法在使用大语言模型进行复杂数据传输任务中的应用",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation",
    "authors": "Gábor Antal, Dénes Bán, Martin Isztin, Rudolf Ferenc, Péter Hegedus",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757075",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "利用GPT-4进行漏洞见证单元测试生成",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Attention-enhanced Gating for Mixture of Expert LLM",
    "authors": "Na Gao, Boqian Fu, Xiuheng Liao, Ziang Wu, Tao Liu, Chunhua Su",
    "publish": "2025 13th International Conference on Awareness Science and Technology (iCAST)",
    "url": "https://doi.org/10.1109/icast68191.2025.11300172",
    "source": "IEEE",
    "abstract": "Transformer-based MoE models have become mainstream in large language models (LLMs). The core design of the Transformer architecture is the attention mechanism that each input token will calculate the attention values with others. The Mixture of Experts (MoE)-based LLMs was proposed to replace the dense layer in the Transformer with a gate function and several sparsely activated small experts. This design saves the inference cost since only part of the experts are used. However, existing MoE works only use the data features as the input of the gate function; the importance information of attention value is ignored. In this paper, we propose an attention-enhanced mixture of experts (AMoE), a novel transformer-based MoE model. Specifically, we propose a new gate with an integrated attention mechanism, which improves the model’s performance. We conduct comprehensive experiments to support the effectiveness of our proposals.",
    "title_zh": "注意力增强的专家混合大型语言模型",
    "abstract_zh": "基于Transformer的混合专家（MoE）模型已成为大型语言模型（LLMs）的主流架构。Transformer架构的核心设计是注意力机制，其中每个输入标记都会与其他标记计算注意力值。基于MoE的LLM提出用门控函数和若干稀疏激活的小型专家来替代Transformer中的密集层，从而降低推理成本，因为仅部分专家在每次计算中被使用。然而，现有的MoE方法仅将数据特征作为门控函数的输入，忽略了注意力值所蕴含的重要信息。本文提出了一种增强注意力的混合专家（AMoE）模型，这是一种新型的基于Transformer的MoE架构。具体而言，我们设计了一种集成注意力机制的新门控结构，显著提升了模型性能。我们通过一系列全面的实验验证了所提方法的有效性。"
  },
  {
    "date": "2025-12-24",
    "title": "CallNavi, A challenge and empirical study on LLM function calling and routing",
    "authors": "Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé Bissyande, Andrey Boytsov, Ulrick Ble, Anne Goujon",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756975",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CallNavi：大语言模型函数调用与路由的挑战与实证研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation",
    "authors": "Lola Solovyeva, Eduardo Carneiro Oliveira, Shiyu Fan, Alper Tuncay, Shamil Gareev, Andrea Capiluppi",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757007",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "利用大语言模型实现遗留代码的自动化翻译：PL/SQL到Java转换的案例研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection",
    "authors": "Seyed Shayan Daneshvar, Da Tan, Shaowei Wang, Carson Leung",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757017",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "一种基于Mixup的增强方法在软件漏洞检测中的研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Ontology-Driven Deep Learning Generation Using Natural Language Style Representations",
    "authors": "Incheon Paik, Zheqi Shen",
    "publish": "2025 13th International Conference on Awareness Science and Technology (iCAST)",
    "url": "https://doi.org/10.1109/icast68191.2025.11300086",
    "source": "IEEE",
    "abstract": "Deep learning (DL) has achieved remarkable progress across various fields, yet designing customized DL architectures remains complex and labor-intensive. While AutoML frameworks assist with model selection and hyperparameter tuning, they lack mechanisms to integrate structured domain knowledge. To overcome this limitation, we propose an ontology-driven approach that enables Large Language Models (LLMs) to reason over structured knowledge and dynamically generate DL architectures. Traditional ontology systems rely on XML formats and rule-based engines, which hinder adaptability and compatibility with modern AI tools. Our approach transforms ontological concepts—such as classes, properties, and rules—into structured natural language, allowing LLMs to process and infer directly from them. This enables intuitive understanding and flexible reasoning without the need for external inference engines. We develop a prototype system that uses LLMs for DL architecture generation guided by ontology-based reasoning. Experimental results demonstrate improved adaptability and reduced reliance on specialized tools. Furthermore, we incorporate a Few-Shot Learning mechanism to enhance LLMs’ capability to interpret and apply ontology rules effectively. This research bridges the gap between structured knowledge representation and natural language-based reasoning, contributing to the development of autonomous and intelligent DL systems capable of domain-specific optimization.",
    "title_zh": "基于本体的深度学习生成：使用自然语言风格表示",
    "abstract_zh": "深度学习（DL）在多个领域取得了显著进展，然而设计定制化的深度学习架构仍然复杂且耗时。尽管AutoML框架能够辅助模型选择和超参数调优，但它们缺乏整合结构化领域知识的机制。为克服这一局限，我们提出了一种基于本体驱动的方法，使大型语言模型（LLMs）能够基于结构化知识进行推理，并动态生成深度学习架构。传统的本体系统依赖于XML格式和基于规则的引擎，这限制了其灵活性与现代AI工具的兼容性。我们的方法将本体中的概念——如类、属性和规则——转化为结构化的自然语言，使LLM可以直接处理并从中推断信息，从而实现直观的理解与灵活的推理，无需依赖外部推理引擎。我们开发了一个原型系统，利用LLM在基于本体推理的指导下生成深度学习架构。实验结果表明，该方法显著提升了系统的适应性，并减少了对专用工具的依赖。此外，我们引入了少样本学习（Few-Shot Learning）机制，以增强LLM对本体规则的理解与应用能力。本研究弥合了结构化知识表示与基于自然语言的推理之间的鸿沟，推动了自主化、智能化深度学习系统的发展，使其具备针对特定领域的优化能力。"
  },
  {
    "date": "2025-12-24",
    "title": "Conthereum: Concurrent Ethereum Optimized Transaction Scheduling for Multi-Core Execution",
    "authors": "Atefeh Zareh Chahoki, Maurice Herlihy, Marco Roveri",
    "publish": "2025 7th Conference on Blockchain Research &amp;amp; Applications for Innovative Networks and Services (BRAINS)",
    "url": "https://doi.org/10.1109/brains67003.2025.11302903",
    "source": "IEEE",
    "abstract": "Conthereum is a concurrent Ethereum solution for intra-block parallel transaction execution, enabling validators to utilize multi-core infrastructure and transform the sequential execution model of Ethereum into a parallel one. This shift significantly increases throughput and transactions per second (TPS), while ensuring conflict-free execution in both proposer and attestor modes and preserving execution order consistency in the attestor. At the heart of Conthereum is a novel, lightweight, high-performance scheduler inspired by the Flexible Job Shop Scheduling Problem (FJSS). We propose a custom greedy heuristic algorithm, along with its efficient implementation, that solves this formulation effectively and decisively outperforms existing scheduling methods in finding suboptimal solutions that satisfy the constraints, achieve minimal makespan, and maximize speedup in parallel execution. Additionally, Conthereum includes an offline phase that equips its real-time scheduler with a conflict analysis repository obtained through static analysis of smart contracts, identifying potentially conflicting functions using a pessimistic approach. Building on this novel scheduler and extensive conflict data, Conthereum outperforms existing concurrent intra-block solutions. Empirical evaluations show nearlinear throughput gains with increasing computational power on standard 8-core machines. Although scalability deviates from linear at higher core counts and increased transaction conflicts, as theoretically expected, Conthereum still significantly improves upon the current Ethereum sequential execution model and outperforms existing intra-block concurrent solutions across a wide range of conditions.",
    "title_zh": "Conthereum：面向多核执行的并发以太坊优化交易调度",
    "abstract_zh": "Conthereum 是一种用于以太坊的并发解决方案，旨在实现区块内的并行交易执行，使验证者能够充分利用多核硬件资源，将以太坊原有的串行执行模型转变为并行执行模式。这一转变显著提升了吞吐量和每秒交易数（TPS），同时在提议者（proposer）和验证者（attestor）模式下均保证无冲突执行，并在验证者模式中维持执行顺序的一致性。\n\nConthereum 的核心是一个受柔性作业车间调度问题（FJSS）启发的新型轻量级、高性能调度器。我们提出了一种自定义的贪心启发式算法及其高效实现，能够有效求解该调度模型，在满足约束条件的前提下，找到次优解，实现最小完工时间（makespan），并最大化并行执行的加速比。此外，Conthereum 还包含一个离线阶段，通过静态分析智能合约，构建一个冲突分析知识库，采用保守策略识别出可能存在冲突的函数调用。基于这一创新的调度机制与丰富的冲突数据，Conthereum 在性能上超越了现有的同类并发区块内解决方案。\n\n实证评估表明，在标准的8核机器上，随着计算能力的提升，Conthereum 实现了接近线性的吞吐量增长。尽管在更高核心数和更多交易冲突的情况下，其可扩展性偏离了理想线性关系——这与理论预期一致，但 Conthereum 仍显著优于当前以太坊的串行执行模型，并在多种运行条件下全面超越现有的区块内并发解决方案。"
  },
  {
    "date": "2025-12-24",
    "title": "Towards Automated Detection of Inline Code Comment Smells",
    "authors": "Ipek Oztas, U. Boran Torun, Eray Tüzün",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756988",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "面向自动检测内联代码注释异味",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "How Well Do Large Language Models Serve as End-to-End Secure Code Agents for Python?",
    "authors": "Jianian Gong, Nachuan Duan, Ziheng Tao, Zhaohui Gong, Yuan Yuan, Minlie Huang",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756984",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型在作为Python的端到端安全代码代理方面表现如何？",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Quality Assessment of Python Tests Generated by Large Language Models",
    "authors": "Victor Alves, Carla Bezerra, Ivan Machado, Larissa Rocha, Tassio Virgínio, Publio Silva",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756964",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型生成的Python测试用例的质量评估",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Understanding Code Smell Detection Through Hyperparameter Optimization and Metric Correlation Analysis",
    "authors": "Marcela Mosquera, Rodolfo Bojorque, Pamela Flores",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3648183",
    "source": "IEEE",
    "abstract": "Hyperparameter optimization plays a pivotal role in the reliability and generalization of machine-learning models for software quality prediction. This paper presents a comparative evaluation of three search strategies: Grid Search, Random Search, and a Hybrid approach applied to the detection of four types of code smells (BLOB, Functional Decomposition, Spaghetti Code, and Swiss Army Knife). Experiments were performed on three open-source Java systems (Azureus, ArgoUML, and Xerces) using Support Vector Machines (SVMs). The results show that all three strategies produce consistent patterns in accuracy and F1-score across the datasets, confirming the robustness of the evaluation framework. Simultaneously, Random Search tends to achieve higher recall for the Functional Decomposition smell, reflecting its ability to explore sparse and irregular hyperparameter spaces. The Hybrid approach combines the exploratory strength of Random Search with the local refinement of Grid Search, offering greater stability with a moderate computational cost. A correlation analysis of software metrics further reveals that while the Blob smell is consistently associated with size and coupling indicators, the other smells—Functional Decomposition, Spaghetti Code, and Swiss Army Knife are captured more indirectly through general structural proxies such as size, cohesion, and coupling. Overall, these findings suggest that hyperparameter tuning not only enhances predictive performance but also provides valuable insights into the structural factors underlying code smells.",
    "title_zh": "通过超参数优化与度量相关性分析理解代码异味检测",
    "abstract_zh": "超参数优化在提升机器学习模型用于软件质量预测的可靠性与泛化能力方面起着至关重要的作用。本文对三种搜索策略——网格搜索（Grid Search）、随机搜索（Random Search）以及一种混合方法——进行了比较评估，应用于四类代码异味（BLOB、功能分解、面条代码和瑞士军刀式设计）的检测。实验基于三个开源Java系统（Azureus、ArgoUML和Xerces），采用支持向量机（SVM）进行测试。结果表明，三种策略在不同数据集上均呈现出一致的准确率与F1分数模式，验证了评估框架的稳健性。同时，随机搜索在检测“功能分解”异味时表现出更高的召回率，体现了其在稀疏且不规则的超参数空间中探索的能力。混合方法结合了随机搜索的全局探索优势与网格搜索的局部精细调优能力，在保持适中计算成本的同时，展现出更强的稳定性。对软件度量指标的相关性分析进一步揭示：BLOB异味始终与代码规模和耦合度等指标密切相关；而其他三类异味——功能分解、面条代码和瑞士军刀式设计，则更多通过诸如规模、内聚度和耦合度等通用结构代理指标间接体现。总体而言，这些发现表明，超参数调优不仅能够提升预测性能，还能为理解代码异味背后的结构性成因提供重要洞见。"
  },
  {
    "date": "2025-12-24",
    "title": "Identifying Helpful Context for LLM-based Vulnerability Repair: A Preliminary Study",
    "authors": "Gábor Antal, Bence Bogenfürst, Rudolf Ferenc, Péter Hegedus",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757078",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于大语言模型的漏洞修复中有用上下文识别：一项初步研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "CoSrch: Syntactic and Semantic Structure-Aware Code Representation for Effective Code Search",
    "authors": "Jia Xu, Yuqiang He, Hengyu Liu, Pin Lv, Tiancheng Zhang, Zhihong Tian",
    "publish": "ACM Transactions on Software Engineering and Methodology",
    "url": "https://doi.org/10.1145/3785469",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CoSrch：面向有效代码搜索的语法与语义结构感知代码表示",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "LELANTE: LEveraging LLM for Automated ANdroid TEsting",
    "authors": "Haz Sameen Shahgir, Shamit Fatin, Mehbubul Hasan Al-Quvi, Sukarna Barua, Anindya Iqbal, Sadia Sharmin, Md. Mostofa Akbar, Kallol Kumar Pal, A. Asif Al Rashid",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757032",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "LELANTE：利用大语言模型实现安卓自动化测试",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Distributed Modularization of Thought: Lets Small Rival Large LMs",
    "authors": "Matej Zubic, Dario Bojanjac",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3648050",
    "source": "IEEE",
    "abstract": "We present the Distributed Modularization of Thought (DMoT) approach for code generation using several small language models, fine-tuned for distinct phases of the code generation process. Instead of the conventional single-model approach in direct code generation, our DMoT method decomposes the task into a hierarchy of subtasks using hierarchical Multi-Level Reasoning (MLR) graphs. Each phase, from solving simple subproblems to verifying syntax and compliance with initial requirements, is handled by a dedicated fine-tuned model. Models were trained through knowledge distillation from a larger model (ChatGPT-4.1) using a quantized LoRA technique, enabling execution on accessible hardware. Experimental evaluation is conducted on the BigCodeBench benchmark, which includes realistic and complex programming tasks. These results show that a system composed of several specialized small models outperforms single-model approaches in terms of accuracy (pass@1) and structural quality (CodeBLEU). So, small fine-tuned language models can rival and even outperform larger models, offering a resource-efficient path in the code generation processes.",
    "title_zh": "思想的分布式模块化：让小型模型挑战大型语言模型",
    "abstract_zh": "我们提出了一种名为分布式思维模块化（Distributed Modularization of Thought, DMoT）的方法，用于通过多个小型语言模型进行代码生成。这些小型模型针对代码生成过程的不同阶段进行了微调。与传统的直接代码生成中使用单一模型的方法不同，我们的DMoT方法利用分层的多级推理（Multi-Level Reasoning, MLR）图，将任务分解为一系列层次化的子任务。从解决简单子问题，到验证语法以及符合初始需求等各个阶段，均由专门微调过的模型负责处理。这些模型通过从更大的模型（ChatGPT-4.1）中进行知识蒸馏，并采用量化LoRA技术进行训练，从而能够在普通硬件上高效运行。我们在BigCodeBench基准测试集上进行了实验评估，该基准包含真实且复杂的编程任务。结果表明，由多个专业化的小型模型组成的系统在准确率（pass@1）和结构质量（CodeBLEU）方面均优于单模型方法。这说明，经过微调的小型语言模型不仅能够与大型模型相媲美，甚至在某些情况下表现更优，为代码生成过程提供了一条资源高效的可行路径。"
  },
  {
    "date": "2025-12-24",
    "title": "Achieving Unanimous Consensus Through Multi-Agent Deliberation",
    "authors": "Apurba Pokharel, Ram Dantu, Shakila Zaman, Vinh Quach, Sirisha Talapuru",
    "publish": "2025 7th Conference on Blockchain Research &amp;amp; Applications for Innovative Networks and Services (BRAINS)",
    "url": "https://doi.org/10.1109/brains67003.2025.11302940",
    "source": "IEEE",
    "abstract": "Blockchain consensus mechanisms have relied on algorithms such as Proof-of-Work (PoW) and Proof-of-Stake (PoS) to ensure network functionality and integrity. However, these approaches struggle with adaptability for decision-making where the opinions of each matter rather than reaching an agreement based on honest majority or weighted consensus. This paper introduces a novel deliberation-based consensus mechanism where Large Language Models (LLMs) act as rational agents engaging in structured discussions to reach a unanimous consensus. By leveraging graded consensus and a multi-round deliberation process, our approach ensures unanimous consensus for definitive problems and graded consensus for prioritized decision problems and policies. We provide a formalization of our system and use it to show that the properties of blockchains are maintained, while also addressing the behavior in terms of adversaries, stalled deliberations, and confidence in consensus. Moreover, experimental results demonstrate system feasibility, showcasing convergence, block properties, and accuracy, which enable deliberative decision-making on blockchain networks.",
    "title_zh": "通过多智能体 deliberation 实现一致共识",
    "abstract_zh": "区块链共识机制长期以来依赖于工作量证明（PoW）和权益证明（PoS）等算法来保障网络的功能性与完整性。然而，这些方法在处理需要充分考虑各方意见、而非仅基于多数诚实节点或加权共识达成一致的决策场景时，表现出适应性不足的问题。本文提出一种新型的基于协商的共识机制，其中大型语言模型（LLMs）作为理性主体参与结构化讨论，以达成一致意见。通过引入分级共识与多轮协商机制，我们的方法能够确保对明确问题达成完全一致，同时对优先级较高的决策问题与政策实现分级共识。我们对系统进行了形式化建模，并证明该机制在保持区块链核心属性的同时，有效应对了恶意攻击者、协商停滞以及共识可信度等问题。此外，实验结果验证了系统的可行性，展示了其收敛性、区块特性及准确性，从而实现了在区块链网络上进行协商式决策的可能。"
  },
  {
    "date": "2025-12-24",
    "title": "Can We Enhance Bug Report Quality Using LLMs?: An Empirical Study of LLM-Based Bug Report Generation",
    "authors": "Jagrit Acharya, Gouri Ginde",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756995",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "我们能否利用大语言模型提升缺陷报告质量？——基于大语言模型的缺陷报告生成的实证研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Optimizing Code Embeddings and ML Classifiers for Python Source code Vulnerability Detection",
    "authors": "Talaya Farasat, Joachim Posegga",
    "publish": "Proceedings of the IEEE/ACM 12th International Conference on Big Data Computing, Applications and Technologies",
    "url": "https://doi.org/10.1145/3773276.3776566",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "优化代码嵌入与机器学习分类器以检测Python源代码漏洞",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Simplicity by Obfuscation: Evaluating LLM-Driven Code Transformation with Semantic Elasticity",
    "authors": "Lorenzo De Tomasi, Claudio Di Sipio, Antinisca Di Marco, Phuong T. Nguyen",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757041",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "以晦涩实现简洁：基于语义弹性评估大语言模型驱动的代码转换",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Improved Labeling of Security Defects in Code Review by Active Learning with LLMs",
    "authors": "Johannes Härtel",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756986",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "通过大语言模型的主动学习提升代码审查中安全缺陷的标注效果",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "An Anatomy of 488 Faults from Defects4J Based on the Control- and Data-Flow Graph Representations of Programs",
    "authors": "Alexandra van der Spuy, Bernd Fischer",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757025",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于程序控制流图和数据流图表示的Defects4J中488个缺陷的剖析",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models",
    "authors": "Fernando Vallecillos Ruiz, Max Hort, Leon Moonen",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756966",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "修复的艺术：利用指令微调模型优化迭代式程序修复",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Do Prompt Patterns Affect Code Quality? A First Empirical Assessment of ChatGPT-Generated Code",
    "authors": "Antonio Della Porta, Stefano Lambiase, Fabio Palomba",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756938",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "提示模式是否影响代码质量？对ChatGPT生成代码的首次实证评估",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Fast Chaincode Prototyping: a productivity IDE Plugin for Chaincode Development in Hyperledger Fabric",
    "authors": "Stefano Avola, Pierpaolo Baglietto, Andrea Parodi",
    "publish": "2025 7th Conference on Blockchain Research &amp;amp; Applications for Innovative Networks and Services (BRAINS)",
    "url": "https://doi.org/10.1109/brains67003.2025.11302945",
    "source": "IEEE",
    "abstract": "Permissioned Blockchains like Hyperledger Fabric (HLF) are precious tools for enhancing trust and speed up digitalization and data sharing within industry consortia. Though, given the complexity and the many components of the framework, the development process is rather articulated, with lots of pre-requirements and preparation steps. In this demo paper we introduce FCP: an innovative tool for Fast Chaincode Prototyping. FCP is a tool that helps speeding up the development of HLF Chaincodes (CCs), provided as a JetBrains IDE plugin. FCP is still under development.",
    "title_zh": "快速链码原型设计：Hyperledger Fabric 链码开发的高效生产力IDE插件",
    "abstract_zh": "许可型区块链（如Hyperledger Fabric，简称HLF）是提升产业联盟内部信任、加速数字化进程及数据共享的宝贵工具。然而，由于该框架结构复杂且组件繁多，开发过程相当繁琐，需要大量的前期准备和配置步骤。在本文的演示论文中，我们介绍了FCP：一种用于快速链码原型设计的创新工具。FCP是一款专为JetBrains IDE设计的插件，旨在加速HLF链码（Chaincode，简称CC）的开发。目前，FCP仍处于开发阶段。"
  },
  {
    "date": "2025-12-24",
    "title": "Tracking the Moving Target: A Framework for Continuous Evaluation of LLM Test Generation in Industry",
    "authors": "Maider Azanza, Beatriz Pérez Lamancha, Eneko Pizarro",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756946",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "追踪移动的目标：面向工业界大语言模型测试生成的持续评估框架",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "LAMeD: LLM-generated Annotations for Memory Leak Detection",
    "authors": "Ekaterina Shemetova, Ivan Smirnov, Anton Alekseev, Ilya Shenbin, Alexey Rukhovich, Sergey Nikolenko, Vadim Lomshakov, Irina Piontkovskaya",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756999",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "LAMeD：基于大语言模型生成的内存泄漏检测注释",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Unlocking On-Chain Intelligence: A Practical Framework for GenAI-Powered Smart Contracts",
    "authors": "Rabimba Karanjai, Yang Lu, Lei Xu, Weidong Larry Shi",
    "publish": "2025 7th Conference on Blockchain Research &amp;amp; Applications for Innovative Networks and Services (BRAINS)",
    "url": "https://doi.org/10.1109/brains67003.2025.11302909",
    "source": "IEEE",
    "abstract": "Generative AI and modern Machine Learning are rapidly transforming industries, creating new tools and use cases. As these models grow, there is an increasing need for reliable Machine Learning Operations (MLOps) to manage and deploy them. At the same time, demand is rising for smarter smart contracts and more complex on-chain computation. Our paper presents a new framework that brings GenAI inference directly onto the blockchain. Using the Cosmos SDK, Ethermint, and the ONNX runtime, we enable AI models to run on-chain across multiple blockchain nodes. We evaluate the system’s feasibility, performance, and portability, showing that it can support different AI engines and model types. By enabling GenAI inference on-chain, our approach expands what smart contracts can do, especially for data-driven DeFi, and opens the door to new applications in the future.",
    "title_zh": "解锁链上智能：一种基于生成式AI的智能合约实用框架",
    "abstract_zh": "生成式人工智能与现代机器学习正在迅速重塑各行各业，催生出全新的工具和应用场景。随着这些模型的不断演进，对可靠机器学习运维（MLOps）的需求日益增长，以实现对模型的有效管理与部署。与此同时，市场对更智能的智能合约以及更复杂的链上计算能力也提出了更高要求。本文提出了一种新框架，将生成式AI推理直接引入区块链。通过结合Cosmos SDK、Ethermint以及ONNX运行时，我们实现了AI模型在多个区块链节点上的链上运行。我们评估了该系统的可行性、性能及可移植性，结果表明其能够支持多种AI引擎和不同类型的模型。通过在链上实现生成式AI推理，我们的方法显著拓展了智能合约的功能边界，尤其在数据驱动的去中心化金融（DeFi）领域具有重要意义，并为未来开辟了全新的应用可能性。"
  },
  {
    "date": "2025-12-24",
    "title": "Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code",
    "authors": "Michele Carissimi, Martina Saletta, Claudio Ferretti",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757026",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "利用大型语言模型摘要进行源代码主题建模",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Don’t Panic: Error Handling Patterns in Go Smart Contracts and Blockchain Software",
    "authors": "Luca Olivieri, Luca Negrini",
    "publish": "2025 7th Conference on Blockchain Research &amp;amp; Applications for Innovative Networks and Services (BRAINS)",
    "url": "https://doi.org/10.1109/brains67003.2025.11302935",
    "source": "IEEE",
    "abstract": "Issues in error handling may have critical consequences in blockchain software, ranging from silent execution with invalid states to denial of services due to unexpected crashes. This paper discusses the pitfalls of errors handling within blockchain frameworks written in Go such as Hyperledger Fabric, Tendermint Core (including its derivatives, e.g. CometBFT, Ignite), and other frameworks (e.g. Cosmos SDK), as well as the Ethereum implementation. Then, it explores how a static analysis approach can be applied for the automatic detection of such of issues, allowing to fix buggy code before deployment, i.e., when the code becomes difficult to patch being blockchain a trustless, distributed, and decentralized environment. Finally, we evaluate our analysis implementation within GoLiSA on a set of existing smart contracts and blockchain applications, empirically demonstrating the feasibility of the proposed approach.",
    "title_zh": "别慌：Go智能合约与区块链软件中的错误处理模式",
    "abstract_zh": "错误处理中的问题在区块链软件中可能带来严重后果，从导致无效状态的静默执行，到因意外崩溃引发的服务拒绝。本文探讨了使用Go语言编写的区块链框架（如Hyperledger Fabric、Tendermint Core及其衍生版本，例如CometBFT、Ignite）以及其他框架（如Cosmos SDK）以及以太坊实现中的错误处理陷阱。接着，文章研究了如何应用静态分析方法来自动检测此类问题，从而在代码部署前修复存在缺陷的代码——因为在区块链这种无信任、分布式且去中心化的环境中，代码一旦上线便极难修补。最后，我们通过在GoLiSA上对现有智能合约和区块链应用进行评估，实证证明了所提出方法的可行性。"
  },
  {
    "date": "2025-12-24",
    "title": "How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study on the Prevalence of Community Smells",
    "authors": "Giusy Annunziata, Stefano Lambiase, Fabio Palomba, Gemma Catolino, Filomena Ferrucci",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756941",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "ML-增强系统社区的“气味”如何？一项关于社区气味普遍性的横断面研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Design and Development of a Predictive Security Threat Management System Leveraging CWEs, CVEs, and CAPECs",
    "authors": "Joaquín Sierra-Granados, José L. Ruiz-Catalán, David G. Rosado, Manuel A. Serrano",
    "publish": "Proceedings of the IEEE/ACM 12th International Conference on Big Data Computing, Applications and Technologies",
    "url": "https://doi.org/10.1145/3773276.3775245",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于CWE、CVE和CAPEC的预测性安全威胁管理系统的设计与开发",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "MCLPF: Malware Collaborative Detection with LLM-Enhanced Pruning for Attributed Interpretable Flow Graphs",
    "authors": "Jun Tang, Zijun Li, Haiping Huang, Le Yu, Fu Xiao, Ruilong Deng",
    "publish": "IEEE Transactions on Information Forensics and Security",
    "url": "https://doi.org/10.1109/tifs.2025.3648113",
    "source": "IEEE",
    "abstract": "With the increasing sophistication of malware, enhanced Attributed Control Flow Graphs (ACFGs) have become a fundamental representation and are widely applied in malware detection. However, existing CFG-based detection techniques primarily extract shallow features of malware, neglecting deeper structural and semantic characteristics. Additionally, retaining all basic blocks in CFGs significantly increases the memory overhead of detection models. To address these issues, we propose MCLPF, collaborative malware detection with interpretable pruning, to improve the overall performance of existing malware detection systems that rely on fine-grained control flow features. MCLPF first introduces a novel Attributed Interpretable Flow Graph (AIFG) to extract functional attributes, integrating node-level features, edge-level features, and assembly language embedding features derived from Large Language Models (LLMs). Subsequently, it proposes an efficient and reliable detection scheme by alternately updating the graph structure and language learning modules through L-Step and G-Step, rather than synchronously training Language Models (LMs) with Graph Neural Networks (GNNs) on large-scale graphs. We conduct experiments using public datasets involving four different architectures (i.e., PE-32, PE-64, ELF-32, and ELF-64) and demonstrate that our model achieves an exceptionally high detection accuracy (i.e., 99.30%). After pruning 100% of noncritical nodes and edges, the sample size is reduced to approximately 8% of the original, with an average time cost reduction of 74.7%, while the detection performance fluctuation averages only about 1%. Extensive cross-dataset evaluations validate the effectiveness and efficiency of the proposed method.",
    "title_zh": "MCLPF：基于大语言模型增强剪枝的属性可解释流图恶意软件协同检测",
    "abstract_zh": "随着恶意软件技术的日益复杂，增强型属性控制流图（ACFG）已成为一种基础表示形式，并在恶意软件检测中得到广泛应用。然而，现有的基于CFG的检测方法主要提取恶意软件的浅层特征，忽视了更深层次的结构与语义特性。此外，保留CFG中所有基本块会显著增加检测模型的内存开销。为解决这些问题，我们提出了一种可解释剪枝协同恶意软件检测方法——MCLPF，以提升依赖细粒度控制流特征的现有恶意软件检测系统的整体性能。\n\nMCLPF首先引入一种新型的属性可解释流图（AIFG），用于提取功能属性，整合了节点级特征、边级特征以及由大语言模型（LLMs）生成的汇编语言嵌入特征。随后，该方法通过交替更新图结构与语言学习模块，采用L-Step和G-Step的迭代策略，而非在大规模图上同步训练语言模型（LMs）与图神经网络（GNNs），从而实现高效且可靠的检测方案。\n\n我们在涵盖四种不同架构（即PE-32、PE-64、ELF-32和ELF-64）的公开数据集上进行了实验，结果表明，我们的模型达到了极高的检测准确率（99.30%）。在完全剪除非关键节点与边后，样本规模缩减至原始大小的约8%，平均时间开销降低74.7%，而检测性能波动仅平均约为1%。大量跨数据集评估验证了所提方法的有效性与高效性。"
  },
  {
    "date": "2025-12-24",
    "title": "Benchmarking Large Language Models for Autonomous Run-time Error Repair: Toward Self-Healing Software Systems",
    "authors": "Alessio Bucaioni, Gabriele Gualandi, Johan Toma",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757021",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型在自主运行时错误修复中的基准测试：迈向自愈软件系统",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Design and Evaluation of a Secure Coding Approach Based on Static and Dynamic Testing in Compliance with ISO 27001:2022 Standard",
    "authors": "Warsun Najib, Antonius Daiva Prabawisesa, Dani Adhipta",
    "publish": "2025 13th International Conference on Awareness Science and Technology (iCAST)",
    "url": "https://doi.org/10.1109/icast68191.2025.11300153",
    "source": "IEEE",
    "abstract": "Software vulnerabilities remain a critical challenge, with many security flaws introduced during development due to insufficient integration of security testing into coding workflows. This paper presents an automated secure merge workflow that integrates Static Application Security Testing (SAST) and Dynamic Application Security Testing (DAST), aligned with the ISO/IEC 27001:2022 standard. The workflow leverages Semgrep for SAST and OWASP ZAP for DAST to enable early vulnerability detection, automated scanning, detailed reporting, and conditional merge control. Evaluation against the OWASP Benchmark dataset shows that Semgrep achieved a recall of 88.20%, while OWASP ZAP reached a precision of 97.77%, confirming their complementary roles. Beyond tool performance, the workflow demonstrates how ISO/IEC 27001 controls can be operationalized in practice, providing auditable evidence of secure coding and vulnerability management. While the pipeline alone cannot fulfill all principles of the standard, it strengthens compliance assurance and offers a practical model for integrating security into modern development pipelines.",
    "title_zh": "基于静态与动态测试的符合ISO 27001:2022标准的安全编码方法设计与评估",
    "abstract_zh": "软件漏洞仍然是一个关键挑战，许多安全缺陷在开发过程中引入，原因是安全测试未能充分融入编码工作流程。本文提出了一种自动化的安全合并工作流，整合了静态应用安全测试（SAST）与动态应用安全测试（DAST），并符合ISO/IEC 27001:2022标准要求。该工作流利用Semgrep进行SAST、OWASP ZAP进行DAST，实现了早期漏洞检测、自动化扫描、详细报告生成以及条件化合并控制。针对OWASP基准数据集的评估表明，Semgrep的召回率达到88.20%，而OWASP ZAP的精确度达到97.77%，验证了两者在检测中的互补作用。除了工具性能之外，该工作流还展示了如何在实践中落实ISO/IEC 27001标准的控制措施，为安全编码和漏洞管理提供了可审计的证据。尽管该流水线本身无法完全涵盖标准的所有原则，但它增强了合规性保障，并为将安全集成到现代开发流水线中提供了一个切实可行的范例。"
  },
  {
    "date": "2025-12-24",
    "title": "How Are We Doing With Using AI-Based Programming Assistants For Privacy-Related Code Generation? The Developers' Experience",
    "authors": "Kashumi Madampe, John Grundy, Nalin Arachchilage",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757035",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "我们在使用基于人工智能的编程助手生成与隐私相关的代码方面进展如何？开发者的体验",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "MarkingVLM: Vision-Language Model for Few-Shot IC Marking Detection",
    "authors": "Zhongshu Chen, Zhenghua Chen, Lin Zuo, Yu Liu",
    "publish": "IEEE Transactions on Industrial Informatics",
    "url": "https://doi.org/10.1109/tii.2025.3638609",
    "source": "IEEE",
    "abstract": "Integrated circuit (IC) marking detection faces critical “Triple C” challenges: compact marking scales, complex multidirectional layouts, and costly annotation requirements. Traditional models struggle with data scarcity in dynamic manufacturing environments where fine-grained labeled data are expensive and time-consuming to obtain. This work presents MarkingVLM, a specialized vision-language model designed for IC marking detection with exceptional few-shot learning capabilities. MarkingVLM adapts cross-modal understanding from Contrastive Language-Image Pre-training (CLIP) through unique innovations: 1) dual-granularity detection combining patch-level semantic alignment with pixel-level visual decoding; 2) layout mirror module enabling efficient multidirectional text flow recognition through feature-level augmentation; and 3) enhanced prompt engineering with learnable contexts for effective domain adaptation. Extensive experiments across two IC marking datasets with distinct characteristics substantiate superior performance: 94.2% precision and 96.5% recall on Dataset-1, and 89.6% precision with 92.6% recall on the more challenging Dataset-2. Most significantly, MarkingVLM achieves 92.7% precision with 32 training samples and maintains over 80% recall with merely 8 samples, demonstrating notable data efficiency improvement over conventional methods. Results establish a new paradigm for industrial text detection by bridging open-domain vision-language knowledge with specialized manufacturing requirements.",
    "title_zh": "MarkingVLM：用于少样本IC标记检测的视觉-语言模型",
    "abstract_zh": "集成电路（IC）标记检测面临严峻的“三C”挑战：标记尺寸微小、布局复杂且呈多方向分布、标注成本高昂。在动态制造环境中，传统模型因细粒度标注数据稀缺而难以应用，而获取此类数据既昂贵又耗时。本文提出MarkingVLM——一种专为IC标记检测设计的视觉-语言模型，具备卓越的少样本学习能力。MarkingVLM通过独特的创新机制，从对比语言-图像预训练（CLIP）中迁移跨模态理解能力：1）双粒度检测机制，结合补丁级语义对齐与像素级视觉解码；2）布局镜像模块，通过特征层面的增强实现高效多方向文本流识别；3）增强型提示工程，引入可学习上下文以实现有效的领域自适应。在两个具有不同特性的IC标记数据集上进行的大量实验验证了其优越性能：在Dataset-1上达到94.2%的精确率和96.5%的召回率，在更具挑战性的Dataset-2上实现89.6%的精确率与92.6%的召回率。尤为关键的是，MarkingVLM仅用32个训练样本即达到92.7%的精确率，且在仅8个样本的情况下仍保持超过80%的召回率，显著提升了数据利用效率，远超传统方法。研究成果为工业文本检测树立了新范式，成功实现了开放域视觉-语言知识与专业化制造需求之间的有效衔接。"
  }
]