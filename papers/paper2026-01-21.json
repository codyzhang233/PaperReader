[
  {
    "date": "2026-01-21",
    "title": "Physical Layer Security in Massive MIMO: Challenges and Open Research Directions Against Passive Eavesdroppers",
    "authors": "Nipun Agarwal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15024v1",
    "source": "arXiv",
    "abstract": "Massive Multiple-Input Multiple-Output (MIMO) has become a crucial enabling technology for 5G and beyond, providing previously unheard-of increases in energy and spectrum efficiency. It is still difficult to guarantee secure communication in these systems, particularly when it comes to passive eavesdroppers whose base station is unaware of their channel state information. By taking advantage of the inherent randomness of wireless channels, Physical Layer Security (PLS) offers a promising paradigm; however, its efficacy in massive MIMO is heavily reliant on resource allocation and transmission strategies. In this work, the performance of secure transmission schemes, such as Maximum Ratio Transmission (MRT), Zero-Forcing (ZF), and Artificial Noise (AN)-aided beamforming, is examined when passive eavesdroppers are present. This work will use extensive Monte Carlo simulations to assess important performance metrics such as energy efficiency, secrecy outage probability, and secrecy sum rate under different system parameters (e.g., number of antennas, Signal-to-Noise Ratio (SNR), power allocation). The results aim to provide comparative insight into the strengths and limitations of different PLS strategies and to highlight open research directions to design scalable, energy-efficient, and robust secure transmission techniques in future 6G networks."
  },
  {
    "date": "2026-01-21",
    "title": "Cavity-QED tools for MBQC with optical binomial-codes",
    "authors": "G. P. Teja, Radim Filip",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15019v1",
    "source": "arXiv",
    "abstract": "Measurement-based quantum computation (MBQC) offers a promising paradigm for photonic quantum computing, but its implementation requires the generation of specific non-Gaussian resource states. While continuous-variable encodings such as the highly complex (GKP) states have been widely studied, the much simpler binomial codes offer an experimentally accessible alternative, though they demand a distinct set of operational tools. Here, we present a toolkit for MBQC using optical binomial codes, detailing a cavity-QED protocol for conditional generation of cluster states and the implementation of Pauli measurements. Our work proposes the first steps for existing optical atom-cavity architectures to lay the groundwork for their use in quantum computation."
  },
  {
    "date": "2026-01-21",
    "title": "LiViBench: An Omnimodal Benchmark for Interactive Livestream Video Understanding",
    "authors": "Xiaodong Wang, Langling Huang, Zhirong Wu, Xu Zhao, Teng Xu, Xuhong Xia, Peixi Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15016v1",
    "source": "arXiv",
    "abstract": "The development of multimodal large language models (MLLMs) has advanced general video understanding. However, existing video evaluation benchmarks primarily focus on non-interactive videos, such as movies and recordings. To fill this gap, this paper proposes the first omnimodal benchmark for interactive livestream videos, LiViBench. It features a diverse set of 24 tasks, highlighting the perceptual, reasoning, and livestream-specific challenges. To efficiently construct the dataset, we design a standardized semi-automatic annotation workflow that incorporates the human-in-the-loop at multiple stages. The workflow leverages multiple MLLMs to form a multi-agent system for comprehensive video description and uses a seed-question-driven method to construct high-quality annotations. All interactive videos in the benchmark include audio, speech, and real-time comments modalities. To enhance models' understanding of interactive videos, we design tailored two-stage instruction-tuning and propose a Video-to-Comment Retrieval (VCR) module to improve the model's ability to utilize real-time comments. Based on these advancements, we develop LiVi-LLM-7B, an MLLM with enhanced knowledge of interactive livestreams. Experiments show that our model outperforms larger open-source models with up to 72B parameters, narrows the gap with leading proprietary models on LiViBench, and achieves enhanced performance on general video benchmarks, including VideoMME, LongVideoBench, MLVU, and VideoEval-Pro."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient and Minimax-optimal In-context Nonparametric Regression with Transformers",
    "authors": "Michelle Ching, Ioana Popescu, Nico Smith, Tianyi Ma, William G. Underwood, Richard J. Samworth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15014v1",
    "source": "arXiv",
    "abstract": "We study in-context learning for nonparametric regression with $α$-Hölder smooth regression functions, for some $α>0$. We prove that, with $n$ in-context examples and $d$-dimensional regression covariates, a pretrained transformer with $Θ(\\log n)$ parameters and $Ω\\bigl(n^{2α/(2α+d)}\\log^3 n\\bigr)$ pretraining sequences can achieve the minimax-optimal rate of convergence $O\\bigl(n^{-2α/(2α+d)}\\bigr)$ in mean squared error. Our result requires substantially fewer transformer parameters and pretraining sequences than previous results in the literature. This is achieved by showing that transformers are able to approximate local polynomial estimators efficiently by implementing a kernel-weighted polynomial basis and then running gradient descent."
  },
  {
    "date": "2026-01-21",
    "title": "On a Class of Global Solutions to 3D Free-Boundary Relativistic Euler Equations with a Physical Vacuum Boundary",
    "authors": "Marcelo M. Disconzi, Zhongtian Hu, Chenyun Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15010v1",
    "source": "arXiv",
    "abstract": "We consider the free-boundary relativistic Euler equations in Minkowski spacetime $\\mathbb{M}^{1+3}$ equipped with a physical vacuum boundary, which models the motion of a relativistic gas. We concern ourselves with the family of isentropic, barotropic, and polytropic gas, with an equation of state $p = ρ^{1+κ}, κ\\in (0,\\frac23]$. We construct an open class of initial data that launches future-global solutions. Such solutions are spherically symmetric, have small initial density, and expand asymptotically linearly in time. In particular, the asymptotic rate of expansion is allowed to be arbitrarily close to the speed of light. Therefore, our main result is far from a perturbation of existing results concerning the classical isentropic Euler counterparts."
  },
  {
    "date": "2026-01-21",
    "title": "Characterizations of $\\ast$-Ricci-Bourguignon solitons on Kenmotsu manifolds",
    "authors": "Soumendu Roy, Karthika Ramasamy, Lavanya Kumar, Purabi Jana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15009v1",
    "source": "arXiv",
    "abstract": "In this paper, we have found some features of $\\ast$- Ricci Bourguignon Soliton on Kenmotsu manifold. We estimated the conditions for $\\ast$-Ricci Bourguignon on Kenmotsu manifold to be compressing, balancing or enlarging accordingly. We have found some curvature properties of Kenmotsu manifold admitting $\\ast$-Ricci Bourguignon Soliton. Additionally, we have featured $\\ast$-Ricci Bourguignon on Kenmotsu manifold with torse-forming vector field. Finally, we proved an example of $5$-dimensional Kenmotsu manifold on $\\ast$-Ricci Bourguignon Soliton."
  },
  {
    "date": "2026-01-21",
    "title": "Anomalous Quantum Criticality at a Continuous Metal-Insulator Transition",
    "authors": "M. S. Laad, Prosenjit Haldar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15007v1",
    "source": "arXiv",
    "abstract": "The Falicov-Kimball model (FKM) is long known to be the simplest model of correlated fermions exhibiting a novel Mott-like quantum critical point (QCP) assocaited with a {\\it continuous} MIT in dimensions $D \\geq 3$. It is also known to be isomorphic to an {\\it annealed} binary-alloy disorder model. Notwithstanding extensive numerical studies for the FKM, analytic insight into the microscopic processes spawning novel Mott-like quantum criticality is scarce. Here, we develop a fully analytic theory for the Mott-like quantum criticality in the FKM on a hierarchical Cayley tree (Bethe lattice) by utilizing a single input from a 2-site cluster-dynamical mean-field theory (CDMFT). We find that density fluctuation modes acquire anomalous dimensions, originating from infra-red power-law singular cluster self-energies. Interestingly, we uncover, at $T=0$, that this {\\it sub-diffusive} metal with glassy dynamics separating a weakly ergodic metal from a non-ergodic insulator shrinks to a single point, namely the Mott-like QCP, at least on the Bethe lattice. We detail the consequences of this anomalous quantum criticality for a range of thermal and dynamical responses in a variety of physical systems that can be effectively modelled by the FKM."
  },
  {
    "date": "2026-01-21",
    "title": "How a Close-in Planet Protects its White Dwarf Host from Pollution",
    "authors": "Xin-Yue Zhang, Ji-Wei Xie, Di-Chang Chen, Ji-Lin Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15005v1",
    "source": "arXiv",
    "abstract": "Approximately 25-50% of white dwarfs (WDs) exhibit metal absorption lines in their photospheres, which are attributed to accretion from their remnant planetary systems. Although white dwarfs with detected planetary systems are more likely to show photospheric pollution, one notable exception - WD 1856+534 - hosts a close-in giant planet yet exhibits no detectable photospheric metal pollution. Previous studies have proposed that massive, close-in planets can block inward transport of small particles driven by radiative forces (e.g., Poynting-Robertson drag and the Yarkovsky effect). However, it remains unclear whether the close-in planet can similarly prevent delivery of larger bodies via dynamical interactions. We aim to quantify the protective influence of close-in planets on white-dwarf pollution by asteroids approaching on near-parabolic orbits, and to explore the planetary masses and orbital separations required to provide effective protection. We perform ensembles of short-term N-body integrations, sampling a range of planet masses and orbital separations and initializing asteroids on highly eccentric orbits with periapses near the WD Roche radius, in order to measure scattering, capture, and ejection outcomes and quantify the planet's shielding efficiency. For WD1856+534b-like configurations (a_p = 0.02 au), giant planets with masses greater than 0.5 Jupiter masses are sufficient to clear over 80% of highly eccentric small-body contaminants. The effectiveness of the protective effect diminishes with decreasing planetary mass and increasing semi-major axis. These findings help explain why some white dwarfs that host close-in giant planets do not show the photospheric metal pollution commonly observed in other systems."
  },
  {
    "date": "2026-01-21",
    "title": "Economic Warehouse Lot Scheduling: Approximation Schemes via Efficiently-Representable DP-Encoded Policies",
    "authors": "Danny Segev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14993v1",
    "source": "arXiv",
    "abstract": "In this focused technical paper, we present long-awaited algorithmic advances toward the efficient construction of near-optimal replenishment policies for a true inventory management classic, the economic warehouse lot scheduling problem. While this paradigm has accumulated a massive body of surrounding literature since its inception in the late '50s, we are still very much in the dark as far as basic computational questions are concerned, perhaps due to the intrinsic complexity of dynamic policies in this context. The latter feature forced earlier attempts to either study highly-structured classes of policies or to forgo provably-good performance guarantees altogether; to this day, rigorously analyzable results have been few and far between. The current paper develops novel analytical foundations for directly competing against dynamic policies. Combined with further algorithmic progress and newly-gained insights, these ideas culminate in a polynomial-time approximation scheme for constantly-many commodities. In this regard, the efficient design of $ε$-optimal dynamic policies appeared to have been out of reach, since beyond their inherent algorithmic challenges, even the polynomial-space representation of such policies has been a fundamental open question."
  },
  {
    "date": "2026-01-21",
    "title": "The Torsion of Automorphisms of Nilpotent Spaces",
    "authors": "Sacha Goldman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14988v1",
    "source": "arXiv",
    "abstract": "We reprise a $K_1$-valued refinement of Whitehead torsion originally studied by Gersten. We use this Gersten torsion to show that for nilpotent spaces with infinite fundamental group, any self-equivalence which acts as the identity on the fundamental group has vanishing Whitehead torsion. We find two applications of our vanishing result. First, we provide many examples of spaces with infinitely many simple structures. Second, we conclude that the group of homotopy classes of simple self-equivalences of a connected nilpotent space that act as the identity on the fundamental group is commensurable to an arithmetic group, building on a theorem of Sullivan. We also give a corrected version of Sullivan's proof as an appendix."
  },
  {
    "date": "2026-01-21",
    "title": "Stealthy bias injection attack detection based on Kullback-Leibler divergence in stochastic linear systems",
    "authors": "Jingwei Dong, André M. H. Teixeira",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14984v1",
    "source": "arXiv",
    "abstract": "This paper studies the design of detection observers against stealthy bias injection attacks in stochastic linear systems under Gaussian noise, considering adversaries that exploit noise and inject crafted bias signals into a subset of sensors in a slow and coordinated manner, thereby achieving malicious objectives while remaining stealthy. To address such attacks, we formulate the observer design as a max-min optimization problem to enhance the detectability of worst-case BIAs, which attain a prescribed attack impact with the least detectability evaluated via Kullback-Leibler divergence. To reduce the computational complexity of the derived non-convex design problem, we consider the detectability of worst-case BIAs at three specific time instants: attack onset, one step after attack occurrence, and the steady state. We prove that the Kalman filter is optimal for maximizing the BIA detectability at the attack onset, regardless of the subset of attacked sensors. For the one-step and steady-state cases, the observer design problems are approximated by bi-convex optimization problems, which can be efficiently solved using alternating optimization and alternating direction method of multipliers. Moreover, more tractable linear matrix inequality relaxations are developed. Finally, the effectiveness of the proposed stealth-aware detection framework is demonstrated through an application to a thermal system."
  },
  {
    "date": "2026-01-21",
    "title": "Crystal growth and characterization of a hole-doped iron-based superconductor Ba(Fe$_{0.875}$Ti$_{0.125}$)$_2$As$_2$",
    "authors": "Yi-Li Sun, Ze-Zhong Li, Yang Li, Hong-Lin Zhou, Amit Pokhriyal, Haranath Ghosh, Shi-Liang Li, Hui-Qian Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14981v1",
    "source": "arXiv",
    "abstract": "We report the crystal growth of a new hole-doped iron-based superconductor Ba(Fe$_{0.875}$Ti$_{0.125}$)$_2$As$_2$ by substituting Ti on the Fe site. The crystals are accidentally obtained in trying to grow Ni doped Ba$_2$Ti$_2$Fe$_2$As$_4$O. After annealing at 500 \\textcelsius $ $ in vacuum for one week, superconductivity is observed with zero resistance at $T_{c0} \\approx 17.5$ K, and about 20\\% diamagnetic volume down to 2 K. While both the small anisotropy of superconductivity and the temperature dependence of normal state resistivity are akin to the electron doped 122-type compounds, the Hall coefficient is positive and similar to the case in hole-doped Ba$_{0.9}$K$_{0.1}$Fe$_2$As$_2$. The density functional theory calculations suggest dominated hole pockets contributed by Fe/Ti 3$d$ orbitals. Therefore, the Ba(Fe$_{1-x}$Ti$_{x}$)$_2$As$_2$ system provides a new platform to study the superconductivity with hole doping on the Fe site of iron-based superconductors."
  },
  {
    "date": "2026-01-21",
    "title": "Unsupervised Material Fingerprinting: Ultra-fast hyperelastic model discovery from full-field experimental measurements",
    "authors": "Moritz Flaschel, Miguel Angel Moreno-Mateos, Simon Wiesheier, Paul Steinmann, Ellen Kuhl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14965v1",
    "source": "arXiv",
    "abstract": "Material Fingerprinting is a lookup table-based strategy to discover material models from experimental measurements, which completely avoids the need to solve an optimization problem. In an offline phase, a comprehensive database of simulated material responses, so-called material fingerprints, is generated for a predefined experimental setup. This database can then be used repeatedly in the online phase to discover material models corresponding to experimentally measured observations. To this end, the experimentally measured fingerprint is compared with all fingerprints in the database to identify the closest match. The primary advantage of this strategy is that it does not require solving a continuous optimization problem. This avoids the associated computational costs as well as issues of ill-posedness caused by local minima in non-convex optimization landscapes. Material Fingerprinting has been successfully demonstrated for supervised datasets consisting of stress-strain pairs, as well as for unsupervised datasets involving full-field displacements and net reaction forces. However, to date, there is no experimental validation for the latter approach which is the objective of this work."
  },
  {
    "date": "2026-01-21",
    "title": "Improving Regret Approximation for Unsupervised Dynamic Environment Generation",
    "authors": "Harry Mead, Bruno Lacerda, Jakob Foerster, Nick Hawes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14957v1",
    "source": "arXiv",
    "abstract": "Unsupervised Environment Design (UED) seeks to automatically generate training curricula for reinforcement learning (RL) agents, with the goal of improving generalisation and zero-shot performance. However, designing effective curricula remains a difficult problem, particularly in settings where small subsets of environment parameterisations result in significant increases in the complexity of the required policy. Current methods struggle with a difficult credit assignment problem and rely on regret approximations that fail to identify challenging levels, both of which are compounded as the size of the environment grows. We propose Dynamic Environment Generation for UED (DEGen) to enable a denser level generator reward signal, reducing the difficulty of credit assignment and allowing for UED to scale to larger environment sizes. We also introduce a new regret approximation, Maximised Negative Advantage (MNA), as a significantly improved metric to optimise for, that better identifies more challenging levels. We show empirically that MNA outperforms current regret approximations and when combined with DEGen, consistently outperforms existing methods, especially as the size of the environment grows. We have made all our code available here: https://github.com/HarryMJMead/Dynamic-Environment-Generation-for-UED."
  },
  {
    "date": "2026-01-21",
    "title": "What Should I Cite? A RAG Benchmark for Academic Citation Prediction",
    "authors": "Leqi Zheng, Jiajun Zhang, Canzhi Chen, Chaokun Wang, Hongwei Li, Yuying Li, Yaoxin Mao, Shannan Yan, Zixin Song, Zhiyuan Feng, Zhaolu Kang, Zirong Chen, Hang Zhang, Qiang Liu, Liang Wang, Ziyang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14949v1",
    "source": "arXiv",
    "abstract": "With the rapid growth of Web-based academic publications, more and more papers are being published annually, making it increasingly difficult to find relevant prior work. Citation prediction aims to automatically suggest appropriate references, helping scholars navigate the expanding scientific literature. Here we present \\textbf{CiteRAG}, the first comprehensive retrieval-augmented generation (RAG)-integrated benchmark for evaluating large language models on academic citation prediction, featuring a multi-level retrieval strategy, specialized retrievers, and generators. Our benchmark makes four core contributions: (1) We establish two instances of the citation prediction task with different granularity. Task 1 focuses on coarse-grained list-specific citation prediction, while Task 2 targets fine-grained position-specific citation prediction. To enhance these two tasks, we build a dataset containing 7,267 instances for Task 1 and 8,541 instances for Task 2, enabling comprehensive evaluation of both retrieval and generation. (2) We construct a three-level large-scale corpus with 554k papers spanning many major subfields, using an incremental pipeline. (3) We propose a multi-level hybrid RAG approach for citation prediction, fine-tuning embedding models with contrastive learning to capture complex citation relationships, paired with specialized generation models. (4) We conduct extensive experiments across state-of-the-art language models, including closed-source APIs, open-source models, and our fine-tuned generators, demonstrating the effectiveness of our framework. Our open-source toolkit enables reproducible evaluation and focuses on academic literature, providing the first comprehensive evaluation framework for citation prediction and serving as a methodological template for other scientific domains. Our source code and data are released at https://github.com/LQgdwind/CiteRAG."
  },
  {
    "date": "2026-01-21",
    "title": "TIDAL: Temporally Interleaved Diffusion and Action Loop for High-Frequency VLA Control",
    "authors": "Yuteng Sun, Haoran Wang, Ruofei Bai, Zhengguo Li, Jun Li, Meng Yee, Chuah, Wei Yun Yau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14945v1",
    "source": "arXiv",
    "abstract": "Large-scale Vision-Language-Action (VLA) models offer semantic generalization but suffer from high inference latency, limiting them to low-frequency batch-and-execute paradigm. This frequency mismatch creates an execution blind spot, causing failures in dynamic environments where targets move during the open-loop execution window. We propose TIDAL (Temporally Interleaved Diffusion and Action Loop), a hierarchical framework that decouples semantic reasoning from high-frequency actuation. TIDAL operates as a backbone-agnostic module for diffusion-based VLAs, using a dual-frequency architecture to redistribute the computational budget. Specifically, a low-frequency macro-intent loop caches semantic embeddings, while a high-frequency micro-control loop interleaves single-step flow integration with execution. This design enables approximately 9 Hz control updates on edge hardware (vs. approximately 2.4 Hz baselines) without increasing marginal overhead. To handle the resulting latency shift, we introduce a temporally misaligned training strategy where the policy learns predictive compensation using stale semantic intent alongside real-time proprioception. Additionally, we address the insensitivity of static vision encoders to velocity by incorporating a differential motion predictor. TIDAL is architectural, making it orthogonal to system-level optimizations. Experiments show a 2x performance gain over open-loop baselines in dynamic interception tasks. Despite a marginal regression in static success rates, our approach yields a 4x increase in feedback frequency and extends the effective horizon of semantic embeddings beyond the native action chunk size. Under non-paused inference protocols, TIDAL remains robust where standard baselines fail due to latency."
  },
  {
    "date": "2026-01-21",
    "title": "Solution-derived barium titanate waveguides for integrated electro-optic modulation",
    "authors": "Virginia Falcone, Eleni Prountzou, Jost Kellner, Ülle-Linda Talts, Rachel Grange",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14938v1",
    "source": "arXiv",
    "abstract": "Metal oxides with strong nonlinear optical properties and wide transparency window are key materials for the development of compact and efficient photonic integrated circuits used for electro-optic modulators and entangled photon sources. Among them, barium titanate (BaTiO$_{3}$) is particularly attractive due to its large Pockels coefficient. However, its use has been limited by challenges in material synthesis and in nanopatterning, owing to its chemical stability and inertness. Here, we demonstrate a monolithic electro-optic modulator entirely based on solution-deposited BaTiO$_{3}$, fabricated through a bottom-up soft nanoimprinting lithography process. Fine-tuning the synthesis and nanofabrication enhances the optical properties of the polycrystalline material. By optimizing the process parameters, we achieve a reduction in propagation losses of two orders of magnitude, enabling efficient electro-optic modulation. This scalable, etch-free approach enables direct patterning of high-quality BaTiO$_{3}$ structures, establishing a new route for low-cost, large-scale integrated electro-optic devices entirely based on oxide material compatible with a wide range of substrates."
  },
  {
    "date": "2026-01-21",
    "title": "LLM-Based Repair of C++ Implicit Data Loss Compiler Warnings: An Industrial Case Study",
    "authors": "Chansong You, Hyun Deok Choi, Jingun Hong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14936v1",
    "source": "arXiv",
    "abstract": "This paper presents a method to automatically fix implicit data loss warnings in large C++ projects using Large Language Models (LLMs). Our approach uses the Language Server Protocol (LSP) to gather context, Tree-sitter to extract relevant code, and LLMs to make decisions and generate fixes. The method evaluates the necessity of range checks concerning performance implications and generates appropriate fixes. We tested this method in a large C++ project, resulting in a 92.73% acceptance rate of the fixes by human developers during the code review. Our LLM-generated fixes reduced the number of warning fix changes that introduced additional instructions due to range checks and exception handling by 39.09% compared to a baseline fix strategy. This result was 13.56% behind the optimal solutions created by human developers. These findings demonstrate that our LLM-based approach can reduce the manual effort to address compiler warnings while maintaining code quality and performance in a real-world scenario. Our automated approach shows promise for integration into existing development workflows, potentially improving code maintenance practices in complex C++ software projects."
  },
  {
    "date": "2026-01-21",
    "title": "Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali",
    "authors": "Nouhoum Coulibaly, Ousmane Ly, Michael Leventhal, Ousmane Goro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14931v1",
    "source": "arXiv",
    "abstract": "This study explores the capacity of generative artificial intelligence (Gen AI) to contribute to the construction of peace narratives and the revitalization of musical heritage in Mali. The study has been made in a political and social context where inter-community tensions and social fractures motivate a search for new symbolic frameworks for reconciliation. The study empirically explores three questions: (1) how Gen AI can be used as a tool for musical creation rooted in national languages and traditions; (2) to what extent Gen AI systems enable a balanced hybridization between technological innovation and cultural authenticity; and (3) how AI-assisted musical co-creation can strengthen social cohesion and cultural sovereignty. The experimental results suggest that Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them. However, challenges persist regarding the availability of linguistic corpora, algorithmic censorship, and the ethics of generating compositions derived from copyrighted sources."
  },
  {
    "date": "2026-01-21",
    "title": "Vision-Language Models on the Edge for Real-Time Robotic Perception",
    "authors": "Sarat Ahmad, Maryam Hafeez, Syed Ali Raza Zaidi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14921v1",
    "source": "arXiv",
    "abstract": "Vision-Language Models (VLMs) enable multimodal reasoning for robotic perception and interaction, but their deployment in real-world systems remains constrained by latency, limited onboard resources, and privacy risks of cloud offloading. Edge intelligence within 6G, particularly Open RAN and Multi-access Edge Computing (MEC), offers a pathway to address these challenges by bringing computation closer to the data source. This work investigates the deployment of VLMs on ORAN/MEC infrastructure using the Unitree G1 humanoid robot as an embodied testbed. We design a WebRTC-based pipeline that streams multimodal data to an edge node and evaluate LLaMA-3.2-11B-Vision-Instruct deployed at the edge versus in the cloud under real-time conditions. Our results show that edge deployment preserves near-cloud accuracy while reducing end-to-end latency by 5\\%. We further evaluate Qwen2-VL-2B-Instruct, a compact model optimized for resource-constrained environments, which achieves sub-second responsiveness, cutting latency by more than half but at the cost of accuracy."
  },
  {
    "date": "2026-01-21",
    "title": "Towards gravitational wave parameter inference for binaries with an eccentric companion",
    "authors": "Kai Hendriks, Lorenz Zwick, Pankaj Saini, János Takátsy, Johan Samsing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14918v1",
    "source": "arXiv",
    "abstract": "We introduce a complete model for dephasing due to line-of-sight acceleration (LOSA) in gravitational wave (GW) signals from stellar-mass binary black holes (BBHs) in three-body systems. Our prescription provides curvature- and projection-dependent phase features that are not recovered by local-expansion-based treatments. We perform parameter-space surveys and mock parameter inferences assuming the nominal sensitivity of the Einstein Telescope (ET) to identify the regime where the time-varying LOSA allows for separate constraints on the outer orbital parameters, in particular the tertiary mass and distance. We estimate that ET may detect a few to tens of such systems per year, provided that all binaries merge dynamically, and demonstrate that these constraints can be used to directly discriminate between a dynamical and AGN origin for BBHs. Finally, we reanalyse the GW190814 event and four O4a events finding no evidence for LOSA, with the previously claimed LOSA in GW190814 disappearing when a sufficiently long data segment is used."
  },
  {
    "date": "2026-01-21",
    "title": "Tailoring Adverse Event Prediction in Type 1 Diabetes with Patient-Specific Deep Learning Models",
    "authors": "Giorgia Rigamonti, Mirko Paolo Barbato, Davide Marelli, Paolo Napoletano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14917v1",
    "source": "arXiv",
    "abstract": "Effective management of Type 1 Diabetes requires continuous glucose monitoring and precise insulin adjustments to prevent hyperglycemia and hypoglycemia. With the growing adoption of wearable glucose monitors and mobile health applications, accurate blood glucose prediction is essential for enhancing automated insulin delivery and decision-support systems. This paper presents a deep learning-based approach for personalized blood glucose prediction, leveraging patient-specific data to improve prediction accuracy and responsiveness in real-world scenarios. Unlike traditional generalized models, our method accounts for individual variability, enabling more effective subject-specific predictions. We compare Leave-One-Subject-Out Cross-Validation with a fine-tuning strategy to evaluate their ability to model patient-specific dynamics. Results show that personalized models significantly improve the prediction of adverse events, enabling more precise and timely interventions in real-world scenarios. To assess the impact of patient-specific data, we conduct experiments comparing a multimodal, patient-specific approach against traditional CGM-only methods. Additionally, we perform an ablation study to investigate model performance with progressively smaller training sets, identifying the minimum data required for effective personalization-an essential consideration for real-world applications where extensive data collection is often challenging. Our findings underscore the potential of adaptive, personalized glucose prediction models for advancing next-generation diabetes management, particularly in wearable and mobile health platforms, enhancing consumer-oriented diabetes care solutions."
  },
  {
    "date": "2026-01-21",
    "title": "SynPerf: A Hybrid Analytical-ML Framework for GPU Performance Prediction",
    "authors": "Kaixuan Zhang, Yunfan Cui, Shuhao Zhang, Chutong Ding, Shiyou Qian, Luping Wang, Jian Cao, Guangtao Xue, Cheng Huang, Guodong Yang, Liping Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14910v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of Transformer-based large language models has dramatically increased the need for high-performance GPUs. As a result, there is growing demand for fast, accurate, and widely generalizable GPU performance models to support next-generation hardware selection and system-level exploration. However, current data-driven methods are limited, exhibiting poor generalization across hardware and inadequate modeling of complex production-level kernels common in modern inference stacks. To address these issues, we present SyncPerf, a unified GPU modeling framework. This approach first employs an analytical model to quantify a given kernel's demands on the GPU's heterogeneous instruction pipelines. These analytical features are then fed into a machine learning (ML) model to capture complex cross-pipeline interactions and resource dependencies, enabling high-fidelity performance prediction. Our evaluation across 11 GPU types from four generations of major architectures on two widely-used serving systems demonstrates that SyncPerf delivers high fidelity and strong generalizability. It achieves accurate predictions, with only 6.1% average error at the kernel level and 8.5% for end-to-end inference -- reducing the error of state-of-the-art methods by 6.7x and 4.4x, respectively. We also demonstrate SynPerf's value \"beyond simulation\" by utilizing its performance ceiling to diagnose implementation shortcomings and guide the optimization of a production fused MoE Triton kernel, achieving up to 1.7x speedup."
  },
  {
    "date": "2026-01-21",
    "title": "Biquadratic Cauchy Tensors and Spherical Biquadratic Polynomial Programming",
    "authors": "Haibin Chen, Yixuan Chen, Liqun Qi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14908v1",
    "source": "arXiv",
    "abstract": "This paper addresses biquadratic polynomial programming (BPP), an NP-hard optimization problem closely related to biquadratic tensors. We first establish several necessary and sufficient conditions for the positive semi-definiteness and positive definiteness of biquadratic Cauchy tensors. Leveraging the structured properties of these tensors, we then prove that the BPP and its equivalent multilinear formulation share the same set of optimal solutions. This result allows us to establish the global sequence convergence of the proximal alternating minimization (PAM) algorithm via the Kurdyka- Lojasiewicz (KL) property, extending the analysis in [8]. Furthermore, by reformulating the equivalent multilinear problem as an unconstrained optimization model, we enable the analysis of its KL exponent and derive an explicit expression for the convergence rate of PAM. Finally, numerical experiments are conducted on both biquadratic Cauchy tensors and general biquadratic tensor instances to evaluate the efficiency, stability, and practical performance of the proposed algorithm."
  },
  {
    "date": "2026-01-21",
    "title": "Catalan's conjecture is Mihăilescu's theorem",
    "authors": "Martin Klazar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14900v1",
    "source": "arXiv",
    "abstract": "This text evolves from the lecture notes for my course on Catalan's conjecture in winter term 2025/26. The ultimate goal is to give full details of Mihăilescu's proof. Current chapters: 1. Euler's theorem: $x^2-y^3=1$; 2. V. Lebesgue's theorem: $x^m-y^2=1$; 3. Chao Ko's theorem: $x^2-y^q=1$ with $q\\ge5$; 4. Two relations of Cassels: $p\\,|\\,y$ and $q\\,|\\,x$; 5. Mihăilescu's theorem: $x^p-y^q=1$ with $p>q>2$; 6. An obstruction group; 7. Super-Cassels relations: $p^2\\,|\\,y$ and $q^2\\,|\\,x$; 8. Theorem M4: $p=3,5$ or $q=3,5$; A Results from mathematical anlysis; and B Results from algebra."
  },
  {
    "date": "2026-01-21",
    "title": "SpatialMem: Unified 3D Memory with Metric Anchoring and Fast Retrieval",
    "authors": "Xinyi Zheng, Yunze Liu, Chi-Hao Wu, Fan Zhang, Hao Zheng, Wenqi Zhou, Walterio W. Mayol-Cuevas, Junxiao Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14895v1",
    "source": "arXiv",
    "abstract": "We present SpatialMem, a memory-centric system that unifies 3D geometry, semantics, and language into a single, queryable representation. Starting from casually captured egocentric RGB video, SpatialMem reconstructs metrically scaled indoor environments, detects structural 3D anchors (walls, doors, windows) as the first-layer scaffold, and populates a hierarchical memory with open-vocabulary object nodes -- linking evidence patches, visual embeddings, and two-layer textual descriptions to 3D coordinates -- for compact storage and fast retrieval. This design enables interpretable reasoning over spatial relations (e.g., distance, direction, visibility) and supports downstream tasks such as language-guided navigation and object retrieval without specialized sensors. Experiments across three real-life indoor scenes demonstrate that SpatialMem maintains strong anchor-description-level navigation completion and hierarchical retrieval accuracy under increasing clutter and occlusion, offering an efficient and extensible framework for embodied spatial intelligence."
  },
  {
    "date": "2026-01-21",
    "title": "To Neuro-Symbolic Classification and Beyond by Compiling Description Logic Ontologies to Probabilistic Circuits",
    "authors": "Nicolas Lazzari, Valentina Presutti, Antonio Vergari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14894v1",
    "source": "arXiv",
    "abstract": "Background: Neuro-symbolic methods enhance the reliability of neural network classifiers through logical constraints, but they lack native support for ontologies. Objectives: We aim to develop a neuro-symbolic method that reliably outputs predictions consistent with a Description Logic ontology that formalizes domain-specific knowledge. Methods: We encode a Description Logic ontology as a circuit, a feed-forward differentiable computational graph that supports tractable execution of queries and transformations. We show that the circuit can be used to (i) generate synthetic datasets that capture the semantics of the ontology; (ii) efficiently perform deductive reasoning on a GPU; (iii) implement neuro-symbolic models whose predictions are approximately or provably consistent with the knowledge defined in the ontology. Results We show that the synthetic dataset generated using the circuit qualitatively captures the semantics of the ontology while being challenging for Machine Learning classifiers, including neural networks. Moreover, we show that compiling the ontology into a circuit is a promising approach for scalable deductive reasoning, with runtimes up to three orders of magnitude faster than available reasoners. Finally, we show that our neuro-symbolic classifiers reliably produce consistent predictions when compared to neural network baselines, maintaining competitive performances or even outperforming them. Conclusions By compiling Description Logic ontologies into circuits, we obtain a tighter integration between the Deep Learning and Knowledge Representation fields. We show that a single circuit representation can be used to tackle different challenging tasks closely related to real-world applications."
  },
  {
    "date": "2026-01-21",
    "title": "Quadratic-Phase Fourier--Bessel Transform: definitions, properties and uncertainty principles",
    "authors": "Ahmed Saoudi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14890v1",
    "source": "arXiv",
    "abstract": "In this manuscript, we introduce the quadratic--phase Fourier--Bessel transform and develop its foundational properties, including continuity, the Riemann--Lebesgue lemma, reversibility, and Parseval's identity. We define the associated translation operator and convolution product, establishing their main properties within this framework. As an application, we prove a Donoho-Stark-type uncertainty principle for the quadratic-phase Fourier--Bessel transform, extending classical uncertainty results to this generalized setting."
  },
  {
    "date": "2026-01-21",
    "title": "3D tomographic imaging of skyrmionic cocoons using HERALDO",
    "authors": "Jhon J. Chiliquinga-Jacome, Matthieu Grelier, Riccardo Battistelli, William Bouckaert, Krishnanjana Puzhekadavil Joy, Sophie Collin, Florian Godel, Marisel Di Pietro Martínez, Claire Donnelly, Felix Büttner, Horia Popescu, Vincent Cros, Nicolas Reyren, Nicolas Jaouen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14889v1",
    "source": "arXiv",
    "abstract": "Uncovering the rich and intricate characteristics of three-dimensional (3D) magnetic textures is essential for functional materials such as magnetic multilayers, where the delicate balance of various magnetic interactions leads to complex 3D spin arrangements. Among these textures, skyrmionic cocoons-tubular 3D magnetic structures characterized by a closed magnetization surface wrapping around a core-have emerged as particularly intriguing. Stabilized by competing magnetic interactions, these textures reside within a fraction of the thickness of the magnetic material and exhibit a typical lateral size of approximately 100 nm. Here, we present a vector tomographic reconstruction of the 3D magnetization in aperiodic Pt/Co/Al chiral multilayers, where skyrmionic cocoons have been recently reported. Using soft X-ray Holography with Extended Reference by Autocorrelation Linear Differential Operator (HERALDO), we acquire tomographic projections of the magnetic configuration and reconstruct the full 3D magnetization vector field with a spatial resolution of approximately 30 nm, as determined by Fourier shell correlation (FSC). This resolution allows us to observe critical features of the cocoons, such as their vertical misalignment and their overall chirality. Our findings demonstrate that HERALDO-based vector tomography is a powerful approach for revealing the internal structure and vertical extent of these nanoscale magnetic textures, offering new experimental insights into their intrinsic behavior."
  },
  {
    "date": "2026-01-21",
    "title": "Piecewise omnigenous magnetohydrodynamic equilibria as fusion reactor candidates",
    "authors": "V. Fernández-Pacheco, J. L. Velasco, E. Sánchez, R. Gaur, J. M. García-Regaña, J. A. Alonso, I. Calvo, D. Carralero",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14886v1",
    "source": "arXiv",
    "abstract": "In piecewise omnigenous magnetic fields, charged particles remain perfectly confined in the abscence of collisions and turbulence. This concept extends the traditional notion of omnigenity, the theoretical principle upon which most of existing magnetic fusion reactor designs, including tokamaks, are based. While piecewise omnigenity broadens the range of potentially viable stellarator reactor candidates, it is achieved by relaxing the requirement of continuity in the magnetic field strength, which could appear to pose significant challenges for the design of magnetohydrodynamic equilibria. In this work, a stellarator magnetic configuration is presented that satisfies the ideal magnetohydrodynamic equilibrium equation and that achieves unprecedented levels of piecewise omnigenity. As a result, it exhibits favorable transport characteristics, including reduced bulk radial (neoclassical and turbulent transport), bootstrap current and fast ion losses. In addition, the configuration displays robust MHD stability across a range of \\b{eta} values and possesses a rotational transform profile compatible with an island divertor. Collectively, these features satisfy the standard set of physics criteria required for a viable reactor candidate which, until now, were believed to be attainable only by certain types of omnigenous stellarators."
  },
  {
    "date": "2026-01-21",
    "title": "Probing Late-Stage Hadronic Interactions at High Baryon Density via $K^{*0}$ Production in the RHIC Beam Energy Scan Program",
    "authors": "The STAR Collaboration",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14884v1",
    "source": "arXiv",
    "abstract": "A precision measurement of the $K^{*0}$ meson yield is reported in Au+Au collisions at $\\sqrt{s_{NN}} = 7.7,\\; 11.5,\\; 14.6,\\; 19.6,$ and $27~\\mathrm{GeV}$ using the high-statistics data sample collected by the STAR experiment during the Beam Energy Scan II (BES-II) program at RHIC. The transeverse momentum ($p_{T}$)-integrated yield ratios $(K^{*0} + \\overline{K^{*0}})/(K^{+} + K^{-})$ in central collisions show a suppression relative to peripheral collisions at the $(1.7\\text{-}3.6)\\,σ$ level, while a thermal model without final-stage rescattering overpredicts this ratio with a deviation of $(6.9\\text{-}8.2)\\,σ$. These results indicate a loss of the measured $K^{*0}$ signal in central collisions due to re-scattering of its hadronic decay products in the hadronic phase. The $p_{T}$-integrated yield of charged kaons exhibits an approximate scaling with charged-particle multiplicity, independent of collision energy and system size. A similar trend is observed for the short-lived $K^{*0}$ resonance, although significant deviations emerge at lower energies. At BES energies, the $K^{*0}/K$ ratio shows stronger suppression than at the highest RHIC and LHC energies within a given multiplicity bin, particularly in central and mid-central collisions. This behavior is consistent with changes in the effective hadronic interaction cross section and is supported by transport model calculations, which indicate dominant meson-baryon interactions at lower energies and meson-meson interactions at higher energies."
  },
  {
    "date": "2026-01-21",
    "title": "Analysis of Sensing in OFDM-based ISAC under the Influence of Sampling Jitter",
    "authors": "Lucas Giroto, Ândrei Camponogara, Yueheng Li, Jiayi Chen, Lukas Sigg, Thomas Zwick, Benjamin Nuss",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14881v1",
    "source": "arXiv",
    "abstract": "To enable integrated sensing and communication (ISAC) in cellular networks, a wide range of additional requirements and challenges are either imposed or become more critical. One such impairment is sampling jitter (SJ), which arises due to imperfections in the sampling instants of the clocks of digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). While SJ is already well studied for communication systems based on orthogonal frequency-division multiplexing (OFDM), which is expected to be the waveform of choice for most sixth-generation (6G) scenarios where ISAC could be possible, the implications of SJ on the OFDM-based radar sensing must still be thoroughly analyzed. Considering that phase-locked loop (PLL)-based oscillators are used to derive sampling clocks, which leads to colored SJ, i.e., SJ with non-flat power spectral density, this article analyzes the resulting distortion of the adopted digital constellation modulation and sensing performance in OFDM-based ISAC for both baseband (BB) and bandpass (BP) sampling strategies and different oversampling factors. For BB sampling, it is seen that SJ induces intercarrier interference (ICI), while for BP sampling, it causes carrier phase error and more severe ICI due to a phase noise-like effect at the digital intermediate frequency. Obtained results for a single-input single-output OFDM-based ISAC system with various OFDM signal parameterizations demonstrate that SJ-induced degradation becomes non-negligible for both BB and BP sampling only for root mean square (RMS) SJ values above 10^-11 s at both DAC and ADC, which corresponds to 0.5*10^-2 times the considered critical sampling period without oversampling. Based on the achieved results, it can be concluded that state-of-the-art hardware enables sufficient communication and sensing robustness against SJ, as RMS SJ values in the femtosecond range can be achieved."
  },
  {
    "date": "2026-01-21",
    "title": "Altermagnets versus Antiferromagnets",
    "authors": "V. P. Mineev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14878v1",
    "source": "arXiv",
    "abstract": "Altermagnets are metals with a momentum-dependent spin splitting of electron bands due to a specific crystal structure, which is invariant under time reversal only in combination with rotations and reflections. The developed phenomenological approach makes it possible to obtain a spectrum of electron bands in an altermagnet corresponding to an antiferromagnet with the same symmetry. The anomalous Hall effect is an inherent property of substances whose electron band dispersion is characterized by the Berry curvature. Calculations of the Berry curvature were performed for altermagnet analogs of collinear antiferromagnet, weak ferromagnetic antiferromagnet, and ferrimagnetic structures. It was shown that in the specific cases under consideration, the anomalous Hall effect in the absence of an external magnetic field is possible only in the state of a weak ferromagnet."
  },
  {
    "date": "2026-01-21",
    "title": "Finite-Sample Inference for Sparsely Permuted Linear Regression",
    "authors": "Hirofumi Ota, Masaaki Imaizumi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14872v1",
    "source": "arXiv",
    "abstract": "We study a noisy linear observation model with an unknown permutation called permuted/shuffled linear regression, where responses and covariates are mismatched and the permutation forms a discrete, factorial-size parameter. This unknown permutation is a key component of the data-generating process, yet its statistical investigation remains challenging due to its discrete nature. In this study, we develop a general statistical inference framework on the permutation and regression coefficients. First, we introduce a localization step that reduces the permutation space to a small candidate set building on recent advances in the repro samples method, whose miscoverage decays polynomially with the number of Monte Carlo samples. Then, based on this localized set, we provide statistical inference procedures: a conditional Monte Carlo test of permutation structures with valid finite-sample Type-I error control. We also develop coefficient inference that remains valid under alignment uncertainty of permutations. For computational purposes, we develop a linear assignment problem computable in polynomial time complexity and demonstrate that its solution asymptotically converges to that of the conventional least squares problem with large computational cost. Extensions to partially permuted designs and ridge regularization are also discussed. Extensive simulations and an application to Beijing air-quality data corroborate finite-sample validity, strong power to detect mismatches, and practical scalability."
  },
  {
    "date": "2026-01-21",
    "title": "Central exclusive production of $η$ and $η'$ mesons in diffractive proton-proton collisions at the LHC and the nature of the pomeron",
    "authors": "Piotr Lebiedowicz, Otto Nachtmann, Antoni Szczurek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14870v1",
    "source": "arXiv",
    "abstract": "Central exclusive production (CEP) of $η$ and $η'$ mesons in proton-proton collisions at high-energies is discussed. At the LHC the main mechanism for the production of these mesons should be double-pomeron ($\\rm I\\!P$-$\\rm I\\!P$) exchange, that is, the fusion reactions ${\\rm I\\!P I\\!P} \\to η, η'$. We show that for a scalar pomeron these fusion reactions are not possible. In contrast, in the tensor-pomeron model CEP of $η$ and $η'$ mesons via double-pomeron exchange is allowed. We discuss these reactions for the c.m. energy $\\sqrt{s} = 29.1$ GeV realised at the WA102 experiment and for $\\sqrt{s} = 13$ TeV corresponding to the LHC experiments. Cross sections and distributions are presented and discussed."
  },
  {
    "date": "2026-01-21",
    "title": "Dark Energy Survey: DESI-Independent Angular BAO Measurement",
    "authors": "J. Mena-Fernández, S. Avila, A. Porredon, H. Camacho, J. Muir, E. Sanchez, M. Adamow, K. Bechtol, R. Camilleri, G. Campailla, T. M. Davis, N. Deiosso, C. Doux, A. Drlica-Wagner, A. Ferté, R. A. Gruendl, W. G. Hartley, A. Pieres, M. Raveri, E. S. Rykoff, I. Sevilla-Noarbe, P. Shah, E. Sheldon, M. Vincenzi, B. Yanny, T. M. C. Abbott, M. Aguena, S. Allam, O. Alves, F. Andrade-Oliveira, J. Annis, D. Bacon, J. Blazek, S. Bocquet, D. Brooks, A. Carnero Rosell, J. Carretero, F. J. Castander, R. Cawthon, L. N. da Costa, M. E. da Silva Pereira, J. De Vicente, S. Desai, H. T. Diehl, B. Flaugher, J. Frieman, J. García-Bellido, M. Gatti, D. Gruen, G. Gutierrez, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, N. Jeffrey, K. Kuehn, O. Lahav, S. Lee, J. L. Marshall, F. Menanteau, R. Miquel, J. J. Mohr, J. Myles, R. L. C. Ogando, A. Palmese, W. J. Percival, A. A. Plazas Malagón, M. Rodriguez-Monroy, A. Roodman, S. Samuroff, D. Sanchez Cid, B. O. Sánchez, T. Shin, M. Smith, M. Soares-Santos, E. Suchyta, M. E. C. Swanson, D. L. Tucker, V. Vikram, A. R. Walker, N. Weaverdyck, M. Yamamoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14864v1",
    "source": "arXiv",
    "abstract": "We present a measurement of the angular Baryon Acoustic Oscillation (BAO) scale from the completed Dark Energy Survey (DES) dataset excluding the area of overlap with the Dark Energy Spectroscopic Instrument (DESI). We follow the same methodology and validation process as in the DES Y6 BAO analysis. We interpret the impact of this measurement in the context of the statistical preference for $w_0w_a$CDM over $Λ$CDM when combined with DES Y5 Type Ia supernovae (SN), Planck Cosmic Microwave Background (CMB) and DESI BAO. Based on our previous work, using the full Y6 DES BAO sample, in combination with SN, CMB and DESI DR1 BAO, added 0.3$σ$ in this preference (from 3.7$σ$ to 4.0$σ$), but this ignored possible correlations between datasets. Using our new DESI-independent DES BAO likelihood instead, we find a smaller increase in the statistical preference for $w_0w_a$CDM, from 3.7$σ$ to 3.8$σ$ when using DESI DR1 BAO, and from 4.0$σ$ to 4.1$σ$ when updating to the more recent DESI DR2 BAO. These significances reduce to 3.1$σ$ when using the new calibrated DES SN-Dovekie. Alongside this work, we publicly release BAOfit_wtheta, the BAO fitting code for the angular correlation function used in the DES Y6 BAO analysis."
  },
  {
    "date": "2026-01-21",
    "title": "Strategic Doctrine Language Models (sdLM): A Learning-System Framework for Doctrinal Consistency and Geopolitical Forecasting",
    "authors": "Olaf Yunus Laitinen Imanov, Taner Yilmaz, Derya Umut Kulali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14862v1",
    "source": "arXiv",
    "abstract": "We introduce Strategic Doctrine Language Models (sdLM), a learning-system framework for multi-document strategic reasoning with doctrinal consistency constraints and calibrated uncertainty. The approach combines multi-document attention, temporal encoding, and a doctrine-consistency layer to improve long-horizon forecasting and plan plausibility while reducing severe doctrinal violations. We evaluate sdLM using (i) expert-panel scoring of strategic scenarios (N=47), (ii) doctrine consistency on 336 doctrine publications (12,847 statements), and (iii) geopolitical forecasting on 127 historical counterfactuals (1945-2020) across 12-60 month horizons. Across these benchmarks, sdLM achieves higher strategic quality and better calibration than strong general-purpose LLM baselines, and remains competitive with human experts on long-horizon judgments. We further report ablations, scaling trends, and deployment-oriented performance/latency characteristics to clarify which components drive improvements and how they translate to operational settings."
  },
  {
    "date": "2026-01-21",
    "title": "Modal-Centric Field Inversion via Differentiable Proper Orthogonal Decomposition",
    "authors": "Rohit Sunil Kanchi, Sicheng He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14858v1",
    "source": "arXiv",
    "abstract": "Inverse problems in computational physics often require matching high-dimensional spatio-temporal fields, leading to prohibitive computational costs and ill-conditioned optimizations. We introduce modal-centric field inversion (MCFI), a paradigm that reformulates inverse problems in the reduced space of proper orthogonal decomposition (POD) modes rather than the full physical state space. By targeting dominant flow structures instead of point-wise field values, MCFI provides a compact, physically meaningful objective that naturally regularizes the inversion and dramatically reduces computational burden. Central to this framework is the differentiable POD: an adjoint-based method that efficiently computes sensitivities of POD modes with respect to model parameters, enabling gradient-based optimization in the modal space. We demonstrate MCFI on a one and two-dimensional modified viscous Burger's equation, optimizing spatially varying coefficients to match target dynamics through mode-matching. The adjoint formulation achieves computational cost independent of parameter dimension, in contrast to finite-difference approaches that scale linearly. MCFI establishes a foundation for scalable inverse design and model calibration in unsteady, high-dimensional systems."
  },
  {
    "date": "2026-01-21",
    "title": "Combatting noise in near-term quantum data centres",
    "authors": "Kenny Campbell, Ahmed Lawey, Mohsen Razavi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14845v1",
    "source": "arXiv",
    "abstract": "We analyse the performance of different error handling methods in the quantum data centre paradigm of distributed quantum computing. We compare the impact of quantum error detection, using the three-qubit repetition code and the [[4, 1, 2]] Leung-Nielsen-Chuang-Yamamoto code, on remote gates with that of conventional entanglement distillation techniques. Detailed classical simulation is used to obtain results for realistic near-term hardware."
  },
  {
    "date": "2026-01-21",
    "title": "Approval Ballot Triangles and Strict-Sense Ballots",
    "authors": "Andrew Beveridge, Ian Calaway",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14835v1",
    "source": "arXiv",
    "abstract": "We consider a family of binary triangular arrays, called approval ballot triangles (ABTs), that are in bijection with totally symmetric self-complementary plane partitions (TSSCPPs). These triangles correspond to a ballot process in which voters select their collection of approved candidates rather than voting for a single person. We situate ABTs within the ballot problem literature and then show that a strict-sense ballot can be decomposed into a list of sequentially compatible ABTs."
  },
  {
    "date": "2026-01-21",
    "title": "Comparative Study of Large Language Models on Chinese Film Script Continuation: An Empirical Analysis Based on GPT-5.2 and Qwen-Max",
    "authors": "Yuxuan Cao, Zida Yang, Ye Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14826v1",
    "source": "arXiv",
    "abstract": "As large language models (LLMs) are increasingly applied to creative writing, their performance on culturally specific narrative tasks warrants systematic investigation. This study constructs the first Chinese film script continuation benchmark comprising 53 classic films, and designs a multi-dimensional evaluation framework comparing GPT-5.2 and Qwen-Max-Latest. Using a \"first half to second half\" continuation paradigm with 3 samples per film, we obtained 303 valid samples (GPT-5.2: 157, 98.7% validity; Qwen-Max: 146, 91.8% validity). Evaluation integrates ROUGE-L, Structural Similarity, and LLM-as-Judge scoring (DeepSeek-Reasoner). Statistical analysis of 144 paired samples reveals: Qwen-Max achieves marginally higher ROUGE-L (0.2230 vs 0.2114, d=-0.43); however, GPT-5.2 significantly outperforms in structural preservation (0.93 vs 0.75, d=0.46), overall quality (44.79 vs 25.72, d=1.04), and composite scores (0.50 vs 0.39, d=0.84). The overall quality effect size reaches large effect level (d>0.8). GPT-5.2 excels in character consistency, tone-style matching, and format preservation, while Qwen-Max shows deficiencies in generation stability. This study provides a reproducible framework for LLM evaluation in Chinese creative writing."
  },
  {
    "date": "2026-01-21",
    "title": "Symmetry Informative and Agnostic Feature Disentanglement for 3D Shapes",
    "authors": "Tobias Weißberg, Weikang Wang, Paul Roetzer, Nafie El Amrani, Florian Bernard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14804v1",
    "source": "arXiv",
    "abstract": "Shape descriptors, i.e., per-vertex features of 3D meshes or point clouds, are fundamental to shape analysis. Historically, various handcrafted geometry-aware descriptors and feature refinement techniques have been proposed. Recently, several studies have initiated a new research direction by leveraging features from image foundation models to create semantics-aware descriptors, demonstrating advantages across tasks like shape matching, editing, and segmentation. Symmetry, another key concept in shape analysis, has also attracted increasing attention. Consequently, constructing symmetry-aware shape descriptors is a natural progression. Although the recent method $χ$ (Wang et al., 2025) successfully extracted symmetry-informative features from semantic-aware descriptors, its features are only one-dimensional, neglecting other valuable semantic information. Furthermore, the extracted symmetry-informative feature is usually noisy and yields small misclassified patches. To address these gaps, we propose a feature disentanglement approach which is simultaneously symmetry informative and symmetry agnostic. Further, we propose a feature refinement technique to improve the robustness of predicted symmetry informative features. Extensive experiments, including intrinsic symmetry detection, left/right classification, and shape matching, demonstrate the effectiveness of our proposed framework compared to various state-of-the-art methods, both qualitatively and quantitatively."
  },
  {
    "date": "2026-01-21",
    "title": "Synthetic Data Augmentation for Multi-Task Chinese Porcelain Classification: A Stable Diffusion Approach",
    "authors": "Ziyao Ling, Silvia Mirri, Paola Salomoni, Giovanni Delnevo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14791v1",
    "source": "arXiv",
    "abstract": "The scarcity of training data presents a fundamental challenge in applying deep learning to archaeological artifact classification, particularly for the rare types of Chinese porcelain. This study investigates whether synthetic images generated through Stable Diffusion with Low-Rank Adaptation (LoRA) can effectively augment limited real datasets for multi-task CNN-based porcelain classification. Using MobileNetV3 with transfer learning, we conducted controlled experiments comparing models trained on pure real data against those trained on mixed real-synthetic datasets (95:5 and 90:10 ratios) across four classification tasks: dynasty, glaze, kiln and type identification. Results demonstrate task-specific benefits: type classification showed the most substantial improvement (5.5\\% F1-macro increase with 90:10 ratio), while dynasty and kiln tasks exhibited modest gains (3-4\\%), suggesting that synthetic augmentation effectiveness depends on the alignment between generated features and task-relevant visual signatures. Our work contributes practical guidelines for deploying generative AI in archaeological research, demonstrating both the potential and limitations of synthetic data when archaeological authenticity must be balanced with data diversity."
  },
  {
    "date": "2026-01-21",
    "title": "Polarized Radiative Transfer of Kerr-Newman Black Hole",
    "authors": "Xin Li, Guo Sen, Pei Wang, En-Wei Liang, Xiao-Xiong Zeng, Kai Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14785v1",
    "source": "arXiv",
    "abstract": "In this analysis, we investigate the polarization radiation imaging of Kerr-Newman black holes, with a particular focus on the impact of black hole charge on photon propagation and polarization characteristics. By extending the traditional Walker-Penrose method, which is limited by its reliance on specific symmetric structures and Killing tensors, we overcome these limitations by constructing an ordinary differential equations (ODEs) numerical framework that combines the photon orbit equation with the polarization parallel transport equation. This allows for the self-consistent evolution of photon trajectories and polarization states in any spacetime backgrounds without relying on specific symmetries. Using this framework, we analyze the effects of black hole spin and charge on the polarization characteristics of radiation from both prograde and retrograde accretion disks. Our results show that black hole charge can significantly modify photon trajectories and polarization patterns: increasing charge compresses and distorts the EVPA structure on photon-ring scales, inducing localized rotations and asymmetries that may provide a potential diagnostic of a nonzero black hole charge."
  },
  {
    "date": "2026-01-21",
    "title": "Introducing Timepix2-Lite: A Miniaturized Readout Interface Enabling Nanosecond-Scale Half-Life Measurement",
    "authors": "O. Pavlas, B. Bergmann, M. Holik, M. Malich, S. Pospisil, P. Smolyanskiy, V. Vicha, R. Filgas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14782v1",
    "source": "arXiv",
    "abstract": "This paper presents Timepix2 Lite, a compact readout interface for the Timepix2 hybrid pixel detector, designed to provide high spatial and temporal resolution in a wide range of radiation detection applications. The Timepix2 Lite enables simultaneous energy and precise timing measurements on the nanosecond scale and supports advanced real-time data acquisition and visualization through the TrackLab software framework. Its compact and flexible architecture, enabled by the miniaturized design, allows seamless integration into diverse experimental setups, including nuclear spectroscopy, stratospheric balloon missions, and nanosecond-scale half-life measurements. As a case study, the half-life of the second excited state in 237Np was determined to be 67.5(7) ns for the 59.5 keV transition, consistent with previously reported results."
  },
  {
    "date": "2026-01-21",
    "title": "Polarization properties of changing-look active galactic nuclei: NGC 1365 and NGC 2992",
    "authors": "D. Hutsemékers, F. Marin, B. Agis González, J. -A. Acosta Pulido, M. Kokubo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14781v1",
    "source": "arXiv",
    "abstract": "Changing-look active galactic nuclei (CLAGNs) represent a rare class of AGNs that undergo transitions from type 1 (characterized by the presence of broad emission lines in their spectra) to type 2 (absence of broad emission lines) or vice versa, over timescales ranging from months to years. Since normal type 1 and type 2 AGNs are known to show different polarization properties, detailed investigations of the CLAGN polarization can shed light on the underlying mechanisms responsible for the changing-look phenomenon. We present new (spectro)polarimetric observations of two changing-look AGNs located in the core of the inclined spiral galaxies NGC 1365 and NGC 2992. Both AGNs are radio emitters, thereby enabling a comparison of their polarization to the radio jet axis, which defines the accretion disk geometry. In the case of NGC 1365, the AGN shows polarization characteristics consistent with those observed in type 1 Seyferts, in particular polarization parallel to the radio jet. This intrinsic polarization is modified by the wavelength-dependent dichroic extinction that occurs in the galaxy bar and that rotates the polarization angle at the shortest wavelengths. NGC 2992, on the other hand, is so inclined that dichroic dust extinction in the disk completely dominates the polarization of the AGN, thus overwhelming any polarization due to scattering. Consequently, the polarization properties remain essentially constant between the different AGN states, and the faint broad lines observed in the polarized flux are most likely not scattered light. Differential dilution between the continuum and the narrow-line polarizations can explain the unusually high polarization measured in the emission lines."
  },
  {
    "date": "2026-01-21",
    "title": "On the number of permutation-twisted dot products",
    "authors": "Ruben Carpenter, Colin Defant, Noah Kravitz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15276v1",
    "source": "arXiv",
    "abstract": "For distinct real numbers $a_1, \\ldots, a_n$ and distinct real numbers $b_1, \\ldots, b_n$, consider the sum $S=\\sum_{i=1}^n a_i b_{π(i)}$ as $π$ ranges over the permutations of $[n]$. We show that this sum always assumes at least $Ω(n^3)$ distinct values, which is optimal. This ``support'' bound complements recent work of Do, Nguyen, Phan, Tran, and Vu on the anticoncentration properties of $S$ when $π$ is chosen uniformly at random."
  },
  {
    "date": "2026-01-21",
    "title": "RayRoPE: Projective Ray Positional Encoding for Multi-view Attention",
    "authors": "Yu Wu, Minsik Jeon, Jen-Hao Rick Chang, Oncel Tuzel, Shubham Tulsiani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15275v1",
    "source": "arXiv",
    "abstract": "We study positional encodings for multi-view transformers that process tokens from a set of posed input images, and seek a mechanism that encodes patches uniquely, allows SE(3)-invariant attention with multi-frequency similarity, and can be adaptive to the geometry of the underlying scene. We find that prior (absolute or relative) encoding schemes for multi-view attention do not meet the above desiderata, and present RayRoPE to address this gap. RayRoPE represents patch positions based on associated rays but leverages a predicted point along the ray instead of the direction for a geometry-aware encoding. To achieve SE(3) invariance, RayRoPE computes query-frame projective coordinates for computing multi-frequency similarity. Lastly, as the 'predicted' 3D point along a ray may not be precise, RayRoPE presents a mechanism to analytically compute the expected position encoding under uncertainty. We validate RayRoPE on the tasks of novel-view synthesis and stereo depth estimation and show that it consistently improves over alternate position encoding schemes (e.g. 15% relative improvement on LPIPS in CO3D). We also show that RayRoPE can seamlessly incorporate RGB-D input, resulting in even larger gains over alternatives that cannot positionally encode this information."
  },
  {
    "date": "2026-01-21",
    "title": "Lucas-Pantograph Type Exponential, Trigonometric, and Hyperbolic Functions",
    "authors": "Ronald Orozco López",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15272v1",
    "source": "arXiv",
    "abstract": "In this paper, we include some new results for the Lucas calculus. A Lucas-Pantograph type exponential function is introduced. Additionally, we define Lucas-Pantograph type trigonometric functions, and some of their most notable identities are given: parity, sum and difference formulas, Pythagorean identities, double-angle identities, and some special values. Lucas-Pantograph type hyperbolic functions are also introduced."
  },
  {
    "date": "2026-01-21",
    "title": "On the Faltings height of the curve $y^2=x^n-1$",
    "authors": "Robert Wilms",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15271v1",
    "source": "arXiv",
    "abstract": "We compute the stable Faltings height of the hyperelliptic curve $X_n\\colon y^2=x^{n}-1$ for every odd integer $n\\ge 3$ in terms of special values of Euler's gamma function. In particular, we prove the bounds $$-0.975n< h_{\\mathrm{Fal}}(X_n)-\\tfrac{n}{8}\\log n<\\tfrac{9}{64}n\\log\\log n-0.263n.$$ As an application, we bound the Faltings height of any abelian variety with complex multiplication by the canonical CM-type of the $n$-th cyclotomic field by $\\frac{n}{8}\\log n+\\frac{9}{64}n\\log\\log n-0.136n$."
  },
  {
    "date": "2026-01-21",
    "title": "Global $+$-regularity of regular del Pezzo surfaces in mixed characteristic",
    "authors": "Hirotaka Onuki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15270v1",
    "source": "arXiv",
    "abstract": "Let $R = W(k)$ be the ring of Witt vectors over an algebraically closed field $k$ of characteristic $p > 2$. Let $M$ be a three-dimensional regular integral flat projective $R$-scheme such that $H^0(M,\\mathcal{O}_M) = R$ and the anticanonical sheaf $ω_M^{-1}$ is ample. We show that $M$ is globally $+$-regular if the closed fiber $M_k$ is reduced."
  },
  {
    "date": "2026-01-21",
    "title": "Many Experiments, Few Repetitions, Unpaired Data, and Sparse Effects: Is Causal Inference Possible?",
    "authors": "Felix Schur, Niklas Pfister, Peng Ding, Sach Mukherjee, Jonas Peters",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15254v1",
    "source": "arXiv",
    "abstract": "We study the problem of estimating causal effects under hidden confounding in the following unpaired data setting: we observe some covariates $X$ and an outcome $Y$ under different experimental conditions (environments) but do not observe them jointly; we either observe $X$ or $Y$. Under appropriate regularity conditions, the problem can be cast as an instrumental variable (IV) regression with the environment acting as a (possibly high-dimensional) instrument. When there are many environments but only a few observations per environment, standard two-sample IV estimators fail to be consistent. We propose a GMM-type estimator based on cross-fold sample splitting of the instrument-covariate sample and prove that it is consistent as the number of environments grows but the sample size per environment remains constant. We further extend the method to sparse causal effects via $\\ell_1$-regularized estimation and post-selection refitting."
  },
  {
    "date": "2026-01-21",
    "title": "Automating Idealness Proofs for Binary Programs with Application to Rectangle Packing",
    "authors": "Jamie Fravel, Robert Hildebrand",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15252v1",
    "source": "arXiv",
    "abstract": "An integer program is called ideal if its continuous relaxation coincides with its convex hull allowing the problem to be solved as a continuous program and offering substantial computational advantages. Proving idealness analytically can be extraordinarily tedious -- even for small formulations -- such proofs often span many pages of intricate case analysis which motivates the development of automated verification methods. We develop a general-purpose framework for certifying idealness in Mixed Binary Linear Programs (MBLPs), formulating the verification problem as a linear program when the data is fixed and as a nonconvex quadratic program when the data is parametric. We apply this framework to study several formulations of the rectangle packing problem that are conjectured to be pairwise-ideal, obtaining computational proofs where analytic proofs were previously unknown or impractical. As our second contribution, we introduce and model a novel generalization of the rectangle packing problem that enforces edge clearances between selected rectangles. We present both existing and novel MBLP formulations which arise from different encodings of the underlying disjunctive constraints. We perform some computational experiments on these formulations under a strip-packing objective to determine the importance of pairwise-idealness in practice."
  },
  {
    "date": "2026-01-21",
    "title": "The Effect of Scripts and Formats on LLM Numeracy",
    "authors": "Varshini Reddy, Craig W. Schmidt, Seth Ebner, Adam Wiemerslage, Yuval Pinter, Chris Tanner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15251v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have achieved impressive proficiency in basic arithmetic, rivaling human-level performance on standard numerical tasks. However, little attention has been given to how these models perform when numerical expressions deviate from the prevailing conventions present in their training corpora. In this work, we investigate numerical reasoning across a wide range of numeral scripts and formats. We show that LLM accuracy drops substantially when numerical inputs are rendered in underrepresented scripts or formats, despite the underlying mathematical reasoning being identical. We further demonstrate that targeted prompting strategies, such as few-shot prompting and explicit numeral mapping, can greatly narrow this gap. Our findings highlight an overlooked challenge in multilingual numerical reasoning and provide actionable insights for working with LLMs to reliably interpret, manipulate, and generate numbers across diverse numeral scripts and formatting styles."
  },
  {
    "date": "2026-01-21",
    "title": "Recommending Best Paper Awards for ML/AI Conferences via the Isotonic Mechanism",
    "authors": "Garrett G. Wen, Buxin Su, Natalie Collina, Zhun Deng, Weijie Su",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15249v1",
    "source": "arXiv",
    "abstract": "Machine learning and artificial intelligence conferences such as NeurIPS and ICML now regularly receive tens of thousands of submissions, posing significant challenges to maintaining the quality and consistency of the peer review process. This challenge is particularly acute for best paper awards, which are an important part of the peer review process, yet whose selection has increasingly become a subject of debate in recent years. In this paper, we introduce an author-assisted mechanism to facilitate the selection of best paper awards. Our method employs the Isotonic Mechanism for eliciting authors' assessments of their own submissions in the form of a ranking, which is subsequently utilized to adjust the raw review scores for optimal estimation of the submissions' ground-truth quality. We demonstrate that authors are incentivized to report truthfully when their utility is a convex additive function of the adjusted scores, and we validate this convexity assumption for best paper awards using publicly accessible review data of ICLR from 2019 to 2023 and NeurIPS from 2021 to 2023. Crucially, in the special case where an author has a single quota -- that is, may nominate only one paper -- we prove that truthfulness holds even when the utility function is merely nondecreasing and additive. This finding represents a substantial relaxation of the assumptions required in prior work. For practical implementation, we extend our mechanism to accommodate the common scenario of overlapping authorship. Finally, simulation results demonstrate that our mechanism significantly improves the quality of papers selected for awards."
  },
  {
    "date": "2026-01-21",
    "title": "Taxonomy-Aligned Risk Extraction from 10-K Filings with Autonomous Improvement Using LLMs",
    "authors": "Rian Dolphin, Joe Dursun, Jarrett Blankenship, Katie Adams, Quinton Pike",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15247v1",
    "source": "arXiv",
    "abstract": "We present a methodology for extracting structured risk factors from corporate 10-K filings while maintaining adherence to a predefined hierarchical taxonomy. Our three-stage pipeline combines LLM extraction with supporting quotes, embedding-based semantic mapping to taxonomy categories, and LLM-as-a-judge validation that filters spurious assignments. To evaluate our approach, we extract 10,688 risk factors from S&P 500 companies and examine risk profile similarity across industry clusters. Beyond extraction, we introduce autonomous taxonomy maintenance where an AI agent analyzes evaluation feedback to identify problematic categories, diagnose failure patterns, and propose refinements, achieving 104.7% improvement in embedding separation in a case study. External validation confirms the taxonomy captures economically meaningful structure: same-industry companies exhibit 63% higher risk profile similarity than cross-industry pairs (Cohen's d=1.06, AUC 0.82, p<0.001). The methodology generalizes to any domain requiring taxonomy-aligned extraction from unstructured text, with autonomous improvement enabling continuous quality maintenance and enhancement as systems process more documents."
  },
  {
    "date": "2026-01-21",
    "title": "Optimal control problem associated with three-dimensional critical convective Brinkman-Forchheimer equations",
    "authors": "Kush Kinra, Fernanda Cipriano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15242v1",
    "source": "arXiv",
    "abstract": "In this article, we are concerned about the velocity tracking optimal control problem for 3D critical convective Brinkman-Forchheimer equations defined on a simply connected bounded domain $\\mathbb{D}\\subset\\mathbb{R}^3$ with $\\mathrm{C}^2$-boundary $\\partial\\mathbb{D}$. The control is introduced through an external force. The objective is to optimally minimize a velocity tracking cost functional, for which the velocity vector field is oriented towards a target velocity. Most importantly, we are concerned about the first-order necessary optimality conditions for above-mentioned optimal control problem which is the main challenging task of this article. To overcome the difficulties related to the differentiability of the control-to-state mapping, consequence of the lack of regularity of the state variable on bounded domains, we first establish some intermediate optimality conditions and then pass to the limit."
  },
  {
    "date": "2026-01-21",
    "title": "Multi-context principal component analysis",
    "authors": "Kexin Wang, Salil Bhate, João M. Pereira, Joe Kileel, Matylda Figlerowicz, Anna Seigal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15239v1",
    "source": "arXiv",
    "abstract": "Principal component analysis (PCA) is a tool to capture factors that explain variation in data. Across domains, data are now collected across multiple contexts (for example, individuals with different diseases, cells of different types, or words across texts). While the factors explaining variation in data are undoubtedly shared across subsets of contexts, no tools currently exist to systematically recover such factors. We develop multi-context principal component analysis (MCPCA), a theoretical and algorithmic framework that decomposes data into factors shared across subsets of contexts. Applied to gene expression, MCPCA reveals axes of variation shared across subsets of cancer types and an axis whose variability in tumor cells, but not mean, is associated with lung cancer progression. Applied to contextualized word embeddings from language models, MCPCA maps stages of a debate on human nature, revealing a discussion between science and fiction over decades. These axes are not found by combining data across contexts or by restricting to individual contexts. MCPCA is a principled generalization of PCA to address the challenge of understanding factors underlying data across contexts."
  },
  {
    "date": "2026-01-21",
    "title": "De Giorgi's regularity theory for elliptic, parabolic and kinetic equations",
    "authors": "Cyril Imbert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15238v1",
    "source": "arXiv",
    "abstract": "This book presents a comprehensive regularity theory for solutions of elliptic, parabolic, and kinetic equations. The foundation of this theory was laid by E. De Giorgi's groundbreaking resolution of Hilbert's nineteenth problem in 1956. The innovative tools he developed to tackle this problem proved to be remarkably versatile. In 1957, just one year later, J. Nash independently developed analogous techniques for parabolic equations, concurrently with De Giorgi's research. By the year 2000, these techniques had been extended to address elliptic and parabolic equations featuring integral diffusion, such as the fractional Laplacian. More recently, the theory has evolved to encompass kinetic equations, accommodating both local and integral diffusions. This book aims to present these results in a unified and coherent manner, beginning with the classical elliptic framework and progressing through to the most recent advancements in kinetic equations."
  },
  {
    "date": "2026-01-21",
    "title": "Tracing 3D Anatomy in 2D Strokes: A Multi-Stage Projection Driven Approach to Cervical Spine Fracture Identification",
    "authors": "Fabi Nahian Madhurja, Rusab Sarmun, Muhammad E. H. Chowdhury, Adam Mushtak, Israa Al-Hashimi, Sohaib Bassam Zoghoul",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15235v1",
    "source": "arXiv",
    "abstract": "Cervical spine fractures are critical medical conditions requiring precise and efficient detection for effective clinical management. This study explores the viability of 2D projection-based vertebra segmentation for vertebra-level fracture detection in 3D CT volumes, presenting an end-to-end pipeline for automated analysis of cervical vertebrae (C1-C7). By approximating a 3D volume through optimized 2D axial, sagittal, and coronal projections, regions of interest are identified using the YOLOv8 model from all views and combined to approximate the 3D cervical spine area, achieving a 3D mIoU of 94.45 percent. This projection-based localization strategy reduces computational complexity compared to traditional 3D segmentation methods while maintaining high performance. It is followed by a DenseNet121-Unet-based multi-label segmentation leveraging variance- and energy-based projections, achieving a Dice score of 87.86 percent. Strategic approximation of 3D vertebral masks from these 2D segmentation masks enables the extraction of individual vertebra volumes. The volumes are analyzed for fractures using an ensemble of 2.5D Spatio-Sequential models incorporating both raw slices and projections per vertebra for complementary evaluation. This ensemble achieves vertebra-level and patient-level F1 scores of 68.15 and 82.26, and ROC-AUC scores of 91.62 and 83.04, respectively. We further validate our approach through an explainability study that provides saliency map visualizations highlighting anatomical regions relevant for diagnosis, and an interobserver variability analysis comparing our model's performance with expert radiologists, demonstrating competitive results."
  },
  {
    "date": "2026-01-21",
    "title": "How to Verify a Turing Machine with Dafny",
    "authors": "Edgar F. A. Lederer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15230v1",
    "source": "arXiv",
    "abstract": "This paper describes the formal verification of two Turing machines using the program verifier Dafny. Both machines are deciders, so we prove total correctness. They are typical first examples of Turing machines used in any course of Theoretical Computer Science; in fact, the second machine is literally taken from a relevant textbook. Usually, the correctness of such machines is made plausible by some informal explanations of their basic ideas, augmented with a few sample executions, but neither by rigorous mathematical nor mechanized formal proof. No wonder: The invariants (and variants) required for such proofs are big artifacts, peppered with overpowering technical details. Finding and checking these artifacts without mechanical support is practically impossible, and such support is only available since recent times. But nowadays, just because of these technicalities, with such subjects under proof a program verifier can really show off and demonstrate its capabilities."
  },
  {
    "date": "2026-01-21",
    "title": "Vieta jumping and small norms in quadratic number fields",
    "authors": "Franz Lemmermeyer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15229v1",
    "source": "arXiv",
    "abstract": "In this article we explain the connection between the famous problemfrom the IMO 1988 and elements of small norms in quadratic number fields with parametrized units."
  },
  {
    "date": "2026-01-21",
    "title": "De Sitter Momentum Space",
    "authors": "Nathan Belrhali, Arthur Poisson, Sébastien Renaux-Petel, Denis Werth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15228v1",
    "source": "arXiv",
    "abstract": "We construct a natural and nonperturbative momentum space for quantum field theory on $(d+1)$-dimensional de Sitter (dS) spacetime in the Poincaré slicing, adapted to early Universe cosmology. In particular, we identify the dS frequency as the unitary-representation label of the dS isometry group $\\mathrm{SO}(1, d+1)$. By diagonalizing the quadratic Casimir together with spatial translations, we provide a harmonic expansion of operators in what we call the Kontorovitch-Lebedev-Fourier (KLF) space. This momentum space shares many structural properties with its Minkowski counterpart, for instance: equations of motion reduce to algebraic equations, and the quadratic dynamics provides a simple propagator analogous to flat space. We reformulate the perturbative computation of in-in correlators in KLF momentum space, showing from first principles how time integrals turn into frequency-space integrals over meromorphic functions. We show how our construction streamlines computations, naturally accommodates the contributions from principal and complementary series in the Källén-Lehmann spectral decomposition of composite operators, and leads to an inversion formula for the spectral density."
  },
  {
    "date": "2026-01-21",
    "title": "Second Robin eigenvalue bounds for Schrödinger operators on Riemannian surfaces",
    "authors": "Railane Antonia, Marcos P. Cavalcante, Vinicius Souza",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15213v1",
    "source": "arXiv",
    "abstract": "Let $(Σ^2,ds^2)$ be a compact Riemannian surface, possibly with boundary, and consider Schrödinger-type operators of the form $L=Δ+V-aK$ together with natural Robin and Steklov-type boundary conditions incorporating a boundary potential $W$ and (in the curvature-corrected setting) the geodesic curvature $κ_g$ of $\\partialΣ$. Our main contribution is a geometric upper bound for the second Robin eigenvalue in terms of the topology of $Σ$ and the integrals of $V$ and $W$, obtained via a Hersch balancing argument on the capped surface. As a geometric application, we derive sharp topological restrictions for compact two-sided free boundary minimal surfaces of Morse index at most one inside geodesic balls of negatively curved pinched Cartan--Hadamard $3$-manifolds under a mild radius condition. We also prove complementary upper bounds for first eigenvalues in the closed and Robin settings, including rigidity in the curvature-corrected case, and we establish Steklov-type estimates in a coercive regime where the Dirichlet-to-Neumann operator is well defined for all boundary data."
  },
  {
    "date": "2026-01-21",
    "title": "Variational and Quasi-variational solutions to thick flows",
    "authors": "Jos\\é Francisco Rodrigues, Lisa Santos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15206v1",
    "source": "arXiv",
    "abstract": "We formulate the flow of thick fluids as evolution variational and quasi-variational inequalities, with a variable threshold on the absolute value of the deformation rate tensor. In the variational case, we show the existence and uniqueness of strong and weak solutions in the viscous case and also the existence of strong and weak solutions in the inviscid case. These problems correspond to solve, respectively, the Navier-Stokes and the Euler equations with an additional generalised Lagrange multiplier associated with the threshold on the deformation rate tensor. Applying the continuous dependence of strong and weak solutions to the variational inequalities for the Navier-Stokes with constraints on the derivatives, and on their respective generalised Lagrange multipliers, we can solve the case of the variable threshold depending on the solution itself that correspond to quasi-variational problems. \\vspace{2mm} $$ \\text{Dedicated to Vsevolod Alekseevich Solonnikov, {\\em in memoriam}}$$"
  },
  {
    "date": "2026-01-21",
    "title": "Magneto-Archeology of White Dwarfs. Revisiting the fossil field scenario with observational constraints during the red giant branch",
    "authors": "Lukas Einramhof, Lisa Bugnet, Leila Magdalena Calcaferro, Lucas Barrault, Srijan Bharati Das",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15203v1",
    "source": "arXiv",
    "abstract": "The detection of strong, large-scale magnetic fields at the surface of only the oldest population of white dwarfs might point towards a hidden internal magnetic field slowly rising to the surface. In addition, strong magnetic fields have recently been measured through asteroseismology in the radiative interiors of red giant stars, the progenitors of white dwarfs. To investigate the potential connection between these observations, we revisit the fossil field framework by using the asteroseismic detections to constrain the strength of such magnetic fields as they evolve to the white dwarf stage. We assume that the magnetic field was either created during the main sequence core convection or that it fills the radiative interior as the star evolves on the red giant branch. From these, we evolve the magnetic flux, allowing for magnetic diffusion along the evolution of a 1.5Msun modelled star. We find that measured field strengths in red giants attributed to the hydrogen-burning shell are compatible with the field amplitudes and emergence timescales of magnetized white dwarfs. On the contrary, magnetic fields generated solely from a convective-core dynamo on the main-sequence and detectable during the red giant branch would be buried too deep in the star and not match the breakout timescales and the field strengths of magnetic white dwarfs. A broadly magnetized internal radiative zone during the red giant branch is therefore key for the fossil field theory to connect magnetic fields observed along the late evolution of stars."
  },
  {
    "date": "2026-01-21",
    "title": "A Computer Vision Hybrid Approach: CNN and Transformer Models for Accurate Alzheimer's Detection from Brain MRI Scans",
    "authors": "Md Mahmudul Hoque, Shuvo Karmaker, Md. Hadi Al-Amin, Md Modabberul Islam, Jisun Junayed, Farha Ulfat Mahi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15202v1",
    "source": "arXiv",
    "abstract": "Early and accurate classification of Alzheimers disease (AD) from brain MRI scans is essential for timely clinical intervention and improved patient outcomes. This study presents a comprehensive comparative analysis of five CNN architectures (EfficientNetB0, ResNet50, DenseNet201, MobileNetV3, VGG16), five Transformer-based models (ViT, ConvTransformer, PatchTransformer, MLP-Mixer, SimpleTransformer), and a proposed hybrid model named Evan_V2. All models were evaluated on a four-class AD classification task comprising Mild Dementia, Moderate Dementia, Non-Demented, and Very Mild Dementia categories. Experimental findings show that CNN architectures consistently achieved strong performance, with ResNet50 attaining 98.83% accuracy. Transformer models demonstrated competitive generalization capabilities, with ViT achieving the highest accuracy among them at 95.38%. However, individual Transformer variants exhibited greater class-specific instability. The proposed Evan_V2 hybrid model, which integrates outputs from ten CNN and Transformer architectures through feature-level fusion, achieved the best overall performance with 99.99% accuracy, 0.9989 F1-score, and 0.9968 ROC AUC. Confusion matrix analysis further confirmed that Evan_V2 substantially reduced misclassification across all dementia stages, outperforming every standalone model. These findings highlight the potential of hybrid ensemble strategies in producing highly reliable and clinically meaningful diagnostic tools for Alzheimers disease classification."
  },
  {
    "date": "2026-01-21",
    "title": "Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub",
    "authors": "Ramtin Ehsani, Sakshi Pathak, Shriya Rawal, Abdullah Al Mujahid, Mia Mohammad Imran, Preetha Chatterjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15195v1",
    "source": "arXiv",
    "abstract": "AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five coding agents across GitHub. (RQ1) We first quantitatively characterize merged and not-merged PRs along four broad dimensions: 1) merge outcomes across task types, 2) code changes, 3) CI build results, and 4) review dynamics. We observe that tasks related to documentation, CI, and build update achieve the highest merge success, whereas performance and bug-fix tasks perform the worst. Not-merged PRs tend to involve larger code changes, touch more files, and often do not pass the project's CI/CD pipeline validation. (RQ2) To further investigate why some agentic PRs are not merged, we qualitatively analyze 600 PRs to derive a hierarchical taxonomy of rejection patterns. This analysis complements the quantitative findings in RQ1 by uncovering rejection reasons not captured by quantitative metrics, including lack of meaningful reviewer engagement, duplicate PRs, unwanted feature implementations, and agent misalignment. Together, our findings highlight key socio-technical and human-AI collaboration factors that are critical to improving the success of future agentic workflows."
  },
  {
    "date": "2026-01-21",
    "title": "The early r-process nucleosynthesis scenarios",
    "authors": "Noam Soker",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15187v1",
    "source": "arXiv",
    "abstract": "I compare seven actively studied r-process nucleosynthesis scenarios against observed properties of r-process elements in the early Universe, and conclude that the most likely scenario to contribute to the site of elements below the third r-process peak is the magnetorotational r-process scenario, and that of the third peak is the common envelope jets supernova (CEJSN) r-process scenario. The collapsar and CEJSN r-process scenario might also contribute to the lighter r-process elements, and the binary neutron star (NS-NS) merger r-process scenario might contribute to the third r-process peak. The magnetar, the wind from the newly born NS, and the accretion-induced collapse of a white dwarf r-process scenarios fall short in explaining observations. They might exist, but cannot be major contributors to the r-process in the early Universe. To constrain r-process scenarios in the early Universe, I require that they explain the large scatter in the r-process abundances of very metal-poor stars, account for the correlation between light r-process nucleosynthesis and iron production, and the lack of correlation between the third peak r-process production and iron production, as inferred from very metal-poor stars. I discuss the diversity of the CEJSN r-process scenario and encourage extending its exploration."
  },
  {
    "date": "2026-01-21",
    "title": "A nomenclature for individual exocomets",
    "authors": "Alain Lecavelier des Etangs, Paul A. Strøm, Darryl Z. Seligman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15176v1",
    "source": "arXiv",
    "abstract": "With recent observational advancements, exocomet studies have entered a new era: we have moved from an epoch where exocomets' signatures were analysed to identify their true nature to a new epoch where individual exocomets' detections are studied in detail to characterise the observed bodies. In this context, as with other astronomical objects such as exoplanets and minor bodies in the solar system, a nomenclature system is needed to uniquely identify any observed exocometary body. Here, after outlining the purpose of a nomenclature and its required characteristics, we review the information on exocomets that can be included in the nomenclature. Finally, we propose an exocomet nomenclature scheme to identify the individual exocomets that have been discovered or yet to be discovered. Examples of nomenclature names of a few archetypal exocomets are provided."
  },
  {
    "date": "2026-01-21",
    "title": "Combinatorial Ricci Flows and Hyperbolic Structures on a Class of Compact $3$-Manifolds with Boundary",
    "authors": "Xinrong Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15174v1",
    "source": "arXiv",
    "abstract": "In this paper, we study a combinatorial Ricci flow on closed pseudo $3$-manifolds $(M,\\mathcal{T})$. We prove that if every edge in the triangulation $\\mathcal{T}$ has valence at least $9$, then the combinatorial Ricci flow converges exponentially fast to a hyperbolic metric. As a consequence, for any compact $3$-manifold $N$ with boundary admitting an ideal triangulation $\\mathcal{T}_N$ whose edges all have valence at least $9$, there exists a unique complete hyperbolic metric with totally geodesic boundary on $N$ such that $\\mathcal{T}_N$ is isotopic to a geometric decomposition of $N$. This provides a partial solution to the conjecture of Costantino, Frigerio, Martelli and Petronio, and hence an affirmative answer of Thurston's geometric ideal triangulation conjecture for such manifolds. Moreover, we obtain explicit upper and lower bounds for the resulting hyperbolic metric."
  },
  {
    "date": "2026-01-21",
    "title": "Integrating OTFS in Airplane-Aided Next-Generation Networking",
    "authors": "Ashok S Kumar, Shashank Shekhar, Gokularam Muthukrishnan, Muralikrishnan Srinivasan, Sheetal Kalyani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15166v1",
    "source": "arXiv",
    "abstract": "Next-generation networks explore the opportunistic assistance of airliner/high-altitude platforms (HAPs) in delivering high data rates for terrestrial networks to ensure consistent and reliable communication. When an airliner/HAP moves at very high speeds, its mobility has a substantial impact on ensuring seamless connectivity, stable signal strength, and reliable data transmission. Orthogonal time frequency space (OTFS) modulation has been shown to provide notable improvement in performance when handling Doppler effects during high-mobility situations. This paper presents an OTFS-based airplane-aided next-generation networking system. In the proposed system, the airliner/HAPs are equipped with a planar antenna array that applies null steering beamforming (NSB) at the transmitter for communication with terrestrial users. A comprehensive performance comparison between OTFS and orthogonal frequency division multiplexing (OFDM) is performed under varying airliner altitude, velocity, array dimension, and Rician factor conditions. The simulation results show that OTFS consistently outperforms OFDM, achieving a lower bit error rate (BER) and more stable performance across different airliner altitudes, velocities, array dimensions, and propagation environments."
  },
  {
    "date": "2026-01-21",
    "title": "Increasing the stability of a superfluid in a rotating necklace potential",
    "authors": "Giulio Nesti, Luca Pezzè",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15159v1",
    "source": "arXiv",
    "abstract": "Recent experiments have probed the stability of ring superfluids in the presence of Josephson barriers or Gaussian impurities. Here we present a theoretical analysis that extends beyond the regimes explored so far. We study the onset of dynamical instabilities induced by a one-dimensional potential rotating at an effective angular velocity $ω$, addressing both the tunneling and the hydrodynamic regimes. We show that the critical angular velocity $ω_c$ increases almost linearly with the number of barriers, with a slope set by their height and width. When the system is quenched into the dynamically unstable regime, it emits multiple solitons, which can switch or even reverse the direction of circulation. The stabilization mechanism is robust against imperfections of the potential and does not require a perfectly periodic array of barriers. In particular, we find that adding a disordered speckle potential to an ordered array of barriers can further increase $ω_c$: disorder can therefore make a ring superfluid more resilient to dynamical instabilities."
  },
  {
    "date": "2026-01-21",
    "title": "Outcome-Based RL Provably Leads Transformers to Reason, but Only With the Right Data",
    "authors": "Yuval Ran-Milo, Yotam Alexander, Shahar Mendel, Nadav Cohen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15158v1",
    "source": "arXiv",
    "abstract": "Transformers trained via Reinforcement Learning (RL) with outcome-based supervision can spontaneously develop the ability to generate intermediate reasoning steps (Chain-of-Thought). Yet the mechanism by which sparse rewards drive gradient descent to discover such systematic reasoning remains poorly understood. We address this by analyzing the gradient flow dynamics of single-layer Transformers on a synthetic graph traversal task that cannot be solved without Chain-of-Thought (CoT) but admits a simple iterative solution. We prove that despite training solely on final-answer correctness, gradient flow drives the model to converge to a structured, interpretable algorithm that iteratively traverses the graph vertex-by-vertex. We characterize the distributional properties required for this emergence, identifying the critical role of \"simple examples\": instances requiring fewer reasoning steps. When the training distribution places sufficient mass on these simpler instances, the model learns a generalizable traversal strategy that extrapolates to longer chains; when this mass vanishes, gradient-based learning becomes infeasible. We corroborate our theoretical results through experiments on synthetic data and with real-world language models on mathematical reasoning tasks, validating that our theoretical findings carry over to practical settings."
  },
  {
    "date": "2026-01-21",
    "title": "Chemical evolution of antimatter domains in early Universe",
    "authors": "A. I. Dembitskaia, Stephane Weiss, M. Yu. Khlopov, M. A. Krasnov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15147v1",
    "source": "arXiv",
    "abstract": "According to modern physics, our Universe is baryon-asymmetric. That phenomenon can not be described in the frameworks of the Standard Model of particle physics. Globally, the Universe consists of baryon matter. However, some scenarios can lead to the existence of local antimatter domains. In the research, the chemical evolution of such an isolated antimatter domain, surrounded by baryonic matter, is studied. The size of the domain is estimated according to the conditions of its survival in baryon surrounding, and the process of annihilation at its border is taken into account."
  },
  {
    "date": "2026-01-21",
    "title": "Weather Estimation for Integrated Sensing and Communication",
    "authors": "Victoria Palhares, Artjom Grudnitsky, Silvio Mandelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15145v1",
    "source": "arXiv",
    "abstract": "One of the key features of sixth generation (6G) mobile communications will be integrated sensing and communication (ISAC). While the main goal of ISAC in standardization efforts is to detect objects, the byproducts of radar operations can be used to enable new services in 6G, such as weather sensing. Even though weather radars are the most prominent technology for weather detection and monitoring, they are expensive and usually neglect areas in close vicinity. To this end, we propose reusing the dense deployment of 6G base stations for weather sensing purposes by detecting and estimating weather conditions. We implement both a classifier and a regressor as a convolutional neural network trained across measurements with varying precipitation rates and wind speeds. We implement our approach in an ISAC proof-of-concept, and conduct a multi-week experiment campaign. Experimental results show that we are able to jointly and accurately classify weather conditions with accuracies of 99.38% and 98.99% for precipitation rate and wind speed, respectively. For estimation, we obtain errors of 1.2 mm/h and 1.5 km/h, for precipitation rate and wind speed, respectively. These findings indicate that weather sensing services can be reliably deployed in 6G ISAC networks, broadening their service portfolio and boosting their market value."
  },
  {
    "date": "2026-01-21",
    "title": "Properties and Possible Physical Origins of $γ$-ray Emission in Extreme Synchrotron Blazars",
    "authors": "Ji-Shun Lian, Jia-Xuan Li, Ze-Rui Wang, Rui-Qi Huang, Hai-Ming Zhang, Jin Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15142v1",
    "source": "arXiv",
    "abstract": "Extreme synchrotron blazars, characterized by a first peak in their broadband spectral energy distributions (SEDs) at frequencies exceeding $10^{17}$ Hz, often exhibit a second peak beyond 1~TeV. These sources serve as ideal laboratories for studying particle acceleration and radiation mechanisms in relativistic jets. In this work, we systematically analyze the $\\sim$16-year Fermi-LAT observational data for 25 extreme high-synchrotron-peaked BL Lacs (EHBLs). The results indicate that the majority of these sources display stable or low flux levels in the GeV band, with only 6 sources showing significant variability at a confidence level exceeding 5$σ$. The time-averaged spectra over the 16-year period for most EHBLs are well described by a hard power-law model, with photon indices predominantly clustered between 1.7 and 1.8. Using Fermi-LAT data in conjunction with multiwavelength observations compiled from the literature, we construct broadband SEDs for these EHBLs and fit them with a one-zone synchrotron + synchrotron-self-Compton (SSC) model. We find that this simplified theoretical framework is sufficient for modeling the observed SEDs of most of these EHBLs, albeit requiring relatively higher electron energies compared to other $γ$-ray emitting HBLs, and at times under-representing the UV emission. Based on the SED fitting results, we investigate the physical properties of the emission regions in these EHBLs and compare them with those of other $γ$-ray emitting HBLs. Consistent with other GeV--TeV $γ$-ray-emitting BL Lacs, the jets in these EHBLs are marked by low radiation efficiency and low magnetization."
  },
  {
    "date": "2026-01-21",
    "title": "Illustrating Special-Relativity Phenomena via Gaussian Ray Optics",
    "authors": "M. A. Bouchene",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15137v1",
    "source": "arXiv",
    "abstract": "We highlight the correspondence between one-dimensional Lorentz transformations, which relate events observed from two distinct inertial reference frames, and ray transfer transformations in Gaussian optics. Specifically, we identify optical systems whose transfer matrices reproduce the mathematical structure of the Lorentz transformation. Within this framework, we show that fundamental effects of special relativity as time dilatation, length contraction and loss of synchronicity find a direct counterpart in the behavior of light rays deviated by a diverging lens, thereby providing a novel and illustrative optical equivalence of relativistic phenomena. This article is intended for a broad audience of physicists. The correspondence described is general and may interest students with a moderate background in special relativity and optics, as well as teachers in the corresponding fields."
  },
  {
    "date": "2026-01-21",
    "title": "Vehicle Routing with Finite Time Horizon using Deep Reinforcement Learning with Improved Network Embedding",
    "authors": "Ayan Maity, Sudeshna Sarkar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15131v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the vehicle routing problem with a finite time horizon. In this routing problem, the objective is to maximize the number of customer requests served within a finite time horizon. We present a novel routing network embedding module which creates local node embedding vectors and a context-aware global graph representation. The proposed Markov decision process for the vehicle routing problem incorporates the node features, the network adjacency matrix and the edge features as components of the state space. We incorporate the remaining finite time horizon into the network embedding module to provide a proper routing context to the embedding module. We integrate our embedding module with a policy gradient-based deep Reinforcement Learning framework to solve the vehicle routing problem with finite time horizon. We trained and validated our proposed routing method on real-world routing networks, as well as synthetically generated Euclidean networks. Our experimental results show that our method achieves a higher customer service rate than the existing routing methods. Additionally, the solution time of our method is significantly lower than that of the existing methods."
  },
  {
    "date": "2026-01-21",
    "title": "BREPS: Bounding-Box Robustness Evaluation of Promptable Segmentation",
    "authors": "Andrey Moskalenko, Danil Kuznetsov, Irina Dudko, Anastasiia Iasakova, Nikita Boldyrev, Denis Shepelev, Andrei Spiridonov, Andrey Kuznetsov, Vlad Shakhuro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15123v1",
    "source": "arXiv",
    "abstract": "Promptable segmentation models such as SAM have established a powerful paradigm, enabling strong generalization to unseen objects and domains with minimal user input, including points, bounding boxes, and text prompts. Among these, bounding boxes stand out as particularly effective, often outperforming points while significantly reducing annotation costs. However, current training and evaluation protocols typically rely on synthetic prompts generated through simple heuristics, offering limited insight into real-world robustness. In this paper, we investigate the robustness of promptable segmentation models to natural variations in bounding box prompts. First, we conduct a controlled user study and collect thousands of real bounding box annotations. Our analysis reveals substantial variability in segmentation quality across users for the same model and instance, indicating that SAM-like models are highly sensitive to natural prompt noise. Then, since exhaustive testing of all possible user inputs is computationally prohibitive, we reformulate robustness evaluation as a white-box optimization problem over the bounding box prompt space. We introduce BREPS, a method for generating adversarial bounding boxes that minimize or maximize segmentation error while adhering to naturalness constraints. Finally, we benchmark state-of-the-art models across 10 datasets, spanning everyday scenes to medical imaging. Code - https://github.com/emb-ai/BREPS."
  },
  {
    "date": "2026-01-21",
    "title": "Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories",
    "authors": "Qian Xiong, Yuekai Huang, Yujia Zheng, Tianhao Li, Ziyou Jiang, Zhiyuan Chang, Zhaoyang Li, Huanxiang Feng, Mingyang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15120v1",
    "source": "arXiv",
    "abstract": "LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of \"intent deviation\" severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to reliance on hand-crafted user requests, while the latter suffers from distribution shift from the real tools in the wild. Additionally, both methods lack negative samples tailored to intent deviation scenarios, hindering effective guidance on preference learning. We introduce RISE, a \"Real-to-Virtual\" method designed to mitigate intent deviation. Anchoring on verified tool primitives, RISE synthesizes virtual trajectories and generates diverse negative samples through mutation on critical parameters. With synthetic data, RISE fine-tunes backbone LLMs via the two-stage training for intent alignment. Evaluation results demonstrate that data synthesized by RISE achieve promising results in eight metrics covering user requires, execution trajectories and agent responses. Integrating with training, RISE achieves an average 35.28% improvement in Acctask (task completion) and 23.27% in Accintent (intent alignment), outperforming SOTA baselines by 1.20--42.09% and 1.17--54.93% respectively."
  },
  {
    "date": "2026-01-21",
    "title": "Vision Models for Medical Imaging: A Hybrid Approach for PCOS Detection from Ultrasound Scans",
    "authors": "Md Mahmudul Hoque, Md Mehedi Hassain, Muntakimur Rahaman, Md. Towhidul Islam, Shaista Rani, Md Sharif Mollah",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15119v1",
    "source": "arXiv",
    "abstract": "Polycystic Ovary Syndrome (PCOS) is the most familiar endocrine illness in women of reproductive age. Many Bangladeshi women suffer from PCOS disease in their older age. The aim of our research is to identify effective vision-based medical image analysis techniques and evaluate hybrid models for the accurate detection of PCOS. We introduced two novel hybrid models combining convolutional and transformer-based approaches. The training and testing data were organized into two categories: \"infected\" (PCOS-positive) and \"noninfected\" (healthy ovaries). In the initial stage, our first hybrid model, 'DenConST' (integrating DenseNet121, Swin Transformer, and ConvNeXt), achieved 85.69% accuracy. The final optimized model, 'DenConREST' (incorporating Swin Transformer, ConvNeXt, DenseNet121, ResNet18, and EfficientNetV2), demonstrated superior performance with 98.23% accuracy. Among all evaluated models, DenConREST showed the best performance. This research highlights an efficient solution for PCOS detection from ultrasound images, significantly improving diagnostic accuracy while reducing detection errors."
  },
  {
    "date": "2026-01-21",
    "title": "From Who They Are to How They Act: Behavioral Traits in Generative Agent-Based Models of Social Media",
    "authors": "Valerio La Gatta, Gian Marco Orlando, Marco Perillo, Ferdinando Tammaro, Vincenzo Moscato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15114v1",
    "source": "arXiv",
    "abstract": "Generative Agent-Based Modeling (GABM) leverages Large Language Models to create autonomous agents that simulate human behavior in social media environments, demonstrating potential for modeling information propagation, influence processes, and network phenomena. While existing frameworks characterize agents through demographic attributes, personality traits, and interests, they lack mechanisms to encode behavioral dispositions toward platform actions, causing agents to exhibit homogeneous engagement patterns rather than the differentiated participation styles observed on real platforms. In this paper, we investigate the role of behavioral traits as an explicit characterization layer to regulate agents' propensities across posting, re-sharing, commenting, reacting, and inactivity. Through large-scale simulations involving 980 agents and validation against real-world social media data, we demonstrate that behavioral traits are essential to sustain heterogeneous, profile-consistent participation patterns and enable realistic content propagation dynamics through the interplay of amplification- and interaction-oriented profiles. Our findings establish that modeling how agents act-not only who they are-is necessary for advancing GABM as a tool for studying social media phenomena."
  },
  {
    "date": "2026-01-21",
    "title": "Traveling waves for bistable reaction-diffusion-convection equations with discontinuous density-dependent coefficients",
    "authors": "Pavel Drábek, Soyeun Jung, Eunkyung Ko, Michaela Zahradníková",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15107v1",
    "source": "arXiv",
    "abstract": "Continuing our previous study \\cite{DJKZ} on the monostable reaction-diffusion-convection equation, we analyze the bistable case under weak regularity assumptions. Our approach applies monostable results on the subintervals where the reaction term $g$ has constant sign, thereby establishing both existence and nonexistence of bistable traveling wave solutions. We extend the results of \\cite{MMM04}, obtained for $p=2$ under higher regularity assumptions ($d \\in C^1[0,1]$, $g,h \\in C[0,1]$), to the $p$-Laplacian with $p>1$ in our weak regularity setting."
  },
  {
    "date": "2026-01-21",
    "title": "One scale to rule them all: interpretable multi-scale Deep Learning for predicting cell survival after proton and carbon ion irradiation",
    "authors": "Giulio Bordieri, Giorgio Cartechini, Anna Bianchi, Anna Selva, Valeria Conte, Marta Missiaggia, Francesco G. Cordoni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15106v1",
    "source": "arXiv",
    "abstract": "The relationship between the physical characteristics of the radiation field and biological damage is central to both radiotherapy and radioprotection, yet the link between spatial scales of energy deposition and biological effects remains not entirely understood. To address this, we developed an interpretable deep learning model that predicts cell survival after proton and carbon ion irradiation, leveraging sequential attention to highlight relevant features and provide insight into the contribution of different energy deposition scales. Trained and tested on the PIDE dataset, our model incorporates, beside LET, nanodosimetric and microdosimetric quantities simulated with MC-Startrack and Open-TOPAS, enabling multi-scale characterization. While achieving high predictive accuracy, our approach also emphasizes transparency in decision-making. We demonstrate high accuracy in predicting RBE for in vitro experiments. Multiple scales are utilized concurrently, with no single spatial scale being predominant. Quantities defined at smaller spatial domains generally have a greater influence, whereas the LET plays a lesser role."
  },
  {
    "date": "2026-01-21",
    "title": "Circadian Modulation of Semantic Exploration in Social Media Language",
    "authors": "Vuong Hung Truong, Mariana Gabrielle Cangco Reyes, Masatoshi Koizumi, Jihwan Myung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15091v1",
    "source": "arXiv",
    "abstract": "Human cognition exhibits strong circadian modulation, yet its influence on high-dimensional semantic behavior remains poorly understood. Using large-scale Reddit data, we quantify time-of-day variation in language use by embedding text into a pretrained transformer model and measuring semantic entropy as an index of linguistic exploration-exploitation, for which we show a robust circadian rhythmicity that could be entrained by seasonal light cues. Distinguishing between local and global semantic entropy reveals a systematic temporal dissociation: local semantic exploration peaks in the morning, reflecting broader exploration of semantic space, whereas global semantic diversity peaks later in the day as submissions accumulate around already established topics, consistent with \"rich-get-richer\" dynamics. These patterns are not explained by sentiment or affective valence, indicating that semantic exploration captures a cognitive dimension distinct from mood. The observed temporal structure aligns with known diurnal patterns in neuromodulatory systems, suggesting that biological circadian rhythms extend to the semantic domain."
  },
  {
    "date": "2026-01-21",
    "title": "Five-point partial waves, splitting constraints and hidden zeros",
    "authors": "Arnab Priya Saha, Aninda Sinha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15088v1",
    "source": "arXiv",
    "abstract": "We study the partial-wave expansion of residues of five-point tree-amplitude involving identical scalar particles in the external legs. We check the construction using massive spinor-helicity building blocks and by matching to the tree-level five-point Veneziano amplitude at fixed mass levels. As an application, we express five-point splitting constraints - the reduction of the five-point amplitude to products of four-point amplitudes on special kinematic loci - as linear relations among the five-point partial-wave coefficients. At low mass levels these constraints, together with spin truncation, fix the full five-point partial-wave data in terms of the four-point coefficients and imply simple compatibility conditions; remarkably, imposing two independent splitting loci also forces the residue to vanish on their intersection, making the associated hidden zero manifest in partial-wave space. We also show that once both channels allow spin-2 exchange a genuine kernel can remain, indicating the need for additional higher-point input to achieve complete rigidity."
  },
  {
    "date": "2026-01-21",
    "title": "Space-time evolution of particle emission in p$-$Pb collisions at $\\mathbf{\\sqrt{s_{\\rm NN}}=~5.02}$ TeV with 3D kaon femtoscopy",
    "authors": "ALICE Collaboration",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15081v1",
    "source": "arXiv",
    "abstract": "The measurement of three-dimensional femtoscopic correlations between identical charged kaons (K$^\\pm$K$^\\pm$) produced in p$-$Pb collisions at center-of-mass energy per nucleon pair $\\sqrt{s{_{\\rm NN}}} = 5.02$ TeV with ALICE at the LHC is presented for the first time. This measurement, supplementary to those in pp and Pb$-$Pb collisions, allows understanding the particle-production mechanisms at different charged-particle multiplicities and provides information on the dynamics of the source of particles created in p$-$Pb collisions, for which a general consensus does not yet exist. It is shown that the measured source sizes increase with charged-particle multiplicity and decrease with increasing pair transverse momentum. These trends for K$^\\pm$K$^\\pm$ are similar to the ones observed earlier in identical charged-pion and K$_{\\rm s}^{0}$K$_{\\rm s}^{0}$ correlations in Pb$-$Pb collisions at various energies and in $π^\\pm π^\\pm$ correlations in p$-$Pb collisions at $\\sqrt{s{_{\\rm NN}}} = 5.02$ TeV. At comparable multiplicity, the source sizes measured in p$-$Pb collisions agree within uncertainties with those observed in pp collisions, and there is an indication that they are smaller than those observed in Pb$-$Pb collisions. The obtained results are also compared with predictions from the hadronic interaction model EPOS~3, which tends to underestimate the source size for the most central collisions and agrees with the data for semicentral and peripheral events. Furthermore, the time of maximal emission for kaons is extracted. It turns out to be comparable with the value obtained in highly peripheral Pb$-$Pb collisions at the same energy, indicating that the kaon emission evolution is similar to that in p$-$Pb collisions."
  },
  {
    "date": "2026-01-21",
    "title": "Computable Structuralism: A Categorical Rewrite Calculus of Mythic Variants",
    "authors": "Juan J. Segura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15078v1",
    "source": "arXiv",
    "abstract": "Structural approaches to myth and narrative are compelling in close reading but hard to compare across traditions, media, and scale. We propose a formal framework that renders Lévi-Straussian transformation as mathematics while remaining readable as narrative analysis. Variants, superhero continuities, and franchise arcs are modeled as typed rewrite programs on a coupled two-register state $(X,Y)$, abstracting an everyday/social channel and a symbolic/legitimation channel. The canonical formula becomes coherence data: a natural transformation $η:U\\Rightarrow V$ between update endofunctors, where $U$ updates each register in place and $V$ performs a swap+inversion. Context is internalized by operator choice, turning naturality into a corpus-facing type check: failures diagnose mis-specified oppositions or illegal transport; successes witness coherent structural models. Order effects are summarized by a five-value invariant (Key). We apply the method to 80 narratives (20 folktales, 20 religious myths, 20 superheroes, 20 franchises), each encoded as $(a,b,x,y)$ with a Key. 59/80 (74\\%) explicitly name a normative constraint in $y$ (law, taboo, contract, prophecy), supporting the two-register abstraction. The result is a testable bridge between structural anthropology and cultural analytics: stories remain interpretable yet become transportable objects for computation, comparison, and falsifiable constraints on transformation."
  },
  {
    "date": "2026-01-21",
    "title": "The Why Behind the Action: Unveiling Internal Drivers via Agentic Attribution",
    "authors": "Chen Qian, Peng Wang, Dongrui Liu, Junyao Yang, Dadi Guo, Ling Tang, Jilin Mei, Qihan Ren, Shuai Shao, Yong Liu, Jie Fu, Jing Shao, Xia Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15075v1",
    "source": "arXiv",
    "abstract": "Large Language Model (LLM)-based agents are widely used in real-world applications such as customer service, web navigation, and software engineering. As these systems become more autonomous and are deployed at scale, understanding why an agent takes a particular action becomes increasingly important for accountability and governance. However, existing research predominantly focuses on \\textit{failure attribution} to localize explicit errors in unsuccessful trajectories, which is insufficient for explaining the reasoning behind agent behaviors. To bridge this gap, we propose a novel framework for \\textbf{general agentic attribution}, designed to identify the internal factors driving agent actions regardless of the task outcome. Our framework operates hierarchically to manage the complexity of agent interactions. Specifically, at the \\textit{component level}, we employ temporal likelihood dynamics to identify critical interaction steps; then at the \\textit{sentence level}, we refine this localization using perturbation-based analysis to isolate the specific textual evidence. We validate our framework across a diverse suite of agentic scenarios, including standard tool use and subtle reliability risks like memory-induced bias. Experimental results demonstrate that the proposed framework reliably pinpoints pivotal historical events and sentences behind the agent behavior, offering a critical step toward safer and more accountable agentic systems."
  },
  {
    "date": "2026-01-21",
    "title": "Incentive-Tuning: Understanding and Designing Incentives for Empirical Human-AI Decision-Making Studies",
    "authors": "Simran Kaur, Sara Salimzadeh, Ujwal Gadiraju",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15064v1",
    "source": "arXiv",
    "abstract": "AI has revolutionised decision-making across various fields. Yet human judgement remains paramount for high-stakes decision-making. This has fueled explorations of collaborative decision-making between humans and AI systems, aiming to leverage the strengths of both. To explore this dynamic, researchers conduct empirical studies, investigating how humans use AI assistance for decision-making and how this collaboration impacts results. A critical aspect of conducting these studies is the role of participants, often recruited through crowdsourcing platforms. The validity of these studies hinges on the behaviours of the participants, hence effective incentives that can potentially affect these behaviours are a key part of designing and executing these studies. In this work, we aim to address the critical role of incentive design for conducting empirical human-AI decision-making studies, focusing on understanding, designing, and documenting incentive schemes. Through a thematic review of existing research, we explored the current practices, challenges, and opportunities associated with incentive design for human-AI decision-making empirical studies. We identified recurring patterns, or themes, such as what comprises the components of an incentive scheme, how incentive schemes are manipulated by researchers, and the impact they can have on research outcomes. Leveraging the acquired understanding, we curated a set of guidelines to aid researchers in designing effective incentive schemes for their studies, called the Incentive-Tuning Framework, outlining how researchers can undertake, reflect on, and document the incentive design process. By advocating for a standardised yet flexible approach to incentive design and contributing valuable insights along with practical tools, we hope to pave the way for more reliable and generalizable knowledge in the field of human-AI decision-making."
  },
  {
    "date": "2026-01-21",
    "title": "CO Diffusion on Interstellar Amorphous Solid Water: A Computational Study",
    "authors": "Francesco Benedetti, Mauro Satta, Tommaso Grassi, Stefan Vogt-Geisse, Stefano Bovino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15057v1",
    "source": "arXiv",
    "abstract": "Surface chemistry on interstellar dust grains is recognized as a central component in astrochemical models, representing a plausible formation route for many of the observed complex molecular species. However, key parameters governing interstellar surface chemistry, such as diffusion energy barriers, remain poorly constrained. In particular, surface diffusion constitutes a fundamental step for the synthesis of complex organic molecules and plays a crucial role in understanding the desorption process. In this paper, the diffusion dynamics of carbon monoxide (CO) on amorphous solid water (ASW) surfaces, representative of interstellar ices, is modeled with quantum-chemical methods. Employing a representative ensemble of water clusters, each made by 22 molecules, diffusion energy barriers between the binding sites are computed using Density Functional Theory. Diffusion rate coefficients are then determined by applying the harmonic approximation of Transition State Theory. The results, in agreement with experimental studies, revealed a wide distribution of diffusion energies. This reflects the intrinsic topological heterogeneity of ASW surfaces, and highlights how surface mobility significantly influences CO's desorption dynamics and, as a consequence, surface-mediated reactivity in interstellar environments. We show that key parameters commonly employed in astrochemical models, like the ratio between binding and diffusion energy, should be carefully revised."
  },
  {
    "date": "2026-01-21",
    "title": "Bispectral rational functions and Leonard trios",
    "authors": "Nicolas Crampé, Wolter Groenevelt, Quentin Labriet, Lucia Morey, Luc Vinet, Carel Wagenaar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15052v1",
    "source": "arXiv",
    "abstract": "It is well-known that Leonard pairs have a close connection with bispectral orthogonal polynomials of the Askey scheme. In this paper, we introduce the notion of a Leonard trio $(V,\\oV,Z)$, an algebraic structure extending Leonard pairs, for which the overlap coefficients of eigenfunctions of $V$ and $\\oV$ are biorthogonal rational functions satisfying generalized eigenvalue problems. We introduce and start the classification of irreducible Leonard trios by using its connection with Leonard pairs and Heun operators. In particular, we show that Wilson's rational functions appear as overlap coefficients, prove its difference, recurrence and biorthogonality relations, and obtain a summation formula expressing them as a finite sum of products of two $q$-Racah polynomials. We also begin to investigate reduced Leonard trios, for which the general eigenvalue problem simplifies to a $R_I$-type recurrence relation. As an illustration, we present an example of this in which the rational functions appearing as overlap coefficients can be expressed as a ${}_{4}φ_3$ and are associated with a Leonard pair of dual $q$-Hahn type."
  },
  {
    "date": "2026-01-21",
    "title": "\\textsc{LogicScore}: Fine-grained Logic Evaluation of Conciseness, Completeness, and Determinateness in Attributed Question Answering",
    "authors": "Zhichao Yan, Yunxiao Zhao, Jiapu Wang, Jiaoyan Chen, Shaoru Guo, Xiaoli Li, Ru Li, Jeff Z. Pan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15050v1",
    "source": "arXiv",
    "abstract": "Current evaluation methods for Attributed Question Answering (AQA) suffer from \\textit{attribution myopia}: they emphasize verification of isolated statements and their attributions but overlook the global logical integrity of long-form answers. Consequently, Large Language Models (LLMs) often produce factually grounded yet logically incoherent responses with elusive deductive gaps. To mitigate this limitation, we present \\textsc{LogicScore}, a unified evaluation framework that shifts the paradigm from local assessment to global reasoning scrutiny. Grounded in Horn Rules, our approach integrates a backward verification mechanism to systematically evaluate three key reasoning dimensions: \\textit{Completeness} (logically sound deduction), \\textit{Conciseness} (non-redundancy), and \\textit{Determinateness} (consistent answer entailment). Extensive experiments across three multi-hop QA datasets (HotpotQA, MusiQue, and 2WikiMultiHopQA) and over 20 LLMs (including GPT-5, Gemini-3-Pro, LLaMA3, and task-specific tuned models) reveal a critical capability gap: leading models often achieve high attribution scores (e.g., 92.85\\% precision for Gemini-3 Pro) but struggle with global reasoning quality (e.g., 35.11\\% Conciseness for Gemini-3 Pro). Our work establishes a robust standard for logical evaluation, highlighting the need to prioritize reasoning coherence alongside factual grounding in LLM development. Codes are available at: https://github.com/zhichaoyan11/LogicScore."
  },
  {
    "date": "2026-01-21",
    "title": "Deep Leakage with Generative Flow Matching Denoiser",
    "authors": "Isaac Baglin, Xiatian Zhu, Simon Hadfield",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15049v1",
    "source": "arXiv",
    "abstract": "Federated Learning (FL) has emerged as a powerful paradigm for decentralized model training, yet it remains vulnerable to deep leakage (DL) attacks that reconstruct private client data from shared model updates. While prior DL methods have demonstrated varying levels of success, they often suffer from instability, limited fidelity, or poor robustness under realistic FL settings. We introduce a new DL attack that integrates a generative Flow Matching (FM) prior into the reconstruction process. By guiding optimization toward the distribution of realistic images (represented by a flow matching foundation model), our method enhances reconstruction fidelity without requiring knowledge of the private data. Extensive experiments on multiple datasets and target models demonstrate that our approach consistently outperforms state-of-the-art attacks across pixel-level, perceptual, and feature-based similarity metrics. Crucially, the method remains effective across different training epochs, larger client batch sizes, and under common defenses such as noise injection, clipping, and sparsification. Our findings call for the development of new defense strategies that explicitly account for adversaries equipped with powerful generative priors."
  },
  {
    "date": "2026-01-21",
    "title": "CADGrasp: Learning Contact and Collision Aware General Dexterous Grasping in Cluttered Scenes",
    "authors": "Jiyao Zhang, Zhiyuan Ma, Tianhao Wu, Zeyuan Chen, Hao Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15039v1",
    "source": "arXiv",
    "abstract": "Dexterous grasping in cluttered environments presents substantial challenges due to the high degrees of freedom of dexterous hands, occlusion, and potential collisions arising from diverse object geometries and complex layouts. To address these challenges, we propose CADGrasp, a two-stage algorithm for general dexterous grasping using single-view point cloud inputs. In the first stage, we predict sparse IBS, a scene-decoupled, contact- and collision-aware representation, as the optimization target. Sparse IBS compactly encodes the geometric and contact relationships between the dexterous hand and the scene, enabling stable and collision-free dexterous grasp pose optimization. To enhance the prediction of this high-dimensional representation, we introduce an occupancy-diffusion model with voxel-level conditional guidance and force closure score filtering. In the second stage, we develop several energy functions and ranking strategies for optimization based on sparse IBS to generate high-quality dexterous grasp poses. Extensive experiments in both simulated and real-world settings validate the effectiveness of our approach, demonstrating its capability to mitigate collisions while maintaining a high grasp success rate across diverse objects and complex scenes."
  },
  {
    "date": "2026-01-21",
    "title": "Visual and Cognitive Demands of a Large Language Model-Powered In-vehicle Conversational Agent",
    "authors": "Chris Monk, Allegra Ayala, Christine S. P. Yu, Gregory M. Fitch, Dara Gruber",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15034v1",
    "source": "arXiv",
    "abstract": "Driver distraction remains a leading contributor to motor vehicle crashes, necessitating rigorous evaluation of new in-vehicle technologies. This study assessed the visual and cognitive demands associated with an advanced Large Language Model (LLM) conversational agent (Gemini Live) during on-road driving, comparing it against handsfree phone calls, visual turn-by-turn guidance (low load baseline), and the Operation Span (OSPAN) task (high load anchor). Thirty-two licensed drivers completed five secondary tasks while visual and cognitive demands were measured using the Detection Response Task (DRT) for cognitive load, eye-tracking for visual attention, and subjective workload ratings. Results indicated that Gemini Live interactions (both single-turn and multi-turn) and hands-free phone calls shared similar levels of cognitive load, between that of visual turn-by-turn guidance and OSPAN. Exploratory analysis showed that cognitive load remained stable across extended multi-turn conversations. All tasks maintained mean glance durations well below the well-established 2-second safety threshold, confirming low visual demand. Furthermore, drivers consistently dedicated longer glances to the roadway between brief off-road glances toward the device during task completion, particularly during voice-based interactions, rendering longer total-eyes-off-road time findings less consequential. Subjective ratings mirrored objective data, with participants reporting low effort, demands, and perceived distraction for Gemini Live. These findings demonstrate that advanced LLM conversational agents, when implemented via voice interfaces, impose cognitive and visual demands comparable to established, low-risk hands-free benchmarks, supporting their safe deployment in the driving environment."
  },
  {
    "date": "2026-01-21",
    "title": "Single-Node Wilson--Cowan Model Accounts for Speech-Evoked $γ$-Band Deficits in Schizophrenia",
    "authors": "Zhengdi Zhang, Yan Xu, Wenjun Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15032v1",
    "source": "arXiv",
    "abstract": "Cortical gamma ($γ$)-band activity reflects local excitation-inhibition (E/I) balance. In schizophrenia (SCZ), reduced task-evoked gamma suggests altered E/I dynamics, but it is unclear whether differences stem from input properties or systematic shifts in E/I operating point and gain. We coupled a cochlear-inspired speech front end to a Wilson-Cowan E/I model to simulate gamma responses across three conditions: Healthy, SCZ-speech, and SCZ-semantics. Metrics included event-related spectral perturbation (ERSP$_γ$) and threshold-time fraction ($γ%$). A stable hierarchy emerged: Healthy(speech/semantics) $>$ SCZ(speech) $>$ SCZ(semantics), robust under equal-energy control and gain perturbations. Network dynamics coincided with single-node solutions, supporting interpretability. Pharmacological analogs showed bidirectional effects: reduced inhibition lowered $γ$, while reduced excitation increased $γ$, with no self-sustained oscillations. Findings indicate SCZ gamma deficits align more with shifts in E/I operating point and gain than input differences. This pipeline provides a testable, reusable mechanistic framework for speech-evoked gamma and a baseline for cross-population studies."
  },
  {
    "date": "2026-01-21",
    "title": "STEAD: Robust Provably Secure Linguistic Steganography with Diffusion Language Model",
    "authors": "Yuang Qi, Na Zhao, Qiyi Yao, Benlong Wu, Weiming Zhang, Nenghai Yu, Kejiang Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14778v1",
    "source": "arXiv",
    "abstract": "Recent provably secure linguistic steganography (PSLS) methods rely on mainstream autoregressive language models (ARMs) to address historically challenging tasks, that is, to disguise covert communication as ``innocuous'' natural language communication. However, due to the characteristic of sequential generation of ARMs, the stegotext generated by ARM-based PSLS methods will produce serious error propagation once it changes, making existing methods unavailable under an active tampering attack. To address this, we propose a robust, provably secure linguistic steganography with diffusion language models (DLMs). Unlike ARMs, DLMs can generate text in a partially parallel manner, allowing us to find robust positions for steganographic embedding that can be combined with error-correcting codes. Furthermore, we introduce error correction strategies, including pseudo-random error correction and neighborhood search correction, during steganographic extraction. Theoretical proof and experimental results demonstrate that our method is secure and robust. It can resist token ambiguity in stegotext segmentation and, to some extent, withstand token-level attacks of insertion, deletion, and substitution."
  },
  {
    "date": "2026-01-21",
    "title": "A SiPM-Based RICH Detector with Timing Capabilities for Isotope Identification",
    "authors": "M. N. Mazziotta, L. Congedo, G. De Robertis, M. Giliberti, F. Licciulli, A. Liguori, L. Lorusso, N. Nicassio, G. Panzarini, R. Pillera",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14767v1",
    "source": "arXiv",
    "abstract": "In this work, we present a novel compact particle identification (PID) detector concept based on Silicon Photomultipliers (SiPMs) optimized to perform combined Ring-Imaging Cherenkov (RICH) and Time-of-Flight (TOF) measurements using a common photodetector layer. The system consists of a Cherenkov radiator layer separated from a photosensitive surface equipped with SiPMs by an expansion gap. A thin glass slab, acting as a second Cherenkov radiator, is coupled to the SiPMs to perform Cherenkov-based charged particle timing measurements. We assembled a small-scale prototype instrumented with various Hamamatsu SiPM array sensors with pixel pitches ranging from 2 to 3 mm and coupled with 1 mm thick fused silica window. The RICH radiator consisted of a 2 cm thick aerogel tile with a refractive index of 1.03 at 400 nm. The prototype was successfully tested in beam test campaigns at the CERN PS T10 beam line with pions and protons. We measured a single-hit angular resolution of about 4 mrad at the Cherenkov angle saturation value and a time resolution better than 50 ps RMS for charged particles with Z = 1. The present technology makes the proposed SiPM-based PID system particularly attractive for space applications due to the limited detector volumes available. In this work, we present beam test results obtained with the detector prototype and we discuss possible configurations optimized for the identification of ions in space applications."
  },
  {
    "date": "2026-01-21",
    "title": "Secure Communication in MIMOME Movable-Antenna Systems with Statistical Eavesdropper CSI",
    "authors": "Lei Xie, Peilan Wang, Guanxiong Shen, Guyue Li, Weidong Mei, Liquan Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14755v1",
    "source": "arXiv",
    "abstract": "This paper investigates the potential of movable antennas (MAs) to enhance physical layer security within a multiple-input multiple-output multiple-antenna eavesdropper (MIMOME) system. We consider a practical scenario where the transmitter operates with imperfect eavesdropper channel state information (ECSI), knowing only the instantaneous line-of-sight (LoS) component and the statistical properties of non-line-of-sight (NLoS) component. To rigorously quantify secrecy performance under the ECSI uncertainty, we adopt the ergodic secrecy rate (ESR) as the metric. Since deriving an exact analytical expression for the ESR is intractable, we leverage random matrix theory to derive a deterministic equivalent. This avoids heavy Monte Carlo simulations and also provides explicit insights into the effects of channel spatial statistics on secrecy performance. Building upon the deterministic equivalent, we formulate a joint maximization problem for the transmit precoding matrix and the antenna positions at the legitimate transmitter. To tackle the non-convexity of this optimization problem, we develop a comprehensive alternating optimization framework. Specifically, the precoding matrix is optimized via a majorization-minimization (MM) algorithm, where the gradient is computed by solving an implicit fixed-point equation. For the antenna position optimization, the complexity of the objective function prevents the construction of standard MM surrogate. To this end, we further propose a novel AMSGrad-based surrogate function that relies solely on gradient information. We provide a rigorous theoretical proof that guarantees the convergence of this proposed algorithm despite relaxing the strict majorization conditions."
  },
  {
    "date": "2026-01-21",
    "title": "Anomalous Localization and Mobility Edges in Non-Hermitian Quasicrystals with Disordered Imaginary Gauge Fields",
    "authors": "Guolin Nan, Zhijian Li, Feng Mei, Zhihao Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14754v1",
    "source": "arXiv",
    "abstract": "We study anomalous localization in a one-dimensional non-Hermitian quasicrystal with a spatially disordered imaginary gauge field. The system is a generalized Aubry-André-Harper (AAH) chain with asymmetric nearest- and next-nearest-neighbor hoppings generated by a Bernoulli imaginary gauge field and a quasiperiodic onsite potential. In the standard non-Hermitian AAH limit, the system undergoes a transition from a fully erratic non-Hermitian skin effect (ENHSE) phase to a fully localized phase. We show that the fractal dimension cannot distinguish these phases, whereas the Lyapunov exponent and center-of-mass fluctuations provide sharp diagnostics. This transition is accompanied by a complex-to-real spectral change under periodic boundary conditions and a topological change of the spectral winding number. With next-nearest-neighbor hopping, we uncover an anomalous mobility edge separating Anderson-localized states from ENHSE states, rather than extended states. This mobility edge is captured by an energy-dependent winding number that vanishes in the localized regime. Finally, we propose a dynamical probe based on wave-packet expansion: for typical disorder realizations, the dynamics shows winding-controlled drift and disorder-selected pinning or boundary-wrapping recurrence, while disorder averaging restores Hermitian-like transport. These results offer practical spectral, topological, and dynamical diagnostics of anomalous localization and mobility edges in non-Hermitian quasicrystals."
  },
  {
    "date": "2026-01-21",
    "title": "Global-local shrinkage priors for modeling random effects in multivariate spatial small area estimation",
    "authors": "Shushi Nishina, Takahiro Onizuka, Shintaro Hashimoto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14752v1",
    "source": "arXiv",
    "abstract": "Small area estimation (SAE) plays a central role in survey statistics and epidemiology, providing reliable estimates for domains with limited sample sizes. The multivariate Fay-Herriot model has been extensively used for this purpose, because it enhances estimation accuracy by borrowing strength across multiple correlated variables. In this paper, we develop a Bayesian extension of the multivariate Fay-Herriot model that enables flexible, component-specific shrinkage of the random effects. The proposed approach employs global-local priors formulated through a sandwich mixture representation, allowing adaptive regularization of each element of the random-effect vectors. This construction yields greater robustness and prevents excessive shrinkage in areas exhibiting strong underlying signals. In addition, we incorporate spatial dependence into the model to account for geographical correlation across small areas. The resulting spatial multivariate framework simultaneously exploits cross-variable relationships and spatial structure, yielding improved estimation efficiency. The utility of the proposed method is demonstrated through simulation studies and an empirical application to real survey data."
  },
  {
    "date": "2026-01-21",
    "title": "Enhancing Text-to-Image Generation via End-Edge Collaborative Hybrid Super-Resolution",
    "authors": "Chongbin Yi, Yuxin Liang, Ziqi Zhou, Peng Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14741v1",
    "source": "arXiv",
    "abstract": "Artificial Intelligence-Generated Content (AIGC) has made significant strides, with high-resolution text-to-image (T2I) generation becoming increasingly critical for improving users' Quality of Experience (QoE). Although resource-constrained edge computing adequately supports fast low-resolution T2I generations, achieving high-resolution output still faces the challenge of ensuring image fidelity at the cost of latency. To address this, we first investigate the performance of super-resolution (SR) methods for image enhancement, confirming a fundamental trade-off that lightweight learning-based SR struggles to recover fine details, while diffusion-based SR achieves higher fidelity at a substantial computational cost. Motivated by these observations, we propose an end-edge collaborative generation-enhancement framework. Upon receiving a T2I generation task, the system first generates a low-resolution image based on adaptively selected denoising steps and super-resolution scales at the edge side, which is then partitioned into patches and processed by a region-aware hybrid SR policy. This policy applies a diffusion-based SR model to foreground patches for detail recovery and a lightweight learning-based SR model to background patches for efficient upscaling, ultimately stitching the enhanced ones into the high-resolution image. Experiments show that our system reduces service latency by 33% compared with baselines while maintaining competitive image quality."
  },
  {
    "date": "2026-01-21",
    "title": "The Interdecadal Bipolar Oscillation: An Atmospheric Water Vapor Mode Driving Asynchronous Polar Climate Change",
    "authors": "Hongyu Wang, Jingfang Fan, Fei Xie, Jingyuan Li, Rui Shi, Yan Xia, Deliang Chen, Xiaosong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14733v1",
    "source": "arXiv",
    "abstract": "Climate change is progressing asynchronously between the Arctic and Antarctic, with important implications for global climate dynamics. While the Arctic has experienced rapid warming and pronounced amplification, the Antarctic has exhibited a delayed and heterogeneous response. Here, we identify an Interdecadal Bipolar Oscillation (IBO) in atmospheric water vapor, a coherent internal mode of variability that connects the two polar regions and helps explain their divergent climate trajectories over the past eight decades. Using reanalysis data alongside historical and pre-industrial control simulations from CMIP6, we demonstrate that the IBO is a robust internal variability mode with a quasi-period of 60 ~ 80 years. This oscillation modulates the background warming signal, with a phase shift in the late 1980s amplifying moistening and warming in the Arctic while concurrently suppressing changes in the Antarctic. Crucially, model projections suggest a possible phase reversal, which could slow water vapor increases in the Arctic while accelerating them in the Antarctic, potentially marking the start of rapid Antarctic climate change. While uncertainties remain in how climate models capture polar water vapor, our findings highlight the IBO as a pivotal driver of polar climate evolution and a potential contributor to emerging climate risks in the Southern Hemisphere."
  },
  {
    "date": "2026-01-21",
    "title": "PULSE: Socially-Aware User Representation Modeling Toward Parameter-Efficient Graph Collaborative Filtering",
    "authors": "Doyun Choi, Cheonwoo Lee, Biniyam Aschalew Tolera, Taewook Ham, Chanyoung Park, Jaemin Yoo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14720v1",
    "source": "arXiv",
    "abstract": "Graph-based social recommendation (SocialRec) has emerged as a powerful extension of graph collaborative filtering (GCF), which leverages graph neural networks (GNNs) to capture multi-hop collaborative signals from user-item interactions. These methods enrich user representations by incorporating social network information into GCF, thereby integrating additional collaborative signals from social relations. However, existing GCF and graph-based SocialRec approaches face significant challenges: they incur high computational costs and suffer from limited scalability due to the large number of parameters required to assign explicit embeddings to all users and items. In this work, we propose PULSE (Parameter-efficient User representation Learning with Social Knowledge), a framework that addresses this limitation by constructing user representations from socially meaningful signals without creating an explicit learnable embedding for each user. PULSE reduces the parameter size by up to 50% compared to the most lightweight GCF baseline. Beyond parameter efficiency, our method achieves state-of-the-art performance, outperforming 13 GCF and graph-based social recommendation baselines across varying levels of interaction sparsity, from cold-start to highly active users, through a time- and memory-efficient modeling process."
  },
  {
    "date": "2026-01-21",
    "title": "PCL-Reasoner-V1.5: Advancing Math Reasoning with Offline Reinforcement Learning",
    "authors": "Yao Lu, Dengdong Fan, Jianzheng Nie, Fan Xu, Jie Chen, Bin Zhou, Yonghong Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14716v1",
    "source": "arXiv",
    "abstract": "We present PCL-Reasoner-V1.5, a 32-billion-parameter large language model (LLM) for mathematical reasoning. The model is built upon Qwen2.5-32B and refined via supervised fine-tuning (SFT) followed by reinforcement learning (RL). A central innovation is our proposed offline RL method, which provides superior training stability and efficiency over standard online RL methods such as GRPO. Our model achieves state-of-the-art performance among models post-trained on Qwen2.5-32B, attaining average accuracies of 90.9% on AIME 2024 and 85.6% on AIME 2025. Our work demonstrates offline RL as a stable and efficient paradigm for advancing reasoning in LLMs. All experiments were conducted on Huawei Ascend 910C NPUs."
  },
  {
    "date": "2026-01-21",
    "title": "Unified Multimodal and Multilingual Retrieval via Multi-Task Learning with NLU Integration",
    "authors": "Xinyuan Zhang, Lina Zhang, Lisung Chen, Guangyao Liu, Shuai Nie, Jiaming Xu, Runyu Shi, Ying Huang, Guoquan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14714v1",
    "source": "arXiv",
    "abstract": "Multimodal retrieval systems typically employ Vision Language Models (VLMs) that encode images and text independently into vectors within a shared embedding space. Despite incorporating text encoders, VLMs consistently underperform specialized text models on text-only retrieval tasks. Moreover, introducing additional text encoders increases storage, inference overhead, and exacerbates retrieval inefficiencies, especially in multilingual settings. To address these limitations, we propose a multi-task learning framework that unifies the feature representation across images, long and short texts, and intent-rich queries. To our knowledge, this is the first work to jointly optimize multilingual image retrieval, text retrieval, and natural language understanding (NLU) tasks within a single framework. Our approach integrates image and text retrieval with a shared text encoder that is enhanced by NLU features for intent understanding and retrieval accuracy."
  },
  {
    "date": "2026-01-21",
    "title": "Proximal Policy Optimization with Evolutionary Mutations",
    "authors": "Casimir Czworkowski, Stephen Hornish, Alhassan S. Yasin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14705v1",
    "source": "arXiv",
    "abstract": "Proximal Policy Optimization (PPO) is a widely used reinforcement learning algorithm known for its stability and sample efficiency, but it often suffers from premature convergence due to limited exploration. In this paper, we propose POEM (Proximal Policy Optimization with Evolutionary Mutations), a novel modification to PPO that introduces an adaptive exploration mechanism inspired by evolutionary algorithms. POEM enhances policy diversity by monitoring the Kullback-Leibler (KL) divergence between the current policy and a moving average of previous policies. When policy changes become minimal, indicating stagnation, POEM triggers an adaptive mutation of policy parameters to promote exploration. We evaluate POEM on four OpenAI Gym environments: CarRacing, MountainCar, BipedalWalker, and LunarLander. Through extensive fine-tuning using Bayesian optimization techniques and statistical testing using Welch's t-test, we find that POEM significantly outperforms PPO on three of the four tasks (BipedalWalker: t=-2.0642, p=0.0495; CarRacing: t=-6.3987, p=0.0002; MountainCar: t=-6.2431, p<0.0001), while performance on LunarLander is not statistically significant (t=-1.8707, p=0.0778). Our results highlight the potential of integrating evolutionary principles into policy gradient methods to overcome exploration-exploitation tradeoffs."
  },
  {
    "date": "2026-01-21",
    "title": "Hierarchical Optimization Based Multi-objective Dynamic Regulation Scheme for VANET Topology",
    "authors": "Ruixing Ren, Minqi Tao, Junhui Zhao, Xiaoke Sun, Qiuping Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14704v1",
    "source": "arXiv",
    "abstract": "As a core technology of intelligent transportation systems, vehicular ad-hoc networks support latency-sensitive services such as safety warning and cooperative perception via vehicle-to-everything communications. However, their highly dynamic topology increases average path length, raises latency, and reduces throughput, severely limiting communication performance. Existing topology optimization methods lack capabilities in multi-objective coordination, dynamic adaptation, and global-local synergy. To address this, this paper proposes a two-layer dynamic topology regulation scheme combining local feature aggregation and global adjustment. The scheme constructs a dynamic multi-objective optimization model integrating average path length, end-to-end latency, and network throughput, and achieves multi-index coordination via link adaptability metrics and a dynamic normalization mechanism. it quickly responds to local link changes via feature fusion of local node feature extraction and dynamic neighborhood sensing, and balances optimization accuracy and real-time performance using a dual-mode adaptive solving strategy for global topology adjustment. It reduces network oscillation risks by introducing a performance improvement threshold and a topology validity verification mechanism. Simulation results on real urban road networks via the SUMO platform show that the proposed scheme outperforms traditional methods in average path length (stabilizing at ~4 hops), end-to-end latency (remaining ~0.01 s), and network throughput."
  },
  {
    "date": "2026-01-21",
    "title": "Regulatory Expectations for Bayesian Methods in Drug and Biologic Clinical Trials: A Practical Perspective on FDA's 2026 Draft Guidance",
    "authors": "Yuan Ji, Ph. D",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14701v1",
    "source": "arXiv",
    "abstract": "The U.S. Food and Drug Administration (FDA) released a landmark draft guidance in January 2026 on the use of Bayesian methodology to support primary inference in clinical trials of drugs and biological products. For sponsors, the central message is not merely that ``Bayes is allowed,'' but that Bayesian designs should be justified through explicit success criteria, thoughtful priors (especially when borrowing external information), prospective operating-characteristic evaluation (often via simulation when simulation is used), and computational transparency suitable for regulatory review. This paper provides a practical, regulatory-oriented synthesis of the draft guidance, highlighting where Bayesian designs can be calibrated to traditional frequentist error-rate targets and where, with sponsor--FDA agreement, alternative Bayesian operating metrics may be appropriate. We illustrate expectations through examples discussed in the guidance (e.g., platform trials, external/nonconcurrent controls, pediatric extrapolation) and conclude with an actionable checklist for planning documents and submission packages."
  },
  {
    "date": "2026-01-21",
    "title": "DARL: Encouraging Diverse Answers for General Reasoning without Verifiers",
    "authors": "Chongxuan Huang, Lei Lin, Xiaodong Shi, Wenping Hu, Ruiming Tang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14700v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated promising gains in enhancing the reasoning capabilities of large language models. However, its dependence on domain-specific verifiers significantly restricts its applicability to open and general domains. Recent efforts such as RLPR have extended RLVR to general domains, enabling training on broader datasets and achieving improvements over RLVR. However, a notable limitation of these methods is their tendency to overfit to reference answers, which constrains the model's ability to generate diverse outputs. This limitation is particularly pronounced in open-ended tasks such as writing, where multiple plausible answers exist. To address this, we propose DARL, a simple yet effective reinforcement learning framework that encourages the generation of diverse answers within a controlled deviation range from the reference while preserving alignment with it. Our framework is fully compatible with existing general reinforcement learning methods and can be seamlessly integrated without additional verifiers. Extensive experiments on thirteen benchmarks demonstrate consistent improvements in reasoning performance. Notably, DARL surpasses RLPR, achieving average gains of 1.3 points on six reasoning benchmarks and 9.5 points on seven general benchmarks, highlighting its effectiveness in improving both reasoning accuracy and output diversity."
  },
  {
    "date": "2026-01-21",
    "title": "Beyond Denial-of-Service: The Puppeteer's Attack for Fine-Grained Control in Ranking-Based Federated Learning",
    "authors": "Zhihao Chen, Zirui Gong, Jianting Ning, Yanjun Zhang, Leo Yu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14687v1",
    "source": "arXiv",
    "abstract": "Federated Rank Learning (FRL) is a promising Federated Learning (FL) paradigm designed to be resilient against model poisoning attacks due to its discrete, ranking-based update mechanism. Unlike traditional FL methods that rely on model updates, FRL leverages discrete rankings as a communication parameter between clients and the server. This approach significantly reduces communication costs and limits an adversary's ability to scale or optimize malicious updates in the continuous space, thereby enhancing its robustness. This makes FRL particularly appealing for applications where system security and data privacy are crucial, such as web-based auction and bidding platforms. While FRL substantially reduces the attack surface, we demonstrate that it remains vulnerable to a new class of local model poisoning attack, i.e., fine-grained control attacks. We introduce the Edge Control Attack (ECA), the first fine-grained control attack tailored to ranking-based FL frameworks. Unlike conventional denial-of-service (DoS) attacks that cause conspicuous disruptions, ECA enables an adversary to precisely degrade a competitor's accuracy to any target level while maintaining a normal-looking convergence trajectory, thereby avoiding detection. ECA operates in two stages: (i) identifying and manipulating Ascending and Descending Edges to align the global model with the target model, and (ii) widening the selection boundary gap to stabilize the global model at the target accuracy. Extensive experiments across seven benchmark datasets and nine Byzantine-robust aggregation rules (AGRs) show that ECA achieves fine-grained accuracy control with an average error of only 0.224%, outperforming the baseline by up to 17x. Our findings highlight the need for stronger defenses against advanced poisoning attacks. Our code is available at: https://github.com/Chenzh0205/ECA"
  },
  {
    "date": "2026-01-21",
    "title": "GEGO: A Hybrid Golden Eagle and Genetic Optimization Algorithm for Efficient Hyperparameter Tuning in Resource-Constrained Environments",
    "authors": "Amaras Nazarians, Sachin Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14672v1",
    "source": "arXiv",
    "abstract": "Hyperparameter tuning is a critical yet computationally expensive step in training neural networks, particularly when the search space is high dimensional and nonconvex. Metaheuristic optimization algorithms are often used for this purpose due to their derivative free nature and robustness against local optima. In this work, we propose Golden Eagle Genetic Optimization (GEGO), a hybrid metaheuristic that integrates the population movement strategy of Golden Eagle Optimization with the genetic operators of selection, crossover, and mutation. The main novelty of GEGO lies in embedding genetic operators directly into the iterative search process of GEO, rather than applying them as a separate evolutionary stage. This design improves population diversity during search and reduces premature convergence while preserving the exploration behavior of GEO. GEGO is evaluated on standard unimodal, multimodal, and composite benchmark functions from the CEC2017 suite, where it consistently outperforms its constituent algorithms and several classical metaheuristics in terms of solution quality and robustness. The algorithm is further applied to hyperparameter tuning of artificial neural networks on the MNIST dataset, where GEGO achieves improved classification accuracy and more stable convergence compared to GEO and GA. These results indicate that GEGO provides a balanced exploration-exploitation tradeoff and is well suited for hyperparameter optimization under constrained computational settings."
  },
  {
    "date": "2026-01-21",
    "title": "Constraints on Axion-Like Particles from Ultra-High-Energy Observations of 3HWC J1908+063 with HAWC",
    "authors": "R. Alfaro, C. Alvarez, A. Andres, E. Anita-Rangel, M. Araya, J. C. Arteaga-Velazquez, D. Avila Rojas, H. A. Ayala Solares, R. Babu, P. Bangale, E. Belmont-Moreno, A. Bernal, K. S. Caballero-Mora, T. Capistran, A. Carraminana, F. Carreon, S. Casanova, U. Cotti, J. Cotzomi, E. De la Fuente, P. Desiati, N. Di Lalla, R. Diaz Hernandez, M. A. DuVernois, J. C. Diaz-Velez, T. Ergin, C. Espinoza, N. Fraija, S. Fraija, J. A. Garcia-Gonzalez, F. Garfias, N. Ghosh, A. Gonzalez Munoz, M. M. Gonzalez, J. A. Gonzalez, J. A. Goodman, J. Gyeong, J. P. Harding, S. Hernandez-Cadena, I. Herzog, D. Huang, F. Hueyotl-Zahuantitla, A. Iriarte, S. Kaufmann, D. Kieda, A. Lara, W. H. Lee, J. Lee, H. Leon Vargas, A. L. Longinotti, G. Luis-Raya, K. Malone, O. Martinez, J. Martinez-Castro, H. Martinez-Huerta, J. A. Matthews, P. Miranda-Romagnoli, P. E. Miron-Enriquez, J. A. Morales-Soto, E. Moreno, M. Mostafa, M. Najafi, A. Nayerhoda, L. Nellen, M. U. Nisa, R. Noriega-Papaqui, N. Omodei, E. Ponce, Y. Perez Araujo, E. G. Perez-Perez, A. Pratts, C. D. Rho, A. Rodriguez Parra, D. Rosa-Gonzalez, M. Roth, A. Sandoval, M. Schneider, J. Serna-Franco, A. J. Smith, Y. Son, R. W. Springer, O. Tibolla, K. Tollefson, I. Torres, R. Torres-Escobedo, E. Varela, L. Villasenor, X. Wang, Z. Wang, I. J. Watson, H. Wu, S. Yu, X. Zhang, H. Zhou, C. de Leon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14661v1",
    "source": "arXiv",
    "abstract": "Axion-like particles (ALPs) are hypothetical particles and compelling candidates for cold dark matter. Their existence could be probed through their conversions into photons in the presence of magnetic fields. In this work, we explore the effect of these photon-ALP conversions by searching for an attenuation in the observed gamma ray spectra of galactic sources that emit at energies of hundreds of TeV. We analyze data from the High-Altitude Water Cherenkov (HAWC) Observatory for the source 3HWC J1908+063. No evidence of photon-ALP conversions was found, and we set constraints on the ALP parameter space. Specifically, we derive exclusion limits for ALPs with masses in the range $10^{-8}~\\mathrm{eV} \\leq m_a \\leq 10^{-6}~\\mathrm{eV}$ and photon-ALP couplings in the range $10^{-12}~\\mathrm{GeV}^{-1} \\leq g_{aγ} \\leq 10^{-10}~\\mathrm{GeV}^{-1}$, based on HAWC observations."
  },
  {
    "date": "2026-01-21",
    "title": "Capillary Orlicz-Minkowski flow in the upper half-space",
    "authors": "Guanghan Li, Chenyang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14659v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the long-time existence and asymptotic behavior of an anisotropic capillary Gauss curvature flow. By studying this flow and proving its convergence to a stationary solution, we establish a new existence result for the capillary Orlicz-Minkowski problem without the evenness assumption, and provide a flow approach to the existence of smooth solutions."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient Imputation for Patch-based Missing Single-cell Data via Cluster-regularized Optimal Transport",
    "authors": "Yuyu Liu, Jiannan Yang, Ziyang Yu, Weishen Pan, Fei Wang, Tengfei Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14653v1",
    "source": "arXiv",
    "abstract": "Missing data in single-cell sequencing datasets poses significant challenges for extracting meaningful biological insights. However, existing imputation approaches, which often assume uniformity and data completeness, struggle to address cases with large patches of missing data. In this paper, we present CROT, an optimal transport-based imputation algorithm designed to handle patch-based missing data in tabular formats. Our approach effectively captures the underlying data structure in the presence of significant missingness. Notably, it achieves superior imputation accuracy while significantly reducing runtime, demonstrating its scalability and efficiency for large-scale datasets. This work introduces a robust solution for imputation in heterogeneous, high-dimensional datasets with structured data absence, addressing critical challenges in both biological and clinical data analysis. Our code is available at Anomalous Github."
  },
  {
    "date": "2026-01-21",
    "title": "A New Framework for Multi-Line Analysis Combined Kernel PCA and Kernel SHAP: A Case of NGC 1068 ALMA Band 3 Data",
    "authors": "Hiroma Okubo, Tsutomu T. Takeuchi, Shotaro Akaho, Toshiki Saito, Yasuhiko Igarashi, Nario Kuno, Nanase Harada, Akio Taniguchi, Shuro Takano, Taku Nakajima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14650v1",
    "source": "arXiv",
    "abstract": "We present a new framework for multi-line analysis that combines kernel principal component analysis (Kernel PCA), an unsupervised machine-learning method, and Kernel SHapley Additive exPlanations (Kernel SHAP), an explainable artificial intelligence (XAI) technique. To enable a comparison with PCA-based studies, which have been widely used in multi-line analyses, we apply our framework to integrated intensity maps of 13 molecular lines from Atacama Large Millimeter/submillimeter Array (ALMA) Band 3 archival data of the nearby galaxy NGC 1068. Previous PCA-based studies of NGC 1068 reported that physically meaningful structures are mainly captured up to the second component. In contrast, our framework can interpret physically meaningful features up to the fourth component. Furthermore, by comparing the results obtained from our framework with molecular column densities derived from local thermodynamical equilibrium (LTE) analysis, we suggest that the abundance of HCO+ is relatively enhanced in the molecular outflow region extending to a radius of about 400 pc from the galactic center, likely due to the effects of ultraviolet radiation and highly dense gas. These results show that our framework can provide data-driven insights into physical and chemical features that have not been clearly identified in previous studies. It also provides an efficient tool for interpreting the rapidly increasing amount of multi-line observational data."
  },
  {
    "date": "2026-01-21",
    "title": "Specifying and Verifying RDMA Synchronisation (Extended Version)",
    "authors": "Guillaume Ambal, Max Stupple, Brijesh Dongol, Azalea Raad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14642v1",
    "source": "arXiv",
    "abstract": "Remote direct memory access (RDMA) allows a machine to directly read from and write to the memory of remote machine, enabling high-throughput, low-latency data transfer. Ensuring correctness of RDMA programs has only recently become possible with the formalisation of $\\text{RDMA}^\\text{TSO}$ semantics (describing the behaviour of RDMA networking over a TSO CPU). However, this semantics currently lacks a formalisation of remote synchronisation, meaning that the implementations of common abstractions such as locks cannot be verified. In this paper, we close this gap by presenting $\\text{RDMA}^{\\text{TSO}}_{\\text{RMW}}$, the first semantics for remote `read-modify-write' (RMW) instructions over TSO. It turns out that remote RMW operations are weak and only ensure atomicity against other remote RMWs. We therefore build a set of composable synchronisation abstractions starting with the $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$ library. Underpinned by $\\text{RDMA}^{\\text{WAIT}}_{\\text{RMW}}$, we then specify, implement and verify three classes of remote locks that are suitable for different scenarios. Additionally, we develop the notion of a strong RDMA model, $\\text{RDMA}^{\\text{SC}}_{\\text{RMW}}$, which is akin to sequential consistency in shared memory architectures. Our libraries are built to be compatible with an existing set of high-performance libraries called LOCO, which ensures compositionality and verifiability."
  },
  {
    "date": "2026-01-21",
    "title": "Forest-Chat: Adapting Vision-Language Agents for Interactive Forest Change Analysis",
    "authors": "James Brock, Ce Zhang, Nantheera Anantrasirichai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14637v1",
    "source": "arXiv",
    "abstract": "The increasing availability of high-resolution satellite imagery, together with advances in deep learning, creates new opportunities for enhancing forest monitoring workflows. Two central challenges in this domain are pixel-level change detection and semantic change interpretation, particularly for complex forest dynamics. While large language models (LLMs) are increasingly adopted for data exploration, their integration with vision-language models (VLMs) for remote sensing image change interpretation (RSICI) remains underexplored, especially beyond urban environments. We introduce Forest-Chat, an LLM-driven agent designed for integrated forest change analysis. The proposed framework enables natural language querying and supports multiple RSICI tasks, including change detection, change captioning, object counting, deforestation percentage estimation, and change reasoning. Forest-Chat builds upon a multi-level change interpretation (MCI) vision-language backbone with LLM-based orchestration, and incorporates zero-shot change detection via a foundation change detection model together with an interactive point-prompt interface to support fine-grained user guidance. To facilitate adaptation and evaluation in forest environments, we introduce the Forest-Change dataset, comprising bi-temporal satellite imagery, pixel-level change masks, and multi-granularity semantic change captions generated through a combination of human annotation and rule-based methods. Experimental results demonstrate that Forest-Chat achieves strong performance on Forest-Change and on LEVIR-MCI-Trees, a tree-focused subset of LEVIR-MCI, for joint change detection and captioning, highlighting the potential of interactive, LLM-driven RSICI systems to improve accessibility, interpretability, and analytical efficiency in forest change analysis."
  },
  {
    "date": "2026-01-21",
    "title": "Elastic lepton-proton two-photon exchange scattering: An exact HB$χ$PT analysis including hadronic effects at NNLO",
    "authors": "Rakshanda Goswami, Pulak Talukdar, Bhoomika Das, Udit Raha, Fred Myhrer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14636v1",
    "source": "arXiv",
    "abstract": "We present an exact analytical evaluation of the two-photon exchange (TPE) correction to the elastic lepton-proton differential scattering cross section at low-energies within the framework of heavy-baryon chiral perturbation theory. Our analysis focuses on the kinematic regime relevant to the ongoing MUSE experiment, and we therefore restrict the intermediate states to the dominant elastic channel. All loop integrals are evaluated analytically without approximations. Radiative and chiral recoil contributions of the proton are included, retaining kinematical and dynamical TPE corrections to the cross section through next-to-next-to-leading order [i.e., ${\\mathcal O}(α/M^2)$] accuracy in the recoil expansion where $M$ is the proton mass. At this chiral order, pion-loop contributions demonstrate that structure-dependent TPE effects arise through the proton form factors. Our analytical results for the scattering cross section reveal non-vanishing residual proton structure effects of ${\\mathcal O}(α/M^2)$, despite substantial cancellations between TPE box and crossed-box contributions. Such effects were entirely absent at this accuracy in our earlier analysis based on the soft-photon approximation. Although the next-to-leading-order contributions are numerically sizable, the next-to-next-to-leading-order TPE corrections are found to be small, thereby indicating that the chiral expansion exhibits reasonably good perturbative convergence."
  },
  {
    "date": "2026-01-21",
    "title": "Break-Resilient Codes with Loss Tolerance",
    "authors": "Canran Wang, Minghui Liwang, Netanel Raviv",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14623v1",
    "source": "arXiv",
    "abstract": "Emerging applications in manufacturing, wireless communication, and molecular data storage require robust coding schemes that remain effective under physical distortions where codewords may be arbitrarily fragmented and partially missing. To address such challenges, we propose a new family of error-correcting codes, termed $(t,s)$-break-resilient codes ($(t,s)$-BRCs). A $(t,s)$-BRC guarantees correct decoding of the original message even after up to~$t$ arbitrary breaks of the codeword and the complete loss of some fragments whose total length is at most~$s$. This model unifies and generalizes previous approaches, extending break-resilient codes (which handle arbitrary fragmentation without fragment loss) and deletion codes (which correct bit losses in unknown positions without fragmentation) into a single information-theoretic framework. We develop a theoretical foundation for $(t,s)$-BRCs, including a formal adversarial channel model, lower bounds on the necessary redundancy, and explicit code constructions that approach these bounds."
  },
  {
    "date": "2026-01-21",
    "title": "Exploiting Spot Instances for Time-Critical Cloud Workloads Using Optimal Randomized Strategies",
    "authors": "Neelkamal Bhuyan, Randeep Bhatia, Murali Kodialam, TV Lakshman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14612v1",
    "source": "arXiv",
    "abstract": "This paper addresses the challenge of deadline-aware online scheduling for jobs in hybrid cloud environments, where jobs may run on either cost-effective but unreliable spot instances or more expensive on-demand instances, under hard deadlines. We first establish a fundamental limit for existing (predominantly-) deterministic policies, proving a worst-case competitive ratio of $Ω(K)$, where $K$ is the cost ratio between on-demand and spot instances. We then present a novel randomized scheduling algorithm, ROSS, that achieves a provably optimal competitive ratio of $\\sqrt{K}$ under reasonable deadlines, significantly improving upon existing approaches. Extensive evaluations on real-world trace data from Azure and AWS demonstrate that ROSS effectively balances cost optimization and deadline guarantees, consistently outperforming the state-of-the-art by up to $30\\%$ in cost savings, across diverse spot market conditions."
  },
  {
    "date": "2026-01-21",
    "title": "U-Harmony: Enhancing Joint Training for Segmentation Models with Universal Harmonization",
    "authors": "Weiwei Ma, Xiaobing Yu, Peijie Qiu, Jin Yang, Pan Xiao, Xiaoqi Zhao, Xiaofeng Liu, Tomo Miyazaki, Shinichiro Omachi, Yongsong Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14605v1",
    "source": "arXiv",
    "abstract": "In clinical practice, medical segmentation datasets are often limited and heterogeneous, with variations in modalities, protocols, and anatomical targets across institutions. Existing deep learning models struggle to jointly learn from such diverse data, often sacrificing either generalization or domain-specific knowledge. To overcome these challenges, we propose a joint training method called Universal Harmonization (U-Harmony), which can be integrated into deep learning-based architectures with a domain-gated head, enabling a single segmentation model to learn from heterogeneous datasets simultaneously. By integrating U-Harmony, our approach sequentially normalizes and then denormalizes feature distributions to mitigate domain-specific variations while preserving original dataset-specific knowledge. More appealingly, our framework also supports universal modality adaptation, allowing the seamless learning of new imaging modalities and anatomical classes. Extensive experiments on cross-institutional brain lesion datasets demonstrate the effectiveness of our approach, establishing a new benchmark for robust and adaptable 3D medical image segmentation models in real-world clinical settings."
  },
  {
    "date": "2026-01-21",
    "title": "Variance-Adaptive Muon: Accelerating LLM Pretraining with NSR-Modulated and Variance-Scaled Momentum",
    "authors": "Jingru Li, Yibo Fan, Huan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14603v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) achieve competitive performance across diverse natural language processing (NLP) tasks, yet pretraining is computationally demanding, making optimizer efficiency an important practical consideration. Muon accelerates LLM pretraining via orthogonal momentum updates that serve as a matrix analogue of the element-wise sign operator. Motivated by the recent perspective that Adam is a variance-adaptive sign update algorithm, we propose two variants of Muon, Muon-NSR and Muon-VS, which apply variance-adaptive normalization to momentum before orthogonalization. Muon-NSR applies noise-to-signal ratio (NSR) modulation, while Muon-VS performs variance-based scaling without introducing additional hyperparameters. Experiments on GPT-2 and LLaMA pretraining demonstrate that our proposed methods accelerate convergence and consistently achieve lower validation loss than both competitive, well-tuned AdamW and Muon baselines. For example, on the LLaMA-1.2B model, Muon-NSR and Muon-VS reduce the iterations required to reach the target validation loss by $1.36\\times$ relative to the well-tuned Muon following the recent benchmark."
  },
  {
    "date": "2026-01-21",
    "title": "Nontrivial integrable weak stationary solutions to active scalar equations with non-odd drift",
    "authors": "Nicholas Gismondi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14592v1",
    "source": "arXiv",
    "abstract": "In this paper we construct nontrivial weak solutions to a class of stationary active scalar equations with a non-odd nonlocal operator in the drift term using a convex integration scheme. We show our solutions lie in $$ \\bigcap_{0 < ε< 1} \\dot{B}^{-ε}_{\\infty,\\infty}(\\mathbb{T}^d) \\cap L^{2-ε}(\\mathbb{T}^d) $$ for $d \\geq 2$. The key ingredient of the construction is the use of highly oscillatory corrections with a variable degree of intermittency, which is arranged to decrease to zero at higher stages of the iteration procedure."
  },
  {
    "date": "2026-01-21",
    "title": "A JWST Paschen-alpha Calibration of the Radio Luminosity-Star Formation Rate Relation at z~1.3",
    "authors": "Nick Seymour, Catherine Hale, Imogen Whittam, Pascal Oesch, Alba Covelo-Paz, Stijn Wuyts, Jose Afonso, Rebecca Bowler, Joe A. Grundy, Ravi Jaiswar, Matt Jarvis, Allison Matthews, Romain A. Meyer, Chloe Neufeld, Naveen A. Reddy, Irene Shivaei, Dan Smith, Rohan Varadaraj, Michael A. Wozniak, Lyla Jung",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14588v1",
    "source": "arXiv",
    "abstract": "As radio emission from normal galaxies is a dust-free tracer of star formation, tracing the star formation history of the Universe is a key goal of the SKA and ngVLA. In order to investigate how well radio luminosity traces star formation rate (SFR) in the early Universe, we have examined the radio properties of a JWST Paschen-alpha sample of galaxies at 1.0<=z<=1.8. In the GOODS-S field, we cross-matched a sample of 506 FRESCO Paschen-alpha emitters with the 1.23 GHz radio continuum data from the MeerKAT MIGHTEE survey finding 47 detections. After filtering for AGN (via X-ray detections, hot mid-infrared dust and extended radio emission), as well as blended sources, we obtained a sample of SFGs comprising: 11 cataloged radio detections, 18 non-cataloged detections (at ~3-5sigma) and 298 undetected sources. Stacking the 298 undetected sources we obtain a 3.3sigma detection in the radio. This sample, along with a local sample of Paschen-alpha emitters, lies along previous radio luminosity/SFR relations from local (z<0.2) to high redshift (z~1). Fitting the FRESCO data at 1.0<=z<=1.8 we find log(L_1.4GHz) = (1.31+/-0.17) x log(SFR_Pa-alpha) + (21.36+/-0.17) which is consistent with other literature relations. We can explain some of the observed scatter in the L_1.4GHz/SFR_Pa-alpha correlation by a toy model in which the synchrotron emission is a delayed/averaged tracer of the instantaneous Paschen-alpha SFR by ~10/75 Myr."
  },
  {
    "date": "2026-01-21",
    "title": "Automatically Tightening Access Control Policies with Restricter",
    "authors": "Ka Lok Wu, Christa Jenkins, Scott D. Stolle, Omar Chowdhury",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14582v1",
    "source": "arXiv",
    "abstract": "Robust access control is a cornerstone of secure software, systems, and networks. An access control mechanism is as effective as the policy it enforces. However, authoring effective policies that satisfy desired properties such as the principle of least privilege is a challenging task even for experienced administrators, as evidenced by many real instances of policy misconfiguration. In this paper, we set out to address this pain point by proposing Restricter, which automatically tightens each (permit) policy rule of a policy with respect to an access log, which captures some already exercised access requests and their corresponding access decisions (i.e., allow or deny). Restricter achieves policy tightening by reducing the number of access requests permitted by a policy rule without sacrificing the functionality of the underlying system it is regulating. We implement Restricter for Amazon's Cedar policy language and demonstrate its effectiveness through two realistic case studies."
  },
  {
    "date": "2026-01-21",
    "title": "Global solution curves in harmonic parameters, and multiplicity of solutions",
    "authors": "Philip Korman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14581v1",
    "source": "arXiv",
    "abstract": "\\[ Δu+g(u)=f(x) \\s \\mbox{for $x \\in Ω$}, \\s u=0 \\s \\mbox{on $\\partial Ω$} \\] decompose $f(x)=μ_1 \\p _1+e(x)$, where $\\p _1$ is the principal eigenfunction of the Laplacian with zero boundary conditions, and $e(x) \\perp \\p _1$ in $L^2(Ω)$, and similarly write $u(x)= ξ_1 \\p _i+U (x)$, with $ U \\perp \\p _1$ in $L^2(Ω)$. We study properties of the solution curve $(u(x),μ_1)(ξ_1)$, and in particular its section $μ_1=μ_1(ξ_1)$, which governs the multiplicity of solutions. We consider both general nonlinearities, and some important classes of equations, and obtain detailed description of solution curves under the assumption $g'(u)<\\la _2$. We obtain particularly detailed results in case of one dimension. This approach is well suited for numerical computations, which we perform to illustrate our results."
  },
  {
    "date": "2026-01-21",
    "title": "The Lie Group Basis of Neuronal Membrane Architecture: Why the Hodgkin-Huxley Equations Take Their Form",
    "authors": "Robert F. Melendy, Daniel H. Blue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14579v1",
    "source": "arXiv",
    "abstract": "The Hodgkin-Huxley equations have described neuronal excitability for seventy years, yet their mathematical structure-gating exponents m3h and n4, exponential voltage dependencies, and bounded activation variables, has remained empirically justified rather than theoretically derived. Hodgkin and Huxley introduced voltage-dependent conductances controlled by gating variables. While these equations reproduce experimental observations, they were derived through curve-fitting without theoretical justification. Modern theoretical physics derives governing equations from symmetry principles through Lie group theory. We prove that the complete Hodgkin-Huxley equations necessarily follow from three fundamental symmetries: (1) compact conformational state spaces, (2) multiplicative conductance scaling, and (3) temporal translation invariance. These symmetries uniquely determine a Lie group structure isomorphic to SO(2) semidirect product with R2. From representation theory, we derive: boundedness from SO(2) compactness, exponential Boltzmann factors from scale invariance, specific integer exponents m3h and n4 from irreducible representations, and first-order kinetics from Lie algebra flows. This demonstrates that the HH equations are not empirical curve-fits but the unique mathematical structure mandated by fundamental symmetries. We reveal why gating variables must be bounded, voltage dependencies must be exponential, sodium requires three activation gates and one inactivation gate, potassium requires four activation gates, and kinetics must be first-order. This establishes that neural electrophysiology obeys the same theoretical framework as modern physics, where symmetries determine dynamics, providing a foundation for understanding channel mutations and network dynamics through group theory."
  },
  {
    "date": "2026-01-21",
    "title": "Quantitative Spectral Stability for an Embedded Annulus under Coupled Curve Shortening and $2$D Ricci Flows",
    "authors": "Mohammadjavad Habibivostakolaei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14575v1",
    "source": "arXiv",
    "abstract": "We study the spectral stability of Dirichlet eigenvalues on an embedded annulus whose boundary evolves by curve shortening flow while the ambient surface evolves under the two dimensional Ricci flow using variational formulas, Rellich--type identities, and harmonic capacity methods, we relate eigenvalue variations to geometric deficit and modulus. We establish quantitative bounds comparing the spectrum of the evolving annulus with that of a flat cylinder of equal modulus. As a consequence, we obtain geometric stability and a spectral gap estimate controlled by the deficit functional."
  },
  {
    "date": "2026-01-21",
    "title": "Excitation Energy Transfer in Nanohybrid System of Organic Molecule and Inorganic Transition Metal Dichalcogenides Nanoflake",
    "authors": "Yan Meng, Kainan Chang, Luxia Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14571v1",
    "source": "arXiv",
    "abstract": "Excitation energy transfer (EET) in an organic/inorganic nanohybrid system, composed of a single \\textit{para}-sexiphenyl (6P) molecule physisorbed on a finite-sized MoS$_2$ nanoflake, is investigated theoretically. % The electronic structure of the MoS$_2$ nanoflake is described by using an 11-band tight-binding model, in which edge states are passivated with H atoms to restore a well-defined bandgap. % Within a configuration-interaction scheme, excitonic states are constructed and, for computational efficiency, approximated by uncorrelated electron-hole pairs in the relevant high-energy window. % The EET rates are evaluated via Fermi's golden rule, incorporating Coulomb coupling, thermal broadening, and spectral overlap between the molecular excitation and the MoS$_2$ nanoflake's electron-hole pairs. % Our results reveal that energy transfer from the molecule to the nanoflake is the dominant process, and its efficiency depends strongly on the size of the MoS$_2$ nanoflake, as well as the molecule's vertical distance and lateral position relative to the nanoflake."
  },
  {
    "date": "2026-01-21",
    "title": "Agent Identity URI Scheme: Topology-Independent Naming and Capability-Based Discovery for Multi-Agent Systems",
    "authors": "Roland R. Rodriguez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14567v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems face a fundamental architectural flaw: agent identity is bound to network location. When agents migrate between providers, scale across instances, or federate across organizations, URI-based identity schemes break references, fragment audit trails, and require centralized coordination. We propose the agent:// URI scheme, which decouples identity from topology through three orthogonal components: a trust root establishing organizational authority, a hierarchical capability path enabling semantic discovery, and a sortable unique identifier providing stable reference. The scheme enables capability-based discovery through DHT key derivation, where queries return agents by what they do rather than where they are. Trust-root scoping prevents cross-organization pollution while permitting federation when desired. Cryptographic attestation via PASETO tokens binds capability claims to agent identity, enabling verification without real-time contact with the issuing authority. We evaluate the scheme across four dimensions: capability expressiveness (100% coverage on 369 production tools with zero collision), discovery precision (F1=1.0 across 10,000 agents), identity stability (formal proofs of migration invariance), and performance (all operations under 5 microseconds). The agent:// URI scheme provides a formally-specified, practically-evaluated foundation for decentralized agent identity and capability-based discovery."
  },
  {
    "date": "2026-01-21",
    "title": "SCSimulator: An Exploratory Visual Analytics Framework for Partner Selection in Supply Chains through LLM-driven Multi-Agent Simulation",
    "authors": "Shenghan Gao, Junye Wang, Junjie Xiong, Yun Jiang, Yun Fang, Qifan Hu, Baolong Liu, Quan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14566v1",
    "source": "arXiv",
    "abstract": "Supply chains (SCs), complex networks spanning from raw material acquisition to product delivery, with enterprises as interconnected nodes, play a pivotal role in organizational success. However, optimizing SCs remains challenging, particularly in partner selection, a key bottleneck shaped by competitive and cooperative dynamics. This challenge constitutes a multi-objective dynamic game requiring a synergistic integration of Multi-Criteria Decision-Making and Game Theory. Traditional approaches, grounded in mathematical simplifications and managerial heuristics, fail to capture real-world intricacies and risk introducing subjective biases. Multi-agent simulation offers promise, but prior research has largely relied on fixed, uniform agent logic, limiting practical applicability. Recent advances in LLMs create opportunities to represent complex SC requirements and hybrid game logic. However, challenges persist in modeling dynamic SC relationships, ensuring interpretability, and balancing agent autonomy with expert control. We present SCSimulator, a visual analytics framework that integrates LLM-driven MAS with human-in-the-loop collaboration for SC partner selection. It simulates SC evolution via adaptive network structures and enterprise behaviors, which are visualized via interpretable interfaces. By combining CoT reasoning with XAI techniques, it generates multi-faceted, transparent explanations of decision trade-offs. Users can iteratively adjust simulation settings to explore outcomes aligned with their expectations and strategic priorities. Developed through iterative co-design with SC experts and industry managers, SCSimulator serves as a proof-of-concept, offering methodological contributions and practical insights for future research on SC decision-making and interactive AI-driven analytics. Usage scenarios and a user study demonstrate the system's effectiveness and usability."
  },
  {
    "date": "2026-01-21",
    "title": "Programming Quantum Measurements of Time inside a Complex Medium",
    "authors": "Dylan Danese, Vatshal Srivastav, Will McCutcheon, Saroch Leedumrongwatthanakun, Mehul Malik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14565v1",
    "source": "arXiv",
    "abstract": "The temporal degree-of-freedom of light is incredibly powerful for modern quantum technologies, enabling large-scale quantum computing architectures and record key-rates in quantum key distribution. However, the generalized measurement of large and complex quantum superpositions of the time-of-arrival of a photon remains a unique experimental challenge. Conventional methods based on unbalanced Franson-type interferometers scale poorly with dimension, requiring multiple cascaded devices and active phase stabilization. In addition, these are limited by construction to a restricted set of phase-only superposition measurements. Here we show how the coupling of spatial and temporal information inside a single multi-mode fiber can be harnessed to program completely generalized measurements for high-dimensional superpositions of photonic time-bin. Using the multi-spectral transmission matrix of the fiber, we find special sets of spatial modes that experience distinct dispersive delays through the fiber. By exciting coherent superpositions of these spatial modes, we engineer the equivalent of large, unbalanced multi-mode interferometers inside the fiber and use them to perform high-quality measurements of arbitrary time-bin superpositions in up to dimension 11. The single fiber functions as a scalable, common-path interferometer for time-bin qudits that significantly eases the experimental overheads of standard approaches based on unbalanced Franson-type interferometers, serving as an essential tool for quantum technologies that harness the temporal properties of light."
  },
  {
    "date": "2026-01-21",
    "title": "Rewarding How Models Think Pedagogically: Integrating Pedagogical Reasoning and Thinking Rewards for LLMs in Education",
    "authors": "Unggi Lee, Jiyeong Bae, Jaehyeon Park, Haeun Park, Taejun Park, Younghoon Jeon, Sungmin Cho, Junbo Koh, Yeil Jeong, Gyeonggeon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14560v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly deployed as intelligent tutoring systems, yet research on optimizing LLMs specifically for educational contexts remains limited. Recent works have proposed reinforcement learning approaches for training LLM tutors, but these methods focus solely on optimizing visible responses while neglecting the model's internal thinking process. We introduce PedagogicalRL-Thinking, a framework that extends pedagogical alignment to reasoning LLMs in education through two novel approaches: (1) Pedagogical Reasoning Prompting, which guides internal reasoning using domain-specific educational theory rather than generic instructions; and (2) Thinking Reward, which explicitly evaluates and reinforces the pedagogical quality of the model's reasoning traces. Our experiments reveal that domain-specific, theory-grounded prompting outperforms generic prompting, and that Thinking Reward is most effective when combined with pedagogical prompting. Furthermore, models trained only on mathematics tutoring dialogues show improved performance on educational benchmarks not seen during training, while preserving the base model's factual knowledge. Our quantitative and qualitative analyses reveal that pedagogical thinking reward produces systematic reasoning trace changes, with increased pedagogical reasoning and more structured instructional decision-making in the tutor's thinking process."
  },
  {
    "date": "2026-01-21",
    "title": "Constructing Multi-label Hierarchical Classification Models for MITRE ATT&CK Text Tagging",
    "authors": "Andrew Crossman, Jonah Dodd, Viralam Ramamurthy Chaithanya Kumar, Riyaz Mohammed, Andrew R. Plummer, Chandra Sekharudu, Deepak Warrier, Mohammad Yekrangian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14556v1",
    "source": "arXiv",
    "abstract": "MITRE ATT&CK is a cybersecurity knowledge base that organizes threat actor and cyber-attack information into a set of tactics describing the reasons and goals threat actors have for carrying out attacks, with each tactic having a set of techniques that describe the potential methods used in these attacks. One major application of ATT&CK is the use of its tactic and technique hierarchy by security specialists as a framework for annotating cyber-threat intelligence reports, vulnerability descriptions, threat scenarios, inter alia, to facilitate downstream analyses. To date, the tagging process is still largely done manually. In this technical note, we provide a stratified \"task space\" characterization of the MITRE ATT&CK text tagging task for organizing previous efforts toward automation using AIML methods, while also clarifying pathways for constructing new methods. To illustrate one of the pathways, we use the task space strata to stage-wise construct our own multi-label hierarchical classification models for the text tagging task via experimentation over general cyber-threat intelligence text -- using shareable computational tools and publicly releasing the models to the security community (via https://github.com/jpmorganchase/MITRE_models). Our multi-label hierarchical approach yields accuracy scores of roughly 94% at the tactic level, as well as accuracy scores of roughly 82% at the technique level. The models also meet or surpass state-of-the-art performance while relying only on classical machine learning methods -- removing any dependence on LLMs, RAG, agents, or more complex hierarchical approaches. Moreover, we show that GPT-4o model performance at the tactic level is significantly lower (roughly 60% accuracy) than our own approach. We also extend our baseline model to a corpus of threat scenarios for financial applications produced by subject matter experts."
  },
  {
    "date": "2026-01-21",
    "title": "Self-Blinding and Counterfactual Self-Simulation Mitigate Biases and Sycophancy in Large Language Models",
    "authors": "Brian Christian, Matan Mazor",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14553v1",
    "source": "arXiv",
    "abstract": "Fair decisions require ignoring irrelevant, potentially biasing, information. To achieve this, decision-makers need to approximate what decision they would have made had they not known certain facts, such as the gender or race of a job candidate. This counterfactual self-simulation is notoriously hard for humans, leading to biased judgments even by well-meaning actors. Here we show that large language models (LLMs) suffer from similar limitations in their ability to approximate what decisions they would make under counterfactual knowledge in offsetting gender and race biases and overcoming sycophancy. We show that prompting models to ignore or pretend not to know biasing information fails to offset these biases and occasionally backfires. However, unlike humans, LLMs can be given access to a ground-truth model of their own counterfactual cognition -- their own API. We show that this access to the responses of a blinded replica enables fairer decisions, while providing greater transparency to distinguish implicit from intentionally biased behavior."
  },
  {
    "date": "2026-01-21",
    "title": "Towards Understanding Best Practices for Quantization of Vision-Language Models",
    "authors": "Gautom Das, Vincent La, Ethan Lau, Abhinav Shrivastava, Matthew Gwilliam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15287v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) deliver impressive results for a variety of tasks, but state-of-the-art systems require fast GPUs with large amounts of memory. To reduce both the memory and latency of these systems, practitioners quantize their learned parameters, typically at half precision. A growing body of research focuses on preserving the model performance with more aggressive bit widths, and some work has been done to apply these strategies to other models, like vision transformers. In our study we investigate how a variety of quantization methods, including state-of-the-art GPTQ and AWQ, can be applied effectively to multimodal pipelines comprised of vision models, language models, and their connectors. We address how performance on captioning, retrieval, and question answering can be affected by bit width, quantization method, and which portion of the pipeline the quantization is used for. Results reveal that ViT and LLM exhibit comparable importance in model performance, despite significant differences in parameter size, and that lower-bit quantization of the LLM achieves high accuracy at reduced bits per weight (bpw). These findings provide practical insights for efficient deployment of MLLMs and highlight the value of exploration for understanding component sensitivities in multimodal models. Our code is available at https://github.com/gautomdas/mmq."
  },
  {
    "date": "2026-01-21",
    "title": "LLM-based Multimodal Feedback Produces Equivalent Learning and Better Student Perceptions than Educator Feedback",
    "authors": "Chloe Qianhui Zhao, Jie Cao, Jionghao Lin, Kenneth R. Koedinger",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15280v1",
    "source": "arXiv",
    "abstract": "Providing timely, targeted, and multimodal feedback helps students quickly correct errors, build deep understanding and stay motivated, yet making it at scale remains a challenge. This study introduces a real-time AI-facilitated multimodal feedback system that integrates structured textual explanations with dynamic multimedia resources, including the retrieved most relevant slide page references and streaming AI audio narration. In an online crowdsourcing experiment, we compared this system against fixed business-as-usual feedback by educators across three dimensions: (1) learning effectiveness, (2) learner engagement, (3) perceived feedback quality and value. Results showed that AI multimodal feedback achieved learning gains equivalent to original educator feedback while significantly outperforming it on perceived clarity, specificity, conciseness, motivation, satisfaction, and reducing cognitive load, with comparable correctness, trust, and acceptance. Process logs revealed distinct engagement patterns: for multiple-choice questions, educator feedback encouraged more submissions; for open-ended questions, AI-facilitated targeted suggestions lowered revision barriers and promoted iterative improvement. These findings highlight the potential of AI multimodal feedback to provide scalable, real-time, and context-aware support that both reduces instructor workload and enhances student experience."
  },
  {
    "date": "2026-01-21",
    "title": "SearchGym: Bootstrapping Real-World Search Agents via Cost-Effective and High-Fidelity Environment Simulation",
    "authors": "Xichen Zhang, Ziyi He, Yinghao Zhu, Sitong Wu, Shaozuo Yu, Meng Chu, Wenhu Zhang, Haoru Tan, Jiaya Jia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14615v1",
    "source": "arXiv",
    "abstract": "Search agents have emerged as a pivotal paradigm for solving open-ended, knowledge-intensive reasoning tasks. However, training these agents via Reinforcement Learning (RL) faces a critical dilemma: interacting with live commercial Web APIs is prohibitively expensive, while relying on static data snapshots often introduces noise due to data misalignment. This misalignment generates corrupted reward signals that destabilize training by penalizing correct reasoning or rewarding hallucination. To address this, we propose SearchGym, a simulation environment designed to bootstrap robust search agents. SearchGym employs a rigorous generative pipeline to construct a verifiable knowledge graph and an aligned document corpus, ensuring that every reasoning task is factually grounded and strictly solvable. Building on this controllable environment, we introduce SearchGym-RL, a curriculum learning methodology that progressively optimizes agent policies through purified feedback, evolving from basic interactions to complex, long-horizon planning. Extensive experiments across the Llama and Qwen families demonstrate strong Sim-to-Real generalization. Notably, our Qwen2.5-7B-Base model trained within SearchGym surpasses the web-enhanced ASearcher baseline across nine diverse benchmarks by an average relative margin of 10.6%. Our results validate that high-fidelity simulation serves as a scalable and highly cost-effective methodology for developing capable search agents."
  },
  {
    "date": "2026-01-21",
    "title": "Koszul Binomial Edge Ideals",
    "authors": "Adam LaClair, Matthew Mastroeni, Jason McCullough, Irena Peeva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15243v1",
    "source": "arXiv",
    "abstract": "As the binomial edge ideal of a graph is always generated by homogeneous quadratic polynomials corresponding to the edges of the graph, the question of when a binomial edge ideal defines a Koszul algebra has been studied by many authors ever since the class of ideals was first defined. Several partial results are known, including a characterization of those binomial edge ideals that possess a quadratic Gröbner basis. However, a complete characterization of the graphs determining Koszul binomial edge ideals has remained elusive. Inspired by our recent work characterizing when the graded Möbius algebras of graphic matroids are Koszul, we answer the question once and for all by proving that a graph defines a Koszul binomial edge ideal if and only if it is strongly chordal and claw-free."
  },
  {
    "date": "2026-01-21",
    "title": "On the DGKT brane dual and its decoupling",
    "authors": "Fien Apers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15093v1",
    "source": "arXiv",
    "abstract": "It is not understood whether scale-separated AdS vacua in string theory admit a holographic dual. A well-known class of such vacua is provided by the DGKT solutions of massive type IIA string theory, where scale separation arises from large fluxes. In this work, we construct a ten-dimensional brane geometry whose near-horizon limit reproduces the DGKT vacua, using a flux-backtracking approach combined with intersecting D4-brane stacks dual to the unbounded flux sector. We then use this setup to test whether the brane worldvolume theory decouples from the bulk. Modes localised near the branes, deep in the AdS throat, are found to be infinitely redshifted with respect to asymptotic observers. Moreover, an analysis of graviton fluctuations shows the presence of an infinite potential barrier near the branes, providing a direct indication of decoupling. We conclude by comparing these results with recent arguments against decoupling in scale-separated AdS vacua, which focus on the asymptotic region where modes are blueshifted."
  },
  {
    "date": "2026-01-21",
    "title": "From carbon management strategies to implementation: Modeling and physical simulation of CO2 pipeline infrastructure -- a case study for Germany",
    "authors": "Mehrnaz Anvari, Marius Neuwirth, Okan Akca, Luna Lütz, Simon Lukas Bussmann, Tobias Fleiter, Bernhard Klaassen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15090v1",
    "source": "arXiv",
    "abstract": "Carbon capture and storage or utilization (CCUS) will play an important role to achieve climate neutrality in many economies. Pipelines are widely regarded as the most efficient means of CO2 transport; however, they are currently non-existent. Policy-makers and companies need to develop large-scale infrastructure under substantial uncertainty. Methods and analyses are needed to support pipeline planning and strategy development. This paper presents an integrated method for designing CO2 pipeline networks by combining energy system scenarios with physical network simulation. Using Germany as a case study, we derive spatially highly resolved CO2 balances to develop a dense-phase CO2 pipeline topology that follows existing gas pipeline corridors. The analyzed system includes existing sites for cement and lime production, waste incineration, carbon users, four coastal CO2 hubs, and border crossing points. We then apply the multiphysical network simulator MYNTS to assess the technical feasibility of this network. We determine pipeline diameters, pump locations, and operating conditions that ensure stable dense-phase transport. The method explicitly accounts for elevation and possible impurities. The results indicate that a system of about 7000 km pipeline length and a mixed normed diameter of DN700 on main corridors and of DN500/DN400 on branches presents a feasible solution to connect most sites. Investment costs for the optimized pipeline system are calculated to be about 17 billion Euros. The method provides a reproducible framework and is transferable to other countries and to European scope."
  },
  {
    "date": "2026-01-21",
    "title": "DeepMoLM: Leveraging Visual and Geometric Structural Information for Molecule-Text Modeling",
    "authors": "Jing Lan, Hexiao Ding, Hongzhao Chen, Yufeng Jiang, Nga-Chun Ng, Gwing Kei Yip, Gerald W. Y. Cheng, Yunlin Mao, Jing Cai, Liang-ting Lin, Jung Sun Yoo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14732v1",
    "source": "arXiv",
    "abstract": "AI models for drug discovery and chemical literature mining must interpret molecular images and generate outputs consistent with 3D geometry and stereochemistry. Most molecular language models rely on strings or graphs, while vision-language models often miss stereochemical details and struggle to map continuous 3D structures into discrete tokens. We propose DeepMoLM: Deep Molecular Language M odeling, a dual-view framework that grounds high-resolution molecular images in geometric invariants derived from molecular conformations. DeepMoLM preserves high-frequency evidence from 1024 $\\times$ 1024 inputs, encodes conformer neighborhoods as discrete Extended 3-Dimensional Fingerprints, and fuses visual and geometric streams with cross-attention, enabling physically grounded generation without atom coordinates. DeepMoLM improves PubChem captioning with a 12.3% relative METEOR gain over the strongest generalist baseline while staying competitive with specialist methods. It produces valid numeric outputs for all property queries and attains MAE 13.64 g/mol on Molecular Weight and 37.89 on Complexity in the specialist setting. On ChEBI-20 description generation from images, it exceeds generalist baselines and matches state-of-the-art vision-language models. Code is available at https://github.com/1anj/DeepMoLM."
  },
  {
    "date": "2026-01-21",
    "title": "Heterogeneous Transfer of Thin Film BaTiO$_3$ onto Silicon for Device Fabrication",
    "authors": "Temazulu S. Zulu, Larissa B. Little, Aaron M. Day, Chaoshen Zhang, Keith Powell, Kyeong-Yoon Baek, Benazir Fazlioglu-Yalcin, Neil Sinclair, Charles M. Brooks, David R. Barton, Marko Loncar, Julia A. Mundy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14551v1",
    "source": "arXiv",
    "abstract": "Thin film BaTiO$_3$ has one of the highest known Pockels coefficients (>1200 pm/V), making it an attractive material for use in electro-optic devices. It is advantageous to integrate BaTiO$_3$ on silicon to enable complementary metal-oxide-semiconductor (CMOS) compatible processing. However, synthesis of high-quality BaTiO$_3$ directly on silicon remains a challenge. Here, we synthesize BaTiO$_3$ using hybrid metal-organic molecular beam epitaxy (hMBE) and demonstrate its transfer onto silicon using thermocompression bonding and chemical lift-off. Hybrid metal-organic MBE enables self-regulated synthesis of highly stoichiometric thin films at high growth rates (>100nm/hr). Our transfer method results in millimeter-scale areas of atomically flat, crack-free BaTiO$_3$ making it a potentially scalable method. Finally, we demonstrate the applicability of our process to device fabrication through characterization of lithographically-patterned and etch-transferred sub-micron features."
  },
  {
    "date": "2026-01-21",
    "title": "The Enclosed Volume for Periodic Constant Mean Curvature Surfaces",
    "authors": "Lynn Heller, Sebastian Heller, Martin Traizet",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14935v1",
    "source": "arXiv",
    "abstract": "We establish a general formula for the enclosed volume of constant mean curvature (CMC) surfaces in Euclidean three space with translational periods forming a lattice. The formula relates the volume to the surface area, a Wess-Zumino-Witten-type term, and a newly defined curvature term of the associated family of flat connections, thereby extending the classical Minkowski formula for closed CMC surfaces. Interpreting the volume as a gauge-invariant quantity, we apply the result to a variety of examples and provide explicit computations. As an application, we construct a counterexample to the isoperimetric problem in $\\mathbb{T}^2 \\times \\mathbb{R}$, disproving the conjecture that minimizers are restricted to spheres, cylinders, or pairs of planes."
  },
  {
    "date": "2026-01-21",
    "title": "The First Upper Bound on the Nano-Hertz Gravitational Waves and Galaxy Cross-Correlation signal using 15-year NANOGrav Data and DESI Galaxy Survey",
    "authors": "Mohit Raj Sah, Suvodip Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14863v1",
    "source": "arXiv",
    "abstract": "The recent detection of a common-spectrum stochastic signal by multiple pulsar timing array (PTA) collaborations has provided tentative evidence for a nanohertz (nHz) stochastic gravitational-wave background (SGWB). This signal can be widely interpreted as originating from a cosmic population of inspiraling supermassive black hole binaries (SMBHBs). Current PTA analyses primarily constrain the SGWB power spectrum and its auto-angular power spectrum. However, the supermassive black holes will produce an underlying correlation with the large-scale structure of the Universe, which can help in understanding the formation and evolution of the binaries. In this work, we develop a new analysis pipeline PyGxGW-PTA for studying the cross-correlation of nHz GW signal with galaxy surveys ($C^{\\rm g\\, GW}_\\ell$) and obtain the first constraint on the SGWB and galaxy distribution cross-correlation using the NANOGrav 15-year dataset in combination with the DESI galaxy catalog. We find no statistically significant correlation between the SGWB and the large-scale distribution of DESI galaxies and using an optimal estimator we put an upper bound on $C^{\\rm g\\, GW}_{\\ell=8} < 0.0083$ at $95\\%$ C.I. This yields the first observational upper limit on the spatial correlation between the nHz SGWB and the large-scale structure of the Universe, establishing the observational groundwork for future multi-tracer analyses that will combine PTA data with next-generation galaxy surveys to unveil the SMBHB-galaxy correlation."
  },
  {
    "date": "2026-01-21",
    "title": "FSX: Message Flow Sensitivity Enhanced Structural Explainer for Graph Neural Networks",
    "authors": "Bizu Feng, Zhimu Yang, Shaode Yu, Zixin Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14730v1",
    "source": "arXiv",
    "abstract": "Despite the widespread success of Graph Neural Networks (GNNs), understanding the reasons behind their specific predictions remains challenging. Existing explainability methods face a trade-off that gradient-based approaches are computationally efficient but often ignore structural interactions, while game-theoretic techniques capture interactions at the cost of high computational overhead and potential deviation from the model's true reasoning path. To address this gap, we propose FSX (Message Flow Sensitivity Enhanced Structural Explainer), a novel hybrid framework that synergistically combines the internal message flows of the model with a cooperative game approach applied to the external graph data. FSX first identifies critical message flows via a novel flow-sensitivity analysis: during a single forward pass, it simulates localized node perturbations and measures the resulting changes in message flow intensities. These sensitivity-ranked flows are then projected onto the input graph to define compact, semantically meaningful subgraphs. Within each subgraph, a flow-aware cooperative game is conducted, where node contributions are evaluated fairly through a Shapley-like value that incorporates both node-feature importance and their roles in sustaining or destabilizing the identified critical flows. Extensive evaluation across multiple datasets and GNN architectures demonstrates that FSX achieves superior explanation fidelity with significantly reduced runtime, while providing unprecedented insights into the structural logic underlying model predictions--specifically, how important sub-structures exert influence by governing the stability of key internal computational pathways."
  },
  {
    "date": "2026-01-21",
    "title": "Finite de Finetti for convex bodies and Polynomial Optimization",
    "authors": "Julius A. Zeiss, Gereon Koßmann, René Schwonnek, Martin Plávala",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15184v1",
    "source": "arXiv",
    "abstract": "Leveraging a recently proposed notion of relative entropy in general probabilistic theories (GPT), we prove a finite de Finetti representation theorem for general convex bodies. We apply this result to address a fundamental question in polynomial optimization: the existence of a convergent outer hierarchy for problems with inequality constraints and analytical convergence guarantees. Our strategy generalizes a quantitative monogamy-of-entanglement argument from quantum theory to arbitrary convex bodies, establishing a uniform upper bound on mutual information in multipartite extensions. This leads to a finite de Finetti theorem and, subsequently, a convergent conic hierarchy for a wide class of polynomial optimization problems subject to both equality and inequality constraints. We further provide a constructive rounding scheme that yields certified interior points with controlled approximation error. As an application, we express the optimal GPT value of a two-player non-local game as a polynomial optimization problem, allowing our techniques to produce approximation schemes with finite convergence guarantees."
  },
  {
    "date": "2026-01-21",
    "title": "Is Peer Review Really in Decline? Analyzing Review Quality across Venues and Time",
    "authors": "Ilia Kuznetsov, Rohan Nayak, Alla Rozovskaya, Iryna Gurevych",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15172v1",
    "source": "arXiv",
    "abstract": "Peer review is at the heart of modern science. As submission numbers rise and research communities grow, the decline in review quality is a popular narrative and a common concern. Yet, is it true? Review quality is difficult to measure, and the ongoing evolution of reviewing practices makes it hard to compare reviews across venues and time. To address this, we introduce a new framework for evidence-based comparative study of review quality and apply it to major AI and machine learning conferences: ICLR, NeurIPS and *ACL. We document the diversity of review formats and introduce a new approach to review standardization. We propose a multi-dimensional schema for quantifying review quality as utility to editors and authors, coupled with both LLM-based and lightweight measurements. We study the relationships between measurements of review quality, and its evolution over time. Contradicting the popular narrative, our cross-temporal analysis reveals no consistent decline in median review quality across venues and years. We propose alternative explanations, and outline recommendations to facilitate future empirical studies of review quality."
  },
  {
    "date": "2026-01-21",
    "title": "ExPrIS: Knowledge-Level Expectations as Priors for Object Interpretation from Sensor Data",
    "authors": "Marian Renz, Martin Günther, Felix Igelbrink, Oscar Lima, Martin Atzmueller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15025v1",
    "source": "arXiv",
    "abstract": "While deep learning has significantly advanced robotic object recognition, purely data-driven approaches often lack semantic consistency and fail to leverage valuable, pre-existing knowledge about the environment. This report presents the ExPrIS project, which addresses this challenge by investigating how knowledge-level expectations can serve as to improve object interpretation from sensor data. Our approach is based on the incremental construction of a 3D Semantic Scene Graph (3DSSG). We integrate expectations from two sources: contextual priors from past observations and semantic knowledge from external graphs like ConceptNet. These are embedded into a heterogeneous Graph Neural Network (GNN) to create an expectation-biased inference process. This method moves beyond static, frame-by-frame analysis to enhance the robustness and consistency of scene understanding over time. The report details this architecture, its evaluation, and outlines its planned integration on a mobile robotic platform."
  },
  {
    "date": "2026-01-21",
    "title": "Plug-and-Play Benchmarking of Reinforcement Learning Algorithms for Large-Scale Flow Control",
    "authors": "Jannis Becktepe, Aleksandra Franz, Nils Thuerey, Sebastian Peitz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15015v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) has shown promising results in active flow control (AFC), yet progress in the field remains difficult to assess as existing studies rely on heterogeneous observation and actuation schemes, numerical setups, and evaluation protocols. Current AFC benchmarks attempt to address these issues but heavily rely on external computational fluid dynamics (CFD) solvers, are not fully differentiable, and provide limited 3D and multi-agent support. To overcome these limitations, we introduce FluidGym, the first standalone, fully differentiable benchmark suite for RL in AFC. Built entirely in PyTorch on top of the GPU-accelerated PICT solver, FluidGym runs in a single Python stack, requires no external CFD software, and provides standardized evaluation protocols. We present baseline results with PPO and SAC and release all environments, datasets, and trained models as public resources. FluidGym enables systematic comparison of control methods, establishes a scalable foundation for future research in learning-based flow control, and is available at https://github.com/safe-autonomous-systems/fluidgym."
  },
  {
    "date": "2026-01-21",
    "title": "The Initial Value Problem for Harmonic maps of Cohomogeneity One manifolds",
    "authors": "Anna Siffert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15022v1",
    "source": "arXiv",
    "abstract": "We set up and solve the initial value problem for equivariant harmonic maps of cohomogeneity one manifolds, i.e. we show the local existence of a harmonic map in the neighborhood of a singular orbit. Furthermore, we present some theory of regular-singular systems of first order."
  },
  {
    "date": "2026-01-21",
    "title": "Mixture-of-Experts Models in Vision: Routing, Optimization, and Generalization",
    "authors": "Adam Rokah, Daniel Veress, Caleb Caulk, Sourav Sharan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15021v1",
    "source": "arXiv",
    "abstract": "Mixture-of-Experts (MoE) architectures enable conditional computation by routing inputs to multiple expert subnetworks and are often motivated as a mechanism for scaling large language models. In this project, we instead study MoE behavior in an image classification setting, focusing on predictive performance, expert utilization, and generalization. We compare dense, SoftMoE, and SparseMoE classifier heads on the CIFAR10 dataset under comparable model capacity. Both MoE variants achieve slightly higher validation accuracy than the dense baseline while maintaining balanced expert utilization through regularization, avoiding expert collapse. To analyze generalization, we compute Hessian-based sharpness metrics at convergence, including the largest eigenvalue and trace of the loss Hessian, evaluated on both training and test data. We find that SoftMoE exhibits higher sharpness by these metrics, while Dense and SparseMoE lie in a similar curvature regime, despite all models achieving comparable generalization performance. Complementary loss surface perturbation analyses reveal qualitative differences in non-local behavior under finite parameter perturbations between dense and MoE models, which help contextualize curvature-based measurements without directly explaining validation accuracy. We further evaluate empirical inference efficiency and show that naively implemented conditional routing does not yield inference speedups on modern hardware at this scale, highlighting the gap between theoretical and realized efficiency in sparse MoE models."
  },
  {
    "date": "2026-01-21",
    "title": "Decomposition of angular momentum projected nuclear wave function",
    "authors": "Wen Chen, Zhan-Jiang Lian, Xue-Wei Li, Xin-Yang Xia, Zi-Yang He, Ke-Zheng Ruan, Zao-Chun Gao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15002v1",
    "source": "arXiv",
    "abstract": "Angular momentum projection is a basic technique in constructing nuclear wave functions with good spins. Traditionally, a projected nuclear wave function is expressed in terms of the bases built by performing the angular momentum projection directly on reference states for the whole nuclear system. Alternatively, one can construct nuclear wave function with another kind of projected bases, called as the coupled projected bases, which are generated by first performing the angular momentum projections on the reference states for neutrons and protons, respectively, then coupling the neutron projected states with the proton ones via Clebsch-Gordon coefficients. In the present work, we derive a new identity, which provides a decomposition of the conventional angular momentum projected nuclear wave function in terms of the coupled projected bases. This decomposition offers direct insight into the underlying structure of nuclear states. To show this point, we present the decompositions of variation after projection shell model (VAPSM) wave functions for the ground states in some $sd$ shell nuclei. It is interesting to see that even for the ground states in even-even nuclei, the nucleons are not fully paired. Finally, we demonstrate that the VAPSM wave function can be further improved by adopting the coupled projected bases."
  },
  {
    "date": "2026-01-21",
    "title": "Obscuring Data Contamination Through Translation: Evidence from Arabic Corpora",
    "authors": "Chaymaa Abbas, Nour Shamaa, Mariette Awad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14994v1",
    "source": "arXiv",
    "abstract": "Data contamination undermines the validity of Large Language Model evaluation by enabling models to rely on memorized benchmark content rather than true generalization. While prior work has proposed contamination detection methods, these approaches are largely limited to English benchmarks, leaving multilingual contamination poorly understood. In this work, we investigate contamination dynamics in multilingual settings by fine-tuning several open-weight LLMs on varying proportions of Arabic datasets and evaluating them on original English benchmarks. To detect memorization, we extend the Tested Slot Guessing method with a choice-reordering strategy and incorporate Min-K% probability analysis, capturing both behavioral and distributional contamination signals. Our results show that translation into Arabic suppresses conventional contamination indicators, yet models still benefit from exposure to contaminated data, particularly those with stronger Arabic capabilities. This effect is consistently reflected in rising Mink% scores and increased cross-lingual answer consistency as contamination levels grow. To address this blind spot, we propose Translation-Aware Contamination Detection, which identifies contamination by comparing signals across multiple translated benchmark variants rather than English alone. The Translation-Aware Contamination Detection reliably exposes contamination even when English-only methods fail. Together, our findings highlight the need for multilingual, translation-aware evaluation pipelines to ensure fair, transparent, and reproducible assessment of LLMs."
  },
  {
    "date": "2026-01-21",
    "title": "Random Gilbert-Varshamov Codes for Joint Source-Channel Coding",
    "authors": "AmirPouya Moeini, Albert Guillén i Fàbregas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14987v1",
    "source": "arXiv",
    "abstract": "We propose a random coding technique for joint source-channel coding of discrete memoryless sources and channels. The approach builds on the random Gilbert-Varshamov code construction of Somekh-Baruch et al. and extends it to the joint source-channel setting. We show that the resulting ensemble attains the maximum of the random-coding and expurgated error exponents."
  },
  {
    "date": "2026-01-21",
    "title": "Energy-efficient time series processing in real-time with fluidic iontronic memristor circuits",
    "authors": "T. M. Kamsma, Y. Gu, C. Spitoni, M. Dijkstra, Y. Xie, R. van Roij",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14986v1",
    "source": "arXiv",
    "abstract": "Iontronic neuromorphic computing has emerged as a rapidly expanding paradigm. The arrival of angstrom-confined iontronic devices enables ultra-low power consumption with dynamics and memory timescales that intrinsically align well with signals of natural origin, a challenging combination for conventional (solid-state) neuromorphic materials. However, comparisons to earlier conventional substrates and evaluations of concrete application domains remain a challenge for iontronics. Here we propose a pathway toward iontronic circuits that can address established time series benchmark tasks, enabling performance comparisons and highlighting possible application domains for efficient real-time time series processing. We model a Kirchhoff-governed circuit with iontronic memristors as edges, while the dynamic internal voltages serve as output vector for a linear readout function, during which energy consumption is also logged. All these aspects are integrated into the open-source pyontronics package. Without requiring input encoding or virtual timing mechanisms, our simulations demonstrate prediction performance comparable to various earlier solid-state reservoirs, notably with an exceptionally low energy consumption of over 5 orders of magnitude lower. These results suggest a pathway of iontronic technologies for ultra-low-power real-time neuromorphic computation."
  },
  {
    "date": "2026-01-21",
    "title": "Kinematics of the HII region NGC 7538 from study of the Ha line",
    "authors": "D. Russeil, H. Plana, P. Amram, A. Zavagno, F. Michel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14975v1",
    "source": "arXiv",
    "abstract": "Aims. Massive stars impact their surrounding initiating star-formation along their photo-dissociation region. Once the HII region is formed it is unclear if and how the second generation of stars impacts its aspect and evolution. Methods. We performed high spectral resolution (R ~ 23400) Ha Fabry-Perot observations in five fields covering the Galactic HII region NGC 7538 and lead profiles multi-gaussian fitting to extract the parameters as peak intensity, width and velocity. We then analyse the kinematics of the ionised gas building kinematic diagrams and second order structure functions for every field. Results. The observations reveal a general blue-shifted ionised gas flow larger than 11 km s-1 in NGC 7538, consistent with previous studies. Profiles originating from features that are dark in Ha due to extinction or from outside the region show velocity dispersion larger than the one typically found for the Warm Interstellar Medium. The analysis of kinematic diagrams and second-order structure functions reveals non-thermal motions attributed to turbulence and large-scale velocity gradients. In the direction of the HII region itself the turbulence seems to be shock-dominated, with a characteristic scale length between ~ 0.72 and 1.46 pc. In this context, we propose that the kinematics of the central part of the region could be explained by the superposition of the outflow coming from IRS1 and a wind bow shock formed ahead IRS6."
  },
  {
    "date": "2026-01-21",
    "title": "Comment on \"Electrostatics-induced breakdown of the integer quantum Hall effect in cavity QED''",
    "authors": "C. Ciuti, G. Scalari, J. Faist",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14974v1",
    "source": "arXiv",
    "abstract": "We comment on the preprint arXiv:2511.04744 by Andolina et al."
  },
  {
    "date": "2026-01-21",
    "title": "Top quark FCNC in Randall-Sundrum models: post-LHC allowed rates and searches at $e^+e^-$ and $μ^+ μ^-$ colliders",
    "authors": "Sagar Airen, Roberto Franceschini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14966v1",
    "source": "arXiv",
    "abstract": "We present the sensitivity to Flavor Changing Neutral Currents (FCNC) in interactions involving the top quark at future $e^+e^-$ and $μ^+μ^-$ machines. We consider the $Ztc$ vertex as well as four-fermion contact interactions involving top and charm quarks. To incorporate limits from (HL-)LHC we consider FCNC from Randall-Sundrum models and we recast LHC searches for the resonances that at the microscopic level give rise to the FCNC effects. We determine the maximal strength of the effective FCNC couplings $Ztc$ coupling allowed by LHC. We find that the LHC currently improves on the limit set by previous machines, e.g. LEP indirect sensitivity to heavy vectors. Future improvements of direct searches at HL-LHC may reach a level equivalent to $BR(t\\to c Z)\\simeq 10^{-6}$. We explore the possibility to probe even smaller FCNC coupling strength using an $e^+e^-$ machine at center-of-mass energy suitable for a Higgs factory $E_{cm}\\in$ [200,240] GeV or to probe contact interactions involving top and charm flavors at a high-energy muon collider at $E_{cm}=10$ TeV."
  },
  {
    "date": "2026-01-21",
    "title": "How to Improve Portuguese Secondary Education",
    "authors": "C. J. A. P. Martins",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14962v1",
    "source": "arXiv",
    "abstract": "I share some personal thoughts on the status of Portuguese secondary education in general, and of the physics part thereof in particular, drawn from several decades of experience of organizing training activities for students and school teachers, as well as several hundred visits to secondary schools and similar numbers of interviews of secondary school students (from Portugal and elsewhere). I offer various suggestions for improving and modernising our current system."
  },
  {
    "date": "2026-01-21",
    "title": "A Comprehensive Benchmark of Language Models on Unicode and Romanized Sinhala",
    "authors": "Minuri Rajapakse, Ruvan Weerasinghe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14958v1",
    "source": "arXiv",
    "abstract": "The performance of Language Models (LMs) on lower-resource, morphologically rich languages like Sinhala remains under-explored, particularly for Romanized Sinhala, which is prevalent in digital communication. This paper presents a comprehensive benchmark of modern LMs on a diverse corpus of Unicode and Romanized Sinhala. We evaluate open-source models using perplexity, a measure of how well a model predicts a text, and leading closed-source models via a qualitative analysis of sentence completion. Our findings reveal that the Mistral-Nemo-Base-2407 model achieves the strongest predictive performance on Unicode text and the Mistral-7B-v0.3 model for Romanized text. The results also highlight the strong all-around performance of the Llama-3.1-8B model for both scripts. Furthermore, a significant performance disparity exists among closed-source models: Gemini-1.5-pro and DeepSeek excel at Unicode generation, whereas Claude-3.5-Sonnet is superior at handling Romanized text. These results provide an essential guide for practitioners selecting models for Sinhala-specific applications and highlight the critical role of training data in handling script variations."
  },
  {
    "date": "2026-01-21",
    "title": "Bending strain induced thermal conductivity suppression in freestanding BaTiO3 and SrTiO3 membranes",
    "authors": "Ziyan Qian, Guangwu Zhang, Weikun Zhou, Tsukasa Katayama, Qiye Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14956v1",
    "source": "arXiv",
    "abstract": "Freestanding perovskite oxide membranes provide a novel platform for elastic strain engineering, enabling the manipulation of phonon transport free from substrate clamping. In this work, we investigate the thermal transport properties of strontium titanate (SrTiO3) and barium titanate (BaTiO3) membranes subjected to self-formed crease induced inhomogeneous strain. By integrating spatially resolved Frequency-Domain Thermoreflectance (FDTR) with micro-Raman spectroscopy, we observe a sharp, localized suppression of thermal conductivity (k) in high-curvature regions. Specifically, k is reduced from 4.43 to 3.62 W/(m K) in SrTiO3 and from 2.27 to 1.81 W/(m K) in BaTiO3 at the crease centers, directly correlating with the local strain distribution. First-principles calculations reveal that, unlike uniform strain, the symmetry breaking induced by strain gradients significantly broadens phonon dispersion and enhances scattering rates. These findings not only elucidate the microscopic mechanisms governing phonon-strain coupling but also demonstrate the potential of inhomogeneous strain fields as a potent tool for designing dynamic solid-state thermal switches and active thermal management devices."
  },
  {
    "date": "2026-01-21",
    "title": "Multimodal Rumor Detection Enhanced by External Evidence and Forgery Features",
    "authors": "Han Li, Hua Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14954v1",
    "source": "arXiv",
    "abstract": "Social media increasingly disseminates information through mixed image text posts, but rumors often exploit subtle inconsistencies and forged content, making detection based solely on post content difficult. Deep semantic mismatch rumors, which superficially align images and texts, pose particular challenges and threaten online public opinion. Existing multimodal rumor detection methods improve cross modal modeling but suffer from limited feature extraction, noisy alignment, and inflexible fusion strategies, while ignoring external factual evidence necessary for verifying complex rumors. To address these limitations, we propose a multimodal rumor detection model enhanced with external evidence and forgery features. The model uses a ResNet34 visual encoder, a BERT text encoder, and a forgery feature module extracting frequency-domain traces and compression artifacts via Fourier transformation. BLIP-generated image descriptions bridge image and text semantic spaces. A dual contrastive learning module computes contrastive losses between text image and text description pairs, improving detection of semantic inconsistencies. A gated adaptive feature-scaling fusion mechanism dynamically adjusts multimodal fusion and reduces redundancy. Experiments on Weibo and Twitter datasets demonstrate that our model outperforms mainstream baselines in macro accuracy, recall, and F1 score."
  },
  {
    "date": "2026-01-21",
    "title": "Deep Learning assisted Port-Cycling based Channel Sounding for Precoder Estimation in Massive MIMO Arrays",
    "authors": "Advaith Arun, Shiv Shankar, Dhivagar Baskaran, Klutto Milleth, Bhaskar Ramamurthi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14953v1",
    "source": "arXiv",
    "abstract": "Future wireless systems are expected to employ a substantially larger number of transmit ports for channel state information (CSI) estimation compared to current specifications. Although scaling ports improves spectral efficiency, it also increases the resource overhead to transmit reference signals across the time-frequency grid, ultimately reducing achievable data throughput. In this work, we propose an deep learning (DL)-based CSI reconstruction framework that serves as an enabler for reliable CSI acquisition in future 6G systems. The proposed solution involves designing a port-cycling mechanism that sequentially sounds different portions of CSI ports across time, thereby lowering the overhead while preserving channel observability. The proposed CSI Adaptive Network (CsiAdaNet) model exploits the resulting sparse measurements and captures both spatial and temporal correlations to accurately reconstruct the full-port CSI. The simulation results show that our method achieves overhead reduction while maintaining high CSI reconstruction accuracy."
  },
  {
    "date": "2026-01-21",
    "title": "Diagonals and algebraicity modulo $p$: a sharper degree bound",
    "authors": "Boris Adamczewski, Alin Bostan, Xavier Caruso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14920v1",
    "source": "arXiv",
    "abstract": "In 1984, Deligne proved that for any prime number $p$, the reduction modulo $p$ of the diagonal of a multivariate algebraic power series with integer coefficients is algebraic over the field of rational functions with coefficients in $\\mathbb F_p$. Moreover, he conjectured that the algebraic degrees $d_p$ of these functions should grow at most polynomially in $p$. In this article, we provide a new and elementary proof of Deligne's theorem, which yields the first general polynomial bound on $d_p$ with an explicit and reasonable degree."
  },
  {
    "date": "2026-01-21",
    "title": "Citation of scientific evidence from video description and its association with attention and impact",
    "authors": "Pablo Dorta-González, María Isabel Dorta-González",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14916v1",
    "source": "arXiv",
    "abstract": "This study investigates how YouTube content creators utilize scientific evidence in videos. Log-linear regression examines the influence of alternative communication channels on video creators in Biotechnology, using data from 81,302 papers (2018-2023). This reveals a positive association with news articles and Wikipedia pages, but a negative association with scientific papers, policy documents, and patents. Despite the potential for enriching discussions, science video creators seem to favor materials with wider public attention over influential science, technology, and policy papers. These findings suggest a need for improved dissemination strategies for scientific research. Authors, universities, and journals should consider how their work can be made more accessible and engaging for science communicators on video."
  },
  {
    "date": "2026-01-21",
    "title": "Random infinite ideal angled graphs and ideal hyperbolic polyhedra",
    "authors": "Huabin Ge, Yangxiang Lu, Chuwen Wang, Tian Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14909v1",
    "source": "arXiv",
    "abstract": "This article aims to develop the uniformization and boundary theory of random infinite ideal hyperbolic polyhedra (abbr. IHP) and their dual 1-skeleton, i.e., ideal angled graphs (abbr. IAG) from multiple perspectives, including combinatorics, geometry, analysis and random walks. For unimodular random IAG, we establish an ICP analog of the dichotomy theorem of Angel-Hutchcroft-Nachmias-Ray [4,5]. Specifically, the character $T(ρ):=\\sum_{e\\niρ}Θ_e$ of an IAG, introduced in [40], determines its ICP type: the graph is a.s. ICP-parabolic if and only if $\\mathbb{E}[T(ρ)]=2π$. In the ICP-hyperbolic case, the simple random walk converges a.s. to $\\partial\\mathbb{D}$ with positive hyperbolic speed. Moreover, the geometric, Poisson, Martin, and Gromov boundaries coincide, extending the boundary theory of Angel-Barlow-Gurevich-Nachmias [3] and Hutchcroft-Peres [37] beyond triangulations to cellular decompositions. As a corollary of the aforementioned IHP/IAG duality, we obtain the systematic characterizations of the random IHP. To develop our theory, we strengthen and refine the Ring Lemma of Ge-Yu-Zhou [27] for ICP, which provides quantitative local control of the packing geometry. This key estimate makes it possible to extend the boundary theory beyond triangulations."
  },
  {
    "date": "2026-01-21",
    "title": "PodBench: A Comprehensive Benchmark for Instruction-Aware Audio-Oriented Podcast Script Generation",
    "authors": "Chenning Xu, Mao Zheng, Mingyu Zheng, Mingyang Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14903v1",
    "source": "arXiv",
    "abstract": "Podcast script generation requires LLMs to synthesize structured, context-grounded dialogue from diverse inputs, yet systematic evaluation resources for this task remain limited. To bridge this gap, we introduce PodBench, a benchmark comprising 800 samples with inputs up to 21K tokens and complex multi-speaker instructions. We propose a multifaceted evaluation framework that integrates quantitative constraints with LLM-based quality assessment. Extensive experiments reveal that while proprietary models generally excel, open-source models equipped with explicit reasoning demonstrate superior robustness in handling long contexts and multi-speaker coordination compared to standard baselines. However, our analysis uncovers a persistent divergence where high instruction following does not guarantee high content substance. PodBench offers a reproducible testbed to address these challenges in long-form, audio-centric generation."
  },
  {
    "date": "2026-01-21",
    "title": "Enhanced Charge-Density-Wave Order and Suppressed Superconductivity in Intercalated Bulk $\\mathrm{Nb}{\\mathrm{Se}}_{2}$",
    "authors": "Huanhuan Shi, Qili Li, Antoine M. T. Baron, Marie-Aude Méasson, Sangjun Kang, Dirk Fuchs, Fabian Henssler, Alexander Haas, Paolo Battistoni, Nour Maraytta, Michael Merz, Amir-Abbas Haghighirad, Wulf Wulfhekel, Christian Kübel, Matthieu Le Tacon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14902v1",
    "source": "arXiv",
    "abstract": "The electronic ground states of transition-metal dichalcogenides are strongly shaped by reduced dimensionality, yet the properties of atomically thin layers remain difficult to probe due to their small size and environmental sensitivity. Here we demonstrate that controlled electrochemical intercalation of organic cations provides a robust bulk platform for accessing monolayer-like physics in NbSe$_2$. Intercalation of tetrapropylammonium and tetrabutylammonium expands the interlayer spacing by nearly a factor of two, electronically decoupling the NbSe$_2$ layers while simultaneously introducing well-defined charge doping. Using a combination of Raman spectroscopy, scanning tunneling microscopy, X-ray diffraction, and photoemission, we uncover a pronounced enhancement of the charge-density-wave transition temperature to $\\sim 130$ K together with a strong suppression of superconductivity, reproducing the phase diagram observed in exfoliated monolayers. The enhanced charge-density-wave order and reduced $T_c$ arise from the combined effects of dimensionality reduction and electron injection, and are accompanied by distinct dip-hump anomalies in the tunneling spectra suggestive of collective mode excitations. Our results establish molecular intercalation as a powerful and scalable route for engineering competing orders in layered quantum materials."
  },
  {
    "date": "2026-01-21",
    "title": "Just aware enough: Evaluating awareness across artificial systems",
    "authors": "Nadine Meertens, Suet Lee, Ophelia Deroy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14901v1",
    "source": "arXiv",
    "abstract": "Recent debates on artificial intelligence increasingly emphasise questions of AI consciousness and moral status, yet there remains little agreement on how such properties should be evaluated. In this paper, we argue that awareness offers a more productive and methodologically tractable alternative. We introduce a practical method for evaluating awareness across diverse systems, where awareness is understood as encompassing a system's abilities to process, store and use information in the service of goal-directed action. Central to this approach is the claim that any evaluation aiming to capture the diversity of artificial systems must be domain-sensitive, deployable at any scale, multidimensional, and enable the prediction of task performance, while generalising to the level of abilities for the sake of comparison. Given these four desiderata, we outline a structured approach to evaluating and comparing awareness profiles across artificial systems with differing architectures, scales, and operational domains. By shifting the focus from artificial consciousness to being just aware enough, this approach aims to facilitate principled assessment, support design and oversight, and enable more constructive scientific and public discourse."
  },
  {
    "date": "2026-01-21",
    "title": "Modeling the Thermal Behavior of Photopolymers for In-Space Fabrication",
    "authors": "Jonathan Ericson, Daniel Widerker, Eytan Stibbe, Mor Elgarisi, Yotam Katzman, Omer Luria, Khaled Gommed, Alexey Razin, Amos A. Hari, Israel Gabay, Valeri Frumkin, Hanan Abu Hamad, Ester Segal, Yaron Amouyal, Titus Szobody, Rachel Ticknor, Edward Balaban, Moran Bercovici",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14897v1",
    "source": "arXiv",
    "abstract": "Future long-duration space missions will require in-situ, on-demand manufacturing of tools and components. Photopolymer-based processes are attractive for this purpose due to their low energy requirements, volume efficiency, and precise control of curing. However, photopolymerization generates significant heat, which is difficult to regulate in microgravity where natural convection is absent, leading to defects such as surface blistering and deformation. In this work, we combine experimental studies and modeling to address these thermal challenges. We report results from International Space Station (ISS) experiments and a dedicated parabolic flight campaign, which confirm that suppressed convective heat transfer in microgravity exacerbates thermal buildup and defect formation. Building on these observations, we present a predictive thermal model that couples heat transfer, light absorption, and evolving material properties to simulate polymerization and temperature evolution under terrestrial and microgravity conditions. Laboratory validation demonstrates strong agreement between model predictions and measured temperature profiles. Applying the model to the ISS experiments, we show that the model accurately reproduces experimentally observed blistering in TJ-3704A, a commercial acrylate-based polymer resin, while also predicting defect-free outcomes for Norland optical adhesives. The model functions as a design tool for defect-free in-space manufacturing, enabling selection of polymer properties, exposure strategies, and environmental conditions that together inhibit excess thermal buildup, paving the way for scalable, reliable in-situ manufacturing during future missions."
  },
  {
    "date": "2026-01-21",
    "title": "What Makes Low-Bit Quantization-Aware Training Work for Reasoning LLMs? A Systematic Study",
    "authors": "Keyu Lv, Manyi Zhang, Xiaobo Xia, Jingchen Ni, Shannan Yan, Xianzhi Yu, Lu Hou, Chun Yuan, Haoli Bai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14888v1",
    "source": "arXiv",
    "abstract": "Reasoning models excel at complex tasks such as coding and mathematics, yet their inference is often slow and token-inefficient. To improve the inference efficiency, post-training quantization (PTQ) usually comes with the cost of large accuracy drops, especially for reasoning tasks under low-bit settings. In this study, we present a systematic empirical study of quantization-aware training (QAT) for reasoning models. Our key findings include: (1) Knowledge distillation is a robust objective for reasoning models trained via either supervised fine-tuning or reinforcement learning; (2) PTQ provides a strong initialization for QAT, improving accuracy while reducing training cost; (3) Reinforcement learning remains feasible for quantized models given a viable cold start and yields additional gains; and (4) Aligning the PTQ calibration domain with the QAT training domain accelerates convergence and often improves the final accuracy. Finally, we consolidate these findings into an optimized workflow (Reasoning-QAT), and show that it consistently outperforms state-of-the-art PTQ methods across multiple LLM backbones and reasoning datasets. For instance, on Qwen3-0.6B, it surpasses GPTQ by 44.53% on MATH-500 and consistently recovers performance in the 2-bit regime."
  },
  {
    "date": "2026-01-21",
    "title": "Contingency Planning for Safety-Critical Autonomous Vehicles: A Review and Perspectives",
    "authors": "Lei Zheng, Luyao Zhang, Peiqi Yu, Yifan Sun, Sergio Grammatico, Jun Ma, Changliu Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14880v1",
    "source": "arXiv",
    "abstract": "Contingency planning is the architectural capability that enables autonomous vehicles (AVs) to anticipate and mitigate discrete, high-impact hazards, such as sensor outages and adversarial interactions. This paper presents a comprehensive survey of the field, synthesizing fragmented literature into a unified logic-conditioned hybrid control framework. Within this formalism, we categorize approaches into two distinct paradigms: Reactive Safety, which responds to realized hazards by enforcing safety constraints or executing fail-safe maneuvers; and Proactive Safety, which optimizes for future recourse by branching over potential modal transitions. In addition, we propose a fine-grained taxonomy that partitions the landscape into external contingencies (environmental and interactive hazards) and internal contingencies (system faults). Through a critical comparative analysis, we reveal a fundamental structural divergence: internal faults are predominantly addressed via reactive fail-safe mechanisms, whereas external interaction uncertainties increasingly require proactive branching strategies. Furthermore, we identify a critical methodological divergence: whereas physical hazards are typically managed with formal guarantees, semantic and out-of-distribution anomalies currently rely heavily on empirical validation. We conclude by identifying the open challenges in bridging the gap between theoretical guarantees and practical validation, advocating for hybrid architectures and standardized benchmarking to transition contingency planning from formulation to certifiable real-world deployment."
  },
  {
    "date": "2026-01-21",
    "title": "Multiparameter estimation for the superresolution of two incoherent sources",
    "authors": "Antonin Grateau, Alexander Boeschoten, Tanguy Favin-Lévêque, Isael Herrera, Nicolas Treps",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14876v1",
    "source": "arXiv",
    "abstract": "We experimentally demonstrate the simultaneous estimation of the three parameters characterizing a pair of incoherent optical sources in the sub-Rayleigh regime, enabling super-resolved scene characterization. Using spatial-mode demultiplexing (SPADE) with two demultiplexers--one deliberately shifted--we determine separations well below the diffraction limit and achieve sensitive joint estimation of separation, centroid, and relative brightness over a broad range of scene configurations in a single experimental setting. We benchmark our performance using Fisher-information-based Cramér-Rao bounds, and discuss the corresponding quantum limits. We investigate two complementary scenarios: a realistic case with slightly non-identical sources, and an idealized case of indistinguishable sources."
  },
  {
    "date": "2026-01-21",
    "title": "HumanoidVLM: Vision-Language-Guided Impedance Control for Contact-Rich Humanoid Manipulation",
    "authors": "Yara Mahmoud, Yasheerah Yaqoot, Miguel Altamirano Cabrera, Dzmitry Tsetserukou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14874v1",
    "source": "arXiv",
    "abstract": "Humanoid robots must adapt their contact behavior to diverse objects and tasks, yet most controllers rely on fixed, hand-tuned impedance gains and gripper settings. This paper introduces HumanoidVLM, a vision-language driven retrieval framework that enables the Unitree G1 humanoid to select task-appropriate Cartesian impedance parameters and gripper configurations directly from an egocentric RGB image. The system couples a vision-language model for semantic task inference with a FAISS-based Retrieval-Augmented Generation (RAG) module that retrieves experimentally validated stiffness-damping pairs and object-specific grasp angles from two custom databases, and executes them through a task-space impedance controller for compliant manipulation. We evaluate HumanoidVLM on 14 visual scenarios and achieve a retrieval accuracy of 93%. Real-world experiments show stable interaction dynamics, with z-axis tracking errors typically within 1-3.5 cm and virtual forces consistent with task-dependent impedance settings. These results demonstrate the feasibility of linking semantic perception with retrieval-based control as an interpretable path toward adaptive humanoid manipulation."
  },
  {
    "date": "2026-01-21",
    "title": "Order isomorphisms in $C^*$-algebras",
    "authors": "Youssef El Khatiri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14873v1",
    "source": "arXiv",
    "abstract": "We provide a complete description of the order isomorphisms between the self-adjoint parts of $C^*$-algebras. Furthermore, we characterize such isomorphisms between general operator intervals in $AW^*$-algebras. For the description, we use Jordan $^*$-isomorphisms and closed operators in the regular rings of $AW^{*}$-algebras. This work generalizes previous results on von Neumann algebras."
  },
  {
    "date": "2026-01-21",
    "title": "Early warning signals of non-critical transitions from linearised time-varying dynamics with applications to epidemic systems",
    "authors": "Joshua Looker, Kat S. Rock, Louise Dyson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14869v1",
    "source": "arXiv",
    "abstract": "In the wake of the SARS-CoV-2 pandemic, there has been heightened interest from applied mathematicians in infectious disease modelling. Modelling efforts often focus on predicting whether diseases are likely to be eliminated or, instead, (re-)emerge, especially as a result of control measures.This tipping point between elimination and infection waves has been successfully anticipated in the literature through the use of early warning signals and such signals often rely on the theory of critical slowing down. Recent developments have shown that these signals (increases in fluctuation variance and return time) can emerge from the system geometry in the case of non-normal dynamics rather than a change in asymptotic stability. We show how such dynamical behaviour occurs in the fluctuations from the mean-field in general stochastic systems. Using the susceptible-infectious-recovered model as an example application, we analyse how critical-like behaviour can be exploited to anticipate infection waves in the absence of an equilibrium bifurcation."
  },
  {
    "date": "2026-01-21",
    "title": "Movable Antenna Empowered Covert Dual-Functional Radar-Communication",
    "authors": "Ran Yang, Ning Wei, Zheng Dong, Lin Zhang, Wanting Lyu, Yue Xiu, Ahmad Bazzi, Chadi Assi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14868v1",
    "source": "arXiv",
    "abstract": "Movable antenna (MA) has emerged as a promising technology to flexibly reconfigure wireless channels by adjusting antenna placement. In this paper, we study a secured dual-functional radar-communication (DFRC) system aided by movable antennas. To enhance the communication security, we aim to maximize the achievable sum rate by jointly optimizing the transmitter beamforming vectors, receiving filter, and antenna placement, subject to radar signal-to-noise ratio (SINR) and transmission covertness constraints. We consider multiple Willies operating in both non-colluding and colluding modes. For noncolluding Willies, we first employ a Lagrangian dual transformation procedure to reformulate the challenging optimization problem into a more tractable form. Subsequently, we develop an efficient block coordinate descent (BCD) algorithm that integrates semidefinite relaxation (SDR), projected gradient descent (PGD), Dinkelbach transformation, and successive convex approximation (SCA) techniques to tackle the resulting problem. For colluding Willies, we first derive the minimum detection error probability (DEP) by characterizing the optimal detection statistic, which is proven to follow the generalized Erlang distribution. Then, we develop a minimum mean square error (MMSE)-based algorithm to address the colluding detection problem. We further provide a comprehensive complexity analysis on the unified design framework. Simulation results demonstrate that the proposed method can significantly improve the covert sum rate, and achieve a superior balance between communication and radar performance compared with existing benchmark schemes."
  },
  {
    "date": "2026-01-21",
    "title": "Exotic collective behaviors of giant quantum emitters in two-dimensional baths",
    "authors": "Qing-Yang Qiu, Wen Huang, Lei Du, Xin-You Lü",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14867v1",
    "source": "arXiv",
    "abstract": "Nonlocal light-matter interactions with giant atoms in high-dimensional environments are not only fundamentally intriguing for testing quantum electrodynamics beyond the dipole approximation but also crucial for building high-dimensional quantum networks and engineering multipartite entangled states. Given the enigmatic and largely uncharted collective signatures exhibited by multiple giant atoms within two-dimensional optical baths, we delve into their nonperturbative collective dynamics within the single-excitation subspace, focusing on the case where they are coupled to a common two-dimensional photonic reservoir and employing a resolvent operator approach. We demonstrate that precisely engineered atomic arrangements lead to unconventional quantum dynamics, featuring non-Markovianity-induced beats and long-lived bound states in the continuum, thereby providing a versatile platform for implementing two-dimensional quantum memory. Phenomenologically, we observe the emergence of exotic photon emission patterns in both two- and three-dimensional (3D) baths. The emission directions are shown to be precisely controllable on demand through exact phase engineering of the coupling parameters, enabling a highly efficient chiral light-matter interface. Moreover, our generalization to a 3D bath reveals that coherent dipole-dipole interactions can survive despite the coupling to a continuum of modes, a finding that challenges conventional wisdom regarding decoherence."
  },
  {
    "date": "2026-01-21",
    "title": "Reclaiming Software Engineering as the Enabling Technology for the Digital Age",
    "authors": "Tanja E. J. Vos, Tijs van der Storm, Alexander Serebrenik, Lionel Briand, Roberto Di Cosmo, J. -M Bruel, Benoît Combemale",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14861v1",
    "source": "arXiv",
    "abstract": "Software engineering is the invisible infrastructure of the digital age. Every breakthrough in artificial intelligence, quantum computing, photonics, and cybersecurity relies on advances in software engineering, yet the field is too often treated as a supportive digital component rather than as a strategic, enabling discipline. In policy frameworks, including major European programmes, software appears primarily as a building block within other technologies, while the scientific discipline of software engineering remains largely absent. This position paper argues that the long-term sustainability, dependability, and sovereignty of digital technologies depend on investment in software engineering research. It is a call to reclaim the identity of software engineering."
  },
  {
    "date": "2026-01-21",
    "title": "HiNS: Hierarchical Negative Sampling for More Comprehensive Memory Retrieval Embedding Model",
    "authors": "Motong Tian, Allen P. Wong, Mingjun Mao, Wangchunshu Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14857v1",
    "source": "arXiv",
    "abstract": "Memory-augmented language agents rely on embedding models for effective memory retrieval. However, existing training data construction overlooks a critical limitation: the hierarchical difficulty of negative samples and their natural distribution in human-agent interactions. In practice, some negatives are semantically close distractors while others are trivially irrelevant, and natural dialogue exhibits structured proportions of these types. Current approaches using synthetic or uniformly sampled negatives fail to reflect this diversity, limiting embedding models' ability to learn nuanced discrimination essential for robust memory retrieval. In this work, we propose a principled data construction framework HiNS that explicitly models negative sample difficulty tiers and incorporates empirically grounded negative ratios derived from conversational data, enabling the training of embedding models with substantially improved retrieval fidelity and generalization in memory-intensive tasks. Experiments show significant improvements: on LoCoMo, F1/BLEU-1 gains of 3.27%/3.30%(MemoryOS) and 1.95%/1.78% (Mem0); on PERSONAMEM, total score improvements of 1.19% (MemoryOS) and 2.55% (Mem0)."
  },
  {
    "date": "2026-01-21",
    "title": "Que révèle l'activité de validation de démonstration circulaire sur la compréhension de démonstration",
    "authors": "Alexis Gautreau",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14853v1",
    "source": "arXiv",
    "abstract": "This communication contributes to research on proof validation as a lens for uncovering didactical phenomena related to proof and proving. We revisit the puzzling case of lower secondary students in France who validate circular proofs. That is proofs in which the conclusion is used within a step of the proof itself. While these 12--13-year-old students accurately identify the final statement of such proofs as a reformulation of the conclusion of the claim, they encounter difficulties in interpreting how the condition of the claim is taken up within the proof. Our analysis challenges Miyazaki and al.'s interpretation of this phenomenon, which attributes students' acceptation of the validity of circular reasoning to a misunderstanding of modus ponens when there are two in a row. Instead, we propose an alternative explanation grounded in the distinction between the operative and theoretical statuses of mathematical propositions. This distinction provides both a theoretical rationale for the invalidity of circular proofs and a didactical tool for examining students' argumentative activity when they attempt to reject such proofs."
  },
  {
    "date": "2026-01-21",
    "title": "Testing the three massive neutrino paradigm: Constraints on Neutrino Properties and Interactions from Recent Experimental Data",
    "authors": "João Paulo Pinheiro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14851v1",
    "source": "arXiv",
    "abstract": "Neutrino physics offers unique insights into phenomena beyond the Standard Model (BSM). This thesis presents phenomenological investigations organized around three pillars: consolidation of the three-flavor oscillation paradigm, exploration of new physics viability, and precise determination of solar neutrino fluxes. The theoretical framework introduces massive neutrinos, leptonic mixing, and flavor transitions, followed by experimental results emphasizing Borexino and NOvA data analyses. The first pillar establishes the three-flavor framework through global analysis of solar, atmospheric, reactor, and accelerator data, providing updated determinations of mixing angles ($θ_{12}$, $θ_{13}$, $θ_{23}$) and mass-squared differences ($Δm^2_{21}$, $Δm^2_{31}$), while quantifying ambiguities in mass ordering and $θ_{23}$ octant. The second pillar investigates Non-Standard Interactions (NSI) with electrons and quarks, combining Borexino data with COHERENT's CE$ν$NS measurements to establish bounds on propagation and detection couplings, excluding viable NSI parameter regions including potential LMA-D solutions. The third pillar advances solar neutrino physics through precision flux determinations, integrating pp-chain and CNO-cycle measurements. Results show preference for high-metallicity Standard Solar Models and incompatibility between $3+1$ mixing parameters favored by Gallium experiments and solar observations. This synthesis guides future experiments toward resolving mass ordering, CP violation, and dark sector interactions."
  },
  {
    "date": "2026-01-21",
    "title": "Multi-Tast Transformer for Explainable Speech Deepfake Detection via Formant Modeling",
    "authors": "Viola Negroni, Luca Cuccovillo, Paolo Bestagini, Patrick Aichroth, Stefano Tubaro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14850v1",
    "source": "arXiv",
    "abstract": "In this work, we introduce a multi-task transformer for speech deepfake detection, capable of predicting formant trajectories and voicing patterns over time, ultimately classifying speech as real or fake, and highlighting whether its decisions rely more on voiced or unvoiced regions. Building on a prior speaker-formant transformer architecture, we streamline the model with an improved input segmentation strategy, redesign the decoding process, and integrate built-in explainability. Compared to the baseline, our model requires fewer parameters, trains faster, and provides better interpretability, without sacrificing prediction performance."
  },
  {
    "date": "2026-01-21",
    "title": "From Observation to Prediction: LSTM for Vehicle Lane Change Forecasting on Highway On/Off-Ramps",
    "authors": "Mohamed Abouras, Catherine M. Elias",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14848v1",
    "source": "arXiv",
    "abstract": "On and off-ramps are understudied road sections even though they introduce a higher level of variation in highway interactions. Predicting vehicles' behavior in these areas can decrease the impact of uncertainty and increase road safety. In this paper, the difference between this Area of Interest (AoI) and a straight highway section is studied. Multi-layered LSTM architecture to train the AoI model with ExiD drone dataset is utilized. In the process, different prediction horizons and different models' workflow are tested. The results show great promise on horizons up to 4 seconds with prediction accuracy starting from about 76% for the AoI and 94% for the general highway scenarios on the maximum horizon."
  },
  {
    "date": "2026-01-21",
    "title": "A note on the $m$-extended module categories of Nakayama algebras",
    "authors": "Endre Sørmo Rundsveen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14843v1",
    "source": "arXiv",
    "abstract": "We study the extended module category $m\\operatorname{-mod}Λ$ of an algebra $Λ$, recently introduced by Gupta and Zhou. The existence of a postprojective component of $m\\operatorname{-mod}Λ$ is shown for certain algebras $Λ$, and a knitting algorithm through cohomological dimension vectors is provided. In particular, the extended module category of Nakayama algebras with homogeneous relations are investigated, and it is classified when they are of finite type. The paper give fully calculated AR-quivers for several Nakayama algebras."
  },
  {
    "date": "2026-01-21",
    "title": "Mild Solutions for Time--Fractional Stochastic Nonlocal Diffusion Equations",
    "authors": "M. Alwohaibi, D. Alsaleh, M. El-Beltagy, M. Majdoub, E. Mliki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14838v1",
    "source": "arXiv",
    "abstract": "We study a time--space nonlocal diffusion equation driven by additive time--space white noise, where the time derivative is the Caputo derivative of order $α\\in(0,2)$. The model couples local diffusion with a nonlocal convolution operator generated by a radial probability density, thus incorporating memory effects and long-range spatial interactions. For Dirac initial data, we derive an explicit solution formula in the space of tempered distributions, decomposing the solution into a deterministic part and a stochastic convolution kernel expressed through Mittag--Leffler functions. Our main contribution is a sharp characterization of the existence of mild solutions in terms of $α$, the spatial dimension $N$, and the coefficients of the local and nonlocal diffusion terms. In particular, when the Laplacian term is absent, no mild solution exists, whereas for $λ>0$ the admissible regimes depend critically on $(α,N)$, extending and sharpening the known results for purely local fractional stochastic heat equations. Numerical simulations illustrate the evolution of the mean and variance and emphasize subdiffusive spreading and memory effects."
  },
  {
    "date": "2026-01-21",
    "title": "Moving Beyond Compliance in Soft-Robotic Catheters Through Modularity for Precision Therapies",
    "authors": "B. Calmé, N. J. Greenidge, A. Metcalf, A. Bacchetti, G. Loza, D. Kpeglo, P. Lloyd, V. Pensabene, J. H. Chandler, P. Valdastri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14837v1",
    "source": "arXiv",
    "abstract": "Soft robotic instruments could navigate delicate, tortuous anatomy more safely than rigid tools, but clinical adoption is limited by insufficient tip functionalization and real-time feedback at the tissue interface. Few sensing and therapeutic modules are compact, robust, and adaptable enough to measure, and respond to, subtle physiological cues during intraluminal procedures. We present a 1.47 mm diameter modular soft robotic catheter that integrates sensing, actuation, and therapy while retaining the compliance needed for safe endoluminal navigation. Validated across multiple in vivo settings, we emphasize its utility in endoscopic retrograde cholangiopancreatography (ERCP), a highly technical procedure and a key access route to the pancreas, an organ that is fragile, difficult to instrument, and central to diseases such as pancreatic cancer. Our architecture supports up to four independently controlled functional units, allowing customizable combinations of anchoring, manipulation, sensing, and targeted drug delivery. In a live porcine model, we demonstrate semi-autonomous deployment into the pancreatic duct and 7.5 cm of endoscopic navigation within it, a region currently inaccessible with standard catheters. A closed-loop autonomous/shared-control system that combines a learned model, magnetic actuation, onboard shape sensing, and visual marker tracking further improves cannulation accuracy. Together, these results establish a scalable platform for multifunctional soft robotic catheters and a new paradigm for complex endoluminal interventions, with potential to reduce radiation exposure, shorten training, and accelerate clinical translation of soft robotic technologies."
  },
  {
    "date": "2026-01-21",
    "title": "Dark Energy Survey Year 6 Results: Magnification modeling and its impact on galaxy clustering and galaxy-galaxy lensing cosmology",
    "authors": "E. Legnani, J. Elvin-Poole, D. Anbajagane, D. Sanchez Cid, A. Ferté, N. Weaverdyck, A. Porredon, S. Avila, R. Miquel, J. De Vicente, J. Coloma, S. Samuroff, W. d'Assignies, A. Alarcon, C. Sánchez, J. Muir, J. Prat, N. MacCrann, D. Bacon, M. A. Troxel, C. Chang, M. Crocce, M. R. Becker, J. Blazek, M. Yamamoto, T. Schutt, M. Rodriguez-Monroy, G. Giannini, B. Yin, A. Amon, K. Bechtol, I. Sevilla-Noarbe, T. M. C. Abbott, M. Aguena, S. Allam, O. Alves, F. Andrade-Oliveira, G. M. Bernstein, S. Bocquet, D. Brooks, R. Camilleri, A. Carnero Rosell, J. Carretero, L. N. da Costa, M. E. da Silva Pereira, T. M. Davis, S. Desai, S. Dodelson, P. Doel, C. Doux, J. García-Bellido, D. Gruen, G. Gutierrez, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, D. J. James, K. Kuehn, O. Lahav, S. Lee, J. L. Marshall, J. Mena-Fernández, F. Menanteau, J. J. Mohr, J. Myles, R. L. C. Ogando, M. Paterno, A. A. Plazas Malagón, R. Rosenfeld, E. Sanchez, M. Smith, M. Soares-Santos, E. Suchyta, V. Vikram",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14833v1",
    "source": "arXiv",
    "abstract": "Gravitational lensing magnification alters the observed spatial distribution of galaxies and must be accounted for to prevent biases in cosmological probes of the large-scale structure. We investigate its effects on the Dark Energy Survey Year 6 galaxy clustering and galaxy-galaxy lensing analyses using the fiducial lens (position tracer) sample MagLim++. Magnification bias is parameterized by a coefficient that describes the response of the number of selected objects per unlensed area element to a change in the lensing convergence. We quantify this coefficient using the Balrog synthetic source injection catalog to account for the complexity of the selection function, and compare these results with simplified estimates. The resulting values of the magnification coefficients for each redshift bin are [3.16 $\\pm$ 0.08, 2.76 $\\pm$ 0.21, 4.09 $\\pm$ 0.15, 4.42 $\\pm$ 0.16, 4.90 $\\pm$ 0.29, 4.83 $\\pm$ 0.25]. Relative to Year 3, this analysis provides more precise and accurate magnification bias estimates through a larger Balrog area and reweighting to better match the data properties. The cosmological results are robust when tested against various magnification parameter prior choices and also when adding cross-clustering between lens redshift bins. Neglecting magnification, however, introduces significant systematic shifts: relative to the fiducial analysis with Gaussian priors centered on the Balrog-derived estimates, we observe shifts of 1.37$σ$ in $S_8$ and -0.84$σ$ in $Ω_m$ (with cosmic shear included: -0.61$σ$ in $S_8$ and -0.71$σ$ in $Ω_m$), in agreement with findings from simulated data, demonstrating that magnification must be modeled to avoid biases. Freeing the magnification bias in lens bin 2 leads to unphysical negative values, further justifying its exclusion from the fiducial Year 6 analysis."
  },
  {
    "date": "2026-01-21",
    "title": "SN 2023zcu: A Type IIP SN with Early Flash Features",
    "authors": "Monalisa Dubey, Kuntal Misra, Géza Csörnyei, Raya Dastidar, D. Andrew Howell, David J. Sand, Stefano Valenti, WeiKang Zheng, Alexei V. Filippenko, Saurabh Jha, Jesper Sollerman, Peter Brown, Kate D. Alexander, Moira Andrews, Jennifer Andrews, Dre Betz, Emma Born, Kate Bostow, K. Azalee Bostroem, Sea'n J. Brennan, Thomas G. Brink, Collin Christy, Elma Chuang, Yize Dong, Naveen Dukiya, Joseph R. Farah, Noah Franz, Estefania Padilla Gonzalez, Joshua Haislip, Emily Hoang, Griffin Hosseinzadeh, Brian Hsu, Connor Jennings, Vladimir Kouprianov, M. J. Lundquist, Colin Macrie, Curtis McCully, Andrew Mchaty, Darshana Mehta, Katie Mora, Megan Newsome, Jeniveve Pearson, Neil Pichay, Conor Ransome, Aravind P. Ravi, Daniel E. Reichart, Nicolás Meza Retamal, Sophia Risin, Manisha Shrestha, Ajay Kumar Singh, Nathan Smith, Bhagya Subrayan, Giacomo Terreran, William Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14830v1",
    "source": "arXiv",
    "abstract": "We present a detailed photometric and spectroscopic analysis of the Type IIP supernova SN~2023zcu, which exploded in the galaxy NGC~2139 (redshift $z$ = 0.006). SN~2023zcu exhibits a well-sampled light curve covering the rise, plateau, and nebular phases. It has an optically thick phase of $100.6 \\pm 0.6$ d with a magnitude drop of $\\sim$1.7 mag in the {\\em V} band during the transition between the plateau and the nebular phases. Weak emission features in the early-time spectra indicate a low-level interaction between circumstellar material (CSM) and the SN ejecta. The spectral evolution is well sampled and exhibits a prominent P-Cygni profile of H$α$, a defining characteristic of Type IIP SNe. Signatures of metal-line formation (e.g., \\ion{Fe}{2}, \\ion{Ca}{2} near-infrared triplet) are also evident in the spectra as the SN evolves. Spectral modeling with the radiative-transfer code \\texttt{TARDIS} during the early photospheric phase (8.7--35.5 d since explosion) yields photospheric temperatures decreasing from $\\sim$9,000 to $\\sim$6,000 K and expansion velocities declining from $\\sim$10,000 to $\\sim$5,400 km s$^{-1}$. A tailored expanding photosphere method (EPM) fit based on the \\texttt{TARDIS} models provides a distance estimate of $27.8 \\pm 2.0$ Mpc. Nebular-phase spectra and bolometric light-curve modeling suggest a progenitor mass in the range 12--15 M$_\\odot$. This thorough analysis helps to constrain progenitor properties and explosion parameters, thereby strengthening our understanding of Type IIP SNe."
  },
  {
    "date": "2026-01-21",
    "title": "Routing Qubits on Noisy Networks",
    "authors": "Claudia Benedetti, Giovanni Ragazzi, Simone Cavazzoni, Paolo Bordone, Matteo G. A. Paris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14824v1",
    "source": "arXiv",
    "abstract": "Robust quantum routing is essential for scalable quantum technologies. This paper investigates the resilience of routing protocols in network architectures designed for perfect, high-fidelity transfer of both classical and quantum information under ideal conditions. We encode information in the position of a quantum walker on a graph, modelling the routing of a generic qubit state from a single input to multiple (orthogonal) outputs. We analyse and assess routing performance in various regimes, evaluating their robustness against static and dynamical noise."
  },
  {
    "date": "2026-01-21",
    "title": "Multimodal system for skin cancer detection",
    "authors": "Volodymyr Sydorskyi, Igor Krashenyi, Oleksii Yakubenko",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14822v1",
    "source": "arXiv",
    "abstract": "Melanoma detection is vital for early diagnosis and effective treatment. While deep learning models on dermoscopic images have shown promise, they require specialized equipment, limiting their use in broader clinical settings. This study introduces a multi-modal melanoma detection system using conventional photo images, making it more accessible and versatile. Our system integrates image data with tabular metadata, such as patient demographics and lesion characteristics, to improve detection accuracy. It employs a multi-modal neural network combining image and metadata processing and supports a two-step model for cases with or without metadata. A three-stage pipeline further refines predictions by boosting algorithms and enhancing performance. To address the challenges of a highly imbalanced dataset, specific techniques were implemented to ensure robust training. An ablation study evaluated recent vision architectures, boosting algorithms, and loss functions, achieving a peak Partial ROC AUC of 0.18068 (0.2 maximum) and top-15 retrieval sensitivity of 0.78371. Results demonstrate that integrating photo images with metadata in a structured, multi-stage pipeline yields significant performance improvements. This system advances melanoma detection by providing a scalable, equipment-independent solution suitable for diverse healthcare environments, bridging the gap between specialized and general clinical practices."
  },
  {
    "date": "2026-01-21",
    "title": "POTR: Post-Training 3DGS Compression",
    "authors": "Bert Ramlot, Martijn Courteaux, Peter Lambert, Glenn Van Wallendael",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14821v1",
    "source": "arXiv",
    "abstract": "3D Gaussian Splatting (3DGS) has recently emerged as a promising contender to Neural Radiance Fields (NeRF) in 3D scene reconstruction and real-time novel view synthesis. 3DGS outperforms NeRF in training and inference speed but has substantially higher storage requirements. To remedy this downside, we propose POTR, a post-training 3DGS codec built on two novel techniques. First, POTR introduces a novel pruning approach that uses a modified 3DGS rasterizer to efficiently calculate every splat's individual removal effect simultaneously. This technique results in 2-4x fewer splats than other post-training pruning techniques and as a result also significantly accelerates inference with experiments demonstrating 1.5-2x faster inference than other compressed models. Second, we propose a novel method to recompute lighting coefficients, significantly reducing their entropy without using any form of training. Our fast and highly parallel approach especially increases AC lighting coefficient sparsity, with experiments demonstrating increases from 70% to 97%, with minimal loss in quality. Finally, we extend POTR with a simple fine-tuning scheme to further enhance pruning, inference, and rate-distortion performance. Experiments demonstrate that POTR, even without fine-tuning, consistently outperforms all other post-training compression techniques in both rate-distortion performance and inference speed."
  },
  {
    "date": "2026-01-21",
    "title": "A fast-pivoting algorithm for Whittle's restless bandit index",
    "authors": "José Niño-Mora",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14819v1",
    "source": "arXiv",
    "abstract": "The Whittle index for restless bandits (two-action semi-Markov decision processes) provides an intuitively appealing optimal policy for controlling a single generic project that can be active (engaged) or passive (rested) at each decision epoch, and which can change state while passive. It further provides a practical heuristic priority-index policy for the computationally intractable multi-armed restless bandit problem, which has been widely applied over the last three decades in multifarious settings, yet mostly restricted to project models with a one-dimensional state. This is due in part to the difficulty of establishing indexability (existence of the index) and of computing the index for projects with large state spaces. This paper draws on the author's prior results on sufficient indexability conditions and an adaptive-greedy algorithmic scheme for restless bandits to obtain a new fast-pivoting algorithm that computes the $n$ Whittle index values of an $n$-state restless bandit by performing, after an initialization stage, $n$ steps that entail $(2/3) n^3 + O(n^2)$ arithmetic operations. This algorithm also draws on the parametric simplex method, and is based on elucidating the pattern of parametric simplex tableaux, which allows to exploit special structure to substantially simplify and reduce the complexity of simplex pivoting steps. A numerical study demonstrates substantial runtime speed-ups versus alternative algorithms."
  },
  {
    "date": "2026-01-21",
    "title": "Statistical Learning Theory for Distributional Classification",
    "authors": "Christian Fiedler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14818v1",
    "source": "arXiv",
    "abstract": "In supervised learning with distributional inputs in the two-stage sampling setup, relevant to applications like learning-based medical screening or causal learning, the inputs (which are probability distributions) are not accessible in the learning phase, but only samples thereof. This problem is particularly amenable to kernel-based learning methods, where the distributions or samples are first embedded into a Hilbert space, often using kernel mean embeddings (KMEs), and then a standard kernel method like Support Vector Machines (SVMs) is applied, using a kernel defined on the embedding Hilbert space. In this work, we contribute to the theoretical analysis of this latter approach, with a particular focus on classification with distributional inputs using SVMs. We establish a new oracle inequality and derive consistency and learning rate results. Furthermore, for SVMs using the hinge loss and Gaussian kernels, we formulate a novel variant of an established noise assumption from the binary classification literature, under which we can establish learning rates. Finally, some of our technical tools like a new feature space for Gaussian kernels on Hilbert spaces are of independent interest."
  },
  {
    "date": "2026-01-21",
    "title": "The Nonlocal-to-Local Limit for the Inviscid Leray-α Equations",
    "authors": "Jule Schindler, Emil Wiedemann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14813v1",
    "source": "arXiv",
    "abstract": "We consider the inviscid Leray-$α$ equations - an inviscid nonlocal regularisation of the Euler equations. In the first part, we prove the convergence of strong solutions of the Leray-$α$ equations to strong solutions of the Euler equations in $H^s(\\mathbb{R}^d)$ for $s>d/2 +1 $, $d\\in \\{2,3\\}$, for a large class of regularising kernels. In the second part, we consider weak solutions on a bounded domain with a local scaling property far away from the boundary. The scaling relates to second-order structure functions from turbulence theory and does not imply regularity. Nonetheless, under these assumptions, the weak solutions converge to (possibly wild) weak solutions of Euler in $L^2$ for almost every $t$."
  },
  {
    "date": "2026-01-21",
    "title": "Stochastic Decision-Making Framework for Human-Robot Collaboration in Industrial Applications",
    "authors": "Muhammad Adel Yusuf, Ali Nasir, Zeeshan Hameed Khan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14809v1",
    "source": "arXiv",
    "abstract": "Collaborative robots, or cobots, are increasingly integrated into various industrial and service settings to work efficiently and safely alongside humans. However, for effective human-robot collaboration, robots must reason based on human factors such as motivation level and aggression level. This paper proposes an approach for decision-making in human-robot collaborative (HRC) environments utilizing stochastic modeling. By leveraging probabilistic models and control strategies, the proposed method aims to anticipate human actions and emotions, enabling cobots to adapt their behavior accordingly. So far, most of the research has been done to detect the intentions of human co-workers. This paper discusses the theoretical framework, implementation strategies, simulation results, and potential applications of the bilateral collaboration approach for safety and efficiency in collaborative robotics."
  },
  {
    "date": "2026-01-21",
    "title": "Couette Taylor instabilities in the small-gap regime",
    "authors": "Dongfen Bian, Emmanuel Grenier, Gérard Iooss, Zhuolun Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14806v1",
    "source": "arXiv",
    "abstract": "The Couette-Taylor instability occurs in a viscous fluid confined between two coaxial rotating cylinders. When the Taylor number surpasses a critical value, the stable Couette flow destabilizes, giving way to steady Taylor vortices. As the Taylor number increases further, these vortices themselves become unstable, transitioning into wavy Taylor vortices. In this article, we focus on the small-gap limit, where the ratio of the cylinder radii approaches unity and the rotation rates of the cylinders are nearly identical. We provide a rigorous proof of the existence of a critical Taylor number $T_c$, at which the Couette flow loses stability. For Taylor numbers just above $T_c$, under fixed axial periodicity, the solutions to the limiting Navier-Stokes system are governed by a Ginzburg-Landau-type partial differential equation. Beyond the classical Taylor vortex flow, we demonstrate that a two-parameter family of solutions emerges at criticality for $T>T_c$. This family includes not only wavy vortices but also a variety of other exotic flow patterns, all of which remain steady in the frame rotating at the average angular velocity of the cylinders."
  },
  {
    "date": "2026-01-21",
    "title": "The Supernova Remnant G284.3$-$1.8 and Its Relation to the Gamma-ray Binary 1FGL J1018.6$-$5856",
    "authors": "Natsuki Terano, Takaaki Tanaka, Hiromasa Suzuki, Rei Enokiya, Hiroyuki Uchida, Kai Matsunaga, Takuto Narita, Yasuo Fukui, Toshiki Sato",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14801v1",
    "source": "arXiv",
    "abstract": "G284.3$-$1.8 is a supernova remnant with a radio shell and thermal X-ray emission. Located near its center is the gamma-ray binary 1FGL J1018.6$-$5856, although the physical association between the two systems is not clear yet. Our X-ray spectroscopy with Suzaku reveals that G284.3$-$1.8 and 1FGL J1018.6$-$5856 have compatible absorption column densities of $N_\\mathrm{H} = 6\\textrm{--}7 \\times 10^{21}~\\mathrm{cm}^{-2}$, indicating that the two systems have similar distances. The actual distance is determined as $3~\\mathrm{kpc}$ using $\\mathrm{^{12}CO}$ ($J=1\\textrm{--}0$) data obtained with NANTEN. The X-ray spectrum of G284.3$-$1.8 shows a strong K-shell emission line of Mg, confirming that the earlier claim that the SNR is one of the few Mg-rich SNRs. Comparing recent stellar models taking into account the \"shell merger\" processes, we find that the obtained Mg-to-Ne mass ratio of $M_\\mathrm{Mg}/M_\\mathrm{Ne} = 0.73^{+0.07}_{-0.03}$ and Si-to-Mg mass ratio of $M_\\mathrm{Si}/M_\\mathrm{Mg} = 0.44\\pm0.03$ suggest a supernova explosion that would have left a neutron star. The characteristics of 1FGL J1018.6$-$5856, on the other hand, are better explained with a model in which its compact object is neutron star. The present results, therefore, would suggest a possible scenario where G284.3$-$1.8 and 1FGL J1018.6$-$5856 are both remnants of a common supernova explosion although further observational tests are necessary."
  },
  {
    "date": "2026-01-21",
    "title": "UniRoute: Unified Routing Mixture-of-Experts for Modality-Adaptive Remote Sensing Change Detection",
    "authors": "Qingling Shu, Sibao Chen, Wei Lu, Zhihui You, Chengzhuang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14797v1",
    "source": "arXiv",
    "abstract": "Current remote sensing change detection (CD) methods mainly rely on specialized models, which limits the scalability toward modality-adaptive Earth observation. For homogeneous CD, precise boundary delineation relies on fine-grained spatial cues and local pixel interactions, whereas heterogeneous CD instead requires broader contextual information to suppress speckle noise and geometric distortions. Moreover, difference operator (e.g., subtraction) works well for aligned homogeneous images but introduces artifacts in cross-modal or geometrically misaligned scenarios. Across different modality settings, specialized models based on static backbones or fixed difference operations often prove insufficient. To address this challenge, we propose UniRoute, a unified framework for modality-adaptive learning by reformulating feature extraction and fusion as conditional routing problems. We introduce an Adaptive Receptive Field Routing MoE (AR2-MoE) module to disentangle local spatial details from global semantic context, and a Modality-Aware Difference Routing MoE (MDR-MoE) module to adaptively select the most suitable fusion primitive at each pixel. In addition, we propose a Consistency-Aware Self-Distillation (CASD) strategy that stabilizes unified training under data-scarce heterogeneous settings by enforcing multi-level consistency. Extensive experiments on five public datasets demonstrate that UniRoute achieves strong overall performance, with a favorable accuracy-efficiency trade-off under a unified deployment setting."
  },
  {
    "date": "2026-01-21",
    "title": "Validating Behavioral Proxies for Disease Risk Monitoring via Large-Scale E-commerce Data",
    "authors": "Naomi Sasaya, Shigefumi Kishida, Ryo Kikuchi, Akira Tajima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14795v1",
    "source": "arXiv",
    "abstract": "Digital traces of everyday behavior, such as e-commerce (EC) purchase logs, provide scalable signals for population-level monitoring, yet their epidemiological validity remains unclear due to weak links to clinical outcomes. We propose a behavioral proxy for disease onset based on transitions from regular to therapeutic diets observed in EC purchase histories, and evaluate its validity through large-scale cross-domain analysis. Using EC purchase data (N = 55,645 users) and independent insurance-derived clinical records, we compare ingredient-level risk patterns and seasonal disease dynamics in feline lower urinary tract disease (FLUTD) as a case study. The proxy-based estimates show strong agreement with clinical data, with correlations of r = 0.74 for ingredient-level risk patterns and r = 0.82 for seasonal variation. Both data sources consistently capture elevated disease risk during winter months. Moreover, analysis using EC data alone reproduces established domain knowledge, including the association between higher wet food consumption and lower disease risk. Our results demonstrate that behavioral signals derived from large-scale EC data can serve as validated, cost-effective complements to traditional surveillance systems, and suggest broader applicability to monitoring lifestyle-related and chronic conditions."
  },
  {
    "date": "2026-01-21",
    "title": "LiNUS: Lightweight Automatic Segmentation of Deep Brain Nuclei for Real-Time DBS Surgery",
    "authors": "Shuo Zhang, Zihua Wang, Changgeng He, Chunhua Hu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14793v1",
    "source": "arXiv",
    "abstract": "This paper proposes LiNUS, a lightweight deep learning framework for the automatic segmentation of the Subthalamic Nucleus (STN) in Deep Brain Stimulation (DBS) surgery. Addressing the challenges of small target volume and class imbalance in MRI data, LiNUS improves upon the U-Net architecture by introducing spectral normalization constraints, bilinear interpolation upsampling, and a multi-scale feature fusion mechanism. Experimental results on the Tsinghua DBS dataset (TT14) demonstrate that LiNUS achieves a Dice coefficient of 0.679 with an inference time of only 0.05 seconds per subject, significantly outperforming traditional manual and registration-based methods. Further validation on high-resolution data confirms the model's robustness, achieving a Dice score of 0.89. A dedicated Graphical User Interface (GUI) was also developed to facilitate real-time clinical application."
  },
  {
    "date": "2026-01-21",
    "title": "Reconstruction-Anchored Diffusion Model for Text-to-Motion Generation",
    "authors": "Yifei Liu, Changxing Ding, Ling Guo, Huaiguang Jiang, Qiong Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14788v1",
    "source": "arXiv",
    "abstract": "Diffusion models have seen widespread adoption for text-driven human motion generation and related tasks due to their impressive generative capabilities and flexibility. However, current motion diffusion models face two major limitations: a representational gap caused by pre-trained text encoders that lack motion-specific information, and error propagation during the iterative denoising process. This paper introduces Reconstruction-Anchored Diffusion Model (RAM) to address these challenges. First, RAM leverages a motion latent space as intermediate supervision for text-to-motion generation. To this end, RAM co-trains a motion reconstruction branch with two key objective functions: self-regularization to enhance the discrimination of the motion space and motion-centric latent alignment to enable accurate mapping from text to the motion latent space. Second, we propose Reconstructive Error Guidance (REG), a testing-stage guidance mechanism that exploits the diffusion model's inherent self-correction ability to mitigate error propagation. At each denoising step, REG uses the motion reconstruction branch to reconstruct the previous estimate, reproducing the prior error patterns. By amplifying the residual between the current prediction and the reconstructed estimate, REG highlights the improvements in the current prediction. Extensive experiments demonstrate that RAM achieves significant improvements and state-of-the-art performance. Our code will be released."
  },
  {
    "date": "2026-01-21",
    "title": "On the Real Zeroes of Half-integral Weight Hecke Cusp Forms, II",
    "authors": "Jesse Jääsaari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15268v1",
    "source": "arXiv",
    "abstract": "We show that for $\\gg K^2$ of the half-integral weight Hecke cusp forms in the Kohnen plus subspace with weight bounded by a large parameter $K$, the number of \"real\" zeroes grows at the expected rate. A key technical step in the proof is to obtain sharp bounds for the mollified first and second moments of quadratic twists of modular $L$-functions."
  },
  {
    "date": "2026-01-21",
    "title": "The Circumbinary Disk of HD 34700A: I. CO gas kinematics indicate spirals, infall, and vortex motions",
    "authors": "J. Stadler, M. Benisty, F. Zagaria, A. F. Izquierdo, J. Speedie, A. J. Winter, L. Wölfer, J. Bae, S. Facchini, D. Fasano, N. Kurtovic, R. Teague",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15262v1",
    "source": "arXiv",
    "abstract": "We present the first high-resolution ($\\sim$ 0.14\") Atacama Large Millimeter/submillimeter Array (ALMA) Band 6 dust continuum and CO molecular line emission observations of the quadruple system HD 34700. In particular, HD 34700AaAb is a spectroscopic binary ($M_{\\rm{bin}}=4\\,M_\\odot$) surrounded by two low-mass companions at large separations. Its circumbinary disk is highly substructured, featuring numerous spiral arms and a large cavity observed in infrared (IR) scattered light. We analyzed the CO line channel and intensity moment maps. By fitting a Keplerian model to the line channel emission, we identified the residual motions and conducted a line spectra analysis. We resolved an asymmetric continuum crescent on top of a dust ring at 0.39\" (138 au), colocated with the IR ring. The CO molecule line emissions trace a smaller cavity in gas, whose edge aligns with the inner rim of the ring detected in H$α$ emission at 0.20\" (65 au). The $^{12}$CO line emission and kinematics trace highly non-Keplerian motions ($\\sim0.1Δ\\upsilon_{\\rm kep}$), and these CO spiral features align well with the spiral structures in scattered light. The $^{12}$CO line spectra analysis reveals a streamer above the southeastern disk plane, likely falling onto the disk. The $^{13}$CO and C$^{18}$O kinematics largely follow the disk's underlying Keplerian rotation, while $^{13}$CO exhibits tentative signs of anticyclonic vortex flows at the continuum crescent location. Our multimolecular line study suggests that the circumbinary disk of HD 34700A is highly perturbed in its upper layers, possibly warped and influenced by infalling material. While late-stage infall may account for the IR spirals and the formation of the vortex through Rossby wave instability, an embedded massive companion within the cavity may also contribute to these features."
  },
  {
    "date": "2026-01-21",
    "title": "Orbital angular momentum of spatiotemporal vortices: a ray-mechanical analogy",
    "authors": "Sophie Vo, Konstantin Y. Bliokh, Miguel A. Alonso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15261v1",
    "source": "arXiv",
    "abstract": "Spatiotemporal vortex pulses (STVPs) are wavepackets that carry transverse orbital angular momentum (OAM), whose proper quantification has been the subject of recent debate. In this work, we introduce a simplified mechanical model of STVPs, consisting of a loop of non-interacting point particles traveling at a uniform constant speed but at slightly di!erent angles. We examine di!erent initial conditions for the particle loop, including configurations that are elliptic in space at a given time and configurations that are elliptic in spacetime at a fixed propagation distance. Furthermore, employing a non-uniform mass distribution allows the particle loop to mimic the STVP not only in configuration space but also in momentum space. Remarkably, when supplemented by a semiclassical vorticity quantization condition, our mechanical model exactly reproduces di!erent wave-based OAM results previously reported for paraxial STVPs."
  },
  {
    "date": "2026-01-21",
    "title": "Non-Hydrodynamic Solutions to the linear Density-dependent BGK equation",
    "authors": "Florian Kogelbauer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15259v1",
    "source": "arXiv",
    "abstract": "We prove the existence of non-hydrodynamic solutions to the linear density-dependent BGK equation in $d$ dimensions. Specifically, we show the existence of an initial condition for any Knudsen number $τ$ for which the dissipation rate of the macroscopic mass density diverges $\\sim 1/τ$. Our results rely on a detailed spectral analysis of the linear BGK operator, an explicit solution formula for the time-dependent problem using a combination of Fourier series with the Laplace transform and subsequent contour integration arguments from complex analysis."
  },
  {
    "date": "2026-01-21",
    "title": "Coloring small locally sparse degenerate graphs and related problems",
    "authors": "Domagoj Bradač, Jacob Fox, Raphael Steiner, Benny Sudakov, Shengtong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15245v1",
    "source": "arXiv",
    "abstract": "The classic upper bound on the chromatic number of $d$-degenerate graphs is $d+1$, shown to be tight by complete graphs. A natural question is whether this bound remains tight if one forbids large cliques. Classic constructions of Tutte and Zykov from the early 50s show that there exist $d$-degenerate $(d+1)$-chromatic graphs that are triangle-free, however these constructions grow rapidly with $d$. Motivated by this and addressing a problem posed by the second author at the Oberwolfach Graph Theory workshop, we prove that the minimum order $f(d)$ of a $d$-degenerate triangle-free graph of chromatic number $d+1$ satisfies $e^{Ω(d)}\\le f(d)\\le e^{O(d^2\\log d)}.$ The lower bound follows from a novel upper bound on the chromatic number of triangle-free graphs: Every triangle-free $d$-degenerate graph $G$ on $n \\le e^{O(d)}$ vertices satisfies $$χ(G)\\le O\\left(\\frac{d}{\\log\\left(d/\\log n\\right)}\\right).$$ We extend this to a more general result about degenerate graphs with sparse neighborhoods, which has applications to many graph coloring problems: For example, we prove that every counterexample to Hadwiger's conjecture with parameter $t$ must have a complete bipartite subgraph with one exponentially large side ($K_{a,b}$ where $a=(\\log t)^{1/2-o(1)}$ and $b=e^{t^{1-o(1)}}$) or a small and very dense subgraph (of order $\\le t$ with $t^{2-o(1)}$ edges) in some neighborhood. For the upper bound on $f(d)$ we establish a surprising connection between $f(d)$ and the on-line-chromatic number $g(n)$ of $n$-vertex triangle-free graphs. We also give an asymptotic improvement of the previous best upper bound for $g(n)$ due to Lovász, Saks and Trotter from 1989. Along the way we disprove a generalization of Harris' fractional coloring conjecture to graphs of bounded clique number and raise numerous problems which open up interesting directions to explore for future research."
  },
  {
    "date": "2026-01-21",
    "title": "Feasibility Preservation under Monotone Retrieval Truncation",
    "authors": "Sean Plummer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15241v1",
    "source": "arXiv",
    "abstract": "Retrieval-based systems approximate access to a corpus by exposing only a truncated subset of available evidence. Even when relevant information exists in the corpus, truncation can prevent compatible evidence from co-occurring, leading to failures that are not captured by relevance-based evaluation. This paper studies retrieval from a structural perspective, modeling query answering as a feasibility problem under truncation. We formalize retrieval as a sequence of candidate evidence sets and characterize conditions under which feasibility in the limit implies feasibility at finite retrieval depth. We show that monotone truncation suffices to guarantee finite witnessability for individual queries. For classes of queries, we identify finite generation of witness certificates as the additional condition required to obtain a uniform retrieval bound, and we show that this condition is necessary. We further exhibit sharp counterexamples demonstrating failure under non-monotone truncation, non-finitely-generated query classes, and purely slotwise coverage. Together, these results isolate feasibility preservation as a correctness criterion for retrieval independent of relevance scoring or optimization, and clarify structural limitations inherent to truncation-based retrieval."
  },
  {
    "date": "2026-01-21",
    "title": "Precision Enhancement in Transient Quantum Thermometry:Cold-Probe Bias and Its Removal",
    "authors": "Debarupa Saha, Ujjwal Sen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15237v1",
    "source": "arXiv",
    "abstract": "We unveil a temperature bias of the probe in transient quantum thermometry under Markovian dynamics. Specifically, for qubit thermometers evolving under Markovian dynamics, we show that enhanced precision beyond the steady state limit can be achieved if and only if the probe is initially colder than the thermal state corresponding to the bath temperature to be estimated. In contrast, this temperature bias can be lifted when the probe dynamics is non-Markovian. In the non-Markovian regime, both hot and cold probes can simultaneously attain the same transient maximum precision, well above the steady-state value."
  },
  {
    "date": "2026-01-21",
    "title": "When Agents Fail: A Comprehensive Study of Bugs in LLM Agents with Automated Labeling",
    "authors": "Niful Islam, Ragib Shahriar Ayon, Deepak George Thomas, Shibbir Ahmed, Mohammad Wardat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15232v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have revolutionized intelligent application development. While standalone LLMs cannot perform any actions, LLM agents address the limitation by integrating tools. However, debugging LLM agents is difficult and costly as the field is still in it's early stage and the community is underdeveloped. To understand the bugs encountered during agent development, we present the first comprehensive study of bug types, root causes, and effects in LLM agent-based software. We collected and analyzed 1,187 bug-related posts and code snippets from Stack Overflow, GitHub, and Hugging Face forums, focused on LLM agents built with seven widely used LLM frameworks as well as custom implementations. For a deeper analysis, we have also studied the component where the bug occurred, along with the programming language and framework. This study also investigates the feasibility of automating bug identification. For that, we have built a ReAct agent named BugReAct, equipped with adequate external tools to determine whether it can detect and annotate the bugs in our dataset. According to our study, we found that BugReAct equipped with Gemini 2.5 Flash achieved a remarkable performance in annotating bug characteristics with an average cost of 0.01 USD per post/code snippet."
  },
  {
    "date": "2026-01-21",
    "title": "Reassessing CP Violation in the C2HDM with Machine Learning",
    "authors": "Rafael Boto, Karim Elyaouti, Duarte Fontes, Maria Gonçalves, Margarete Mühlleitner, Jorge C. Romão, Rui Santos, João P. Silva",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15227v1",
    "source": "arXiv",
    "abstract": "We provide a study of the parameter space of the complex 2-Higgs Doublet Model (C2HDM), focusing on signs of large CP-violating couplings of the 125 GeV Higgs boson with the fermions. The study is performed utilizing Machine Learning (ML) techniques developed recently for parameter space exploration, including an Evolutionary Strategy Algorithm and Novelty Reward. We give particular attention to the electron electric dipole moment (eEDM). We confirm that the recently found kite diagrams are crucial for the outcome of the analysis. Moreover, their use also mitigates the dependence of the results on the scale and scheme choice of the masses in the loop diagrams. We furthermore point out that, already at the current level of experimental precision, the Barr-Zee diagrams with charm quark loops must be taken into account. The combined use of kite diagrams and ML techniques allows for the resurrection of large fermion CP-odd couplings for Type-II and Flipped C2HDM when the 125 GeV Higgs coincides with the second lightest neutral scalar. This arises due to cancellations, typically of the per-mil order, which, moreover, will still be possible for a foreseeable eEDM precision down to $10^{-33}$ e.cm. For these cases, the constraints on the CP-odd couplings arises from the precision LHC measurements."
  },
  {
    "date": "2026-01-21",
    "title": "Large time behaviour for a class of 2D and 3D stochastic non-Newtonian fluids of differential types: Attractors and invariant measures",
    "authors": "Kush Kinra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15223v1",
    "source": "arXiv",
    "abstract": "This study investigates a stochastic version of a class of non-Newtonian fluids governed by third-grade fluid equations, which exhibit complex and highly nonlinear dynamics. In particular, we address the random dynamics and asymptotic behavior of stochastic third-grade fluid equations (STGFEs) driven by a \\emph{linear multiplicative Itô-type white noise} on general domains $\\mathbb{Q}\\subseteq\\mathbb{R}^d$, $d\\in\\{2,3\\}$. We first prove that the non-autonomous STGFEs generate a continuous non-autonomous random dynamical system $Φ$, and we establish the existence of a pullback absorbing set. Using compact Sobolev embeddings on bounded domains and uniform tail estimates on unbounded domains, we show the pullback asymptotic compactness of $Φ$, which leads to the existence of pullback random attractors that are compact and attracting in $\\mathbb{L}^2(\\mathbb{Q})$. As a consequence, we demonstrate the existence of an invariant measure associated with the STGFEs and, exploiting the linear multiplicative structure of the noise along with the exponential stability of solutions, we prove uniqueness of the invariant measure in the case of zero external forcing. These results are entirely new for STGFEs on general domains, and, in particular, the existence of pullback random attractors with linear multiplicative noise is obtained here for the first time. We further note that, unlike Stratonovich noise, which is widely used in the literature to study random attractors, Itô noise is more appropriate for domains that do not satisfy the Poincaré inequality. Overall, this work resolves several open problems regarding random attractors, invariant measures, and ergodicity for stochastic third-grade fluids on general unbounded domains $\\mathbb{Q}\\subseteq\\mathbb{R}^d$, $d\\in\\{2,3\\}$."
  },
  {
    "date": "2026-01-21",
    "title": "MonoRace: Winning Champion-Level Drone Racing with Robust Monocular AI",
    "authors": "Stavrow A. Bahnam, Robin Ferede, Till M. Blaha, Anton E. Lang, Erin Lucassen, Quentin Missinne, Aderik E. C. Verraest, Christophe De Wagter, Guido C. H. E. de Croon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15222v1",
    "source": "arXiv",
    "abstract": "Autonomous drone racing represents a major frontier in robotics research. It requires an Artificial Intelligence (AI) that can run on board light-weight flying robots under tight resource and time constraints, while pushing the physical system to its limits. The state of the art in this area consists of a system with a stereo camera and an inertial measurement unit (IMU) that beat human drone racing champions in a controlled indoor environment. Here, we present MonoRace: an onboard drone racing approach that uses a monocular, rolling-shutter camera and IMU that generalizes to a competition environment without any external motion tracking system. The approach features robust state estimation that combines neural-network-based gate segmentation with a drone model. Moreover, it includes an offline optimization procedure that leverages the known geometry of gates to refine any state estimation parameter. This offline optimization is based purely on onboard flight data and is important for fine-tuning the vital external camera calibration parameters. Furthermore, the guidance and control are performed by a neural network that foregoes inner loop controllers by directly sending motor commands. This small network runs on the flight controller at 500Hz. The proposed approach won the 2025 Abu Dhabi Autonomous Drone Racing Competition (A2RL), outperforming all competing AI teams and three human world champion pilots in a direct knockout tournament. It set a new milestone in autonomous drone racing research, reaching speeds up to 100 km/h on the competition track and successfully coping with problems such as camera interference and IMU saturation."
  },
  {
    "date": "2026-01-21",
    "title": "ScenDi: 3D-to-2D Scene Diffusion Cascades for Urban Generation",
    "authors": "Hanlei Guo, Jiahao Shao, Xinya Chen, Xiyang Tan, Sheng Miao, Yujun Shen, Yiyi Liao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15221v1",
    "source": "arXiv",
    "abstract": "Recent advancements in 3D object generation using diffusion models have achieved remarkable success, but generating realistic 3D urban scenes remains challenging. Existing methods relying solely on 3D diffusion models tend to suffer a degradation in appearance details, while those utilizing only 2D diffusion models typically compromise camera controllability. To overcome this limitation, we propose ScenDi, a method for urban scene generation that integrates both 3D and 2D diffusion models. We first train a 3D latent diffusion model to generate 3D Gaussians, enabling the rendering of images at a relatively low resolution. To enable controllable synthesis, this 3DGS generation process can be optionally conditioned by specifying inputs such as 3d bounding boxes, road maps, or text prompts. Then, we train a 2D video diffusion model to enhance appearance details conditioned on rendered images from the 3D Gaussians. By leveraging the coarse 3D scene as guidance for 2D video diffusion, ScenDi generates desired scenes based on input conditions and successfully adheres to accurate camera trajectories. Experiments on two challenging real-world datasets, Waymo and KITTI-360, demonstrate the effectiveness of our approach."
  },
  {
    "date": "2026-01-21",
    "title": "Some reverse inequality in optimal mass transportation",
    "authors": "Luigi De Pascale, Igor Pinheiro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15218v1",
    "source": "arXiv",
    "abstract": "Controlling the $\\mathcal W_\\infty$ Wasserstein distance by the $\\mathcal W_p$ Wasserstein distance is interesting both for theorical and numerical applications. A first paper on this problem was written several years ago [3]. Some year later [14] framed it in the same inequality for more general costs which increase with the distance. In this paper, we prove this type of inequality for optimal transport problems with pointwise cost which is a decreasing function of the distance. We show, in particular, that there is a general framework that encompasses all the cases above."
  },
  {
    "date": "2026-01-21",
    "title": "Transit distances and composition of low-velocity exocomets in the $β$ Pic system",
    "authors": "Théo Vrignaud, Alain Lecavelier des Etangs",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15216v1",
    "source": "arXiv",
    "abstract": "$β$ Pictoris is a young nearby A5V star, about 20 Myr old, embedded in a prominent debris disc. For the past 40 years, variable absorption features have been observed in the stellar spectrum, produced by the gaseous tails of exocomets transiting the star. Yet, despite the large number of observations available, the origin and dynamical evolution of the exocomets remain poorly understood. Here we present new spectroscopic observations of $β$ Pic, obtained on April 29, 2025, with the Hubble Space Telescope and the HARPS spectrograph. We report the detection of three strong exocomet signatures at low radial velocities (-7.5, +2.5 and +10 km/s), in a large set of lines from various species and excitation levels. We show that the three exocometary tails have different excitation states, indicating that they are located at different distances from the star. Using a detailed modelling of the excitation state of the transiting gas, which includes both radiative and collisional excitation, we derive the transit distance of the three exocometary gaseous tails to be $0.88 \\pm 0.08$, $4.7 \\pm 0.3$, and $1.52 \\pm 0.15$ au. These values are much larger than previous estimates, which generally placed the transient features within 0.2 au. This reveals that gaseous tails produced by exocomets sublimating close to the star can expand and migrate over large distances, while still remaining detectable in absorption spectroscopy. Our study provides a new method to measure the transit distance of exocomets, based on excitation modelling, complementing the acceleration method only applicable for high-velocity objects."
  },
  {
    "date": "2026-01-21",
    "title": "The importance of super-Eddington black hole accretion for the emergence of massive quiescent galaxies at high redshift",
    "authors": "Evgenii Chaikin, Joop Schaye, Filip Huško, Cedric G. Lacey, Sylvia Ploeckinger, Matthieu Schaller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15207v1",
    "source": "arXiv",
    "abstract": "Recent JWST observations indicate that massive quiescent galaxies (stellar mass $M_{*}\\gtrsim 10^{10}~\\mathrm{M_\\odot}$) at high redshift ($z\\gtrsim 6$) are more abundant than predicted by most existing galaxy formation simulations and semi-analytic models. Notably, the new COLIBRE simulations have succeeded in reconciling this tension, though the precise reason for their improved agreement with JWST data remains unclear. We demonstrate that the improved agreement is largely due to super-Eddington growth of supermassive black holes (BHs) at high redshift. We run a series of $(100~\\mathrm{cMpc})^{3}$ simulations with the COLIBRE subgrid physics, varying the maximum allowed BH accretion rate in units of the Eddington rate. We show that only the fiducial COLIBRE model, which permits super-Eddington accretion, is consistent with the JWST constraints at $z \\gtrsim 6$. Moreover, we find that in COLIBRE about $50$ per cent of BH mass growth at high redshift occurs in the super-Eddington regime, even though such events are extremely rare in time. Our work highlights the important role of super-Eddington accretion in simulations of galaxy formation for reproducing the observed early emergence of quenching of massive galaxies."
  },
  {
    "date": "2026-01-21",
    "title": "Unveiling the impact of cross-order hyperdegree correlations in contagion processes on hypergraphs",
    "authors": "Andrés Guzmán, Federico Malizia, István Z. Kiss",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15199v1",
    "source": "arXiv",
    "abstract": "Contagion processes in social systems often involve interactions that go beyond pairwise contacts. Higher-order networks, represented as hypergraphs, have been widely used to model multi-body interactions, and their presence can drastically alter contagion dynamics compared to traditional network models. However, existing analytical approaches typically assume independence between pairwise and higher-order degrees, and thus study their roles in isolation. In this paper, we develop an effective hyperdegree model (EHDM) to describe Susceptible-Infected-Susceptible (SIS) dynamics on hypergraphs that explicitly captures correlations between the distribution of groups with different sizes. Our effective hyperdegree model shows excellent agreement with stochastic simulations across different types of higher-order networks, including those with heterogeneous degree distributions. We explore the critical role of cross-order degree correlations, specifically, whether nodes that are hubs in pairwise interactions also serve as hubs in higher-order interactions. We show that positive correlation decreases the epidemic threshold and anti-correlation temporally desynchronizes infection pathways (pairwise and group interactions). Finally, we demonstrate that, depending on the level of correlation, the optimal control strategy shifts -- from one that is purely pairwise- or higher-order-focused to one in which a mixed strategy becomes optimal."
  },
  {
    "date": "2026-01-21",
    "title": "Revealing massive black hole astrophysics: The potential of hierarchical inference with extreme mass-ratio inspiral observations",
    "authors": "Shashwat Singh, Christian E. A. Chapman-Bird, Christopher P. L. Berry, John Veitch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15198v1",
    "source": "arXiv",
    "abstract": "Gravitational waves from extreme mass-ratio inspirals (EMRIs) will enable sub-percent measurements of massive black hole parameters and provide access to the demographics of compact objects in galactic nuclei. During the LISA mission, multiple EMRIs are expected to be detected, allowing statistical studies of massive black hole populations and their formation pathways. We perform hierarchical Bayesian inference on simulated EMRI catalogues to assess how well LISA could constrain the astrophysical population using parametrised population models. We test our inference framework on a variety of populations, including heterogeneous and homogeneous mixtures of parametrised subpopulations, and scenarios in which the assumed model is deliberately misspecified. Our results show that population parameters governing distributions with sharp features can be tightly constrained. Mixed populations can be disentangled with as few as $\\sim20$ detections, and even with model misspecification, the inference retains sensitivity to key population features. These results demonstrate the capabilities and limitations of EMRI population inference, providing guidance for constructing realistic astrophysical population models for LISA analysis."
  },
  {
    "date": "2026-01-21",
    "title": "BayesianVLA: Bayesian Decomposition of Vision Language Action Models via Latent Action Queries",
    "authors": "Shijie Lian, Bin Yu, Xiaopeng Lin, Laurence T. Yang, Zhaolong Shen, Changti Wu, Yuzhuo Miao, Cong Huang, Kai Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15197v1",
    "source": "arXiv",
    "abstract": "Vision-Language-Action (VLA) models have shown promise in robot manipulation but often struggle to generalize to new instructions or complex multi-task scenarios. We identify a critical pathology in current training paradigms where goal-driven data collection creates a dataset bias. In such datasets, language instructions are highly predictable from visual observations alone, causing the conditional mutual information between instructions and actions to vanish, a phenomenon we term Information Collapse. Consequently, models degenerate into vision-only policies that ignore language constraints and fail in out-of-distribution (OOD) settings. To address this, we propose BayesianVLA, a novel framework that enforces instruction following via Bayesian decomposition. By introducing learnable Latent Action Queries, we construct a dual-branch architecture to estimate both a vision-only prior $p(a \\mid v)$ and a language-conditioned posterior $π(a \\mid v, \\ell)$. We then optimize the policy to maximize the conditional Pointwise Mutual Information (PMI) between actions and instructions. This objective effectively penalizes the vision shortcut and rewards actions that explicitly explain the language command. Without requiring new data, BayesianVLA significantly improves generalization. Extensive experiments across on SimplerEnv and RoboCasa demonstrate substantial gains, including an 11.3% improvement on the challenging OOD SimplerEnv benchmark, validating the ability of our approach to robustly ground language in action."
  },
  {
    "date": "2026-01-21",
    "title": "TTCBF: A Truncated Taylor Control Barrier Function for High-Order Safety Constraints",
    "authors": "Jianye Xu, Bassam Alrifaee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15196v1",
    "source": "arXiv",
    "abstract": "Control Barrier Functions (CBFs) enforce safety by rendering a prescribed safe set forward invariant. However, standard CBFs are limited to safety constraints with relative degree one, while High-Order CBF (HOCBF) methods address higher relative degree at the cost of introducing a chain of auxiliary functions and multiple class K functions whose tuning scales with the relative degree. In this paper, we introduce a Truncated Taylor Control Barrier Function (TTCBF), which generalizes standard discrete-time CBFs to consider high-order safety constraints and requires only one class K function, independent of the relative degree. We also propose an adaptive variant, adaptive TTCBF (aTTCBF), that optimizes an online gain on the class K function to improve adaptability, while requiring fewer control design parameters than existing adaptive HOCBF variants. Numerical experiments in a relative-degree-six spring-mass system and a cluttered corridor navigation validate the above theoretical findings."
  },
  {
    "date": "2026-01-21",
    "title": "Alkali recondensation into chondrules",
    "authors": "Emmanuel Jacquet, Yves Marrocchi, Sébastien Charnoz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15190v1",
    "source": "arXiv",
    "abstract": "While sub-mm melt droplets should rapidly lose alkali elements in a vacuum at liquidus temperatures, chondrules are only modestly depleted in them (by less than one order of magnitude). The detection of sodium in olivine cores has previously suggested very high saturating partial pressures of gaseous sodium, but we show that alkalis were lost during heating and recondensed at lower temperatures, essentially in the present-day chondrule mesostases. This recondensation was accompanied by mass-dependent enrichment in light isotopes (for multi-isotope alkalis such as K and Rb), but its limited extent indicates a cooling acceleration (or \"quenching\"). The isotopic fractionation also constrains the ratio of the chondrule density and the cooling rate prior to the quench around $10^{-6}\\:\\mathrm{kg.m^{-3}.K^{-1}.h}$ suggesting densities above $\\sim 10^{-6}\\:\\mathrm{kg/m^3}$. In a nebular context, this is achievable by radial and vertical concentrations near pressure bumps."
  },
  {
    "date": "2026-01-21",
    "title": "Benchmarking Large Language Models for ABAP Code Generation: An Empirical Study on Iterative Improvement by Compiler Feedback",
    "authors": "Stephan Wallraven, Tim Köhne, Hartmut Westenberger, Andreas Moser",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15188v1",
    "source": "arXiv",
    "abstract": "This work investigates the performance of Large Language Models (LLMs) in generating ABAP code. Despite successful applications of generative AI in many programming languages, there are hardly any systematic analyses of ABAP code generation to date. The aim of the study is to empirically analyze to what extent various LLMs can generate syntactically correct and functional ABAP code, how effectively they use compiler feedback for iterative improvement, and which task types pose special challenges. For this purpose, a benchmark with 180 tasks is conducted, consisting of adapted HumanEval tasks and practical SAP scenarios. The results show significant performance differences between the models: more powerful LLMs achieve success rates of around 75% after several iterations and benefit greatly from compiler feedback, while smaller models perform significantly weaker. Overall, the study highlights the high potential of powerful LLMs for ABAP development processes, especially in iterative error correction."
  },
  {
    "date": "2026-01-21",
    "title": "The Zariski Topology on Homeomorphism groups",
    "authors": "Luna Elliott",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15185v1",
    "source": "arXiv",
    "abstract": "The Zariski topology on a group G is the coarsest topology such that all sets of the form $\\{x \\in G | 1_G \\neq g_0 x^{k_0} g_1 ... g_{l-1} x^{k_{l-1}} g_l\\}$ are open. Originally introduced by Bryant as the verbal topology, it serves as a fundamental tool for investigating the topological structure of infinite groups and is always a $T_1$ topology with continuous shifts and inversion. Since the Zariski topology is coarser than every Hausdorff group topology on G, it provides a natural starting point for topologizing groups; specifically, for countable or abelian groups, it is known that the Zariski topology coincides with the Markov topology-the intersection of all Hausdorff group topologies on G. In this paper, we analyze the Zariski topology on various homeomorphism groups. We demonstrate that for the Thompson groups F and T, the Zariski (and thus Markov) topology coincides with the standard compact-open topology derived from their respective actions on $[0,1]$ and $S^1$. In contrast, we show that the Zariski (and thus Markov) topology on Thompson's group V is irreducible, and therefore neither Hausdorff nor a group topology. As V acts highly transitively on each of its orbits, this result stands in notable opposition to a theorem by Banakh et al, which establishes that the Zariski topology on any permutation group containing all finitely supported elements is a Hausdorff group topology. We also extend these investigations to Homeo$([0,1])$, Homeo$(S^1)$, and Homeo$(2^ω)$. We conclude by providing a classification of the topological manifolds $M$ for which the homeomorphism group Homeo$(M)$ admits a Hausdorff Zariski topology."
  },
  {
    "date": "2026-01-21",
    "title": "Complexity analysis and practical resolution of the data classification problem with private characteristics",
    "authors": "David Pantoja, Ismael Rodriguez, Fernando Rubio, Clara Segura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15178v1",
    "source": "arXiv",
    "abstract": "In this work we analyze the problem of, given the probability distribution of a population, questioning an unknown individual that is representative of the distribution so that our uncertainty about certain characteristics is significantly reduced -but the uncertainty about others, deemed private or sensitive, is not. Thus, the goal of the problem is extracting information being relevant to a legitimate purpose while preserving the privacy of individuals, which is crucial to enable non-intrusive selection processes in several areas. For instance, it is essential in the design of non-discriminatory personnel selection, promotion, and layoff processes in companies and institutions; in the retrieval of customer information being relevant to the service provided by a company (and no more); in certifications not revealing sensitive industrial information being irrelevant for the certification itself; etc. Interactive questioning processes are constructed for this purpose, which requires generalizing the notion of decision trees to account the amount of desired and undesired information retrieved for each branch of the plan. Our findings about this problem are both theoretical and practical: on the one hand, we prove its NP-completeness by a reduction from the Set Cover problem; and on the other hand, given this intractability, we provide heuristic solutions to find reasonable solutions in affordable time. In particular, a greedy algorithm and two genetic algorithms are presented. Our experiments indicate that the best results are obtained using a genetic algorithm reinforced with a greedy strategy."
  },
  {
    "date": "2026-01-21",
    "title": "Dark Energy Survey Year 6 Results: Galaxy-galaxy lensing",
    "authors": "G. Giannini, G. Camacho-Ciurana, A. Whyley, J. Prat, J. Blazek, C. Sánchez, G. Zacharegkas, A. Alarcon, E. Legnani, A. Amon, D. Anbajagane, S. Avila, K. Bechtol, M. R. Becker, G. M. Bernstein, S. Bocquet, A. Campos, A. Carnero Rosell, R. Cawthon, C. Chang, M. Crocce, W. d'Assignies, J. De Vicente, A. Drlica-Wagner, S. Elvin-Poole, A. Ferté, M. Gatti, D. Gruen, M. Jarvis, M. Manera, S. Mau, J. McCullough, F. Menanteau, J. Myles, A. Porredon, M. Rodriguez-Monroy, A. Roodman, E. S. Rykoff, S. Samuroff, D. Sanchez Cid, I. Sevilla-Noarbe, T. Schutt, M. A. Troxel, N. Weaverdyck, M. Yamamoto, B. Yin, T. M. C. Abbott, M. Aguena, S. Allam, O. Alves, F. Andrade-Oliveira, D. Bacon, E. Bertin, D. Brooks, H. Camacho, J. Carretero, L. N. da Costa, M. E. da Silva Pereira, T. M. Davis, D. L. DePoy, S. Desai, H. T. Diehl, P. Doel, C. Doux, T. F. Eifler, S. Everett, A. E. Evrard, P. Fosalba, J. Frieman, J. García-Bellido, E. Gaztanaga, P. Giles, K. Glazebrook, I. Harrison, W. G. Hartley, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, B. Jain, D. J. James, N. Jeffrey, T. Kacprzak, S. Kent, E. Krause, O. Lahav, S. Lee, J. L. Marshall, J. Mena-Fernández, R. Miquel, J. J. Mohr, J. Muir, R. C. Nichol, R. L. C. Ogando, A. Palmese, M. Paterno, W. J. Percival, D. Petravick, A. A. Plazas Malagón, M. Raveri, R. Rosenfeld, E. Sanchez, E. Sheldon, T. Shin, J. Allyn. Smith, M. Smith, M. Soares-Santos, E. Suchyta, M. E. C. Swanson, G. Tarle, D. Thomas, C. To, D. L. Tucker, V. Vikram, M. Vincenzi, A. R. Walker, P. Wiseman, B. Yanny",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15175v1",
    "source": "arXiv",
    "abstract": "We present galaxy--galaxy lensing (GGL) measurements from the full six years of data from the Dark Energy Survey (DES Y6), covering $4031\\,\\mathrm{deg}^2$ and used in the DES Y6 $3\\times2$pt cosmological analysis. We use the MagLim++ lens sample, containing $\\sim 9$ million galaxies divided into six redshift bins, and the Metadetection source catalog, including $\\sim 140$ million galaxies divided into four redshift bins. The mean tangential shear signal achieves a total signal-to-noise ratio (S/N) of $173$, corresponding to a $17\\%$ improvement over DES Y3. After applying the scale cuts used in the cosmological analysis, with $R_{\\min}=6\\,\\mathrm{Mpc}/h$ ($4\\,\\mathrm{Mpc}/h$) for the linear (nonlinear) galaxy-bias model, the S/N is reduced to $75$ (90). A comprehensive suite of validation tests demonstrates that the measurement is robust against observational and astrophysical systematics at the statistical precision required for the DES Y6 analysis. Although not used in the main cosmological analysis, we extract high--signal-to-noise geometric shear-ratio measurements from the galaxy--galaxy lensing signal on small angular scales. These measurements provide an internal consistency check on the photometric redshift distributions and shear calibration used in the $3\\times2$pt analysis."
  },
  {
    "date": "2026-01-21",
    "title": "A nearly linear-time Decoded Quantum Interferometry algorithm for the Optimal Polynomial Intersection problem",
    "authors": "Ansis Rosmanis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15171v1",
    "source": "arXiv",
    "abstract": "Recently, Jordan et al. (Nature, 2025) introduced a novel quantum-algorithmic technique called Decoded Quantum Interferometry (DQI) for solving specific combinatorial optimization problems associated with classical codes. They presented a constraint-satisfaction problem called Optimal Polynomial Intersection (OPI) and showed that, for this problem, a DQI algorithm running in polynomial time can satisfy a larger fraction of constraints than any known polynomial-time classical algorithm. In this work, we propose several improvements to the DQI algorithm, including sidestepping the quadratic-time Dicke state preparation. Given random access to the input, we show how these improvements result in a nearly linear-time DQI algorithm for the OPI problem. Concurrently and independently with this work, Khattar et al. (arXiv:2510:10967) also construct a nearly linear-time DQI algorithm for OPI using slightly different techniques."
  },
  {
    "date": "2026-01-21",
    "title": "V-CAGE: Context-Aware Generation and Verification for Scalable Long-Horizon Embodied Tasks",
    "authors": "Yaru Liu, Ao-bo Wang, Nanyang Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15164v1",
    "source": "arXiv",
    "abstract": "Learning long-horizon embodied behaviors from synthetic data remains challenging because generated scenes are often physically implausible, language-driven programs frequently \"succeed\" without satisfying task semantics, and high-level instructions require grounding into executable action sequences. To address these limitations, we introduce V-CAGE, a closed-loop framework for generating robust, semantically aligned manipulation datasets at scale. First, we propose a context-aware instantiation mechanism that enforces geometric consistency during scene synthesis. By dynamically maintaining a map of prohibited spatial areas as objects are placed, our system prevents interpenetration and ensures reachable, conflict-free configurations in cluttered environments. Second, to bridge the gap between abstract intent and low-level control, we employ a hierarchical instruction decomposition module. This decomposes high-level goals (e.g., \"get ready for work\") into compositional action primitives, facilitating coherent long-horizon planning. Crucially, we enforce semantic correctness through a VLM-based verification loop. Acting as a visual critic, the VLM performs rigorous rejection sampling after each subtask, filtering out \"silent failures\" where code executes but fails to achieve the visual goal. Experiments demonstrate that V-CAGE yields datasets with superior physical and semantic fidelity, significantly boosting the success rate and generalization of downstream policies compared to non-verified baselines."
  },
  {
    "date": "2026-01-21",
    "title": "Biphasic Meniscus Coating for Scalable and Material Efficient Quantum Dot Films",
    "authors": "Shlok Joseph Paul, Letian Li, Zheng Li, Andrew Kim, Mia Klopfestein, Stephanie S. Lee, Ayaskanta Sahu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15149v1",
    "source": "arXiv",
    "abstract": "Colloidal quantum dots (cQDs) have emerged as a cornerstone of next-generation optoelectronics, offering unparalleled spectral tunability and solution-processability. However, the transition from laboratory-scale devices to sustainable industrial manufacturing is fundamentally hindered by spin-coating workflows, which are intrinsically wasteful and restricted to planar geometries. These limitations are particularly acute for high-performance cQDs containing regulated elements such as lead, cadmium, or mercury, where poor material utilization exacerbates both environmental burden and cost. Here we report a biphasic dip-coating strategy that redefines the material efficiency of nanocrystal film fabrication. By utilizing an immiscible underlayer to displace ~88% of the active reservoir volume, we demonstrate a deposition geometry that decouples material consumption from total precursor volume. Infrared PbS photodetectors fabricated via this approach maintain their performance against spin-coated benchmarks while reducing ink consumption by up to 20-fold. Our technoeconomic analysis reveals that this biphasic architecture achieves cost parity at film thicknesses an order of magnitude lower than conventional monophasic dip-coating. Our results establish a low-waste framework for solution-processed materials, providing a viable pathway for the resource-efficient manufacturing of optoelectronic devices."
  },
  {
    "date": "2026-01-21",
    "title": "Fractional operators and Sobolev spaces on homogeneous groups",
    "authors": "Nicola Garofalo, Annunziata Loiudice, Dimiter Vassilev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15143v1",
    "source": "arXiv",
    "abstract": "We establish foundational properties of fractional operators on Lie groups of homogeneous type. We prove embedding theorems for the associated Sobolev-type spaces."
  },
  {
    "date": "2026-01-21",
    "title": "Stochastic EMS for Optimal 24/7 Carbon-Free Energy Operations",
    "authors": "Natanon Tongamrak, Kannapha Amaruchkul, Wijarn Wangdee, Jitkomut Songsiri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15135v1",
    "source": "arXiv",
    "abstract": "This paper proposes a two-stage stochastic optimization formulation to determine optimal operation and procurement plans for achieving a 24/7 carbon-free energy (CFE) compliance at minimized cost. The system in consideration follows primary energy technologies in Thailand including solar power, battery storage, and a diverse portfolio of renewable and carbon-based energy procurement sources. Unlike existing literature focused on long-term planning, this study addresses near real-time operations using a 15-minute resolution. A novel feature of the formulation is the explicit treatment of CFE compliance as a model parameter, enabling flexible targets such as a minimum percentage of hourly matching or a required number of carbon-free days within a multi-day horizon. The mixed-integer linear programming formulation accounts for uncertainties in load and solar generation by integrating deep learning-based forecasting within a receding horizon framework. By optimizing battery profiles and multi-source procurement simultaneously, the proposed system provides a feasible pathway for transitioning to carbon-free operations in emerging energy markets."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient prior sensitivity analysis for Bayesian model comparison",
    "authors": "Zixiao Hu, Jason D. McEwen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15132v1",
    "source": "arXiv",
    "abstract": "Bayesian model comparison implements Occam's razor through its sensitivity to the prior. However, prior-dependence makes it important to assess the influence of plausible alternative priors. Such prior sensitivity analyses for the Bayesian evidence are expensive, either requiring repeated, costly model re-fits or specialised sampling schemes. By exploiting the learned harmonic mean estimator (LHME) for evidence calculation we decouple sampling and evidence calculation, allowing resampled posterior draws to be used directly to calculate the evidence without further likelihood evaluations. This provides an alternative approach to prior sensitivity analysis for Bayesian model comparison that dramatically alleviates the computational cost and is agnostic to the method used to generate posterior samples. We validate our method on toy problems and a cosmological case study, reproducing estimates obtained by full Markov chain Monte Carlo (MCMC) sampling and nested sampling re-fits. For the cosmological example considered our approach achieves up to $6000\\times$ lower computational cost."
  },
  {
    "date": "2026-01-21",
    "title": "The Plausibility Trap: Using Probabilistic Engines for Deterministic Tasks",
    "authors": "Ivan Carrera, Daniel Maldonado-Ruiz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15130v1",
    "source": "arXiv",
    "abstract": "The ubiquity of Large Language Models (LLMs) is driving a paradigm shift where user convenience supersedes computational efficiency. This article defines the \"Plausibility Trap\": a phenomenon where individuals with access to Artificial Intelligence (AI) models deploy expensive probabilistic engines for simple deterministic tasks-such as Optical Character Recognition (OCR) or basic verification-resulting in significant resource waste. Through micro-benchmarks and case studies on OCR and fact-checking, we quantify the \"efficiency tax\"-demonstrating a ~6.5x latency penalty-and the risks of algorithmic sycophancy. To counter this, we introduce Tool Selection Engineering and the Deterministic-Probabilistic Decision Matrix, a framework to help developers determine when to use Generative AI and, crucially, when to avoid it. We argue for a curriculum shift, emphasizing that true digital literacy relies not only in knowing how to use Generative AI, but also on knowing when not to use it."
  },
  {
    "date": "2026-01-21",
    "title": "Overcoming In-Memory Bottlenecks in Graph Foundation Models via Retrieval-Augmented Generation",
    "authors": "Haonan Yuan, Qingyun Sun, Jiacheng Tao, Xingcheng Fu, Jianxin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15124v1",
    "source": "arXiv",
    "abstract": "Graph Foundation Models (GFMs) have emerged as a frontier in graph learning, which are expected to deliver transferable representations across diverse tasks. However, GFMs remain constrained by in-memory bottlenecks: they attempt to encode knowledge into model parameters, which limits semantic capacity, introduces heavy lossy compression with conflicts, and entangles graph representation with the knowledge in ways that hinder efficient adaptation, undermining scalability and interpretability. In this work,we propose RAG-GFM, a Retrieval-Augmented Generation aided Graph Foundation Model that offloads knowledge from parameters and complements parameterized learning. To externalize graph knowledge, we build a dual-modal unified retrieval module, where a semantic store from prefix-structured text and a structural store from centrality-based motif. To preserve heterogeneous information, we design a dual-view alignment objective that contrasts both modalities to capture both content and relational patterns. To enable efficient downstream adaptation, we perform in-context augmentation to enrich supporting instances with retrieved texts and motifs as contextual evidence. Extensive experiments on five benchmark graph datasets demonstrate that RAG-GFM consistently outperforms 13 state-of-the-art baselines in both cross-domain node and graph classification, achieving superior effectiveness and efficiency."
  },
  {
    "date": "2026-01-21",
    "title": "From Insight to Intervention: Interpretable Neuron Steering for Controlling Popularity Bias in Recommender Systems",
    "authors": "Parviz Ahmadov, Masoud Mansoury",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15122v1",
    "source": "arXiv",
    "abstract": "Popularity bias is a pervasive challenge in recommender systems, where a few popular items dominate attention while the majority of less popular items remain underexposed. This imbalance can reduce recommendation quality and lead to unfair item exposure. Although existing mitigation methods address this issue to some extent, they often lack transparency in how they operate. In this paper, we propose a post-hoc approach, PopSteer, that leverages a Sparse Autoencoder (SAE) to both interpret and mitigate popularity bias in recommendation models. The SAE is trained to replicate a trained model's behavior while enabling neuron-level interpretability. By introducing synthetic users with strong preferences for either popular or unpopular items, we identify neurons encoding popularity signals through their activation patterns. We then steer recommendations by adjusting the activations of the most biased neurons. Experiments on three public datasets with a sequential recommendation model demonstrate that PopSteer significantly enhances fairness with minimal impact on accuracy, while providing interpretable insights and fine-grained control over the fairness-accuracy trade-off."
  },
  {
    "date": "2026-01-21",
    "title": "An alternative approach to the Painlevé paradox through constitutive characterization of constraints in impulsive Mechanics",
    "authors": "Stefano Pasquero",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15117v1",
    "source": "arXiv",
    "abstract": "We frame the Painlevè mechanical system, which has been extensively studied because of the paradox it generates, within the class of Regular Geometric Impulsive Mechanical Systems (RGIMS), by modeling it as a mechanical system subject to a rough unilateral positional constraint $\\cal{S}$, where friction is represented by an instantaneous kinetic constraint $\\cal{B}$, internal to $\\cal{S}$ and of impulsive nature. The evolution of the system is therefore determined by the choice of a constitutive characterization for these constraints, a choice that restores mechanical determinism and eliminates any paradoxical aspects of the system's behavior, in agreement with experimental evidence. It is shown that, similarly to what occurs in general non ideal impulsive systems, the choice of a constitutive characterization of the constraint system depends on the determination of two numerical coefficients $σ$ and $β$, which depend on the kinematic and mass-related data of the system, and possibly also on physical quantities not strictly of a mechanical nature, such as material properties. The simplicity of the model also allows for a straightforward experimental analysis of the system's behavior and for the experimental determination of the values of these coefficients."
  },
  {
    "date": "2026-01-21",
    "title": "Physics-Informed Wireless Imaging with Implicit Neural Representation in RIS-Aided ISAC System",
    "authors": "Yixuan Huang, Jie Yang, Chao-Kai Wen, Xiao Li, Shi Jin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15113v1",
    "source": "arXiv",
    "abstract": "Wireless imaging is emerging as a key capability in next-generation integrated sensing and communication (ISAC) systems, supporting diverse context-aware applications. However, conventional imaging approaches, whether based on physical models or data-driven learning, face challenges such as accurate multipath separation and representative dataset acquisition. To address these issues, this study explores the use of implicit neural representation (INR), a paradigm that has achieved notable advancements in computer vision, for wireless imaging in reconfigurable intelligent surface-aided ISAC systems. The neural network of INR is specifically designed with positional encoding and sine activation functions. Leveraging physics-informed loss functions, INR is optimized through deep learning to represent continuous target shapes and scattering profiles, enabling resolution-agnostic imaging with strong generalization capability. Extensive simulations demonstrate that the proposed INR-based method achieves significant improvements over state-of-the-art techniques and further reveals the focal length characteristics of the imaging system."
  },
  {
    "date": "2026-01-21",
    "title": "An Agentic Operationalization of DISARM for FIMI Investigation on Social Media",
    "authors": "Kevin Tseng, Juan Carlos Toledano, Bart De Clerck, Yuliia Dukach, Phil Tinn",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15109v1",
    "source": "arXiv",
    "abstract": "The interoperability of data and intelligence across allied partners and their respective end-user groups is considered a foundational enabler to the collective defense capability--both conventional and hybrid--of NATO countries. Foreign Information Manipulation and Interference (FIMI) and related hybrid activities are conducted across various societal dimensions and infospheres, posing an ever greater challenge to the characterization of threats, sustaining situational awareness, and response coordination. Recent advances in AI have further led to the decreasing cost of AI-augmented trolling and interference activities, such as through the generation and amplification of manipulative content. Despite the introduction of the DISARM framework as a standardized metadata and analytical framework for FIMI, operationalizing it at the scale of social media remains a challenge. We propose a framework-agnostic agent-based operationalization of DISARM to investigate FIMI on social media. We develop a multi-agent pipeline in which specialized agentic AI components collaboratively (1) detect candidate manipulative behaviors, and (2) map these behaviors onto standard DISARM taxonomies in a transparent manner. We evaluated the approach on two real-world datasets annotated by domain practitioners. We demonstrate that our approach is effective in scaling the predominantly manual and heavily interpretive work of FIMI analysis, providing a direct contribution to enhancing the situational awareness and data interoperability in the context of operating in media and information-rich settings."
  },
  {
    "date": "2026-01-21",
    "title": "The exact dynamical structure factor of one-dimensional hard rods and its universal random matrix behavior",
    "authors": "Oleksandr Gamayun, Miłosz Panfil",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15108v1",
    "source": "arXiv",
    "abstract": "We obtain an exact analytic expression for the dynamical structure factor of one-dimensional quantum gas of hard rods. Our result is valid for arbitrary many-body state of the system, with finite temperature states and the ground state being important special cases that we analyse in detail. We demonstrate that the expression obeys fundamental relations such like the f-sum rule and the detailed balance. We also reveal the hidden fermionic structure behind the correlator. In the static limit we show that it can be written in terms of universal functions which, at zero temperature, coincide with the level spacing distribution function of the Gaussian Unitary Ensemble. Our work provides a full and exact characterisation of a dynamic correlation function in a strongly correlated interacting quantum many-body system."
  },
  {
    "date": "2026-01-21",
    "title": "Economic feasibility of virtual operators in 5G via network slicing",
    "authors": "Erwin J. Sacoto-Cabrera, Luis Guijarro, Jose R. Vidal, Vicent Pla",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15103v1",
    "source": "arXiv",
    "abstract": "The provision of services by more than one operator over a common network infrastructure, as enabled by 5G network slicing, is analyzed. Two business models to be implemented by a network operator, who owns the network, and a virtual operator, who does not, are proposed. In one business model, named \\emph{strategic}, the network operator provides service to its user base and the virtual operator provides service to its user base and pays a per-subscriber fee to the network operator. In the other business model, named \\emph{monopolistic}, the network operator provides service to both user bases. The two proposals are analyzed by means of a model that captures both system and economic features. As regards the systems features, the slicing of the network is modeled by means of a Discriminatory Processor Sharing queue. As regards the economic features, the incentives are modeled by means of the user utilities and the operators' revenues; and game theory is used to model the strategic interaction between the users' subscription decision and the operators' pricing decision. In both business models, it is shown that the network operator can be provided with the appropriate economic incentives so that it acquiesces in serving the virtual operator's user base (monopolistic model) and in allowing the virtual operator to provide service over the network operator's infrastructure (strategic model). From the point of view of the users, the strategic model results in a higher subscription rate than the monopolistic model."
  },
  {
    "date": "2026-01-21",
    "title": "Field-Space Autoencoder for Scalable Climate Emulators",
    "authors": "Johannes Meuer, Maximilian Witte, Étiénne Plésiat, Thomas Ludwig, Christopher Kadow",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15102v1",
    "source": "arXiv",
    "abstract": "Kilometer-scale Earth system models are essential for capturing local climate change. However, these models are computationally expensive and produce petabyte-scale outputs, which limits their utility for applications such as probabilistic risk assessment. Here, we present the Field-Space Autoencoder, a scalable climate emulation framework based on a spherical compression model that overcomes these challenges. By utilizing Field-Space Attention, the model efficiently operates on native climate model output and therefore avoids geometric distortions caused by forcing spherical data onto Euclidean grids. This approach preserves physical structures significantly better than convolutional baselines. By producing a structured compressed field, it serves as a good baseline for downstream generative emulation. In addition, the model can perform zero-shot super-resolution that maps low-resolution large ensembles and scarce high-resolution data into a shared representation. We train a generative diffusion model on these compressed fields. The model can simultaneously learn internal variability from abundant low-resolution data and fine-scale physics from sparse high-resolution data. Our work bridges the gap between the high volume of low-resolution ensemble statistics and the scarcity of high-resolution physical detail."
  },
  {
    "date": "2026-01-21",
    "title": "Neural Tracking of Sustained Attention, Attention Switching, and Natural Conversation in Audiovisual Environments using Mobile EEG",
    "authors": "Johanna Wilroth, Oskar Keding, Martin A. Skoglund, Maria Sandsten, Martin Enqvist, Emina Alickovic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15097v1",
    "source": "arXiv",
    "abstract": "Everyday communication is dynamic and multisensory, often involving shifting attention, overlapping speech and visual cues. Yet, most neural attention tracking studies are still limited to highly controlled lab settings, using clean, often audio-only stimuli and requiring sustained attention to a single talker. This work addresses that gap by introducing a novel dataset from 24 normal-hearing participants. We used a mobile electroencephalography (EEG) system (44 scalp electrodes and 20 cEEGrid electrodes) in an audiovisual (AV) paradigm with three conditions: sustained attention to a single talker in a two-talker environment, attention switching between two talkers, and unscripted two-talker conversations with a competing single talker. Analysis included temporal response functions (TRFs) modeling, optimal lag analysis, selective attention classification with decision windows ranging from 1.1s to 35s, and comparisons of TRFs for attention to AV conversations versus side audio-only talkers. Key findings show significant differences in the attention-related P2-peak between attended and ignored speech across conditions for scalp EEG. No significant change in performance between switching and sustained attention suggests robustness for attention switches. Optimal lag analysis revealed narrower peak for conversation compared to single-talker AV stimuli, reflecting the additional complexity of multi-talker processing. Classification of selective attention was consistently above chance (55-70% accuracy) for scalp EEG, while cEEGrid data yielded lower correlations, highlighting the need for further methodological improvements. These results demonstrate that mobile EEG can reliably track selective attention in dynamic, multisensory listening scenarios and provide guidance for designing future AV paradigms and real-world attention tracking applications."
  },
  {
    "date": "2026-01-21",
    "title": "Critical and multicritical Lee-Yang fixed points in the local potential approximation",
    "authors": "Dario Benedetti, Fanny Eustachon, Omar Zanusso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15087v1",
    "source": "arXiv",
    "abstract": "The multicritical generalizations of the Lee-Yang universality class arise as renormalization-group fixed points of scalar field theories with complex $i\\varphi^{2n+1}$ interaction, $n\\in\\mathbb{N}$, just below their upper critical dimension. It has been recently conjectured that their continuation to two dimensions corresponds to the non-unitary conformal minimal models $\\mathcal{M}(2,2n+3)$. Motivated by that, we revisit the functional renormalization group approach to complex $\\mathcal{P}\\mathcal{T}$-symmetric scalar field theories in the Local Potential Approximation, without or with wavefunction renormalization (LPA and LPA' respectively), aiming to explore the fate of the $i\\varphi^{2n+1}$ theories from their upper critical dimension to two dimensions. The $i\\varphi^{2n+1}$ fixed points are identified using a perturbative expansion of the functional fixed-point equation near their upper critical dimensions, and they are followed to lower dimensions by numerical integration of the full equation. A peculiar feature of the complex $\\mathcal{P}\\mathcal{T}$-symmetric potentials is that the fixed points are characterized by real but negative anomalous dimensions $η$, and in low dimension $d$, this can lead to a change of sign of the scaling dimensions $Δ=(d-2+η)/2$, thus requiring a novel analysis of the analytical properties of the functional fixed-point equations. We are able to follow the Lee-Yang universality class ($n=1$) down to two dimensions, and numerically determine the scaling dimension of the fundamental field as a function of $d$. On the other hand, within the LPA', multicritical Lee-Yang fixed points with $n>1$ cannot be continued to $d=2$ due to the existence of unexpected non-perturbative fixed points that annihilate with the $i\\varphi^{2n+1}$ fixed points."
  },
  {
    "date": "2026-01-21",
    "title": "Bangla Music Genre Classification Using Bidirectional LSTMS",
    "authors": "Muntakimur Rahaman, Md Mahmudul Hoque, Md Mehedi Hassain",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15083v1",
    "source": "arXiv",
    "abstract": "Bangla music is enrich in its own music cultures. Now a days music genre classification is very significant because of the exponential increase in available music, both in digital and physical formats. It is necessary to index them accordingly to facilitate improved retrieval. Automatically classifying Bangla music by genre is essential for efficiently locating specific pieces within a vast and diverse music library. Prevailing methods for genre classification predominantly employ conventional machine learning or deep learning approaches. This work introduces a novel music dataset comprising ten distinct genres of Bangla music. For the task of audio classification, we utilize a recurrent neural network (RNN) architecture. Specifically, a Long Short-Term Memory (LSTM) network is implemented to train the model and perform the classification. Feature extraction represents a foundational stage in audio data processing. This study utilizes Mel-Frequency Cepstral Coefficients (MFCCs) to transform raw audio waveforms into a compact and representative set of features. The proposed framework facilitates music genre classification by leveraging these extracted features. Experimental results demonstrate a classification accuracy of 78%, indicating the system's strong potential to enhance and streamline the organization of Bangla music genres."
  },
  {
    "date": "2026-01-21",
    "title": "Characterization of sparse monotone graph classes with bounded domination-to-2-independence ratio",
    "authors": "Marthe Bonamy, Zdeněk Dvořák, Lukas Michel, David Mikšaník",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15082v1",
    "source": "arXiv",
    "abstract": "We give an exact characterization of monotone graph classes C with bounded average degree that satisfy the following property: The domination number of every graph from C is bounded by a linear function of its 2-independence number."
  },
  {
    "date": "2026-01-21",
    "title": "Stimulated cooling in non-equilibrium Bose-Einstein condensate",
    "authors": "Ka Kit Kelvin Ho, Vladislav Yu. Shishkov, Mohammad Amini, Leonie Teresa Wrathall, Evgeny Mamonov, Darius Urbonas, Ioannis Georgakilas, Tobias Herkenrath, Michael Forster, Ullrich Scherf, Tapio Niemi, Päivi Törmä, Anton V. Zasedatelev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15080v1",
    "source": "arXiv",
    "abstract": "We report on the experimental observation of stimulated cooling in the non-equilibrium Bose-Einstein condensate (BEC) of weakly interacting exciton-polaritons from approximately room temperature down to 20K. By resolving the condensate in energy-momentum space and performing interferometric measurements, we distinguish the condensate from thermalized particles yet occupying excited states macroscopically. In contrast to the analytical quantum theories of non-equilibrium BEC [Shishkov et al., Phys. Rev. Lett. 128, 065301 (2022)], we observe segmentation of the particle density along the excited states into two fractions both following Bose-Einstein distribution, albeit with different effective temperatures and chemical potentials. Our results indicate that the temperature of the weakly interacting Bose gas is universally set by the density-dependent chemical potential, revealing a defining property of non-equilibrium BECs. Finally, we demonstrate that the stimulated nature of the cooling process directly governs the emergence of quantum coherence of the condensate and shapes the dissipative properties of the excited states."
  },
  {
    "date": "2026-01-21",
    "title": "Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure",
    "authors": "Christopher Scofield",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15077v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MAS implements a factorized composition of constraint-enforcement operators. Under mild conditions, these dynamics converge to invariant solution sets defined by the intersection of agent constraint sets. Such invariant structures are generally not dynamically accessible to a single agent applying all constraints simultaneously, even when expressive capacity and information are identical. We extend this result from exact constraint enforcement to soft constraints via proximal operators, and apply the formalism to contemporary text-based dialog systems."
  },
  {
    "date": "2026-01-21",
    "title": "A combined dose and microdosimetric modeling framework incorporating volume effects correlates with tissue sparing in proton minibeam radiotherapy",
    "authors": "Giulio Bordieri, Marco Battestini, Gianluca Lattanzi, Francesco Romano, Emanuele Scifoni, Marta Missiaggia, Francesco Giuseppe Cordoni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15073v1",
    "source": "arXiv",
    "abstract": "Proton minibeam (pMB) radiotherapy, delivers highly heterogeneous dose distributions alternating high-dose peaks and low-dose valleys. This aims to widen the therapeutic window by improving normal tissue sparing while maintaining the same or even better tumour control. The performance of pMB strongly depends on the collimator design and physical parameters. To better understand the physical and radiobiological drivers of this enhanced therapeutic window, we perform a detailed microdosimetric characterization of proton minibeams and assess their impact. We characterize radiation quality with microdosimetry through Monte Carlo simulations. Then we extend the Generalized Stochastic Microdosimetric Model to predict the normal tissue complication probability (NTCP) at different depths in water, 1cm, 2cm, and 4cm, for 100MeV proton minibeams realized with varying configurations of collimator. Results are compared with conventional homogeneous field (HF) irradiation after dose normalization to the tumor. The developed model is applied by considering tissues as divided into several functional subunits, connected by a seriality parameter. Microdosimetric characterization of proton minibeam irradiation shows differences between peak and valley regions in shaping lineal energy spectra, especially at low depth, while radiation quality uniforms progressively getting closer to the tumor. NTCP calculations results suggest an increased sparing effect for pMB over conventional HF. A strong dependence is found on the peak-to-valley dose ratio (PVDR), and on the seriality parameter. Predictions indicate substantial sparing from pMB, especially for PVDR > 15, including relatively serial organs with seriality around 0.7. This integrated dose-microdosimetric-biological framework elucidates how spatial fractionation, radiation quality, and organ architecture collectively shape tissue sparing in pMB."
  },
  {
    "date": "2026-01-21",
    "title": "Regularity Priors for the Linear Atomic Cluster Expansion",
    "authors": "James P. Darby, Joe D. Morrow, Albert P. Bartók, Volker L. Deringer, Gábor Csányi, Christoph Ortner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15072v1",
    "source": "arXiv",
    "abstract": "Machine-learned interatomic potentials enable large systems to be simulated for long time scales at near ab-initio accuracy. This accuracy is achieved by fitting extremely flexible model architectures to high quality reference data. In practice, this flexibility can cause unwanted behavior such as jagged predicted potential energy surfaces and generally poor out-of-distribution behavior. We investigate a general strategy for incorporating prior beliefs on the regularity of the target energy into linear ACE models and explore to what extent this approach improves the quality of the fitted models. Our main focus is an over-regularisation that replicates the Gaussian broadening used in SOAP descriptors within the ACE framework."
  },
  {
    "date": "2026-01-21",
    "title": "Weak Electron-Phonon Coupling Is Insufficient to Generate Significant CISS in Two-Terminal Transport",
    "authors": "Vipul Upadhyay, Amikam Levy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15063v1",
    "source": "arXiv",
    "abstract": "A central open question in chiral-induced spin selectivity (CISS) is whether weak electron-phonon coupling in a helical molecular junction can generate a sizable spin polarization in two-terminal transport without invoking additional strong symmetry-breaking ingredients. We address this question by implementing a self-consistent nonequilibrium Green's function (NEGF) calculation for a helical tight-binding model with spin-orbit coupling and electron-phonon interactions. The electron-phonon self-energies are evaluated self-consistently, and the transport signal is extracted using the standard magnetization-reversal protocol with a spin-polarized analyzer lead. We benchmark a fully self-consistent NEGF within the self-consistent Born approximation (SCBA) treatment for both global and local electron-phonon couplings against commonly used approximations, including diagonal self-energy schemes. We quantify how the resulting transport regime and spin polarization depend on phonon frequency, coupling strength, bias, temperature, and system size. In contrast to large polarizations and anomalous size trends reported under approximate treatments, the fully self-consistent calculation yields negligible spin polarization, additionally the electron-phonon coupling mainly renormalizes the spectrum, and transport remains quasi-ballistic across the explored parameter range."
  },
  {
    "date": "2026-01-21",
    "title": "Turning Citation Networks Inside Out: Studying Science Using Content-Based Knowledge Graphs from LLM-Derived Taxonomies",
    "authors": "Seorin Kim, Vincent Holst, Vincent Ginis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15062v1",
    "source": "arXiv",
    "abstract": "Scientific fields are often mapped using citations and metadata, despite knowledge being transmitted primarily through content. We introduce an 'inside-out' approach that reconstructs field structure directly from text by representing each paper as a small set of interpretable knowledge components. Using a large language model to induce domain-specific taxonomies and label papers, each publication is encoded as a triplet of measure, data type, and research-question type. These triplets define a knowledge graph with edges weighted by shared papers. Applied to 617 studies on intergenerational wealth mobility, the graph reveals a stable methodological backbone centered on regression-based mobility measures, alongside substantial temporal variation in component recombination. We further utilize normalized betweenness-to-connectivity ratios to identify components and pairings that act as structural bridges disproportionate to their prevalence. This content-derived, taxonomy-driven mapping complements citation-based approaches by exposing the evolving architecture of methods, data, and questions that define a field."
  },
  {
    "date": "2026-01-21",
    "title": "Game-Theoretic Lens on LLM-based Multi-Agent Systems",
    "authors": "Jianing Hao, Han Ding, Yuanjian Xu, Tianze Sun, Ran Chen, Wanbo Zhang, Guang Zhang, Siguang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15047v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated strong reasoning, planning, and communication abilities, enabling them to operate as autonomous agents in open environments. While single-agent systems remain limited in adaptability and coordination, recent progress has shifted attention toward multi-agent systems (MAS) composed of interacting LLMs that pursue cooperative, competitive, or mixed objectives. This emerging paradigm provides a powerful testbed for studying social dynamics and strategic behaviors among intelligent agents. However, current research remains fragmented and lacks a unifying theoretical foundation. To address this gap, we present a comprehensive survey of LLM-based multi-agent systems through a game-theoretic lens. By organizing existing studies around the four key elements of game theory: players, strategies, payoffs, and information, we establish a systematic framework for understanding, comparing, and guiding future research on the design and analysis of LLM-based MAS."
  },
  {
    "date": "2026-01-21",
    "title": "Federated Transformer-GNN for Privacy-Preserving Brain Tumor Localization with Modality-Level Explainability",
    "authors": "Andrea Protani, Riccardo Taiello, Marc Molina Van Den Bosch, Luigi Serio",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15042v1",
    "source": "arXiv",
    "abstract": "Deep learning models for brain tumor analysis require large and diverse datasets that are often siloed across healthcare institutions due to privacy regulations. We present a federated learning framework for brain tumor localization that enables multi-institutional collaboration without sharing sensitive patient data. Our method extends a hybrid Transformer-Graph Neural Network architecture derived from prior decoder-free supervoxel GNNs and is deployed within CAFEIN\\textsuperscript{\\textregistered}, CERN's federated learning platform designed for healthcare environments. We provide an explainability analysis through Transformer attention mechanisms that reveals which MRI modalities drive the model predictions. Experiments on the BraTS dataset demonstrate a key finding: while isolated training on individual client data triggers early stopping well before reaching full training capacity, federated learning enables continued model improvement by leveraging distributed data, ultimately matching centralized performance. This result provides strong justification for federated learning when dealing with complex tasks and high-dimensional input data, as aggregating knowledge from multiple institutions significantly benefits the learning process. Our explainability analysis, validated through rigorous statistical testing on the full test set (paired t-tests with Bonferroni correction), reveals that deeper network layers significantly increase attention to T2 and FLAIR modalities ($p<0.001$, Cohen's $d$=1.50), aligning with clinical practice."
  },
  {
    "date": "2026-01-21",
    "title": "Integrating the probe and singular sources methods: IV. IPS function for the Schrödinger equation",
    "authors": "Masaru Ikehata",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14779v1",
    "source": "arXiv",
    "abstract": "The integrated theory of the probe and singular sources methods (IPS) is developed for an inverse obstacle problem governed by the stationary Schrödinger equation in a bounded domain. The unknown obstacles are penetrable, and their surface is modeled by a part of the support of the potential in the governing equation. The main results concern an analytical detection method for these obstacles from the Dirichlet-to-Neumann map. They consist of three parts: a singular sources method via the probe method using a solution with higher-order singularity for the governing equation of the background medium; the discovery of an IPS function whose two ways of decomposition give us the indicator functions for both the probe and singular sources methods; a completely integrated version of both methods, which means their indicator functions coincide. Furthermore, a result on Side B of IPS is also given, concerning the blowing-up property of a sequence calculated from the Dirichlet-to-Neumann map."
  },
  {
    "date": "2026-01-21",
    "title": "FunCineForge: A Unified Dataset Toolkit and Model for Zero-Shot Movie Dubbing in Diverse Cinematic Scenes",
    "authors": "Jiaxuan Liu, Yang Xiang, Han Zhao, Xiangang Li, Zhenhua Ling",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14777v1",
    "source": "arXiv",
    "abstract": "Movie dubbing is the task of synthesizing speech from scripts conditioned on video scenes, requiring accurate lip sync, faithful timbre transfer, and proper modeling of character identity and emotion. However, existing methods face two major limitations: (1) high-quality multimodal dubbing datasets are limited in scale, suffer from high word error rates, contain sparse annotations, rely on costly manual labeling, and are restricted to monologue scenes, all of which hinder effective model training; (2) existing dubbing models rely solely on the lip region to learn audio-visual alignment, which limits their applicability to complex live-action cinematic scenes, and exhibit suboptimal performance in lip sync, speech quality, and emotional expressiveness. To address these issues, we propose FunCineForge, which comprises an end-to-end production pipeline for large-scale dubbing datasets and an MLLM-based dubbing model designed for diverse cinematic scenes. Using the pipeline, we construct the first Chinese television dubbing dataset with rich annotations, and demonstrate the high quality of these data. Experiments across monologue, narration, dialogue, and multi-speaker scenes show that our dubbing model consistently outperforms SOTA methods in audio quality, lip sync, timbre transfer, and instruction following. Code and demos are available at https://anonymous.4open.science/w/FunCineForge."
  },
  {
    "date": "2026-01-21",
    "title": "From Quantum Amplitudes to Spacetime Geometry: a Multipolar Framework for Black Hole Signatures",
    "authors": "Claudio Gambino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14775v1",
    "source": "arXiv",
    "abstract": "This thesis develops a unified framework that reconstructs the full classical content of General Relativity from the classical limit of quantum scattering amplitudes. By interpreting the analytic structure of amplitudes as the field-theoretic imprint of spacetime geometry, the work establishes a direct correspondence between quantum processes and classical gravitational observables such as metrics, deflection angles, and multipole moments. Starting from the effective-field-theory description of gravity, the thesis shows that loop amplitudes encode not only quantum corrections but also the nonlinear classical self-interaction of the gravitational field, enabling the systematic derivation of the post-Minkowskian expansion of gravitational quantities by rewriting the Einstein equations in terms of graviton scattering processes. Building upon this foundation, the framework is applied to rotating and charged sources in arbitrary spacetime dimensions. A momentum-space formulation of the energy-momentum tensor is then developed, introducing gravitational form factors and source multipoles that link, for the first time, the internal matter distribution to the external multipolar field in a completely relativistic framework. Furthermore, the thesis completes the transition from the microscopic amplitude picture to the macroscopic description of gravitational sources by engineering a multipole-based framework for black hole mimickers, then applied to build horizon-less compact objects mimicking the multipolar structure of Kerr black holes. Finally, exploiting the Kerr-Schild gauge, the Fourier transforms of rotating black hole metrics are computed in closed form, bridging perturbative and non-perturbative descriptions of gravity, and allowing to probe the multipolar structure of higher-dimensional solutions employing scattering amplitudes."
  },
  {
    "date": "2026-01-21",
    "title": "Does medical specialization of VLMs enhance discriminative power?: A comprehensive investigation through feature distribution analysis",
    "authors": "Keita Takeda, Tomoya Sakai",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14774v1",
    "source": "arXiv",
    "abstract": "This study investigates the feature representations produced by publicly available open source medical vision-language models (VLMs). While medical VLMs are expected to capture diagnostically relevant features, their learned representations remain underexplored, and standard evaluations like classification accuracy do not fully reveal if they acquire truly discriminative, lesion-specific features. Understanding these representations is crucial for revealing medical image structures and improving downstream tasks in medical image analysis. This study aims to investigate the feature distributions learned by medical VLMs and evaluate the impact of medical specialization. We analyze the feature distribution of multiple image modalities extracted by some representative medical VLMs across lesion classification datasets on multiple modalities. These distributions were compared them with non-medical VLMs to assess the domain-specific medical training. Our experiments showed that medical VLMs can extract discriminative features that are effective for medical classification tasks. Moreover, it was found that non-medical VLMs with recent improvement with contextual enrichment such as LLM2CLIP produce more refined feature representations. Our results imply that enhancing text encoder is more crucial than training intensively on medical images when developing medical VLMs. Notably, non-medical models are particularly vulnerable to biases introduced by overlaied text strings on images. These findings underscore the need for careful consideration on model selection according to downstream tasks besides potential risks in inference due to background biases such as textual information in images."
  },
  {
    "date": "2026-01-21",
    "title": "Using Multi-Instance Learning to Identify Unique Polyps in Colon Capsule Endoscopy Images",
    "authors": "Puneet Sharma, Kristian Dalsbø Hindberg, Eibe Frank, Benedicte Schelde-Olesen, Ulrik Deding",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14771v1",
    "source": "arXiv",
    "abstract": "Identifying unique polyps in colon capsule endoscopy (CCE) images is a critical yet challenging task for medical personnel due to the large volume of images, the cognitive load it creates for clinicians, and the ambiguity in labeling specific frames. This paper formulates this problem as a multi-instance learning (MIL) task, where a query polyp image is compared with a target bag of images to determine uniqueness. We employ a multi-instance verification (MIV) framework that incorporates attention mechanisms, such as variance-excited multi-head attention (VEMA) and distance-based attention (DBA), to enhance the model's ability to extract meaningful representations. Additionally, we investigate the impact of self-supervised learning using SimCLR to generate robust embeddings. Experimental results on a dataset of 1912 polyps from 754 patients demonstrate that attention mechanisms significantly improve performance, with DBA L1 achieving the highest test accuracy of 86.26\\% and a test AUC of 0.928 using a ConvNeXt backbone with SimCLR pretraining. This study underscores the potential of MIL and self-supervised learning in advancing automated analysis of Colon Capsule Endoscopy images, with implications for broader medical imaging applications."
  },
  {
    "date": "2026-01-21",
    "title": "Test-Time Adaptation For Speech Enhancement Via Mask Polarization",
    "authors": "Tobias Raichle, Erfan Amini, Bin Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14770v1",
    "source": "arXiv",
    "abstract": "Adapting speech enhancement (SE) models to unseen environments is crucial for practical deployments, yet test-time adaptation (TTA) for SE remains largely under-explored due to a lack of understanding of how SE models degrade under domain shifts. We observe that mask-based SE models lose confidence under domain shifts, with predicted masks becoming flattened and losing decisive speech preservation and noise suppression. Based on this insight, we propose mask polarization (MPol), a lightweight TTA method that restores mask bimodality through distribution comparison using the Wasserstein distance. MPol requires no additional parameters beyond the trained model, making it suitable for resource-constrained edge deployments. Experimental results across diverse domain shifts and architectures demonstrate that MPol achieves very consistent gains that are competitive with significantly more complex approaches."
  },
  {
    "date": "2026-01-21",
    "title": "PAColorHolo: A Perceptually-Aware Color Management Framework for Holographic Displays",
    "authors": "Chun Chen, Minseok Chae, Seung-Woo Nam, Myeong-Ho Choi, Minseong Kim, Eunbi Lee, Yoonchan Jeong, Jae-Hyeung Park",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14766v1",
    "source": "arXiv",
    "abstract": "Holographic displays offer significant potential for augmented and virtual reality applications by reconstructing wavefronts that enable continuous depth cues and natural parallax without vergence-accommodation conflict. However, despite advances in pixel-level image quality, current systems struggle to achieve perceptually accurate color reproduction--an essential component of visual realism. These challenges arise from complex system-level distortions caused by coherent laser illumination, spatial light modulator imperfections, chromatic aberrations, and camera-induced color biases. In this work, we propose a perceptually-aware color management framework for holographic displays that jointly addresses input-output color inconsistencies through color space transformation, adaptive illumination control, and neural network-based perceptual modeling of the camera's color response. We validate the effectiveness of our approach through numerical simulations, optical experiments, and a controlled user study. The results demonstrate substantial improvements in perceptual color fidelity, laying the groundwork for perceptually driven holographic rendering in future systems."
  },
  {
    "date": "2026-01-21",
    "title": "Render-of-Thought: Rendering Textual Chain-of-Thought as Images for Visual Latent Reasoning",
    "authors": "Yifan Wang, Shiyu Li, Peiming Li, Xiaochen Yang, Yang Tang, Zheng Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14750v1",
    "source": "arXiv",
    "abstract": "Chain-of-Thought (CoT) prompting has achieved remarkable success in unlocking the reasoning capabilities of Large Language Models (LLMs). Although CoT prompting enhances reasoning, its verbosity imposes substantial computational overhead. Recent works often focus exclusively on outcome alignment and lack supervision on the intermediate reasoning process. These deficiencies obscure the analyzability of the latent reasoning chain. To address these challenges, we introduce Render-of-Thought (RoT), the first framework to reify the reasoning chain by rendering textual steps into images, making the latent rationale explicit and traceable. Specifically, we leverage the vision encoders of existing Vision Language Models (VLMs) as semantic anchors to align the vision embeddings with the textual space. This design ensures plug-and-play implementation without incurring additional pre-training overhead. Extensive experiments on mathematical and logical reasoning benchmarks demonstrate that our method achieves 3-4x token compression and substantial inference acceleration compared to explicit CoT. Furthermore, it maintains competitive performance against other methods, validating the feasibility of this paradigm. Our code is available at https://github.com/TencentBAC/RoT"
  },
  {
    "date": "2026-01-21",
    "title": "Triggers for plasma detachment bifurcation in the edge divertor region of tokamaks",
    "authors": "Menglong Zhao, Thomas Rognlien, Ben Zhu, Filippo Scotti, Xinxing Ma, Adam McLean",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14749v1",
    "source": "arXiv",
    "abstract": "We report the discovery of the trigger for detachment bifurcation phenomenon in tokamak divertors, revealed through steady-state and time-dependent UEDGE simulations: The observed electron temperature cliff at the outer target in DIII-D H-mode plasmas with ion $B\\times \\nabla B$ drift driven into the active divertor results from a bifurcation-induced $T_e$ drop above the X-point accompanied by reversal of the $E\\times B$ flow pattern in the private flux region. Time-dependent simulations reveal a two-phase transition mechanism: the high-field-side radiation front first extends across the last closed flux surface and stabilizes above the X-point, causing local $T_e$ to drop from $\\sim 70\\,\\mathrm{eV}$ to $\\sim 10\\,\\mathrm{eV}$ and inducing $E\\times B$ flow reversal in a thin layer below the X-point, which lasts $< 0.5\\,\\mathrm{ms}$; Flow reversal below the X-point subsequently triggers the sharp drop in outer target temperature on a timescale of $1-2\\,\\mathrm{ms}$, establishing deep detachment a few ms thereafter. A bifurcation transition occurs when the high-field-side radiation front crosses the separatrix while the outer divertor remains attached, with the $T_e$ cliff manifesting distinctly when the outer target $T_e \\gtrsim 10\\,\\mathrm{eV}$ prior to the bifurcation. These results demonstrate that the bifurcation is linked to in-out divertor asymmetry and asymmetric radiation front evolution."
  },
  {
    "date": "2026-01-21",
    "title": "RefProtoFL: Communication-Efficient Federated Learning via External-Referenced Prototype Alignment",
    "authors": "Hongyue Wu, Hangyu Li, Guodong Fan, Haoran Zhu, Shizhan Chen, Zhiyong Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14746v1",
    "source": "arXiv",
    "abstract": "Federated learning (FL) enables collaborative model training without sharing raw data in edge environments, but is constrained by limited communication bandwidth and heterogeneous client data distributions. Prototype-based FL mitigates this issue by exchanging class-wise feature prototypes instead of full model parameters; however, existing methods still suffer from suboptimal generalization under severe communication constraints. In this paper, we propose RefProtoFL, a communication-efficient FL framework that integrates External-Referenced Prototype Alignment (ERPA) for representation consistency with Adaptive Probabilistic Update Dropping (APUD) for communication efficiency. Specifically, we decompose the model into a private backbone and a lightweight shared adapter, and restrict federated communication to the adapter parameters only. To further reduce uplink cost, APUD performs magnitude-aware Top-K sparsification, transmitting only the most significant adapter updates for server-side aggregation. To address representation inconsistency across heterogeneous clients, ERPA leverages a small server-held public dataset to construct external reference prototypes that serve as shared semantic anchors. For classes covered by public data, clients directly align local representations to public-induced prototypes, whereas for uncovered classes, alignment relies on server-aggregated global reference prototypes via weighted averaging. Extensive experiments on standard benchmarks demonstrate that RefProtoFL attains higher classification accuracy than state-of-the-art prototype-based FL baselines."
  },
  {
    "date": "2026-01-21",
    "title": "Safeguarding Facial Identity against Diffusion-based Face Swapping via Cascading Pathway Disruption",
    "authors": "Liqin Wang, Qianyue Hu, Wei Lu, Xiangyang Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14738v1",
    "source": "arXiv",
    "abstract": "The rapid evolution of diffusion models has democratized face swapping but also raises concerns about privacy and identity security. Existing proactive defenses, often adapted from image editing attacks, prove ineffective in this context. We attribute this failure to an oversight of the structural resilience and the unique static conditional guidance mechanism inherent in face swapping systems. To address this, we propose VoidFace, a systemic defense method that views face swapping as a coupled identity pathway. By injecting perturbations at critical bottlenecks, VoidFace induces cascading disruption throughout the pipeline. Specifically, we first introduce localization disruption and identity erasure to degrade physical regression and semantic embeddings, thereby impairing the accurate modeling of the source face. We then intervene in the generative domain by decoupling attention mechanisms to sever identity injection, and corrupting intermediate diffusion features to prevent the reconstruction of source identity. To ensure visual imperceptibility, we perform adversarial search in the latent manifold, guided by a perceptual adaptive strategy to balance attack potency with image quality. Extensive experiments show that VoidFace outperforms existing defenses across various diffusion-based swapping models, while producing adversarial faces with superior visual quality."
  },
  {
    "date": "2026-01-21",
    "title": "Existence and Stability of 3-Cycles in Quadratic Maps",
    "authors": "Dan Comănescu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14736v1",
    "source": "arXiv",
    "abstract": "For a discrete dynamical system on $\\R$ generated by a quadratic function, we show, using elementary computations, that the existence, number, and stability of 3-cycles are determined by a single parameter depending on the coefficients of the function."
  },
  {
    "date": "2026-01-21",
    "title": "On Distributed Quantum Computing with Distributed Fan-Out Operations",
    "authors": "Seng W. Loke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14734v1",
    "source": "arXiv",
    "abstract": "We compare different circuits implementing distributed versions of quantum computations, using entangled pairs only, and using distributed fan-out operations (using GHZ states). We highlight the advantages of using distributed fan-out operations in terms of reductions in circuit depth and (possibly) entanglement resources. We note that distributed fan-out operations (or notably, distributed GHZ states) could be a ``primitive'' building block for distributed quantum operations in the same way as entangled pairs are, if distributed GHZ states could be realized efficiently."
  },
  {
    "date": "2026-01-21",
    "title": "ARFT-Transformer: Modeling Metric Dependencies for Cross-Project Aging-Related Bug Prediction",
    "authors": "Shuning Ge, Fangyun Qin, Xiaohui Wan, Yang Liu, Qian Dai, Zheng Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14731v1",
    "source": "arXiv",
    "abstract": "Software systems that run for long periods often suffer from software aging, which is typically caused by Aging-Related Bugs (ARBs). To mitigate the risk of ARBs early in the development phase, ARB prediction has been introduced into software aging research. However, due to the difficulty of collecting ARBs, within-project ARB prediction faces the challenge of data scarcity, leading to the proposal of cross-project ARB prediction. This task faces two major challenges: 1) domain adaptation issue caused by distribution difference between source and target projects; and 2) severe class imbalance between ARB-prone and ARB-free samples. Although various methods have been proposed for cross-project ARB prediction, existing approaches treat the input metrics independently and often neglect the rich inter-metric dependencies, which can lead to overlapping information and misjudgment of metric importance, potentially affecting the model's performance. Moreover, they typically use cross-entropy as the loss function during training, which cannot distinguish the difficulty of sample classification. To overcome these limitations, we propose ARFT-Transformer, a transformer-based cross-project ARB prediction framework that introduces a metric-level multi-head attention mechanism to capture metric interactions and incorporates Focal Loss function to effectively handle class imbalance. Experiments conducted on three large-scale open-source projects demonstrate that ARFT-Transformer on average outperforms state-of-the-art cross-project ARB prediction methods in both single-source and multi-source cases, achieving up to a 29.54% and 19.92% improvement in Balance metric."
  },
  {
    "date": "2026-01-21",
    "title": "Differential Privacy on Affine Manifolds: Geometrically Confined Privacy in Linear Dynamical Systems",
    "authors": "Zihao Ren, Lei Wang, Deming Yuan, Guodong Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14725v1",
    "source": "arXiv",
    "abstract": "In this paper, we present a comprehensive framework for differential privacy over affine manifolds and validate its usefulness in the contexts of differentially private cloud-based control and average consensus. We consider differential privacy mechanisms for linear queries when the input data are constrained to lie on affine manifolds, a structural property that is assumed to be available as prior knowledge to adversaries. In this setting, the definition of neighborhood adjacency must be formulated with respect to the intrinsic geometry of the manifolds. We demonstrate that such affine-manifold constraints can fundamentally alter the attainable privacy levels relative to the unconstrained case. In particular, we derive necessary and sufficient conditions under which differential privacy can be realized via structured noise injection mechanisms, wherein correlated Gaussian or Laplace noise distributions, rather than i.i.d. perturbations, are calibrated to the dataset. Based on these characterizations, we develop explicit noise calibration procedures that guarantee the tight realization of any prescribed privacy budget with a matching noise magnitude. Finally, we show that the proposed framework admits direct applications to linear dynamical systems ranging from differentially private cloud-based control to privacy-preserving average consensus, all of which naturally involve affine-manifold constraints. The established theoretical results are illustrated through numerical examples."
  },
  {
    "date": "2026-01-21",
    "title": "The Effect of Planar Harmonic Mappings on the Lebesgue Measure of Sets",
    "authors": "Hunduma Legesse Geleta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14717v1",
    "source": "arXiv",
    "abstract": "We investigate the effect of planar univalent harmonic mappings on the Lebesgue measure of measurable sets in the complex plane. Motivated by Problem 3.25 of Koh and Kovalev (HQM2010), we establish sharp quantitative area distortion inequalities for disks and for arbitrary measurable sets under sense-preserving harmonic self-maps of the unit disk. Using the area formula and the canonical decomposition of harmonic mappings, we derive bounds in terms of the Jacobian and the dilatation, and we identify rigidity phenomena characterizing equality. In particular, we prove global area contraction for disks, star-shaped sets, and sufficiently small sets, and we refine the results using Hardy space methods to obtain sharp bounds with equality only for conformal automorphisms. Extremal affine and non-affine examples illustrate the sharpness of our estimates. Our results provide a complete, rigorous, and strengthened solution to Problem 3.25 and highlight several natural conjectures on global area contraction, extremal distortion, and rigidity for harmonic mappings."
  },
  {
    "date": "2026-01-21",
    "title": "Brill--Noether Generality of Curves and K3 Surfaces",
    "authors": "Irina Shatova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14709v1",
    "source": "arXiv",
    "abstract": "Lazarsfeld proved Brill--Noether generality of any smooth curve in the linear system $|H|$ where $(X,H)$ is a polarized K3 surface with $\\mathrm{Pic}(X) = \\mathbb{Z}\\cdot H$. Mukai introduced the notion of Brill--Noether generality for quasi-polarized K3 surfaces. We prove Brill--Noether generality of any smooth curve in the linear system $|H|$ where $(X,H)$ is a Brill--Noether general quasi-polarized K3 surface."
  },
  {
    "date": "2026-01-21",
    "title": "Talk Me Through It: Developing Effective Systems for Chart Authoring",
    "authors": "Nazar Ponochevnyi, Young-Ho Kim, Joseph Jay Williams, Anastasia Kuzminykh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14707v1",
    "source": "arXiv",
    "abstract": "Recent chart-authoring systems increasingly focus on natural-language input, enabling users to form a mental image of the chart they wish to create and express this intent using spoken instructions (spoken imagined-chart data). Yet these systems are predominantly trained on typed instructions written while viewing the target chart (typed existing-chart data). While the cognitive processes for describing an existing chart arguably differ from those for creating a new chart, the structural differences in the corresponding prompts remain underexplored. We present empirical findings on the structural differences among spoken imagined-chart instructions, typed imagined-chart instructions, and typed existing-chart instructions for chart creation, showing that imagined-chart prompts contain richer command formats, element specifications, and complex linguistic features, especially in spoken instructions. We then compare the performance of systems trained on spoken imagined-chart data versus typed existing-chart data, finding that the first system outperforms the second one on both voice and text input, highlighting the necessity of targeted training on spoken imagined-chart data. We conclude with design guidelines for chart-authoring systems to improve performance in real-world scenarios."
  },
  {
    "date": "2026-01-21",
    "title": "RegFreeNet: A Registration-Free Network for CBCT-based 3D Dental Implant Planning",
    "authors": "Xinquan Yang, Xuguang Li, Mianjie Zheng, Xuefen Liu, Kun Tang, Kian Ming Lim, He Meng, Jianfeng Ren, Linlin Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14703v1",
    "source": "arXiv",
    "abstract": "As the commercial surgical guide design software usually does not support the export of implant position for pre-implantation data, existing methods have to scan the post-implantation data and map the implant to pre-implantation space to get the label of implant position for training. Such a process is time-consuming and heavily relies on the accuracy of registration algorithm. Moreover, not all hospitals have paired CBCT data, limitting the construction of multi-center dataset. Inspired by the way dentists determine the implant position based on the neighboring tooth texture, we found that even if the implant area is masked, it will not affect the determination of the implant position. Therefore, we propose to mask the implants in the post-implantation data so that any CBCT containing the implants can be used as training data. This paradigm enables us to discard the registration process and makes it possible to construct a large-scale multi-center implant dataset. On this basis, we proposes ImplantFairy, a comprehensive, publicly accessible dental implant dataset with voxel-level 3D annotations of 1622 CBCT data. Furthermore, according to the area variation characteristics of the tooth's spatial structure and the slope information of the implant, we designed a slope-aware implant position prediction network. Specifically, a neighboring distance perception (NDP) module is designed to adaptively extract tooth area variation features, and an implant slope prediction branch assists the network in learning more robust features through additional implant supervision information. Extensive experiments conducted on ImplantFairy and two public dataset demonstrate that the proposed RegFreeNet achieves the state-of-the-art performance."
  },
  {
    "date": "2026-01-21",
    "title": "Triage knowledge distillation for speaker verification",
    "authors": "Ju-ho Kim, Youngmoon Jung, Joon-Young Yang, Jaeyoung Roh, Chang Woo Han, Hoon-Young Cho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14699v1",
    "source": "arXiv",
    "abstract": "Deploying speaker verification on resource-constrained devices remains challenging due to the computational cost of high-capacity models; knowledge distillation (KD) offers a remedy. Classical KD entangles target confidence with non-target structure in a Kullback-Leibler term, limiting the transfer of relational information. Decoupled KD separates these signals into target and non-target terms, yet treats non-targets uniformly and remains vulnerable to the long tail of low-probability classes in large-class settings. We introduce Triage KD (TRKD), a distillation scheme that operationalizes assess-prioritize-focus. TRKD introduces a cumulative-probability cutoff $τ$ to assess per-example difficulty and partition the teacher posterior into three groups: the target class, a high-probability non-target confusion-set, and a background-set. To prioritize informative signals, TRKD distills the confusion-set conditional distribution and discards the background. Concurrently, it transfers a three-mass (target/confusion/background) that capture sample difficulty and inter-class confusion. Finally, TRKD focuses learning via a curriculum on $τ$: training begins with a larger $τ$ to convey broad non-target context, then $τ$ is progressively decreased to shrink the confusion-set, concentrating supervision on the most confusable classes. In extensive experiments on VoxCeleb1 with both homogeneous and heterogeneous teacher-student pairs, TRKD was consistently superior to recent KD variants and attained the lowest EER across all protocols."
  },
  {
    "date": "2026-01-21",
    "title": "Re-understanding Graph Unlearning through Memorization",
    "authors": "Pengfei Ding, Yan Wang, Guanfeng Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14694v1",
    "source": "arXiv",
    "abstract": "Graph unlearning (GU), which removes nodes, edges, or features from trained graph neural networks (GNNs), is crucial in Web applications where graph data may contain sensitive, mislabeled, or malicious information. However, existing GU methods lack a clear understanding of the key factors that determine unlearning effectiveness, leading to three fundamental limitations: (1) impractical and inaccurate GU difficulty assessment due to test-access requirements and invalid assumptions, (2) ineffectiveness on hard-to-unlearn tasks, and (3) misaligned evaluation protocols that overemphasize easy tasks and fail to capture true forgetting capability. To address these issues, we establish GNN memorization as a new perspective for understanding graph unlearning and propose MGU, a Memorization-guided Graph Unlearning framework. MGU achieves three key advances: it provides accurate and practical difficulty assessment across different GU tasks, develops an adaptive strategy that dynamically adjusts unlearning objectives based on difficulty levels, and establishes a comprehensive evaluation protocol that aligns with practical requirements. Extensive experiments on ten real-world graphs demonstrate that MGU consistently outperforms state-of-the-art baselines in forgetting quality, computational efficiency, and utility preservation."
  },
  {
    "date": "2026-01-21",
    "title": "Gaming the Judge: Unfaithful Chain-of-Thought Can Undermine Agent Evaluation",
    "authors": "Muhammad Khalifa, Lajanugen Logeswaran, Jaekyeom Kim, Sungryull Sohn, Yunxiang Zhang, Moontae Lee, Hao Peng, Lu Wang, Honglak Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14691v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly used as judges to evaluate agent performance, particularly in non-verifiable settings where judgments rely on agent trajectories including chain-of-thought (CoT) reasoning. This paradigm implicitly assumes that the agent's CoT faithfully reflects both its internal reasoning and the underlying environment state. We show this assumption is brittle: LLM judges are highly susceptible to manipulation of agent reasoning traces. By systematically rewriting agent CoTs while holding actions and observations fixed, we demonstrate that manipulated reasoning alone can inflate false positive rates of state-of-the-art VLM judges by up to 90% across 800 trajectories spanning diverse web tasks. We study manipulation strategies spanning style-based approaches that alter only the presentation of reasoning and content-based approaches that fabricate signals of task progress, and find that content-based manipulations are consistently more effective. We evaluate prompting-based techniques and scaling judge-time compute, which reduce but do not fully eliminate susceptibility to manipulation. Our findings reveal a fundamental vulnerability in LLM-based evaluation and highlight the need for judging mechanisms that verify reasoning claims against observable evidence."
  },
  {
    "date": "2026-01-21",
    "title": "Ramping-aware Enhanced Flexibility Aggregation of Distributed Generation with Energy Storage in Power Distribution Networks",
    "authors": "Hyeongon Park, Daniel K. Molzahn, Rahul K. Gupta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14689v1",
    "source": "arXiv",
    "abstract": "Power distribution networks are increasingly hosting controllable and flexible distributed energy resources (DERs) that, when aggregated, can provide ancillary support to transmission systems. However, existing aggregation schemes often ignore the ramping constraints of these DERs, which can render them impractical in real deployments. This work proposes a ramping-aware flexibility aggregation scheme, computed at the transmission-distribution boundary, that explicitly accounts for DER ramp limits and yields flexibility envelopes that are provably disaggregable. To further enhance the attainable flexibility region, we introduce a novel pre-ramping strategy, which proactively adjusts resource operating points to enlarge the aggregated flexibility envelope while preserving both network feasibility and disaggregation guarantees. The proposed method demonstrates a 5.2% to 19.2% improvement in flexibility relative to the baseline model, depending on system conditions. We validate the scheme on an IEEE-33 bus distribution system and provide formal proofs showing that both aggregation strategies are disaggregable for all feasible trajectories within the aggregate flexibility envelope."
  },
  {
    "date": "2026-01-21",
    "title": "FARE: Fast-Slow Agentic Robotic Exploration",
    "authors": "Shuhao Liao, Xuxin Lv, Jeric Lew, Shizhe Zhang, Jingsong Liang, Peizhuo Li, Yuhong Cao, Wenjun Wu, Guillaume Sartoretti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14681v1",
    "source": "arXiv",
    "abstract": "This work advances autonomous robot exploration by integrating agent-level semantic reasoning with fast local control. We introduce FARE, a hierarchical autonomous exploration framework that integrates a large language model (LLM) for global reasoning with a reinforcement learning (RL) policy for local decision making. FARE follows a fast-slow thinking paradigm. The slow-thinking LLM module interprets a concise textual description of the unknown environment and synthesizes an agent-level exploration strategy, which is then grounded into a sequence of global waypoints through a topological graph. To further improve reasoning efficiency, this module employs a modularity-based pruning mechanism that reduces redundant graph structures. The fast-thinking RL module executes exploration by reacting to local observations while being guided by the LLM-generated global waypoints. The RL policy is additionally shaped by a reward term that encourages adherence to the global waypoints, enabling coherent and robust closed-loop behavior. This architecture decouples semantic reasoning from geometric decision, allowing each module to operate in its appropriate temporal and spatial scale. In challenging simulated environments, our results show that FARE achieves substantial improvements in exploration efficiency over state-of-the-art baselines. We further deploy FARE on hardware and validate it in complex, large scale $200m\\times130m$ building environment."
  },
  {
    "date": "2026-01-21",
    "title": "CSST Strong Lensing Preparation: Cosmological constraints from double-source-plane strong lensing systems in era of CSST",
    "authors": "Bei-Chen Wu, Xiaoyue Cao, Nan Li, Yan Gong, Shenzhe Cui, Di Wu, Tong Zhao, Junhui Yan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14675v1",
    "source": "arXiv",
    "abstract": "Double source plane strong lensing (DSPL) systems offer a robust, independent probe of cosmological parameters. The Chinese Space Station Telescope (CSST) is expected to discover hundreds of DSPLs, yet the survey modes and system configurations that best enable cosmological inference remain uncertain. To investigate the impact of varying signal-to-noise ratios (SNR) and Einstein radius ratios of DSPLs (denoted as $β^{-1}$ parameters) on cosmographic inference under different CSST survey modes (Wide Field (WF), Deep Field (DF), and Ultra-Deep Field (UDF)), we simulate and model mock lenses with Singular Isothermal Ellipsoid (SIE) mass profiles and Sérsic sources whose image properties are tailored to CSST specifications. Assuming a flat $w$CDM universe with fiducial values $Ω_{\\rm m} = 0.30966$ and $w = -1$, and uniform priors of $Ω_{\\rm m} \\in [0, 1]$ and $w \\in [-2, -1/3$), we find that the constraining power on cosmological parameters for a given DSPL system increases significantly with survey depth. For a representative DSPL system with two prominent arcs and a moderate $β^{-1}=1.17$, the constraints on ($w, Ω_{\\rm m}$) improve from ($-1.28_{-1.00}^{+0.64}, 0.50_{-0.32}^{+0.28}$) in the WF to ($-1.59_{-0.32}^{+0.63}, 0.42_{-0.06}^{+0.15}$) in the UDF. Furthermore, we find that systems with smaller $β$ values yield tighter cosmographic constraints. We conclude that DSPL systems identified in UDF observations, particularly those with small $β$, are the most promising candidates for early-stage cosmological studies with CSST."
  },
  {
    "date": "2026-01-21",
    "title": "LaVR: Scene Latent Conditioned Generative Video Trajectory Re-Rendering using Large 4D Reconstruction Models",
    "authors": "Mingyang Xie, Numair Khan, Tianfu Wang, Naina Dhingra, Seonghyeon Nam, Haitao Yang, Zhuo Hui, Christopher Metzler, Andrea Vedaldi, Hamed Pirsiavash, Lei Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14674v1",
    "source": "arXiv",
    "abstract": "Given a monocular video, the goal of video re-rendering is to generate views of the scene from a novel camera trajectory. Existing methods face two distinct challenges. Geometrically unconditioned models lack spatial awareness, leading to drift and deformation under viewpoint changes. On the other hand, geometrically-conditioned models depend on estimated depth and explicit reconstruction, making them susceptible to depth inaccuracies and calibration errors. We propose to address these challenges by using the implicit geometric knowledge embedded in the latent space of a large 4D reconstruction model to condition the video generation process. These latents capture scene structure in a continuous space without explicit reconstruction. Therefore, they provide a flexible representation that allows the pretrained diffusion prior to regularize errors more effectively. By jointly conditioning on these latents and source camera poses, we demonstrate that our model achieves state-of-the-art results on the video re-rendering task. Project webpage is https://lavr-4d-scene-rerender.github.io/"
  },
  {
    "date": "2026-01-21",
    "title": "On zeta elements and functional equations for Tate motives over totally real fields",
    "authors": "Mahiro Atsuta",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14668v1",
    "source": "arXiv",
    "abstract": "In this paper, we study Iwasawa theory for Tate motives over totally real fields. More precisely, we construct a zeta element that interpolates the values of $L$-functions at positive integers over totally real fields under a certain unramified condition at $p$. As an application of this, we construct a canonical element in the exterior power bidual of the Galois cohomology group that is also related to the values of $L$-functions at positive integers."
  },
  {
    "date": "2026-01-21",
    "title": "A Two-Stage Risk-Averse DRO-MILP Methodological Framework for Managing AI/Data Center Demand Shocks",
    "authors": "Sharaf K. Magableh, Caisheng Wang, Oraib Dawaghreh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14665v1",
    "source": "arXiv",
    "abstract": "The rapid growth of artificial intelligence (AI)-driven data centers is reshaping electricity demand patterns. This is achieved by introducing fast, multi-gigawatt load ramps that challenge the stability and resilience of modern power systems. Traditional resilience frameworks focus mainly on physical outages and largely overlook these emerging digital-era disturbances. This paper proposes a unified two-stage, risk-aware distributionally robust optimization (DRO)-MILP framework that coordinates the pre-allocation and post-event dispatch of Flexible Capacity Modules (FCMs), including BESS, fast-ramping generation, demand response, and potential long-duration storage. Stage-I optimally positions FCMs using DRO with CVaR to hedge against uncertain AI load surges. Stage-II models real-time stabilization following stochastic demand-shock scenarios, minimizing imbalance, unserved energy, and restoration penalties. The framework is designed to be applied on IEEE 33-bus system or expanded for scalability to larger IEEE test feeders capable of representing AI-scale loads. This contributes a scalable planning tool for resilient, AI-integrated distribution grids."
  },
  {
    "date": "2026-01-21",
    "title": "The role of angular momentum in general relativity: heuristic and covariant interpretations",
    "authors": "Erick Pasten, Claudia Alvarez, Norman Cruz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14664v1",
    "source": "arXiv",
    "abstract": "We examine the role of angular momentum in general relativity from both heuristic and fully covariant perspectives, with the aim of clarifying conceptual ambiguities that arise when Newtonian intuition is extrapolated into the relativistic regime. Focusing on free--fall dynamics in the Schwarzschild and Kerr spacetimes in the test--particle limit, we employ an effective--potential heuristic approach to isolate the roles of the specific energy $E$, specific angular momentum $L$, and black--hole spin $a$. Within this framework, we identify well--defined regions of parameter space in which the Kerr spacetime leads to stronger or weaker local radial infall than the Schwarzschild case at the same radius. By analysing the kinematics of infalling geodesic congruences, we show how these local regimes combine along complete trajectories to either enhance or reduce gravitational focusing. We then interpret these results within a covariant 1+3 description of general relativity, in terms of the expansion, shear and Raychaudhuri evolution of timelike congruences. We demonstrate that black--hole rotation systematically modifies the shear of infalling irrotational flows, even when the magnitude of the local expansion is reduced, and that this shear modulation governs the overall rate of focusing. Our work complements previous studies of relativistic infall by providing a unified energetic and geometric interpretation of how angular momentum and rotation can strengthen or weaken gravitational collapse relative to the non--rotating case."
  },
  {
    "date": "2026-01-21",
    "title": "Query-Efficient Agentic Graph Extraction Attacks on GraphRAG Systems",
    "authors": "Shuhua Yang, Jiahao Zhang, Yilong Wang, Dongwon Lee, Suhang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14662v1",
    "source": "arXiv",
    "abstract": "Graph-based retrieval-augmented generation (GraphRAG) systems construct knowledge graphs over document collections to support multi-hop reasoning. While prior work shows that GraphRAG responses may leak retrieved subgraphs, the feasibility of query-efficient reconstruction of the hidden graph structure remains unexplored under realistic query budgets. We study a budget-constrained black-box setting where an adversary adaptively queries the system to steal its latent entity-relation graph. We propose AGEA (Agentic Graph Extraction Attack), a framework that leverages a novelty-guided exploration-exploitation strategy, external graph memory modules, and a two-stage graph extraction pipeline combining lightweight discovery with LLM-based filtering. We evaluate AGEA on medical, agriculture, and literary datasets across Microsoft-GraphRAG and LightRAG systems. Under identical query budgets, AGEA significantly outperforms prior attack baselines, recovering up to 90% of entities and relationships while maintaining high precision. These results demonstrate that modern GraphRAG systems are highly vulnerable to structured, agentic extraction attacks, even under strict query limits."
  },
  {
    "date": "2026-01-21",
    "title": "Limit theorems for a supercritical multi-type branching process with immigration in a random environment",
    "authors": "Jiangrui Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14655v1",
    "source": "arXiv",
    "abstract": "Let $\\{Z_n^i = (Z_n^i(r))_{1 \\le r \\le d}: n \\ge 0\\}$ be a supercritical $d$-type branching process in an i.i.d. environment $ξ= (ξ_0, ξ_1, \\dots)$, starting from a single particle of type $i$. The offspring distribution at generation $n$ depends on the environment $ξ_n$, and we denote by $M_n = (M_n(i,j))_{1 \\le i,j \\le d}$ the corresponding (random) mean matrix. Recently, Grama et al. (Ann. Appl. Probab. \\textbf{33}(2023) 1213-1251) extended the famous Kesten--Stigum theorem to the random environment case with $d>1$. They improved upon previous work by innovatively constructing a new normalized population process $(\\tilde{W}^i_n)$. Under several simple assumptions, they proved that $\\tilde{W}^i_n$ converges almost surely to a limit $\\tilde{W}^i$, and that $\\tilde{W}^i$ is non-degenerate if and only if a $\\mbb{E}X\\log^+ X<\\infty$ type condition holds. In this paper, we study the situation where an immigrant vector $Y_n$ joins the population $Z_n^i$ at each generation $n \\ge 0$; the distribution of $Y_n$ also depends on the environment $ξ_n$. Following the approach of Grama et al., we construct a normalized process $(W^i_n)$ for the model with immigration, establishing a Kesten--Stigum type theorem that characterizes the non-degeneracy of its almost sure limit. Moreover, we provide complete $L^p$-convergence criteria for $(W^i_n)$, treating separately the cases $1 < p < \\infty$ and $0 < p < 1$. As an important byproduct, a sufficient condition for the boundedness of the maximal function $\\sup_n \\tilde{W}_n^i$ is also obtained. Our results show that, under a mild restriction on the number of immigrants, the inclusion of immigration does not affect the almost sure convergence property of the original normalized process, but it does have an impact on the criterion for $L^p$ convergence."
  },
  {
    "date": "2026-01-21",
    "title": "Quantitative Kelvin Probe Force Microscopy of back-gated 2D semiconductors",
    "authors": "Zander Scholl, Ezra Frohlich, Natalie Rogers, Paul Nguyen, Baker Hase, Joseph Tatsuro Murphy, Joel Toledo-Urena, David Cobden, Jennifer T. Heath",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14644v1",
    "source": "arXiv",
    "abstract": "In 2D field effect transistors the gate electrostatically dopes the 2D semiconductor (2DSC) channel, tuning the Fermi level. In principle, Kelvin probe force microscopy (KPFM) can detect the Fermi level, and its dependence on gate bias as well as position, potentially directly yielding band gaps, contact barriers, spatial nonuniformities, and sub-gap densities of states in such devices. However, KPFM relies on an oscillating probe voltage which itself electrostatically dopes the 2DSC, potentially creating a nonlinear response. Here, we show that when a suitably thin hBN back-gate dielectric is used, the KPFM signal agrees well with expectations, as explained by a quasistatic charge-balance model. Corresponding experimental results show excellent consistency with the literature values of the bandgaps of monolayer and trilayer WSe2. With this approach, the widely available technique of KPFM should find improved utility and new uses in the study of 2D devices."
  },
  {
    "date": "2026-01-21",
    "title": "Input-to-State Stabilizing Neural Controllers for Unknown Switched Nonlinear Systems within Compact Sets",
    "authors": "Bhabani Shankar Dey, Ahan Basu, Pushpak Jagtap",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14643v1",
    "source": "arXiv",
    "abstract": "This paper develops a neural network based control framework that ensures system safety and input-to-state stability (ISS) for general nonlinear switched systems with unknown dynamics. Leveraging the concept of dwell time, we derive Lyapunov based sufficient conditions under which both safety and ISS of the closed-loop switched system are guaranteed. The feedback controllers and the associated Lyapunov functions are parameterized using neural networks and trained from data collected over a compact state space via deterministic sampling. To provide formal stability guarantees under the learned controllers, we introduce a validity condition based on Lipschitz continuity assumptions, which is embedded directly into the training framework. This ensures that the resulting neural network controllers satisfy provable correctness and stability guarantees beyond the sampled data. As a special case, the proposed framework recovers ISS and safety under arbitrary switching when a common Lyapunov function exists. Simulation results on a representative switched nonlinear system demonstrate the effectiveness of the proposed approach."
  },
  {
    "date": "2026-01-21",
    "title": "Landing-Induced Viscoelastic Changes in an Anthropomimetic Foot Joint Structure are Modulated by Foot Structure and Posture",
    "authors": "Satoru Hashimoto, Yinlai Jiang, Hiroshi Yokoi, Shunta Togo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14634v1",
    "source": "arXiv",
    "abstract": "Cadaveric studies have provided important insights into the mechanics of the human foot arch and plantar fascia. However, repeatedly probing posture-dependent viscoelastic responses immediately after landing impact is difficult in biological specimens, leaving the contribution of skeletal architecture to landing dynamics incompletely understood. In this study, we developed an anthropomimetic foot joint structure aimed at replicating the skeletal geometry of the human foot. Using a vertical drop apparatus that simulates landing and a viscoelastic system-identification model, we investigated how skeletal structure and posture modulate the apparent post-impact viscoelastic response. The results show that the multi-jointed anthropomimetic structure exhibited a higher damping ratio than simplified flat and rigid feet. Moreover, ankle dorsiflexion and toe extension systematically shifted the identified parameters, reducing the damping ratio under the tested conditions. Taken together, these findings indicate that an arch-like, multi-jointed skeletal architecture can enhance impact attenuation in an anthropomimetic mechanical foot, and that morphology and passive posture alone can tune the trade-off between attenuation and rebound. The observed posture-dependent trends are qualitatively consistent with reported differences in human landing strategies, suggesting that skeletal architecture may partly account for the modulation. Furthermore, these results highlight the engineering advantage of anatomically informed skeletal replication for achieving human-like apparent viscoelastic behavior through postural adjustment during landing."
  },
  {
    "date": "2026-01-21",
    "title": "Diffusion Epistemic Uncertainty with Asymmetric Learning for Diffusion-Generated Image Detection",
    "authors": "Yingsong Huang, Hui Guo, Jing Huang, Bing Bai, Qi Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14625v1",
    "source": "arXiv",
    "abstract": "The rapid progress of diffusion models highlights the growing need for detecting generated images. Previous research demonstrates that incorporating diffusion-based measurements, such as reconstruction error, can enhance the generalizability of detectors. However, ignoring the differing impacts of aleatoric and epistemic uncertainty on reconstruction error can undermine detection performance. Aleatoric uncertainty, arising from inherent data noise, creates ambiguity that impedes accurate detection of generated images. As it reflects random variations within the data (e.g., noise in natural textures), it does not help distinguish generated images. In contrast, epistemic uncertainty, which represents the model's lack of knowledge about unfamiliar patterns, supports detection. In this paper, we propose a novel framework, Diffusion Epistemic Uncertainty with Asymmetric Learning~(DEUA), for detecting diffusion-generated images. We introduce Diffusion Epistemic Uncertainty~(DEU) estimation via the Laplace approximation to assess the proximity of data to the manifold of diffusion-generated samples. Additionally, an asymmetric loss function is introduced to train a balanced classifier with larger margins, further enhancing generalizability. Extensive experiments on large-scale benchmarks validate the state-of-the-art performance of our method."
  },
  {
    "date": "2026-01-21",
    "title": "Probing Prompt Design for Socially Compliant Robot Navigation with Vision Language Models",
    "authors": "Ling Xiao, Toshihiko Yamasaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14622v1",
    "source": "arXiv",
    "abstract": "Language models are increasingly used for social robot navigation, yet existing benchmarks largely overlook principled prompt design for socially compliant behavior. This limitation is particularly relevant in practice, as many systems rely on small vision language models (VLMs) for efficiency. Compared to large language models, small VLMs exhibit weaker decision-making capabilities, making effective prompt design critical for accurate navigation. Inspired by cognitive theories of human learning and motivation, we study prompt design along two dimensions: system guidance (action-focused, reasoning-oriented, and perception-reasoning prompts) and motivational framing, where models compete against humans, other AI systems, or their past selves. Experiments on two socially compliant navigation datasets reveal three key findings. First, for non-finetuned GPT-4o, competition against humans achieves the best performance, while competition against other AI systems performs worst. For finetuned models, competition against the model's past self yields the strongest results, followed by competition against humans, with performance further influenced by coupling effects among prompt design, model choice, and dataset characteristics. Second, inappropriate system prompt design can significantly degrade performance, even compared to direct finetuning. Third, while direct finetuning substantially improves semantic-level metrics such as perception, prediction, and reasoning, it yields limited gains in action accuracy. In contrast, our system prompts produce a disproportionately larger improvement in action accuracy, indicating that the proposed prompt design primarily acts as a decision-level constraint rather than a representational enhancement."
  },
  {
    "date": "2026-01-21",
    "title": "Direct and Converse Theorems in Estimating Signals with Sublinear Sparsity",
    "authors": "Keigo Takeuchi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14621v1",
    "source": "arXiv",
    "abstract": "This paper addresses the estimation of signals with sublinear sparsity sent over the additive white Gaussian noise channel. This fundamental problem arises in designing denoisers used in message-passing algorithms for sublinear sparsity. The main results are direct and converse theorems in the sublinear sparsity limit, where the signal sparsity grows sublinearly in the signal dimension as the signal dimension tends to infinity. As a direct theorem, the maximum likelihood estimator is proved to achieve vanishing square error in the sublinear sparsity limit if the noise variance is smaller than a threshold. As a converse theorem, all estimators cannot achieve square errors smaller than the signal power under a mild condition if the noise variance is larger than another threshold. In particular, the two thresholds coincide with each other when non-zero signals have constant amplitude. These results imply the asymptotic optimality of an existing separable Bayesian estimator used in approximate message-passing for sublinear sparsity."
  },
  {
    "date": "2026-01-21",
    "title": "An Ion-Intercalation Memristor for Enabling Full Parallel Writing in Crossbar Networks",
    "authors": "Tingwei Zhang, Jiahui Liu, David Allstot, Huaping Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14613v1",
    "source": "arXiv",
    "abstract": "Crossbar architectures have long been seen as a promising foundation for in-memory computing, using memristor arrays for high-density, energy-efficient analog computation. However, this conventional architecture suffers from a fundamental limitation: the inability to perform parallel write operations due to the sneak path problem. This arises from the structural overlap of read and write paths, forcing sequential or semi-parallel updates and severely limiting scalability. To address this, we introduce a new memristor design that decouples read and write operations at the device level. This design enables orthogonal conductive paths, and employs a reversible ion doping mechanism, inspired by lithium-ion battery principles, to modulate resistance states independently of computation. Fabricated devices exhibit near-ideal memristive characteristics and stable performance under isolated read/write conditions."
  },
  {
    "date": "2026-01-21",
    "title": "Learning Consistent Taxonomic Classification through Hierarchical Reasoning",
    "authors": "Zhenghong Li, Kecheng Zheng, Haibin Ling",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14610v1",
    "source": "arXiv",
    "abstract": "While Vision-Language Models (VLMs) excel at visual understanding, they often fail to grasp hierarchical knowledge. This leads to common errors where VLMs misclassify coarser taxonomic levels even when correctly identifying the most specific level (leaf level). Existing approaches largely overlook this issue by failing to model hierarchical reasoning. To address this gap, we propose VL-Taxon, a two-stage, hierarchy-based reasoning framework designed to improve both leaf-level accuracy and hierarchical consistency in taxonomic classification. The first stage employs a top-down process to enhance leaf-level classification accuracy. The second stage then leverages this accurate leaf-level output to ensure consistency throughout the entire taxonomic hierarchy. Each stage is initially trained with supervised fine-tuning to instill taxonomy knowledge, followed by reinforcement learning to refine the model's reasoning and generalization capabilities. Extensive experiments reveal a remarkable result: our VL-Taxon framework, implemented on the Qwen2.5-VL-7B model, outperforms its original 72B counterpart by over 10% in both leaf-level and hierarchical consistency accuracy on average on the iNaturalist-2021 dataset. Notably, this significant gain was achieved by fine-tuning on just a small subset of data, without relying on any examples generated by other VLMs."
  },
  {
    "date": "2026-01-21",
    "title": "3D Space as a Scratchpad for Editable Text-to-Image Generation",
    "authors": "Oindrila Saha, Vojtech Krs, Radomir Mech, Subhransu Maji, Matheus Gadelha, Kevin Blackburn-Matzen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14602v1",
    "source": "arXiv",
    "abstract": "Recent progress in large language models (LLMs) has shown that reasoning improves when intermediate thoughts are externalized into explicit workspaces, such as chain-of-thought traces or tool-augmented reasoning. Yet, visual language models (VLMs) lack an analogous mechanism for spatial reasoning, limiting their ability to generate images that accurately reflect geometric relations, object identities, and compositional intent. We introduce the concept of a spatial scratchpad -- a 3D reasoning substrate that bridges linguistic intent and image synthesis. Given a text prompt, our framework parses subjects and background elements, instantiates them as editable 3D meshes, and employs agentic scene planning for placement, orientation, and viewpoint selection. The resulting 3D arrangement is rendered back into the image domain with identity-preserving cues, enabling the VLM to generate spatially consistent and visually coherent outputs. Unlike prior 2D layout-based methods, our approach supports intuitive 3D edits that propagate reliably into final images. Empirically, it achieves a 32% improvement in text alignment on GenAI-Bench, demonstrating the benefit of explicit 3D reasoning for precise, controllable image generation. Our results highlight a new paradigm for vision-language models that deliberate not only in language, but also in space. Code and visualizations at https://oindrilasaha.github.io/3DScratchpad/"
  },
  {
    "date": "2026-01-21",
    "title": "Rethinking Reinforcement fine-tuning of LLMs: A Multi-armed Bandit Learning Perspective",
    "authors": "Xiao Hu, Hong Xie, Tao Tan, Defu Lian, Jianyu Han",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14599v1",
    "source": "arXiv",
    "abstract": "A large number of heuristics have been proposed to optimize the reinforcement fine-tuning of LLMs. However, inconsistent claims are made from time to time, making this area elusive. Reflecting on this situation, two fundamental questions still lack a clear understanding: 1) what is the role of each optimizing choice? 2) which ones are the bottlenecks? This paper aims to shed light on them, and it faces the challenge of several entangled confounding factors in the fine-tuning process. To tackle this challenge, we propose a bottom-up experiment pipeline. The bottom layer is composed of a minimalist configuration: one training data, one rollout per round and the reward directly serve as the learning signal without advantage function design. This minimalist configuration connects to multi-armed bandit learning with extremely large discrete action space, which offers theories to corroborate the experiment findings. The up procedure of the experiment pipeline expanding the minimalist configuration layer by layer, examining the role of each design choice. Experimental results on three LLMs and two reasoning datasets not only reveal new understanding of the design choice but also yield essential insights to shape the area."
  },
  {
    "date": "2026-01-21",
    "title": "Explainable OOHRI: Communicating Robot Capabilities and Limitations as Augmented Reality Affordances",
    "authors": "Lauren W. Wang, Mohamed Kari, Parastoo Abtahi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14587v1",
    "source": "arXiv",
    "abstract": "Human interaction is essential for issuing personalized instructions and assisting robots when failure is likely. However, robots remain largely black boxes, offering users little insight into their evolving capabilities and limitations. To address this gap, we present explainable object-oriented HRI (X-OOHRI), an augmented reality (AR) interface that conveys robot action possibilities and constraints through visual signifiers, radial menus, color coding, and explanation tags. Our system encodes object properties and robot limits into object-oriented structures using a vision-language model, allowing explanation generation on the fly and direct manipulation of virtual twins spatially aligned within a simulated environment. We integrate the end-to-end pipeline with a physical robot and showcase diverse use cases ranging from low-level pick-and-place to high-level instructions. Finally, we evaluate X-OOHRI through a user study and find that participants effectively issue object-oriented commands, develop accurate mental models of robot limitations, and engage in mixed-initiative resolution."
  },
  {
    "date": "2026-01-21",
    "title": "Symmetry Nonrestoration in the Pati-Salam Model",
    "authors": "N. Okada, A. Stern",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14580v1",
    "source": "arXiv",
    "abstract": "We demonstrate that symmetry need not be restored in the Pati-Salam model, so that $SU(2)_L\\otimes SU(2)_R\\otimes SU(4)_c$ remains broken to the Standard Model group at temperatures above the Pati-Salam symmetry breaking scale. Including the leading finite-temperature corrections, suitable quartic couplings prevent a restoration transition, thereby avoiding the thermal production of 't Hooft-Polyakov monopoles after inflation, even if the reheating temperature is very high. This removes monopole-based constraints on the Pati-Salam symmetry breaking scale."
  },
  {
    "date": "2026-01-21",
    "title": "Higher Harmonics of Double White Dwarfs in the Centihertz Band: Linking LISA and DECIGO",
    "authors": "Naoki Seto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14578v1",
    "source": "arXiv",
    "abstract": "We investigate the detectability of post-Newtonian higher harmonics from Galactic double white dwarfs in the centihertz band ($\\sim 0.01$ Hz). Using a synthetic population, we show that, unlike the quadrupole mode, higher harmonics remain undetectable with LISA except for rare nearby systems. In contrast, planned mid-band (decihertz) observatories such as DECIGO and BBO will be able to detect the third harmonic for about 10\\% of inspiral binaries above $\\sim 5$ mHz, enabling statistical constraints on mass ratios. These results highlight the successive roles of LISA and future decihertz missions in establishing a coherent strategy for space-based gravitational-wave astronomy."
  },
  {
    "date": "2026-01-21",
    "title": "The Effects of Radially Varying Diffusivities on Stellar Convection Zone Dynamics",
    "authors": "Brandon J. Lazard, Nicholas A. Featherstone, Jonathan M. Aurnou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14564v1",
    "source": "arXiv",
    "abstract": "Convection is ubiquitous in stellar and planetary interiors where it likely plays an integral role in the generation of magnetic fields. As the interiors of these objects remain hidden from direct observation, numerical models of convection are an important tool in the study of astrophysical dynamos. In such models, unrealistic large values of the viscous ($ν$) and thermal ($κ$) diffusivity are routinely used as an ad-hoc representation of the effects of subgrid scale turbulence which is otherwise too small-scale to resolve numerically. However, the functional forms of these diffusion coefficients can vary greatly between studies, complicating efforts to compare between results and against observations. We explore this issue by considering a series of non-rotating, non-magnetic, solar-like convection models with varying radial functions for the diffusivities and differing boundary conditions. We find that the bulk kinetic energy scales similarly regardless of the diffusivity parameterization. This scaling is consistent with a free-fall scaling, wherein viscosity plays a subdominant role in the force balance. We do not, however, observe such diffusion-free behavior in the convective heat transport. Our results also indicate that the functional form adopted for the diffusion coefficients can impact the distribution of turbulence within the convective shell. These results suggest that some care should be taken when comparing solar convection models directly against helioseismic observations."
  },
  {
    "date": "2026-01-21",
    "title": "SmartOracle -- An Agentic Approach to Mitigate Noise in Differential Oracles",
    "authors": "Srinath Srinivasan, Tim Menzies, Marcelo D'Amorim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15074v1",
    "source": "arXiv",
    "abstract": "Differential fuzzers detect bugs by executing identical inputs across distinct implementations of the same specification, such as JavaScript interpreters. Validating the outputs requires an oracle and for differential testing of JavaScript, these are constructed manually, making them expensive, time-consuming, and prone to false positives. Worse, when the specification evolves, this manual effort must be repeated. Inspired by the success of agentic systems in other SE domains, this paper introduces SmartOracle. SmartOracle decomposes the manual triage workflow into specialized Large Language Model (LLM) sub-agents. These agents synthesize independently gathered evidence from terminal runs and targeted specification queries to reach a final verdict. For historical benchmarks, SmartOracle achieves 0.84 recall with an 18% false positive rate. Compared to a sequential Gemini 2.5 Pro baseline, it improves triage accuracy while reducing analysis time by 4$\\times$ and API costs by 10$\\times$. In active fuzzing campaigns, SmartOracle successfully identified and reported previously unknown specification-level issues across major engines, including bugs in V8, JavaScriptCore, and GraalJS. The success of SmartOracle's agentic architecture on Javascript suggests it might be useful other software systems- a research direction we will explore in future work."
  },
  {
    "date": "2026-01-21",
    "title": "Limits of the Formal Integrals of Motion",
    "authors": "George Contopoulos, Athanasios C. Tzemos, Foivos Zanias",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14899v1",
    "source": "arXiv",
    "abstract": "We consider a formal (approximate) integral of motion in Hamiltonians of the form $H=\\frac{1}{2}(X^2+Y^2+ω_1^2x^2+ω_2^2y^2)+ε(ηxy^2+αx^3+βx^2y+γy^3)$ generalizing previous cases with $β=γ=0$. First we give the general form of this integral when $ω_1/ω_2$ is irrational and then we consider the case of commensurable frequencies. In particular we study the integrals for the resonances $ω_1/ω_2=4/1, 5/1, 3/2, 4/3, 3/1$ and $2/1$. We also calculate the invariant curves and the orbits in the cases $ω_1/ω_2=2/1$ and $1/1$ (with $β=γ=0$) and we compare the exact-numerical and the theoretical results predicted by the formal integral when $βγ\\neq0$. In the special case $ω_1/ω_2=1/1$ we find an integral when $β=γ=0$ and $ηα\\neq0$ or $η=α=0$ and $βγ\\neq 0$, but this is not possible when $ηαβγ\\neq 0$. However, we find that the invariant curves and the orbits can be approximated by a non-resonant integral with $ω_1/ω_2=5\\sqrt{2}/7=1.010\\dots$."
  },
  {
    "date": "2026-01-21",
    "title": "On the existence of Ulanowicz's optimal structural resilience in complex networks",
    "authors": "Si-Yao Wei, Wei-Xing Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14747v1",
    "source": "arXiv",
    "abstract": "This study investigates the mathematical existence and asymptotic properties of Ulanowicz's structural resilience in complex systems such as supply chain networks. While ecological evidence suggests that sustainable systems gravitate toward an optimal state at $α= 1/\\mathrm{e}$, the universality of this configuration in generalized networks remains theoretically unverified. We prove that while optimal resilience is unattainable in two-node networks due to structural over-determinacy, it exists for any directed graph with $N_\\mathcal{V} \\geq 3$. By constructing a symmetric network model with three types of link weights $(x, y, z)$ and uniform marginal distributions, we derive the governing equations for the optimal resilience configuration. Our analytical and numerical results reveal that as the network size $N_\\mathcal{V}$ increases, the link weights required to maintain optimal resilience exhibit a power-law scaling behavior: the adjacent links scale as $O(N_\\mathcal{V}^{-1})$, while the non-adjacent links scale as $O(N_\\mathcal{V}^{-2})$, both accompanied by specific logarithmic corrections. This work establishes a rigorous mathematical foundation for the optimal resilience framework and provides a unified perspective on how entropy-based principles govern the robustness and evolution of large-scale complex networks, which may offer quantitative guidance for designing large-scale networked systems under robustness constraints."
  },
  {
    "date": "2026-01-21",
    "title": "ARISE -- Adaptive Refinement and Iterative Scenario Engineering",
    "authors": "Konstantin Poddubnyy, Igor Vozniak, Nils Lipp, Ivan Burmistrov, Davit Hovhannisyan, Christian Mueller, Philipp Slusallek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14743v1",
    "source": "arXiv",
    "abstract": "The effectiveness of collision-free trajectory planners depends on the quality and diversity of training data, especially for rare scenarios. A widely used approach to improve dataset diversity involves generating realistic synthetic traffic scenarios. However, producing such scenarios remains difficult due to the precision required when scripting them manually or generating them in a single pass. Natural language offers a flexible way to describe scenarios, but existing text-to-simulation pipelines often rely on static snippet retrieval, limited grammar, single-pass decoding, or lack robust executability checks. Moreover, they depend heavily on constrained LLM prompting with minimal post-processing. To address these limitations, we introduce ARISE - Adaptive Refinement and Iterative Scenario Engineering, a multi-stage tool that converts natural language prompts into executable Scenic scripts through iterative LLM-guided refinement. After each generation, ARISE tests script executability in simulation software, feeding structured diagnostics back to the LLM until both syntactic and functional requirements are met. This process significantly reduces the need for manual intervention. Through extensive evaluation, ARISE outperforms the baseline in generating semantically accurate and executable traffic scenarios with greater reliability and robustness."
  },
  {
    "date": "2026-01-21",
    "title": "A radially broad collisional cascade in the debris disk of $γ$ Ophiuchi observed by JWST",
    "authors": "Yinuo Han, Mark Wyatt, Kate Y. L. Su, Antranik A. Sefilian, Joshua B. Lovell, Carlos del Burgo, Jonathan P. Marshall, Sebastian Marino, David J. Wilner, Brenda C. Matthews, Max Sommer, A. Meredith Hughes, John M. Carpenter, Meredith A. MacGregor, Nicole Pawellek, Thomas Henning",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15285v1",
    "source": "arXiv",
    "abstract": "The A1V star $γ$ Oph, at a distance of 29.7 pc, is known from Spitzer imaging to host a debris disk with a large radial extent and from its spectral energy distribution to host inner warm dust. We imaged $γ$ Oph with JWST/MIRI at 15 and 25.5 microns, which reveal smooth and radially broad emission that extends to a radius of at least 250 au at 25.5 microns. In contrast to JWST findings of an inner small-grain component with distinct ringed substructures in Fomalhaut and Vega, the mid-infrared radial profile combined with prior ALMA imaging suggests a radially broad steady-state collisional cascade with the same grain size distribution throughout the disk. This further suggests that the system is populated by a radially broad planetesimal belt from tens of au or less to well over 200 au, rather than a narrow planetesimal belt from which the observed dust is displaced to appear broad. The disk is also found to be asymmetric, which could be modelled by a stellocentric offset corresponding to a small eccentricity of $\\sim$0.02. Such a disk eccentricity could be induced by a mildly eccentric $<$$10\\,M_\\mathrm{Jup}$ giant planet outside 10 au, or a more eccentric companion up to stellar mass at a few au, without producing a resolvable radial gap in the disk."
  },
  {
    "date": "2026-01-21",
    "title": "Robust Fake News Detection using Large Language Models under Adversarial Sentiment Attacks",
    "authors": "Sahar Tahmasebi, Eric Müller-Budack, Ralph Ewerth",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15277v1",
    "source": "arXiv",
    "abstract": "Misinformation and fake news have become a pressing societal challenge, driving the need for reliable automated detection methods. Prior research has highlighted sentiment as an important signal in fake news detection, either by analyzing which sentiments are associated with fake news or by using sentiment and emotion features for classification. However, this poses a vulnerability since adversaries can manipulate sentiment to evade detectors especially with the advent of large language models (LLMs). A few studies have explored adversarial samples generated by LLMs, but they mainly focus on stylistic features such as writing style of news publishers. Thus, the crucial vulnerability of sentiment manipulation remains largely unexplored. In this paper, we investigate the robustness of state-of-the-art fake news detectors under sentiment manipulation. We introduce AdSent, a sentiment-robust detection framework designed to ensure consistent veracity predictions across both original and sentiment-altered news articles. Specifically, we (1) propose controlled sentiment-based adversarial attacks using LLMs, (2) analyze the impact of sentiment shifts on detection performance. We show that changing the sentiment heavily impacts the performance of fake news detection models, indicating biases towards neutral articles being real, while non-neutral articles are often classified as fake content. (3) We introduce a novel sentiment-agnostic training strategy that enhances robustness against such perturbations. Extensive experiments on three benchmark datasets demonstrate that AdSent significantly outperforms competitive baselines in both accuracy and robustness, while also generalizing effectively to unseen datasets and adversarial scenarios."
  },
  {
    "date": "2026-01-21",
    "title": "Two-Qubit Spin-Boson Model in the Strong Coupling Regime: Coherence, Non-Markovianity, and Quantum Thermodynamics",
    "authors": "Hasan Mehdi Rizvi, Devvrat Tiwari, Subhashish Banerjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15026v1",
    "source": "arXiv",
    "abstract": "We investigate the dynamics of a two-qubit open quantum system, in particular the two-qubit spin-boson model in the strong coupling regime, coupled to two thermal bosonic baths under non-Markovian and non-equilibrium conditions. Two complementary approaches, the Hierarchical Equations of Motion (HEOM) and Reaction Coordinate Mapping (RCM), are employed to examine various coupling regimes between the qubits and their respective baths. The dynamical features of the model and the impact of the tunneling amplitude on quantum coherence of the system are probed using the $l_1$-norm of coherence. The model is further shown to have non-Markovian evolution. The nontrivial task of calculating entropy production in the strong-coupling regime is performed using auxiliary density operators in HEOM. Motivated by the realization of a quantum thermal device in the strong-coupling regime, the non-equilibrium steady-state behavior of the system is investigated. Furthermore, the relationship between the heat and spin currents and the tunneling amplitude is probed."
  },
  {
    "date": "2026-01-21",
    "title": "$H$ dibaryon and its cousins from SU(6)-constrained baryon-baryon interaction",
    "authors": "Tao-Ran Hu, Feng-Kun Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14922v1",
    "source": "arXiv",
    "abstract": "We constrain the $S$-wave baryon-baryon interaction using SU(6) symmetry within a nonrelativistic effective field theory. The most general leading-order Lagrangian contains two independent parameters, which we determine using physical $NN$ and lattice QCD $ΩΩ$ scattering lengths. This framework allows for parameter-free predictions in the strangeness $S=-2$ sector relevant to the $H$ dibaryon. Solving the coupled-channel scattering problem, we identify two bound states below the $ΛΛ$ threshold, one deeply bound and one shallow, along with resonances near the $ΣΣ$ and $Σ^*Σ^*$ thresholds. We demonstrate that these poles result in distinct enhancements in $ΛΛ$ invariant mass distributions, suggesting that the $H$ dibaryon exists as a multichannel bound state and providing clear signatures for experimental verification."
  },
  {
    "date": "2026-01-21",
    "title": "Knowledge Restoration-driven Prompt Optimization: Unlocking LLM Potential for Open-Domain Relational Triplet Extraction",
    "authors": "Xiaonan Jing, Gongqing Wu, Xingrui Zhuo, Lang Sun, Jiapu Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15037v1",
    "source": "arXiv",
    "abstract": "Open-domain Relational Triplet Extraction (ORTE) is the foundation for mining structured knowledge without predefined schemas. Despite the impressive in-context learning capabilities of Large Language Models (LLMs), existing methods are hindered by their reliance on static, heuristic-driven prompting strategies. Due to the lack of reflection mechanisms required to internalize erroneous signals, these methods exhibit vulnerability in semantic ambiguity, often making erroneous extraction patterns permanent. To address this bottleneck, we propose a Knowledge Reconstruction-driven Prompt Optimization (KRPO) framework to assist LLMs in continuously improving their extraction capabilities for complex ORTE task flows. Specifically, we design a self-evaluation mechanism based on knowledge restoration, which provides intrinsic feedback signals by projecting structured triplets into semantic consistency scores. Subsequently, we propose a prompt optimizer based on a textual gradient that can internalize historical experiences to iteratively optimize prompts, which can better guide LLMs to handle subsequent extraction tasks. Furthermore, to alleviate relation redundancy, we design a relation canonicalization memory that collects representative relations and provides semantically distinct schemas for the triplets. Extensive experiments across three datasets show that KRPO significantly outperforms strong baselines in the extraction F1 score."
  },
  {
    "date": "2026-01-21",
    "title": "Optimized Schwarz Waveform Relaxation for the Damped Wave Equation",
    "authors": "Gerardo Cicalese, Gabriele Ciaramella, Ilario Mazzieri, Martin J. Gander",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15070v1",
    "source": "arXiv",
    "abstract": "The performance of Schwarz Waveform Relaxation is critically dependent on the choice of transmission conditions. While classical absorbing conditions work well for wave propagation, they prove insufficient for damped wave equations, particularly in viscoelastic damping regimes where convergence becomes prohibitively slow. This paper addresses this limitation by introducing a more general transmission operator with two free parameters for the one-dimensional damped wave equation. Through frequency-domain analysis, we derive an explicit expression for the convergence factor governing the convergence rate. We propose and compare two optimization strategies (L-infinity and L-2 minimization) for determining optimal transmission parameters. Numerical experiments demonstrate that our optimized approach significantly accelerates convergence compared to standard absorbing conditions, especially for viscoelastic damping cases. The method provides a computationally efficient alternative to exhaustive parameter search while maintaining robust performance across different damping regimes."
  },
  {
    "date": "2026-01-21",
    "title": "Multipartite entanglement in the quantum tetrahedron",
    "authors": "Robert Amelung, Hanno Sahlmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14964v1",
    "source": "arXiv",
    "abstract": "The space $\\mathrm{Inv}(j_1,j_2,j_3,j_4)$ of SU(2)-invariant four-valent tensors, also known as intertwiners, can be understood as the quantum states of a tetrahedron in Euclidean space with fixed areas. In loop quantum gravity, they are states of the smallest \"atom of space\" with non-zero volume. At the same time they correspond to four-party tensor product states invariant under global rotations. We consider the multipartite entanglement of states in $\\mathrm{Inv}(j_1,j_2,j_3,j_4)$ using the recently proposed entropic fill. Numerically evaluating entropic fill in the case of equal spins between $1/2$ and $11$, we find that the distributions of entanglement are very different for intertwiners as compared to generic tensors, and for coherent intertwiners as compared to generic ones. The peak in the distribution seems to be at the highest entanglement for generic intertwiners and at the lowest for generic tensors, but in terms of average entanglement, the roles are switched: average entanglement is highest in arbitrary tensors and lower in intertwiners, at least in the regime of large $j$. We also find that entanglement depends on the geometric data of coherent intertwiners in a complicated way."
  },
  {
    "date": "2026-01-21",
    "title": "On the Effectiveness of Mempool-based Transaction Auditing",
    "authors": "Jannik Albrecht, Ghassan Karame",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14996v1",
    "source": "arXiv",
    "abstract": "While the literature features a number of proposals to defend against transaction manipulation attacks, existing proposals are still not integrated within large blockchains, such as Bitcoin, Ethereum, and Cardano. Instead, the user community opted to rely on more practical but ad-hoc solutions (such as Mempool.space) that aim at detecting censorship and transaction displacement attacks by auditing discrepancies in the mempools of so-called observers. In this paper, we precisely analyze, for the first time, the interplay between mempool auditing and the ability to detect censorship and transaction displacement attacks by malicious miners in Bitcoin and Ethereum. Our analysis shows that mempool auditing can result in mis-accusations against miners with a probability larger than 25% in some settings. On a positive note, however, we show that mempool auditing schemes can successfully audit the execution of any two transactions (with an overwhelming probability of 99.9%) if they are consistently received by all observers and sent at least 30 seconds apart from each other. As a direct consequence, our findings show, for the first time, that batch-order fair-ordering schemes can offer only strong fairness guarantees for a limited subset of transactions in real-world deployments."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient and precise Cherenkov-based charged particle timing using SiPMs",
    "authors": "M. N. Mazziotta, A. Di Mauro, M. Giliberti, A. Liguori, L. Lorusso, E. Nappi, N. Nicassio, G. Panzarini, R. Pillera, G. Volpe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14768v1",
    "source": "arXiv",
    "abstract": "Dedicated R&D efforts are currently underway to couple a thin Cherenkov radiator to Silicon Photomultiplier (SiPM) arrays for precise charged particle Time-of-Flight (ToF) measurements. The prompt nature of Cherenkov radiation makes it an ideal candidate for achieving ultimate timing performance in a ToF detector. Using a thin radiator with a high refractive index, such as fused silica, enables the generation of a fast signal from charged particles that exceed the Cherenkov threshold. A crucial requirement for approaching the target time resolution is the optimization of both the radiator material and thickness, as well as the optical coupling to the SiPM arrays. In this work, we present the main factors that affect the time resolution and the expected performance achieved through a detailed Monte Carlo simulation and the comparison with beam test results."
  },
  {
    "date": "2026-01-21",
    "title": "Anytime Optimal Decision Tree Learning with Continuous Features",
    "authors": "Harold Kiossou, Pierre Schaus, Siegfried Nijssen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14765v1",
    "source": "arXiv",
    "abstract": "In recent years, significant progress has been made on algorithms for learning optimal decision trees, primarily in the context of binary features. Extending these methods to continuous features remains substantially more challenging due to the large number of potential splits for each feature. Recently, an elegant exact algorithm was proposed for learning optimal decision trees with continuous features; however, the rapidly increasing computational time limits its practical applicability to shallow depths (typically 3 or 4). It relies on a depth-first search optimization strategy that fully optimizes the left subtree of each split before exploring the corresponding right subtree. While effective in finding optimal solutions given sufficient time, this strategy can lead to poor anytime behavior: when interrupted early, the best-found tree is often highly unbalanced and suboptimal. In such cases, purely greedy methods such as C4.5 may, paradoxically, yield better solutions. To address this limitation, we propose an anytime, yet complete approach leveraging limited discrepancy search, distributing the computational effort more evenly across the entire tree structure, and thus ensuring that a high-quality decision tree is available at any interruption point. Experimental results show that our approach outperforms the existing one in terms of anytime performance."
  },
  {
    "date": "2026-01-21",
    "title": "An XAI View on Explainable ASP: Methods, Systems, and Perspectives",
    "authors": "Thomas Eiter, Tobias Geibinger, Zeynep G. Saribatur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14764v1",
    "source": "arXiv",
    "abstract": "Answer Set Programming (ASP) is a popular declarative reasoning and problem solving approach in symbolic AI. Its rule-based formalism makes it inherently attractive for explainable and interpretive reasoning, which is gaining importance with the surge of Explainable AI (XAI). A number of explanation approaches and tools for ASP have been developed, which often tackle specific explanatory settings and may not cover all scenarios that ASP users encounter. In this survey, we provide, guided by an XAI perspective, an overview of types of ASP explanations in connection with user questions for explanation, and describe how their coverage by current theory and tools. Furthermore, we pinpoint gaps in existing ASP explanations approaches and identify research directions for future work."
  },
  {
    "date": "2026-01-21",
    "title": "Functionalization of reduced graphite oxide sheets with a zwitterionic surfactant",
    "authors": "Beatriz Martín-García, M. Mercedes Velázquez, Francesco Rossella, Vittorio Bellani, Enrique Diez, Jose Luis García Fierro, Jose Antonio Pérez-Hernández, Juan Hernández-Toro, Sergi Claramunt, Albert Cirera",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14760v1",
    "source": "arXiv",
    "abstract": "Films of a few layers in thickness of reduced graphite oxide, RGO, sheets functionalized by the zwitterionic surfactant N-dodecyl-N,N-dimethyl-3-ammonio-1-propanesulfonate, DDPS, are obtained by using the Langmuir-Blodgett method. The quality of the RGO sheets is checked by analyzing the degrees of reduction and defect repair by means of X-ray photoelectron spectroscopy, atomic force microscopy -AFM, field-emission scanning electron microscopy -SEM, micro-Raman spectroscopy, and electrical conductivity measurements. A modified Hummers method is used to obtain highly oxidized graphite oxide, GO, together with a centrifugation-based method to improve the quality of GO. The GO samples are reduced by hydrazine or vitamin C. Functionalization of RGO with the zwitterionic surfactant improves the degrees of reduction and defect repair of the two reducing agents and significantly increases the electrical conductivity of paperlike films compared with those prepared from unfunctionalized RGO."
  },
  {
    "date": "2026-01-21",
    "title": "Many-to-many. Usability challenges of entity reconciliation in art history and photographic studies",
    "authors": "Marilena Daquino, Francesca Mambelli, Artem Kozlov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14753v1",
    "source": "arXiv",
    "abstract": "This article investigates challenges in reconciling heterogeneous records across cultural institutions, focusing on art historical photo archives within the PHAROS consortium. Through case studies, the study analyses reconciliation workflows and cataloguing traditions, with attention to institutional contexts, data granularities, and modelling strategies. Reconciliation is seldom a one-to-one operation. Ambiguities, incomplete data, shifting attributions, and varying practices shape outcomes. Strategies observed include the creation of anonymous or collective entities, the use of umbrella terms, the addition of uncertainty qualifiers, and reticence when ambiguity cannot be resolved. The article highlights the need to model uncertainty explicitly, offering a framework that connects technical reconciliation methods with institutional practices. Insights from PHAROS provide guidance for designing more robust, interoperable, and sustainable cultural heritage infrastructures."
  },
  {
    "date": "2026-01-21",
    "title": "Model-Driven Conditional Fourier Neural Operator for Spectrum-Consistent Synthetic Turbulence Generation",
    "authors": "Hongyuan Lin, Shizhao Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14745v1",
    "source": "arXiv",
    "abstract": "This short note proposes a model-driven conditional Fourier neural operator (MD-CFNO) for synthetic turbulence generation. Spectrum-consistent synthetic turbulence is essential for inflow boundary construction in computational fluid dynamics and for broadband aeroacoustic noise prediction. Data-driven turbulence synthesis with neural networks has emerged as a promising direction. However, generating flow fields that match prescribed energy spectra across wide physical regimes remains challenging. Existing data-driven methods typically rely on expensive reliable datasets with limited generalization and are prone to regression-to-the-mean when trained in the spatial domain. To address these issues, the MD-CFNO is proposed with three components: a model-driven data construction strategy is adopted to improve interpretability and broaden the generalizable parameter regime; conditional stochastic generation is integrated into the Fourier neural operator architecture to alleviate regression-to-the-mean effects; and a composite loss is introduced to accelerate convergence and enhance spectral fidelity. Results show that the proposed MD-CFNO generates spectrum-consistent synthetic turbulence and achieves robust performance under both interpolation and out-of-distribution extrapolation conditions. This study provides a model-driven perspective on synthetic turbulence, showing the advantages of Fourier neural operators for conditional generation."
  },
  {
    "date": "2026-01-21",
    "title": "SimD3: A Synthetic drone Dataset with Payload and Bird Distractor Modeling for Robust Detection",
    "authors": "Ami Pandat, Kanyala Muvva, Punna Rajasekhar, Gopika Vinod, Rohit Shukla",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14742v1",
    "source": "arXiv",
    "abstract": "Reliable drone detection is challenging due to limited annotated real-world data, large appearance variability, and the presence of visually similar distractors such as birds. To address these challenges, this paper introduces SimD3, a large-scale high-fidelity synthetic dataset designed for robust drone detection in complex aerial environments. Unlike existing synthetic drone datasets, SimD3 explicitly models drones with heterogeneous payloads, incorporates multiple bird species as realistic distractors, and leverages diverse Unreal Engine 5 environments with controlled weather, lighting, and flight trajectories captured using a 360 six-camera rig. Using SimD3, we conduct an extensive experimental evaluation within the YOLOv5 detection framework, including an attention-enhanced variant termed Yolov5m+C3b, where standard bottleneck-based C3 blocks are replaced with C3b modules. Models are evaluated on synthetic data, combined synthetic and real data, and multiple unseen real-world benchmarks to assess robustness and generalization. Experimental results show that SimD3 provides effective supervision for small-object drone detection and that Yolov5m+C3b consistently outperforms the baseline across in-domain and cross-dataset evaluations. These findings highlight the utility of SimD3 for training and benchmarking robust drone detection models under diverse and challenging conditions."
  },
  {
    "date": "2026-01-21",
    "title": "Finite-dimensional approximations of random attractor for stochastic discrete complex Ginzburg-Landau equations",
    "authors": "Xinjie Fang, Jianhua Huang, Fang Su, Jun Ouyang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14740v1",
    "source": "arXiv",
    "abstract": "In this paper, we apply an implicit Euler scheme to discretize the complex Ginzburg-Landau equation and prove the existence of a numerical attractor for the discrete Ginzburg-Landau system. We establish the upper semicontinuity of the numerical attractor with respect to the global attractor as the time step tends to zero. Furthermore, we provide finite-dimensional approximations for three types of attractors (global, numerical, and random), and demonstrate the existence of truncated attractors along with their convergence as the dimension of the state space tends to infinity. Finally, we prove the existence of a random attractor and establish the upper semi-continuity both of the global random attractor and the truncated random attractor."
  },
  {
    "date": "2026-01-21",
    "title": "Recent advances in the Bradley--Terry Model: theory, algorithms, and applications",
    "authors": "Shuxing Fang, Ruijian Han, Yuanhang Luo, Yiming Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14727v1",
    "source": "arXiv",
    "abstract": "This article surveys recent progress in the Bradley-Terry (BT) model and its extensions. We focus on the statistical and computational aspects, with emphasis on the regime in which both the number of objects and the volume of comparisons tend to infinity, a setting relevant to large-scale applications. The main topics include asymptotic theory for statistical estimation and inference, along with the associated algorithms. We also discuss applications of these models, including recent work on preference alignment in machine learning. Finally, we discuss several key challenges and outline directions for future research."
  },
  {
    "date": "2026-01-21",
    "title": "Kerr-enhanced amplification of three-wave mixing and emergent masing regimes",
    "authors": "Ragheed Alhyder, Rishabh Sahu, Johannes M. Fink, Mikhail Lemeshko, Georgios M. Koutentakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14726v1",
    "source": "arXiv",
    "abstract": "Integrated optical microresonators exploiting either second-order ($χ^{(2)}$) or third-order ($χ^{(3)}$) nonlinearities have become key platforms for frequency conversion, low-noise microwave photonics, and quantum entanglement generation. Here, we present an analytic theory of Kerr-enhanced three-wave mixing amplification in an electro-optic microresonator with both $χ^{(2)}$ and $χ^{(3)}$ nonlinearities. We demonstrate that Kerr dressing hybridizes the optical sidebands, renormalizing the $χ^{(2)}$ couplings and detunings. As a result the system exhibits gain in regions where analogous bare $χ^{(2)}$ or $χ^{(3)}$ amplifiers are subthreshold. Time-domain Langevin simulations confirm this threshold reduction, mapping a practical design window for experiments."
  },
  {
    "date": "2026-01-21",
    "title": "Typhoon OCR: Open Vision-Language Model For Thai Document Extraction",
    "authors": "Surapon Nonesung, Natapong Nitarach, Teetouch Jaknamon, Pittawat Taveekitworachai, Kunat Pipatanakul",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14722v1",
    "source": "arXiv",
    "abstract": "Document extraction is a core component of digital workflows, yet existing vision-language models (VLMs) predominantly favor high-resource languages. Thai presents additional challenges due to script complexity from non-latin letters, the absence of explicit word boundaries, and the prevalence of highly unstructured real-world documents, limiting the effectiveness of current open-source models. This paper presents Typhoon OCR, an open VLM for document extraction tailored for Thai and English. The model is fine-tuned from vision-language backbones using a Thai-focused training dataset. The dataset is developed using a multi-stage data construction pipeline that combines traditional OCR, VLM-based restructuring, and curated synthetic data. Typhoon OCR is a unified framework capable of text transcription, layout reconstruction, and document-level structural consistency. The latest iteration of our model, Typhoon OCR V1.5, is a compact and inference-efficient model designed to reduce reliance on metadata and simplify deployment. Comprehensive evaluations across diverse Thai document categories, including financial reports, government forms, books, infographics, and handwritten documents, show that Typhoon OCR achieves performance comparable to or exceeding larger frontier proprietary models, despite substantially lower computational cost. The results demonstrate that open vision-language OCR models can achieve accurate text extraction and layout reconstruction for Thai documents, reaching performance comparable to proprietary systems while remaining lightweight and deployable."
  },
  {
    "date": "2026-01-21",
    "title": "NLP-Based Review for Toxic Comment Detection Tailored to the Chinese Cyberspace",
    "authors": "Ruixing Ren, Junhui Zhao, Xiaoke Sun, Qiuping Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14721v1",
    "source": "arXiv",
    "abstract": "With the in-depth integration of mobile Internet and widespread adoption of social platforms, user-generated content in the Chinese cyberspace has witnessed explosive growth. Among this content, the proliferation of toxic comments poses severe challenges to individual mental health, community atmosphere and social trust. Owing to the strong context dependence, cultural specificity and rapid evolution of Chinese cyber language, toxic expressions are often conveyed through complex forms such as homophones and metaphors, imposing notable limitations on traditional detection methods. To address this issue, this review focuses on the core topic of natural language processing based toxic comment detection in the Chinese cyberspace, systematically collating and critically analyzing the research progress and key challenges in this field. This review first defines the connotation and characteristics of Chinese toxic comments, and analyzes the platform ecology and transmission mechanisms they rely on. It then comprehensively reviews the construction methods and limitations of existing public datasets, and proposes a novel fine-grained and scalable framework for toxic comment definition and classification, along with corresponding data annotation and quality assessment strategies. We systematically summarize the evolutionary path of detection models from traditional methods to deep learning, with special emphasis on the importance of interpretability in model design. Finally, we thoroughly discuss the open challenges faced by current research and provide forward-looking suggestions for future research directions."
  },
  {
    "date": "2026-01-21",
    "title": "LookBench: A Live and Holistic Open Benchmark for Fashion Image Retrieval",
    "authors": "Chao Gao, Siqiao Xue, Yimin Peng, Jiwen Fu, Tingyi Gu, Shanshan Li, Fan Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14706v1",
    "source": "arXiv",
    "abstract": "In this paper, we present LookBench (We use the term \"look\" to reflect retrieval that mirrors how people shop -- finding the exact item, a close substitute, or a visually consistent alternative.), a live, holistic and challenging benchmark for fashion image retrieval in real e-commerce settings. LookBench includes both recent product images sourced from live websites and AI-generated fashion images, reflecting contemporary trends and use cases. Each test sample is time-stamped and we intend to update the benchmark periodically, enabling contamination-aware evaluation aligned with declared training cutoffs. Grounded in our fine-grained attribute taxonomy, LookBench covers single-item and outfit-level retrieval across. Our experiments reveal that LookBench poses a significant challenge on strong baselines, with many models achieving below $60\\%$ Recall@1. Our proprietary model achieves the best performance on LookBench, and we release an open-source counterpart that ranks second, with both models attaining state-of-the-art results on legacy Fashion200K evaluations. LookBench is designed to be updated semi-annually with new test samples and progressively harder task variants, providing a durable measure of progress. We publicly release our leaderboard, dataset, evaluation code, and trained models."
  },
  {
    "date": "2026-01-21",
    "title": "CoScale-RL: Efficient Post-Training by Co-Scaling Data and Computation",
    "authors": "Yutong Chen, Jiandong Gao, Ji Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14695v1",
    "source": "arXiv",
    "abstract": "Training Large Reasoning Model (LRM) is usually unstable and unpredictable, especially on hard problems or weak foundation models. We found that the current post-training scaling strategy can still improve on these cases. We propose CoScale-RL, a novel scaling strategy with better data and computational efficiency. We first scale up solutions to make problems solvable. The core idea is to collect multiple solutions for each problem, rather than simply enlarging the dataset. Then, we scale up rollout computation to stabilize Reinforcement Learning. We further leverage a model merge technique called Re-distillation to sustain or even improve computational efficiency when scaling up. Our method significantly improves data and computational efficiency, with an average 3.76$\\times$ accuracy improvement on four benchmarks. CoScale-RL is able to improve an LRM's ability boundary without an extensive SFT dataset. Our method provides a new scaling direction to further improve LRM's reasoning ability."
  },
  {
    "date": "2026-01-21",
    "title": "Detailed lens modeling and kinematics of the submillimeter galaxy G09v1.97. An analysis of CO, H2O, H2O+, and dust continuum emission",
    "authors": "K. Kade, C. Yang, M. Yttergren, K. K. Knudsen, S. König, A. Amvrosiadis, S. Dye, J. Nightingale, L. Zhang, Z. Zhang, A. Cooray, P. Cox, R. Gavazzi, E. Ibar, M. J. Michałowski, P. van der Werf, R. Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14685v1",
    "source": "arXiv",
    "abstract": "The formation mechanisms of intensely starbursting galaxies at high redshift remain unknown. One possible mechanism for triggering these starbursts is mergers and interactions, but detecting these at high redshift remains a challenge. Observations of high-redshift gravitationally lensed galaxies enable studies of the interstellar medium and environment of these extreme starbursts in detail. We used high angular resolution observations of dust continuum, CO(6-5), H2O(211-202), and H2O+(202-111) emission to constrain the ongoing processes in the z = 3.63 gravitationally lensed submillimeter galaxy H-ATLAS J083051.0+013224 (G09v1.97). We used PyAutoLens to create a de-magnified source plane CO(6-5) emission line cube and performed kinematic modeling using 3DBarolo. Additionally, we investigated the properties of the continuum and molecular line emission in the source plane. We find that the regions of CO(6-5) and H2O(211-202) emission match closely in the source plane but that the dust continuum emission is more compact. We find that our lens modeling results do not require more than one source, contrary to what has been found in previous studies. Instead, we find that G09v1.97 resembles a rotating disk with Vmax/sigma = 2.8 +/- 0.4 with evidence for residual emission indicative of non-circular motions such as outflows, tidal tails, or an additional background galaxy. We suggest that the origin of the non-circular motions may be associated with a bi-conical outflow, a tidal tail from an interaction, or indicate the possible presence of an additional galaxy. We calculate the dynamical mass, gas mass, star-formation rate, and depletion time for G09v1.97 and find a high star-formation rate and low gas depletion time. In combination, this suggests that G09v1.97 has recently undergone an interaction, triggering intense star formation, and is in the process of settling into a disk."
  },
  {
    "date": "2026-01-21",
    "title": "Dissecting Performance Degradation in Audio Source Separation under Sampling Frequency Mismatch",
    "authors": "Kanami Imamura, Tomohiko Nakamura, Kohei Yatabe, Hiroshi Saruwatari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14684v1",
    "source": "arXiv",
    "abstract": "Audio processing methods based on deep neural networks are typically trained at a single sampling frequency (SF). To handle untrained SFs, signal resampling is commonly employed, but it can degrade performance, particularly when the input SF is lower than the trained SF. This paper investigates the causes of this degradation through two hypotheses: (i) the lack of high-frequency components introduced by up-sampling, and (ii) the greater importance of their presence than their precise representation. To examine these hypotheses, we compare conventional resampling with three alternatives: post-resampling noise addition, which adds Gaussian noise to the resampled signal; noisy-kernel resampling, which perturbs the kernel with Gaussian noise to enrich high-frequency components; and trainable-kernel resampling, which adapts the interpolation kernel through training. Experiments on music source separation show that noisy-kernel and trainable-kernel resampling alleviate the degradation observed with conventional resampling. We further demonstrate that noisy-kernel resampling is effective across diverse models, highlighting it as a simple yet practical option."
  },
  {
    "date": "2026-01-21",
    "title": "A comprehensive overview of deep learning models for object detection from videos/images",
    "authors": "Sukana Zulfqar, Sadia Saeed, M. Azam Zia, Anjum Ali, Faisal Mehmood, Abid Ali",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14677v1",
    "source": "arXiv",
    "abstract": "Object detection in video and image surveillance is a well-established yet rapidly evolving task, strongly influenced by recent deep learning advancements. This review summarises modern techniques by examining architectural innovations, generative model integration, and the use of temporal information to enhance robustness and accuracy. Unlike earlier surveys, it classifies methods based on core architectures, data processing strategies, and surveillance specific challenges such as dynamic environments, occlusions, lighting variations, and real-time requirements. The primary goal is to evaluate the current effectiveness of semantic object detection, while secondary aims include analysing deep learning models and their practical applications. The review covers CNN-based detectors, GAN-assisted approaches, and temporal fusion methods, highlighting how generative models support tasks such as reconstructing missing frames, reducing occlusions, and normalising illumination. It also outlines preprocessing pipelines, feature extraction progress, benchmarking datasets, and comparative evaluations. Finally, emerging trends in low-latency, efficient, and spatiotemporal learning approaches are identified for future research."
  },
  {
    "date": "2026-01-21",
    "title": "Long-Lived Oscillons as Closed Domain Walls in the $\\mathbb Z_2$-Symmetric Two-Higgs-Doublet Model",
    "authors": "Zhaoyu Meng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14676v1",
    "source": "arXiv",
    "abstract": "We identify an oscillatory solution that exists as a long-lived, bubble-like closed domain wall in the two-Higgs-doublet model (2HDM) under a $\\mathbb{Z}_2$ symmetry constraint, and these structures emerge naturally during the late stages of domain wall decay. \\\\ \\\\ The longevity of these structures is attributed to a potential landscape characterized by two distinct vacuum regions, the oscillating region lies in one vacuum, while the constant outer region lies in the other. The lifetime of the structure depends on the parameter in the Lagrangian, we identify a specific parameter space where radiation is suppressed, the solution exhibits a maximum lifetime that goes up to infinity. \\\\ \\\\ The simpler two-complex-field system is first used to introduce the mathematical requirements of the structure before extending it to the more physical but complex 2HDM. Further Numerical verification via Floquet analysis shows these structures are stable under perturbation."
  },
  {
    "date": "2026-01-21",
    "title": "Decomposing the growth mechanisms of galaxies over the last 10 billion years",
    "authors": "Luke J. M. Davies, Annagrazia Puglisi, Marcella Longhetti, Mark Sargent, Simon P. Driver, Aaron S. G. Robotham, Sabine Bellstedt, Fabio Rosario Ditrani, Anna R. Gallazzi, Laura Scholz Díaz, Stefania Barsanti, Stefano Zibetti, Sabine Thater",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14666v1",
    "source": "arXiv",
    "abstract": "Determining how galaxies accumulate stellar mass is paramount to understanding the Universe. Two primary mechanisms drive this process: star-formation (SF) & mergers. Our understanding of star formation, and to some degree the processes that influence the baryon cycle (environment, gas supply, feedback, etc), are either relatively well constrained or will develop significantly over the coming decades via upcoming facilities (i.e. through their imprint on galaxy properties measured with deep multi-wavelength and spectroscopic data). However, the same can not be said for mergers. It is telling that we indirectly know hierarchical assembly through mergers is one of the most crucial processes that shape our Universe, but the robust observational measurement of mergers is almost non-existent outside of the local Universe - let alone how these mergers impact galaxy properties. This is not likely to significantly change in the coming decades as existing or approved facilities/surveys are inadequate in charactering mergers in the distant Universe. Motivated by this, we discuss an ambitious study to first explore mergers, and then the co-dependent astrophysical process that govern the accumulation of stellar mass over the last ~10billion years, and highlight the essential need for a 10m+ class multi-object spectroscopic facility."
  },
  {
    "date": "2026-01-21",
    "title": "Say Anything but This: When Tokenizer Betrays Reasoning in LLMs",
    "authors": "Navid Ayoobi, Marcus I Armstrong, Arjun Mukherjee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14658v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) reason over discrete token ID sequences, yet modern subword tokenizers routinely produce non-unique encodings: multiple token ID sequences can detokenize to identical surface strings. This representational mismatch creates an unmeasured fragility wherein reasoning processes can fail. LLMs may treat two internal representations as distinct \"words\" even when they are semantically identical at the text level. In this work, we show that tokenization can betray LLM reasoning through one-to-many token ID mappings. We introduce a tokenization-consistency probe that requires models to replace designated target words in context while leaving all other content unchanged. The task is intentionally simple at the surface level, enabling us to attribute failures to tokenizer-detokenizer artifacts rather than to knowledge gaps or parameter limitations. Through analysis of over 11000 replacement trials across state-of-the-art open-source LLMs, we find a non-trivial rate of outputs exhibit phantom edits: cases where models operate under the illusion of correct reasoning, a phenomenon arising from tokenizer-induced representational defects. We further analyze these cases and provide a taxonomy of eight systematic tokenizer artifacts, including whitespace-boundary shifts and intra-word resegmentation. These findings indicate that part of apparent reasoning deficiency originates in the tokenizer layer, motivating tokenizer-level remedies before incurring the cost of training ever-larger models on ever-larger corpora."
  },
  {
    "date": "2026-01-21",
    "title": "Dosimetry for Proton Therapy Using a β-Ga$_2$O$_3$ Metal-Semiconductor-Metal Detector with Low-Noise Amplification",
    "authors": "Hunter D. Ellis, Ajayvarman Mallapillai, Jared Miller, Imteaz Rahaman, Botong Li, Vikren Sarkar, Kai Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14654v1",
    "source": "arXiv",
    "abstract": "Intensity-modulated proton therapy (IMPT) employs proton radiation rather than conventional X-rays to treat cancerous tumors. This approach offers significant advantages by minimizing the radiation exposure of surrounding healthy tissue, leading to improved patient outcomes and reduced side effects compared to traditional X-ray therapy. To ensure patient safety, each treatment plan must be experimentally validated before clinical implementation. However, current dosimetry devices face limitations in performing angled beam measurements and obtaining multi-depth assessments, both of which are essential for verifying IMPT treatment plans. In this study, the performance of a β-Ga$_2$O$_3$-based metal-semiconductor-metal (MSM) detector with a low-noise amplifier is studied and evaluated under various proton radiation doses and energy levels delivered by a MEVION S250i proton accelerator. The detector performance is also compared with that of an ionization chamber. The β-Ga$_2$O$_3$ detector exhibits a linear response with proton dose for single-spot irradiations, and its response to varying proton energies closely matches both the ion chamber data and simulated dose distributions. These findings highlight the potential of β-Ga$_2$O$_3$-based detectors as robust dosimetry devices for IMPT applications."
  },
  {
    "date": "2026-01-21",
    "title": "MAS-Orchestra: Understanding and Improving Multi-Agent Reasoning Through Holistic Orchestration and Controlled Benchmarks",
    "authors": "Zixuan Ke, Yifei Ming, Austin Xu, Ryan Chin, Xuan-Phi Nguyen, Prathyusha Jwalapuram, Semih Yavuz, Caiming Xiong, Shafiq Joty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14652v1",
    "source": "arXiv",
    "abstract": "While multi-agent systems (MAS) promise elevated intelligence through coordination of agents, current approaches to automatic MAS design under-deliver. Such shortcomings stem from two key factors: (1) methodological complexity - agent orchestration is performed using sequential, code-level execution that limits global system-level holistic reasoning and scales poorly with agent complexity - and (2) efficacy uncertainty - MAS are deployed without understanding if there are tangible benefits compared to single-agent systems (SAS). We propose MAS-Orchestra, a training-time framework that formulates MAS orchestration as a function-calling reinforcement learning problem with holistic orchestration, generating an entire MAS at once. In MAS-Orchestra, complex, goal-oriented sub-agents are abstracted as callable functions, enabling global reasoning over system structure while hiding internal execution details. To rigorously study when and why MAS are beneficial, we introduce MASBENCH, a controlled benchmark that characterizes tasks along five axes: Depth, Horizon, Breadth, Parallel, and Robustness. Our analysis reveals that MAS gains depend critically on task structure, verification protocols, and the capabilities of both orchestrator and sub-agents, rather than holding universally. Guided by these insights, MAS-Orchestra achieves consistent improvements on public benchmarks including mathematical reasoning, multi-hop QA, and search-based QA. Together, MAS-Orchestra and MASBENCH enable better training and understanding of MAS in the pursuit of multi-agent intelligence."
  },
  {
    "date": "2026-01-21",
    "title": "Experimental Performance of Bidirectional Phase Coherent Transmission and Sensing for mmWave Cell-free Massive MIMO Systems with Reciprocity Calibration",
    "authors": "Qingji Jiang, Jing jin, Qixing Wang, Yuanyuan Tang, Yang Cao, Bin Kuang, Jing Dong, Siying Lv, Dongming Wang, Yongming Huang, Jiangzhou Wang, Xiaohu You",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14648v1",
    "source": "arXiv",
    "abstract": "Phase synchronization among distributed transmission reception points (TRPs) is a prerequisite for enabling coherent joint transmission and high-precision sensing in millimeter wave (mmWave) cell-free massive multiple-input and multiple-output (MIMO) systems. This paper proposes a bidirectional calibration scheme and a calibration coefficient estimation method for phase synchronization, and presents a calibration coefficient phase tracking method using unilateral uplink/downlink channel state information (CSI). Furthermore, this paper introduces the use of reciprocity calibration to eliminate non-ideal factors in sensing and leverages sensing results to achieve calibration coefficient phase tracking in dynamic scenarios, thus enabling bidirectional empowerment of both communication and sensing. Simulation results demonstrate that the proposed method can effectively implement reciprocal calibration with lower overhead, enabling coherent collaborative transmission, and resolving non-ideal factors to acquire lower sensing error in sensing applications. Experimental results show that, in the mmWave band, over-the-air (OTA) bidirectional calibration enables coherent collaborative transmission for both collaborative TRPs and collaborative user equipments (UEs), achieving beamforming gain and long-time coherent sensing capabilities."
  },
  {
    "date": "2026-01-21",
    "title": "Boundary Disintegration for Weighted Residual Energy Trees",
    "authors": "James Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14646v1",
    "source": "arXiv",
    "abstract": "We study iterated weighted residual (WR) splittings generated by a positive operator $R_{0}\\in B\\left(H\\right)_{+}$ and a finite family of contractions $C_{1},\\dots,C_{m}$ in $B\\left(H\\right)$. The associated residual update $R\\mapsto R^{1/2}(I-C^{*}_{j}C_{j})R^{1/2}$ produces an $m$-ary energy tree of residuals $\\left\\{ R_{w}\\right\\} $ and dissipated pieces $\\left\\{ D_{w,j}\\right\\} $ indexed by finite words. From this tree we construct intrinsic path measures on the path space by biasing transitions either by a fixed quadratic form $x\\mapsto\\left\\langle x,D_{w,j}x\\right\\rangle $ (defining the measures $ν_{x}$) or, in the trace-class setting, by ${\\rm tr}\\left(D_{w,j}\\right)$ (yielding a reference measure $ν_{\\mathrm{tr}}$). When $R_{0}\\in S_{1}\\left(H\\right)_{+}$, we show that $ν_{\\mathrm{tr}}$ dominates the family $\\left\\{ ν_{x}\\right\\} $ and identify $dν_{x}/dν_{\\mathrm{tr}}$ as a canonical martingale limit of cylinder likelihood ratios. Along $ν_{\\mathrm{tr}}$-almost every branch the residuals decrease to a terminal trace-class random variable $R_{\\infty}$, which we interpret as the WR boundary variable. We then disintegrate $ν_{\\mathrm{tr}}$ over $σ\\left(R_{\\infty}\\right)$, obtaining a boundary law $μ_{\\mathrm{tr}}=\\left(R_{\\infty}\\right)_{\\#}ν_{\\mathrm{tr}}$ and conditional path measures $\\left\\{ ν^{T}_{\\mathrm{tr}}\\right\\} $. Finally, we show that each $ν_{x}$ admits a boundary representation as a mixture of $\\left\\{ ν^{T}_{\\mathrm{tr}}\\right\\} $ with an explicit boundary density $h_{x}=dμ_{x}/dμ_{\\mathrm{tr}}$, thereby organizing the family of intrinsic WR path measures by a single trace-biased boundary disintegration."
  },
  {
    "date": "2026-01-21",
    "title": "Quantum Interference Needs Convention: Overlap-Determinability and Unified No-Superposition Principle",
    "authors": "Jeongho Bang, Kyoungho Cho, Ki Hyuk Yee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14638v1",
    "source": "arXiv",
    "abstract": "Quantum superposition is often phrased as the ability to add state vectors. In practice, however, the physical quantity is a ray (a rank-one projector), so each input specifies only a projector and leaves a gauge freedom in the phases of its vector representatives. This becomes a real operational barrier when one asks for a device that, given two independently prepared unknown pure states, outputs a coherent state proportional to a prescribed linear combination. We identify the missing ingredient as not probabilistic but phase-like. One needs a physical scenario that fixes a single phase convention on the relevant set of rays, so that the overlaps become well defined complex numbers. Thus, we formalize this through phase conventions and a single notion -- dubbed as \"overlap-determinability.\" Our main theorem gives an exact equivalence: A nonzero completely positive trace-nonincreasing map that probabilistically produces superposition on a domain exists if and only if that domain is overlap-determinable. This unifies modern no-superposition results and characterizes the exceptional yes-go protocols, which succeed precisely when side information supplies the required missing resource. We then show that granting universal access to such convention-fixed overlaps destabilizes the familiar foundational and computational constraints. It enables forbidden transformations akin to quantum cloning and yields super-luminal signaling. It would also permit reflections about unknown states, leading to exponentially fast overlap amplification and a collapse of Grover's search lower bound to a logarithmic query complexity."
  },
  {
    "date": "2026-01-21",
    "title": "Relational Graph Modeling for Credit Default Prediction: Heterogeneous GNNs and Hybrid Ensemble Learning",
    "authors": "Yvonne Yang, Eranki Vasistha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14633v1",
    "source": "arXiv",
    "abstract": "Credit default risk arises from complex interactions among borrowers, financial institutions, and transaction-level behaviors. While strong tabular models remain highly competitive in credit scoring, they may fail to explicitly capture cross-entity dependencies embedded in multi-table financial histories. In this work, we construct a massive-scale heterogeneous graph containing over 31 million nodes and more than 50 million edges, integrating borrower attributes with granular transaction-level entities such as installment payments, POS cash balances, and credit card histories. We evaluate heterogeneous graph neural networks (GNNs), including heterogeneous GraphSAGE and a relation-aware attentive heterogeneous GNN, against strong tabular baselines. We find that standalone GNNs provide limited lift over a competitive gradient-boosted tree baseline, while a hybrid ensemble that augments tabular features with GNN-derived customer embeddings achieves the best overall performance, improving both ROC-AUC and PR-AUC. We further observe that contrastive pretraining can improve optimization stability but yields limited downstream gains under generic graph augmentations. Finally, we conduct structured explainability and fairness analyses to characterize how relational signals affect subgroup behavior and screening-oriented outcomes."
  },
  {
    "date": "2026-01-21",
    "title": "Maximum Edge-based Quasi-Clique: Novel Iterative Frameworks",
    "authors": "Hongbo Xia, Shengxin Liu, Zhaoquan Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14619v1",
    "source": "arXiv",
    "abstract": "Extracting cohesive subgraphs from complex networks is a fundamental task in graph analytics and is essential for understanding biological, social, and web graphs. The edge-based $γ$-quasi-clique model offers a flexible alternative by identifying subgraphs whose edge densities exceed a specified threshold $γ$. However, finding the exact maximum edge-based quasi-clique is computationally challenging, as the problem is NP-hard and lacks the hereditary property. These characteristics limit the effectiveness of conventional pruning methods and the development of efficient reduction rules. As a result, existing algorithms, such as QClique and FPCE, struggle to scale to large graphs. In this paper, we revisit the problem and propose a novel iterative framework that reformulates the problem as a sequence of hereditary subproblems, enabling more effective pruning and reduction strategies and improving the worst-case time complexity. Furthermore, we redesign the iterative process and introduce a novel heuristic to further improve practical efficiency. Extensive experiments on 253 large-scale real-world graphs demonstrate that our proposed algorithm EQC-Pro outperforms existing methods by up to four orders of magnitude."
  },
  {
    "date": "2026-01-21",
    "title": "HELIOS: Hierarchical Graph Abstraction for Structure-Aware LLM Decompilation",
    "authors": "Yonatan Gizachew Achamyeleh, Harsh Thomare, Mohammad Abdullah Al Faruque",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14598v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have recently been applied to binary decompilation, yet they still treat code as plain text and ignore the graphs that govern program control flow. This limitation often yields syntactically fragile and logically inconsistent output, especially for optimized binaries. This paper presents \\textsc{HELIOS}, a framework that reframes LLM-based decompilation as a structured reasoning task. \\textsc{HELIOS} summarizes a binary's control flow and function calls into a hierarchical text representation that spells out basic blocks, their successors, and high-level patterns such as loops and conditionals. This representation is supplied to a general-purpose LLM, along with raw decompiler output, optionally combined with a compiler-in-the-loop that returns error messages when the generated code fails to build. On HumanEval-Decompile for \\texttt{x86\\_64}, \\textsc{HELIOS} raises average object file compilability from 45.0\\% to 85.2\\% for Gemini~2.0 and from 71.4\\% to 89.6\\% for GPT-4.1~Mini. With compiler feedback, compilability exceeds 94\\% and functional correctness improves by up to 5.6 percentage points over text-only prompting. Across six architectures drawn from x86, ARM, and MIPS, \\textsc{HELIOS} reduces the spread in functional correctness while keeping syntactic correctness consistently high, all without fine-tuning. These properties make \\textsc{HELIOS} a practical building block for reverse engineering workflows in security settings where analysts need recompilable, semantically faithful code across diverse hardware targets."
  },
  {
    "date": "2026-01-21",
    "title": "LFS: Learnable Frame Selector for Event-Aware and Temporally Diverse Video Captioning",
    "authors": "Lianying Chao, Linfeng Yin, Peiyu Ren, Yifan Jiang, Qiaoyu Ren, Dingcheng Shan, Jing-cheng Pang, Sijie Wu, Xubin Li, Kai Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14594v1",
    "source": "arXiv",
    "abstract": "Video captioning models convert frames into visual tokens and generate descriptions with large language models (LLMs). Since encoding all frames is prohibitively expensive, uniform sampling is the default choice, but it enforces equal temporal coverage while ignoring the uneven events distribution. This motivates a Learnable Frame Selector (LFS) that selects temporally diverse and event-relevant frames. LFS explicitly models temporal importance to balance temporal diversity and event relevance, and employs a stratified strategy to ensure temporal coverage while avoiding clustering. Crucially, LFS leverages caption feedback from frozen video-LLMs to learn frame selection that directly optimizes downstream caption quality. Additionally, we identify the gap between existing benchmark and human's cognition. Thus, we introduce ICH-CC built from carefully designed questions by annotators that reflect human-consistent understanding of video. Experiments indicate that LFS consistently improves detailed video captioning across two representative community benchmarks and ICH-CC, achieving up to 2.0% gains on VDC and over 4% gains on ICH-CC. Moreover, we observe that enhanced captions with LFS leads to improved performance on video question answering. Overall, LFS provides an effective and easy-to-integrate solution for detailed video captioning."
  },
  {
    "date": "2026-01-21",
    "title": "Uniqueness of Ground State Solutions for a Defocusing Hartree Equation via Inverse Optimal Problems",
    "authors": "Yavdat Il'yasov, Juntao Sun, Nur Valeev, Shuai Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14591v1",
    "source": "arXiv",
    "abstract": "We study a generalized defocusing Hartree equation with nonlocal exchange potential and repulsive Hartree--Fock interaction. Using an inverse optimal problem (IOP) approach, we prove the existence and uniqueness of ground state solutions. Additionally, we establish the existence of principal solutions, their continuous dependence on parameters, and a dual variational formulation. The IOP method provides a systematic framework for addressing inverse problems in nonlocal Schrödinger operators and offers new insights into the structure of solutions for defocusing Hartree-type equations."
  },
  {
    "date": "2026-01-21",
    "title": "Counterfactual Modeling with Fine-Tuned LLMs for Health Intervention Design and Sensor Data Augmentation",
    "authors": "Shovito Barua Soumma, Asiful Arefeen, Stephanie M. Carpenter, Melanie Hingle, Hassan Ghasemzadeh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14590v1",
    "source": "arXiv",
    "abstract": "Counterfactual explanations (CFEs) provide human-centric interpretability by identifying the minimal, actionable changes required to alter a machine learning model's prediction. Therefore, CFs can be used as (i) interventions for abnormality prevention and (ii) augmented data for training robust models. We conduct a comprehensive evaluation of CF generation using large language models (LLMs), including GPT-4 (zero-shot and few-shot) and two open-source models-BioMistral-7B and LLaMA-3.1-8B, in both pretrained and fine-tuned configurations. Using the multimodal AI-READI clinical dataset, we assess CFs across three dimensions: intervention quality, feature diversity, and augmentation effectiveness. Fine-tuned LLMs, particularly LLaMA-3.1-8B, produce CFs with high plausibility (up to 99%), strong validity (up to 0.99), and realistic, behaviorally modifiable feature adjustments. When used for data augmentation under controlled label-scarcity settings, LLM-generated CFs substantially restore classifier performance, yielding an average 20% F1 recovery across three scarcity scenarios. Compared with optimization-based baselines such as DiCE, CFNOW, and NICE, LLMs offer a flexible, model-agnostic approach that generates more clinically actionable and semantically coherent counterfactuals. Overall, this work demonstrates the promise of LLM-driven counterfactuals for both interpretable intervention design and data-efficient model training in sensor-based digital health. Impact: SenseCF fine-tunes an LLM to generate valid, representative counterfactual explanations and supplement minority class in an imbalanced dataset for improving model training and boosting model robustness and predictive performance"
  },
  {
    "date": "2026-01-21",
    "title": "Designing KRIYA: An AI Companion for Wellbeing Self-Reflection",
    "authors": "Shanshan Zhu, Wenxuan Song, Jiayue Melissa Shi, Dong Whi Yoo, Karthik S. Bhat, Koustuv Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14589v1",
    "source": "arXiv",
    "abstract": "Most personal wellbeing apps present summative dashboards of health and physical activity metrics, yet many users struggle to translate this information into meaningful understanding. These apps commonly support engagement through goals, reminders, and structured targets, which can reinforce comparison, judgment, and performance anxiety. To explore a complementary approach that prioritizes self-reflection, we design KRIYA, an AI wellbeing companion that supports co-interpretive engagement with personal wellbeing data. KRIYA aims to collaborate with users to explore questions, explanations, and future scenarios through features such as Comfort Zone, Detective Mode, and What-If Planning. We conducted semi-structured interviews with 18 college students interacting with a KRIYA prototype using hypothetical data. Our findings show that through KRIYA interaction, users framed engaging with wellbeing data as interpretation rather than performance, experienced reflection as supportive or pressuring depending on emotional framing, and developed trust through transparency. We discuss design implications for AI companions that support curiosity, self-compassion, and reflective sensemaking of personal health data."
  },
  {
    "date": "2026-01-21",
    "title": "Cluster size distributions of discrete random fields",
    "authors": "Dan Cheng, John Ginos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14586v1",
    "source": "arXiv",
    "abstract": "We study discrete random fields $\\{X_t: t\\in \\mathbb{Z}^d\\}$ parameterized on the $d$-dimensional integer lattice $\\mathbb{Z}^d$. For a fixed threshold $u$, the excursion set $\\{t \\in \\mathbb{Z}^d : X_t > u\\}$ decomposes into connected components or clusters, whose size, defined as the number of lattice points they contain, are random. This paper investigates the probability distribution of these cluster sizes. For stationary random fields, we derive exact expressions for the cluster size distribution. To address nonstationary settings, we introduce a peak-based cluster size distribution, which characterizes the distribution of cluster sizes conditional on the presence of a local maximum above $u$. This formulation provides a tractable alternative when exact cluster size distributions are analytically inaccessible. The proposed framework applies broadly to Gaussian and non-Gaussian random fields, relying only on their joint dependence structure. Our results provide a theoretical foundation for quantifying spatial extent in discretely sampled data, with applications to medical imaging, geoscience, environmental monitoring, and other scientific areas where thresholded random fields naturally arise."
  },
  {
    "date": "2026-01-21",
    "title": "Two-port CW measurements on RF cavities: Notes on self-consistency assessment and indirect methods",
    "authors": "Walter H. Hartung, Wei Chang, Sang-Hoon Kim, Taro Konomi, Ting Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14583v1",
    "source": "arXiv",
    "abstract": "In the case of a radio-frequency (RF) cavity with a mismatched input coupler, a direct calculation of the power dissipation in the cavity and the intrinsic quality factor from continuous-wave (CW) measurements may have uncertainty due to systematic errors. Formulae for an indirect calculation of these quantities are derived for the case of a cavity with two couplers of fixed coupling strength. In this approach, the signal from the pickup coupler is used to infer the amplitude of the \"emitted wave\" from the input coupler. A graphical method for self-consistency assessment is evaluated. The impact of frequency offsets is considered. Applications of these methods are presented, drawing on cold tests of superconducting cavities produced for the Facility for Rare Isotope Beams."
  },
  {
    "date": "2026-01-21",
    "title": "Nanodroplet-Confined Electroplating Enables Submicron Printing of Metals and Oxide Ceramics",
    "authors": "Mirco Nydegger, Rebecca A. Gallivan, Arthur Barras, Henning Galinski, Ralph Spolenak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14576v1",
    "source": "arXiv",
    "abstract": "The fabrication of functional micro- and nano-electronic devices requires the deposition of high-quality materials of different electronic material classes, such as conductors, semiconductors and insulators. To establish ultra-high-resolution additive manufacturing as a viable addition to existing fabrication methods requires the combinatorial additive deposition of different electronic material classes. However, current techniques do not provide such a capability. Here, we demonstrate that droplet confined electroplating, an ultra-high-resolution AM technique initially developed for metals as electrohydrodynamic redox printing (EHD-RP), allows not only the direct deposition of many metals, but also of metal-oxides. Particularly, we demonstrate that applying fundamental electrochemical principles in combination with on-the-fly switching of the deposited material allows for the direct co-deposition of metals, metal-hydroxides and -oxides. Our results exemplify the feasibility of leveraging simple water-based electrochemical concepts to produce intricate and multi-material structures at the nanoscale."
  },
  {
    "date": "2026-01-21",
    "title": "Possible Existence of $^3_φ$H, $^4_φ$H, $^4_φ$He, and $^5_φ$He Nuclei",
    "authors": "Rimantas Lazauskas, Roman Ya. Kezerashvili, Igor Filikhin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14572v1",
    "source": "arXiv",
    "abstract": "Motivated by recent HAL QCD simulations of the $φN$ interaction in the $^4S_{3/2}$ channel and its modification in the $^2S_{1/2}$ channel, we develop a first-principles few-body framework that embeds these potentials into configuration-space Faddeev--Yakubovsky equations. We predict bound $^4_φ\\mathrm{H}$, $^4_φ\\mathrm{He}$, and $^5_φ\\mathrm{He}$ nuclei by performing calculations for $φ$-mesic $φNNN$ and $φNNNN$ systems. Both spin-dependent and spin-independent $φN$ interactions are considered, leading to deeply and moderately bound states, respectively. The deeply bound states originate from the strong attraction in the $^2S_{1/2}$ $φN$ channel. Coulomb shifts of the binding energies are evaluated. Our findings provide the binding mechanism and demonstrate the importance of short-range $φN$ attraction."
  },
  {
    "date": "2026-01-21",
    "title": "Social Caption: Evaluating Social Understanding in Multimodal Models",
    "authors": "Bhaavanaa Thumu, Leena Mathur, Youssouf Kebe, Louis-Philippe Morency",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14569v1",
    "source": "arXiv",
    "abstract": "Social understanding abilities are crucial for multimodal large language models (MLLMs) to interpret human social interactions. We introduce Social Caption, a framework grounded in interaction theory to evaluate social understanding abilities of MLLMs along three dimensions: Social Inference (SI), the ability to make accurate inferences about interactions; Holistic Social Analysis (HSA), the ability to generate comprehensive descriptions of interactions; Directed Social Analysis (DSA), the ability to extract relevant social information from interactions. We analyze factors influencing model performance in social understanding, such as scale, architectural design, and spoken context. Experiments with MLLM judges contribute insights about scaling automated evaluation of multimodal social understanding."
  },
  {
    "date": "2026-01-21",
    "title": "Breaking the accuracy-resource dilemma: a lightweight adaptive video inference enhancement",
    "authors": "Wei Ma, Shaowu Chen, Junjie Ye, Peichang Zhang, Lei Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14568v1",
    "source": "arXiv",
    "abstract": "Existing video inference (VI) enhancement methods typically aim to improve performance by scaling up model sizes and employing sophisticated network architectures. While these approaches demonstrated state-of-the-art performance, they often overlooked the trade-off of resource efficiency and inference effectiveness, leading to inefficient resource utilization and suboptimal inference performance. To address this problem, a fuzzy controller (FC-r) is developed based on key system parameters and inference-related metrics. Guided by the FC-r, a VI enhancement framework is proposed, where the spatiotemporal correlation of targets across adjacent video frames is leveraged. Given the real-time resource conditions of the target device, the framework can dynamically switch between models of varying scales during VI. Experimental results demonstrate that the proposed method effectively achieves a balance between resource utilization and inference performance."
  },
  {
    "date": "2026-01-21",
    "title": "Analysis of Stakeholder Involvement in Nuclear Power Plant Cost Overruns and Implications for Contract Structuring",
    "authors": "Christopher Forsyth, Levi M. Larsen, Ryan Spangler, Chandu Bolisetti, Jason Hansen, Botros Hanna, Abdalla Abou-Jaoude, Jia Zhou, Koroush Shirvan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14558v1",
    "source": "arXiv",
    "abstract": "This study introduces a novel framework to model cost overruns associated with four key stakeholders in nuclear power plant construction: equipment suppliers, construction subcontractors, the design and management team, and creditors. The framework estimates the share of overruns caused by each stakeholder and the share of overruns they receive as payment. The results show that the share of cost overruns a given stakeholder causes and the share of overruns they receive as payment are often starkly different, which can lead to profit misallocations and litigation between parties, further exacerbating overruns. The magnitude of these potential profit misallocations is examined under three common contract structures - fixed-price, cost-plus, and performance-based - revealing the advantages and disadvantages of each framework for aligning stakeholder incentives. Regardless of the contract type chosen, strong owner involvement is crucial for project success, and the study concludes with specific recommendations for project owners seeking to minimize cost overruns."
  },
  {
    "date": "2026-01-21",
    "title": "The baryonic mass-size relation of galaxies. II. Implications for the evolutionary paths between star-forming and passive galaxies",
    "authors": "Zichen Hua, Lelli Federico, Enrico Di Teodoro, Stacy McGaugh, James Schombert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15274v1",
    "source": "arXiv",
    "abstract": "The baryonic mass-size relation of galaxies links the total baryonic mass (stars plus gas) to the baryonic half-mass radius. In the first paper of this series, we showed that star-forming galaxies from the SPARC sample follow two distinct relations in the baryonic mass-size plane: one defined by high-surface-density (HSD), star-dominated, Sa-to-Sc galaxies, and one defined by low-surface-density (LSD), gas-dominated, Sd-to-dI galaxies. In this second paper, we study the structural relations between baryonic mass, half-mass radius, and mean surface density to constrain possible morphological transformations between star-forming and passive galaxies. We complemented the SPARC sample with $\\sim$1200 passive galaxies that are nearly devoid of gas: ellipticals (Es), lenticulars (S0s), dwarf ellipticals (dEs) or dwarf spheroidals (dSphs), and the so-called `ultra-diffuse galaxies' (UDGs). Our results can be summarised as follows: (1) passive stellar components follow four distinct relations at high statistical significance, namely (i) ellipticals plus bulges, (ii) S0 disks, (iii) non-nucleated dwarfs (dEs, dSphs, UDGs), and (iv) nucleated dEs; (2) star-forming HSD disks (mostly Sa to Sc) overlap with S0 disks within 2$σ$ in the baryonic relations and within 1$σ$ in the stellar ones, so present-day spirals may simply evolve into lenticulars as they run out of gas; (3) star-forming LSD disks (mostly Sd to dI) are offset from non-nucleated passive dwarfs at more than 3$σ$ in the baryonic relations, but the two galaxy populations overlap within 1$σ$ in the stellar relations, suggesting that non-nucleated passive dwarfs may form from star-forming dwarfs only after gas removal; (4) UDGs extend the sequence of non-nucleated dEs/dSphs and may originate from the most diffuse star-forming LSD galaxies with no need for a substantial expansion of the stellar component."
  },
  {
    "date": "2026-01-21",
    "title": "Center-preserving irreducible representations of finite groups",
    "authors": "Pierre-Emmanuel Caprace, Geoffrey Janssens, François Thilmany",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15266v1",
    "source": "arXiv",
    "abstract": "Given finite groups $H \\leq G$, a representation $σ$ of $G$ is called center-preserving on $H$ if the only elements of $H$ that become central under $σ$ are those that were already central in $G$. We prove that if $H$ has a faithful irreducible representation $ρ$, then at least one of the irreducible components of the induction $\\operatorname{Ind}_H^G(ρ)$ is center-preserving on $H$. In consequence, $H$ has a faithful irreducible representation if and only if every finite group $G$ containing $H$ as a subgroup has an irreducible representation whose restriction to $H$ is faithful, and which is center-preserving on $H$. In addition, we give examples illustrating the sharpness of the statement, and discuss the connection with projective representations."
  },
  {
    "date": "2026-01-21",
    "title": "Superluminal Transformations and Indeterminism",
    "authors": "Amrapali Sen, Flavio Del Santo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15263v1",
    "source": "arXiv",
    "abstract": "Quantum theory is widely regarded as fundamentally indeterministic, yet classical frameworks can also exhibit indeterminism once infinite information is abandoned. At the same time, relativity is usually taken to forbid superluminal signalling, yet Lorentz symmetry formally admits superluminal transformations (SpTs). Dragan and Ekert have argued that SpTs entail indeterminism analogous to the quantum one. Here, we derive a no-go theorem from natural assumptions, which can be interpreted as: superluminal transformations (SpTs) and finite information cannot coexist. Any theory accommodating SpTs must therefore allow unbounded information content, leading to a deterministic ontology akin to that of classical theories formulated over the real numbers. Thus, any apparent indeterminism arising from superluminal transformations reflects only probabilities arising from subjective ignorance, unlike the objective nature of probabilities in quantum theory, indicating that the claimed indeterminacy from superluminal extensions is not quantum."
  },
  {
    "date": "2026-01-21",
    "title": "DAMSA Experiment Conceptual Design White Paper",
    "authors": "Prithak Bhattarai, Andrew Brandt, Alan Bross, Bradley Brown, Samriddha Chakraborty, Bhupal Dev, Bhaskar Dutta, Juan V. Estrada, Eric Garcia, Anthony Gomez, Gajendra Gurung, Brian Joshua Gomez Hernandez, Wooyoung Jang, Jay Hyun Jo, Doojin Kim, Eunsu Kim, Hyunyong Kim, Shin Hyung Kim, Young-Kee Kim, Jing Liu, Chang-Seong Moon, Donna Naples, David Nygren, Minseok Oh, Vittorio Paolone, Hyangkyu Park, Jong-Chul Park, Nathaniel J. Pastika, Rohit Raut, Juergen Reichenbacher, Paul Rubinov, Eunsuk Seo, Veronika Shalamova, Seodong Shin, Melvin Shochet, Adrian Thompson, Yau Wah, Shawn Westerdale, Guang Yang, Un-Ki Yang, Inseok Yoon, Jaehoon Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15255v1",
    "source": "arXiv",
    "abstract": "DAMSA (DArk Messenger Searches at an Accelerator) is a novel short-baseline accelerator experiment aimed at probing short-lived physics processes, including searches for evidence of a dark sector of particle physics and well-motivated Standard Model signals. Motivated by open questions in neutrino physics and the absence of conclusive evidence for conventional weakly interacting massive particles, DAMSA targets MeV-to-sub-GeV dark-sector messengers with feeble couplings that can be produced in abundance at the PIP-II LINAC. By employing an ultra-short baseline of order one meter, DAMSA is uniquely positioned to overcome the beam-dump \"ceiling\" that limits sensitivity to promptly decaying particles in longer-baseline experiments. The conceptual design emphasizes a beam-dump production scheme combined with a compact detector optimized for rare decays while mitigating intense neutron-induced backgrounds inherent to high-power proton beams. To validate the experimental strategy and detector technologies, the Little DAMSA Path-Finder (LDPF) proof-of-concept experiment is proposed, focusing on axion-like particles decaying to two photons and operating with 300 MeV electron beams at FAST. Successful realization of LDPF will establish the feasibility of the DAMSA approach, enabling a broad and powerful program to explore short-lived new physics and precision Standard Model processes in a previously inaccessible regime. This conceptual design document outlines the technical details of DAMSA's physics goals, the beam facility proposals, key experimental challenges and how to overcome them, and the proposed experimental staging campaigns."
  },
  {
    "date": "2026-01-21",
    "title": "The Wahl map of the normalization of nodal curves on Hirzebruch surfaces",
    "authors": "Miguel Guerrero-Castillo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15244v1",
    "source": "arXiv",
    "abstract": "In this paper we study the Wahl map for the normalization of a $δ$-nodal curve $C$ on a Hirzebruch surface $\\mathbb{F}_{n}$ for $n\\geq 0$. Let $σ:X\\rightarrow \\mathbb{F}_{n}$ be the blow up of $\\mathbb{F}_{n}$ along the $δ$ nodes of $C$ and let $\\widetilde{C}$ be the normalization of $C$ under $σ$. Let $K_{X}$ be the canonical bundle of $X$ and let $Ω^{1}_{X}$ be the sheaf of $1$-holomorphic forms on $X$. We give conditions for the surjectivity of the map $Φ_{X,\\mathcal{O}_{X}(K_{X}+\\widetilde{C})}: \\bigwedge^{2}H^{0}(X,\\mathcal{O}_{X}(K_{X}+\\widetilde{C}))\\rightarrow H^{0}(X,Ω^{1}_{X}(2K_{X}+2\\widetilde{C}))$. Using this surjectivity, we analyze the Wahl map $Φ_{\\widetilde{C}}:\\bigwedge^{2}H^{0}(\\widetilde{C},Ω^{1}_{\\widetilde{C}})\\rightarrow H^{0}(\\widetilde{C},(Ω^{1}_{\\widetilde{C}})^{\\otimes 3})$ and compute the corank of $Φ_{\\widetilde{C}}$ in various cases. We prove that the corank of the Wahl map for the normalization of a $δ$-nodal curve on $\\mathbb{F}_{n}$ is $h^{0}(\\mathbb{F}_{n},\\mathcal{O}_{\\mathbb{F}_{n}}(-K_{\\mathbb{F}_{n}}))$, that verifies a conjecture by Wahl. Furthermore, as an application of our results, we demonstrate that, under certain conditions, a $δ$-nodal curve on a Hirzebruch surface $\\mathbb{F}_{n}$ cannot be embedded as $δ-$nodal curve on a different Hirzebruch surface $\\mathbb{F}_{m}$, for $n\\neq m$."
  },
  {
    "date": "2026-01-21",
    "title": "Elementary excitations in dilute gases",
    "authors": "Jaeyun Moon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15233v1",
    "source": "arXiv",
    "abstract": "In solids, elementary excitations of atomic vibrations are identified in reciprocal space by their frequency and wavevector as phonons. At the opposite end of the matter spectrum, dynamics of dilute gases is conventionally described in terms of atomic or molecular collisions and translations in real space and time. These two formalisms are apparently incompatible, leading to difficulties in understanding atomic dynamics in intermediate matter. In this work, we demonstrate that normal modes, often synonymously considered as phonons in solids, provide a microscopic description of various transport processes, including thermal conductivity, diffusion coefficient, and shear viscosity, in a prototypical dilute gas, argon. Our results reveal that normal modes constitute elementary excitations in dilute gases, extending their physical relevance far beyond vibrational excitations in solids."
  },
  {
    "date": "2026-01-21",
    "title": "Privacy Collapse: Benign Fine-Tuning Can Break Contextual Privacy in Language Models",
    "authors": "Anmol Goel, Cornelius Emde, Sangdoo Yun, Seong Joon Oh, Martin Gubri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15220v1",
    "source": "arXiv",
    "abstract": "We identify a novel phenomenon in language models: benign fine-tuning of frontier models can lead to privacy collapse. We find that diverse, subtle patterns in training data can degrade contextual privacy, including optimisation for helpfulness, exposure to user information, emotional and subjective dialogue, and debugging code printing internal variables, among others. Fine-tuned models lose their ability to reason about contextual privacy norms, share information inappropriately with tools, and violate memory boundaries across contexts. Privacy collapse is a ``silent failure'' because models maintain high performance on standard safety and utility benchmarks whilst exhibiting severe privacy vulnerabilities. Our experiments show evidence of privacy collapse across six models (closed and open weight), five fine-tuning datasets (real-world and controlled data), and two task categories (agentic and memory-based). Our mechanistic analysis reveals that privacy representations are uniquely fragile to fine-tuning, compared to task-relevant features which are preserved. Our results reveal a critical gap in current safety evaluations, in particular for the deployment of specialised agents."
  },
  {
    "date": "2026-01-21",
    "title": "Bigraph independence : a mixture of the five natural independences",
    "authors": "Nicolas Gilliers, David Jekel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15215v1",
    "source": "arXiv",
    "abstract": "We introduce a notion of non-commutative joint independence for multiple algebras in a non-commutative probability space. The pairwise relationships between these algebras are encoded by a graph with two edge sets -- a combinatorial structure we call a bigraph -- and naturally encompass the five fundamental types of independence: tensor, free, (anti)monotone, and Boolean. It subsumes the BMT independence of Arizmendi--Mendoza--Vazquez-Becerra (when all pairwise relationships are Boolean, (anti)monotone, or tensor) and the $ε$ or $Λ$-independence of Mlotkowski (when the pairwise relationships are tensor and free). We present explicit combinatorial moment formulas, a Hilbert space construction, and natural associativity relations within this setting. Furthermore, we demonstrate that bigraph independence emerges in the asymptotic behavior of tensor product random matrix models with respect to a vector state, encompassing the Charlesworth--Collins model for $\\varepsilon$-independence as a special case and offering a random matrix perspective on BMT independence."
  },
  {
    "date": "2026-01-21",
    "title": "A Complete Propositional Dynamic Logic for Regular Expressions with Lookahead",
    "authors": "Yoshiki Nakamura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15214v1",
    "source": "arXiv",
    "abstract": "We consider (logical) reasoning for regular expressions with lookahead (REwLA). In this paper, we give an axiomatic characterization for both the (match-)language equivalence and the largest substitution-closed equivalence that is sound for the (match-)language equivalence. To achieve this, we introduce a variant of propositional dynamic logic (PDL) on finite linear orders, extended with two operators: the restriction to the identity relation and the restriction to its complement. Our main contribution is a sound and complete Hilbert-style finite axiomatization for the logic, which captures the equivalences of REwLA. Using the extended operators, the completeness is established via a reduction into an identity-free variant of PDL on finite strict linear orders. Moreover, the extended PDL has the same computational complexity as REwLA."
  },
  {
    "date": "2026-01-21",
    "title": "ZENITH: Automated Gradient Norm Informed Stochastic Optimization",
    "authors": "Dhrubo Saha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15212v1",
    "source": "arXiv",
    "abstract": "Training deep computer vision models requires manual oversight or hyperparameter tuning of the learning rate (LR) schedule. While existing adaptive optimizers schedule the LR automatically, they suffer from computational and memory overhead, incompatibility with regularization, and suboptimal LR choices. In this work, we introduce the ZENITH (Zero-overhead Evolution using Norm-Informed Training History) optimizer, which adapts the LR using the temporal evolution of the gradient norm. Image classification experiments spanning 6 CNN architectures and 6 benchmarks demonstrate that ZENITH achieves higher test accuracy in lower wall-clock time than baselines. It also yielded superior mAP in object detection, keypoint detection, and instance segmentation on MS COCO using the R-CNN family of models. Furthermore, its compatibility with regularization enables even better generalization."
  },
  {
    "date": "2026-01-21",
    "title": "Enhanced posterior sampling via diffusion models for efficient metasurfaces inverse design",
    "authors": "Mathys Le Grand, Pascal Urard, Denis Rideau, Loumi Trémas, Damien Maitre, Louis-Henri Fernandez-Mouron, Adam Fuchs, Régis Orobtchouk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15210v1",
    "source": "arXiv",
    "abstract": "The inverse design of metasurfaces faces inherent challenges due to the nonlinear and highly complex relationship between geometric configurations and their electromagnetic behavior. Traditional optimization approaches often suffer from excessive computational demands and a tendency to converge to suboptimal solutions. This study presents a diffusion-based generative framework that incorporates a dedicated consistency constraint and advanced posterior sampling methods to ensure adherence to desired electromagnetic specifications. Through rigorous validation on small-scale metasurface configurations, the proposed approach demonstrates marked enhancements in both accuracy and reliability of the generated designs.Furthermore, we introduce a scalable methodology that extends inverse design capabilities to large-scale metasurfaces, validated for configurations of up to $98 \\times 98$ nanopillars. Notably, this approach enables rapid design generation completed in minute by leveraging models trained on substantially smaller arrays ($23 \\times 23$). These innovations establish a robust and efficient framework for high-precision metasurface inverse design."
  },
  {
    "date": "2026-01-21",
    "title": "Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface",
    "authors": "Paige S. DeVries, Michaela Okosi, Ming Li, Nora Dunphy. Gidey Gezae, Dante Conway, Abraham Glasser, Raja Kushalnagar, Christian Vogler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15209v1",
    "source": "arXiv",
    "abstract": "We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken English; with Alexa's automatic speech recognition and a Wizard-of-Oz setting with a trained facilitator re-speaking commands against that of a large language model (LLM)-assisted touch interface in a mixed-methods study. The touch method was navigated through an LLM-powered \"task prompter,\" which integrated the user's history and smart environment to suggest contextually-appropriate commands. Quantitative results showed no significant differences across both spoken English conditions vs LLM-assisted touch. Qualitative results showed variability in opinions on the usability of each method. Ultimately, it will be necessary to have robust deaf-accented speech recognized natively by IPAs."
  },
  {
    "date": "2026-01-21",
    "title": "Beyond the Geometric Curse: High-Dimensional N-Gram Hashing for Dense Retrieval",
    "authors": "Sangeet Sharma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15205v1",
    "source": "arXiv",
    "abstract": "Why do even the most powerful 7B-parameter embedding models struggle with simple retrieval tasks that the decades old BM25 handles with ease? Recent theory suggests that this happens because of a dimensionality bottleneck. This occurs when we force infinite linguistic nuances into small, fixed-length learned vectors. We developed NUMEN to break this bottleneck by removing the learning process entirely. Instead of training heavy layers to map text to a constrained space, NUMEN uses deterministic character hashing to project language directly onto high-dimensional vectors. This approach requires no training, supports an unlimited vocabulary, and allows the geometric capacity scale as needed. On the LIMIT benchmark, NUMEN achieves 93.90 % Recall@100 at 32,768 dimensions. This makes it the first dense retrieval model to officially surpass the sparse BM25 baseline 93.6 %. Our findings show that the real problem in dense retrieval isn't the architecture, but the embedding layer itself. The solution isn't necessarily smarter training, but simply providing more room to breathe."
  },
  {
    "date": "2026-01-21",
    "title": "Effects of massive spin-2 fields on gravitational wave propagation",
    "authors": "Jose A. R. Cembranos, Álvaro Cendal, Hector Villarrubia-Rojo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15201v1",
    "source": "arXiv",
    "abstract": "Massive spin-2 fields in addition to the standard massless graviton arise naturally in extensions of General Relativity, such as massive bigravity or models with extra dimensions. This work explores the observational signatures of these fields on the propagation of gravitational waves. Adopting a phenomenological framework consistent with such theories, we derive an analytical transfer function in the ultrarelativistic limit and establish detectability bounds. Finally, we provide forecasts for the accessible parameter space using current and future gravitational wave detectors."
  },
  {
    "date": "2026-01-21",
    "title": "BBoxMaskPose v2: Expanding Mutual Conditioning to 3D",
    "authors": "Miroslav Purkrabek, Constantin Kolomiiets, Jiri Matas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15200v1",
    "source": "arXiv",
    "abstract": "Most 2D human pose estimation benchmarks are nearly saturated, with the exception of crowded scenes. We introduce PMPose, a top-down 2D pose estimator that incorporates the probabilistic formulation and the mask-conditioning. PMPose improves crowded pose estimation without sacrificing performance on standard scenes. Building on this, we present BBoxMaskPose v2 (BMPv2) integrating PMPose and an enhanced SAM-based mask refinement module. BMPv2 surpasses state-of-the-art by 1.5 average precision (AP) points on COCO and 6 AP points on OCHuman, becoming the first method to exceed 50 AP on OCHuman. We demonstrate that BMP's 2D prompting of 3D model improves 3D pose estimation in crowded scenes and that advances in 2D pose quality directly benefit 3D estimation. Results on the new OCHuman-Pose dataset show that multi-person performance is more affected by pose prediction accuracy than by detection. The code, models, and data are available on https://MiraPurkrabek.github.io/BBox-Mask-Pose/."
  },
  {
    "date": "2026-01-21",
    "title": "Single-laser scheme for reaching strong field QED regime via direct laser acceleration",
    "authors": "Robert Babjak, Marija Vranic",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15181v1",
    "source": "arXiv",
    "abstract": "We investigate a single-laser scheme for reaching the strong-field QED regime based on direct laser acceleration (DLA) of electrons followed by their head-on collision with the same laser pulse reflected from an overdense foil. In this configuration, electrons are first accelerated inside an underdense plasma by a relativistic laser pulse and subsequently interact with the reflected laser field, emitting high-energy photons via nonlinear Compton scattering which decay into electron-positron pairs through the nonlinear Breit-Wheeler process. Using analytical scalings supported by quasi-3D particle-in-cell simulations including QED effects, we demonstrate that a laser pulse with power as low as 2 PW is sufficient to reach the quantum regime characterized by $χ_e> 1$ . For higher powers, we observe a rapid nonlinear increase in the number of generated positrons, reaching more than 2 nC for a 10 PW laser pulse with energy of approximately 1.1 kJ. A semi-analytical model is employed to estimate the positron yield, showing good agreement with simulation results. We further study the influence of laser depletion and the positioning of the reflecting foil on the efficiency of pair production. The presented scheme provides an experimentally feasible platform for probing strong-field QED effects using currently available multi-petawatt laser systems."
  },
  {
    "date": "2026-01-21",
    "title": "Role of (periodic as well as aperiodic) tessellations in contemporary composition. The cases of Tesselles sonores and Le Chapeau à douze cornes by Marisa Acuña",
    "authors": "Maria Luisa Acuña Fuentes, Édouard Thomas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15179v1",
    "source": "arXiv",
    "abstract": "The recent discovery of a family of aperiodic monotiles, which includes David Smith's famous Hat, has shaken the field of plane tessellations. Music composers have already utilised the visual representation of plane tilings in their artwork (Tom Johnson through his use of Vuza's canons, talea and color in isorhythmic motets...). Constructions of the Hat from elementary geometric polygons provide a different perspective, for example through the sound transformation of microtonal intervals, as seen in Marisa Acuña's piece Le Chapeau à douze cornes."
  },
  {
    "date": "2026-01-21",
    "title": "Large-Scale Multidimensional Knowledge Profiling of Scientific Literature",
    "authors": "Zhucun Xue, Jiangning Zhang, Juntao Jiang, Jinzhuo Liu, Haoyang He, Teng Hu, Xiaobin Hu, Guangming Yao, Yi Yuan, Yong Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15170v1",
    "source": "arXiv",
    "abstract": "The rapid expansion of research across machine learning, vision, and language has produced a volume of publications that is increasingly difficult to synthesize. Traditional bibliometric tools rely mainly on metadata and offer limited visibility into the semantic content of papers, making it hard to track how research themes evolve over time or how different areas influence one another. To obtain a clearer picture of recent developments, we compile a unified corpus of more than 100,000 papers from 22 major conferences between 2020 and 2025 and construct a multidimensional profiling pipeline to organize and analyze their textual content. By combining topic clustering, LLM-assisted parsing, and structured retrieval, we derive a comprehensive representation of research activity that supports the study of topic lifecycles, methodological transitions, dataset and model usage patterns, and institutional research directions. Our analysis highlights several notable shifts, including the growth of safety, multimodal reasoning, and agent-oriented studies, as well as the gradual stabilization of areas such as neural machine translation and graph-based methods. These findings provide an evidence-based view of how AI research is evolving and offer a resource for understanding broader trends and identifying emerging directions. Code and dataset: https://github.com/xzc-zju/Profiling_Scientific_Literature"
  },
  {
    "date": "2026-01-21",
    "title": "Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems",
    "authors": "Yinzhu Chen, Abdine Maiga, Hossein A. Rahmani, Emine Yilmaz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15161v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this paper, we propose a retrieval-augmented multi-agent framework designed to automate the generation of instance-specific evaluation rubrics. Our approach grounds evaluation in authoritative medical evidence by decomposing retrieved content into atomic facts and synthesizing them with user interaction constraints to form verifiable, fine-grained evaluation criteria. Evaluated on HealthBench, our framework achieves a Clinical Intent Alignment (CIA) score of 60.12%, a statistically significant improvement over the GPT-4o baseline (55.16%). In discriminative tests, our rubrics yield a mean score delta ($μ_Δ = 8.658$) and an AUROC of 0.977, nearly doubling the quality separation achieved by GPT-4o baseline (4.972). Beyond evaluation, our rubrics effectively guide response refinement, improving quality by 9.2% (from 59.0% to 68.2%). This provides a scalable and transparent foundation for both evaluating and improving medical LLMs. The code is available at https://anonymous.4open.science/r/Automated-Rubric-Generation-AF3C/."
  },
  {
    "date": "2026-01-21",
    "title": "Knowledge Graphs are Implicit Reward Models: Path-Derived Signals Enable Compositional Reasoning",
    "authors": "Yuval Kansal, Niraj K. Jha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15160v1",
    "source": "arXiv",
    "abstract": "Large language models have achieved near-expert performance in structured reasoning domains like mathematics and programming, yet their ability to perform compositional multi-hop reasoning in specialized scientific fields remains limited. We propose a bottom-up learning paradigm in which models are grounded in axiomatic domain facts and compose them to solve complex, unseen tasks. To this end, we present a post-training pipeline, based on a combination of supervised fine-tuning and reinforcement learning (RL), in which knowledge graphs act as implicit reward models. By deriving novel reward signals from knowledge graph paths, we provide verifiable, scalable, and grounded supervision that encourages models to compose intermediate axioms rather than optimize only final answers during RL. We validate this approach in the medical domain, training a 14B model on short-hop reasoning paths (1-3 hops) and evaluating its zero-shot generalization to complex multi-hop queries (4-5 hops). Our experiments show that path-derived rewards act as a \"compositional bridge\", enabling our model to significantly outperform much larger models and frontier systems like GPT-5.2 and Gemini 3 Pro, on the most difficult reasoning tasks. Furthermore, we demonstrate the robustness of our approach to adversarial perturbations against option-shuffling stress tests. This work suggests that grounding the reasoning process in structured knowledge is a scalable and efficient path toward intelligent reasoning."
  },
  {
    "date": "2026-01-21",
    "title": "Competition between clustering and dispersion of cobalt atoms on perovskite surfaces: SrTiO3(001) and KTaO3(001)",
    "authors": "Aji Alexander, Pankaj Kumar Samal, Llorenc Albons, Jesus Redondo, Jan Skvara, Igor Pis, Lukas Fusek, Josef Myslivecek, Viktor Johanek, Dominik Wrana, Martin Setvin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15156v1",
    "source": "arXiv",
    "abstract": "Perovskite oxides are attractive for reactions in photo/electrocatalytic schemes, and extrinsic doping is a common strategy for tuning their properties. It is widely known that extrinsic dopants impact the structure and stability of perovskite surfaces, but an atomic-scale view is missing. Here, noncontact atomic force microscopy (ncAFM) and photoelectron spectroscopy (XPS/PES) are used to combine microscopic and spectroscopic evidence of cobalt adsorption, incorporation, and clustering at surfaces of two prototypical perovskites SrTiO3 and KTaO3. A number of different sub-ML coverages and temperatures of annealing were investigated. Several common features are observed: cobalt shows a strong preference for ionic nature (+2 and +3 charge states), and remains dispersed as single atoms to a certain extent in both perovskites. Two competing mechanisms are observed upon annealing: coalescence into clusters with a mixed metallic/ionic character, and incorporation into the surface and subsurface regions. The latter is more pronounced in SrTiO3, where a cobalt-stabilized surface reconstruction is identified, whereas for KTaO3 cobalt likely incorporates in the near-surface region."
  },
  {
    "date": "2026-01-21",
    "title": "SAGA: Detecting Security Vulnerabilities Using Static Aspect Analysis",
    "authors": "Yoann Marquer, Domenico Bianculli, Lionel C. Briand",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15154v1",
    "source": "arXiv",
    "abstract": "Python is one of the most popular programming languages; as such, projects written in Python involve an increasing number of diverse security vulnerabilities. However, existing state-of-the-art analysis tools for Python only support a few vulnerability types. Hence, there is a need to detect a large variety of vulnerabilities in Python projects. In this paper, we propose the SAGA approach to detect and locate vulnerabilities in Python source code in a versatile way. SAGA includes a source code parser able to extract control- and data-flow information and to represent it as a symbolic control-flow graph, as well as a domain-specific language defining static aspects of the source code and their evolution during graph traversals. We have leveraged this language to define a library of static aspects for integrity, confidentiality, and other security-related properties. We have evaluated SAGA on a dataset of 108 vulnerabilities, obtaining 100% sensitivity and 99.15% specificity, with only one false positive, while outperforming four common security analysis tools. This analysis was performed in less than 31 seconds, i.e., between 2.5 and 512.1 times faster than the baseline tools."
  },
  {
    "date": "2026-01-21",
    "title": "The integrable Volterra system in the case of infinitely manyspecies, either countable or uncountable",
    "authors": "Orlando Ragnisco, Federico Zullo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15150v1",
    "source": "arXiv",
    "abstract": "In the present paper we derive a further extension of the results contained in two recent articles, both published in Open Communications in Mathematical Physics, where it was shown that the integrable version of the N-species Volterra model, introduced by V. Volterra in 1937, is in fact maximally superintegrable. Here we point out that the superintegrability property applies as well to the case of infinitely many competing species, either countable or uncountable. Analytical and numerical results are given."
  },
  {
    "date": "2026-01-21",
    "title": "CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning",
    "authors": "Tianshi Xu, Yuteng Chen, Meng Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15141v1",
    "source": "arXiv",
    "abstract": "Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise leads to a critical credit assignment issue, where erroneous actions are inadvertently reinforced alongside successful outcomes. Existing mitigations face a dilemma: dense rewards often trigger reward hacking, while supersampling incurs prohibitive computational costs. To address these challenges, we propose CLEANER. Distinct from external filtering methods, CLEANER exploits the model's intrinsic self-correction capabilities to eliminate error-contaminated context directly during data collection. At its core, the Similarity-Aware Adaptive Rollback (SAAR) mechanism autonomously constructs clean, purified trajectories by retrospectively replacing failures with successful self-corrections. Based on semantic similarity, SAAR adaptively regulates replacement granularity from shallow execution repairs to deep reasoning substitutions. By training on these self-purified paths, the model internalizes correct reasoning patterns rather than error-recovery loops. Empirical results on AIME24/25, GPQA, and LiveCodeBench show average accuracy gains of 6%, 3%, and 5% over baselines. Notably, CLEANER matches state-of-the-art performance using only one-third of the training steps, highlighting trajectory purification as a scalable solution for efficient agentic RL. Our models and code are available at GitHub"
  },
  {
    "date": "2026-01-21",
    "title": "Why Authors and Maintainers Link (or Don't Link) Their PyPI Libraries to Code Repositories and Donation Platforms",
    "authors": "Alexandros Tsakpinis, Nicolas Raube, Alexander Pretschner",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15139v1",
    "source": "arXiv",
    "abstract": "Metadata of libraries on the Python Package Index (PyPI)-including links to source code repositories and donation platforms-plays a critical role in supporting the transparency, trust, and sustainability of open-source libraries. Yet, many packages lack such metadata, and little is known about the underlying reasons. This paper presents a large-scale empirical study combining two targeted surveys sent to 50,000 PyPI authors and maintainers. We analyze more than 1,400 responses using large language model (LLM)-based topic modeling to uncover key motivations and barriers related to linking repositories and donation platforms. While repository URLs are often linked to foster collaboration, increase transparency, and enable issue tracking, some maintainers omit them due to oversight, laziness, or the perceived irrelevance to their project. Donation platform links are reported to support open source work or receive financial contributions, but are hindered by skepticism, technical friction, and organizational constraints. Cross-cutting challenges-such as outdated links, lack of awareness, and unclear guidance-affect both types of metadata. We further assess the robustness of our topic modeling pipeline across 30 runs (84% lexical and 89% semantic similarity) and validate topic quality with 23 expert raters (Randolph's kappa = 0.55). The study contributes empirical insights into PyPI's metadata practices and provides recommendations for improving them, while also demonstrating the effectiveness of our topic modeling approach for analyzing short-text survey responses."
  },
  {
    "date": "2026-01-21",
    "title": "Conversational AI for Social Good (CAI4SG): An Overview of Emerging Trends, Applications, and Challenges",
    "authors": "Yi-Chieh Lee, Junti Zhang, Tianqi Song, Yugin Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15136v1",
    "source": "arXiv",
    "abstract": "The integration of Conversational Agents (CAs) into daily life offers opportunities to tackle global challenges, leading to the emergence of Conversational AI for Social Good (CAI4SG). This paper examines the advancements of CAI4SG using a role-based framework that categorizes systems according to their AI autonomy and emotional engagement. This framework emphasizes the importance of considering the role of CAs in social good contexts, such as serving as empathetic supporters in mental health or functioning as assistants for accessibility. Additionally, exploring the deployment of CAs in various roles raises unique challenges, including algorithmic bias, data privacy, and potential socio-technical harms. These issues can differ based on the CA's role and level of engagement. This paper provides an overview of the current landscape, offering a role-based understanding that can guide future research and design aimed at the equitable, ethical, and effective development of CAI4SG."
  },
  {
    "date": "2026-01-21",
    "title": "Sparse Sensor Arrays for Active Sensing: Models, Configurations and Applications",
    "authors": "Robin Rajamäki, Visa Koivunen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15126v1",
    "source": "arXiv",
    "abstract": "This chapter focuses on active sensing using sparse arrays. In active sensing applications, such as radar, sonar, wireless communications, and medical ultrasound, a collection of sensors probes the environment by emitting self-generated energy. A key benefit of such active multi-sensor arrays is their ability to focus and steer energy in desired directions by beamforming on transmit. Sparse sensor arrays offer several advantages over conventional uniform arrays, including improved resolution using fewer physical sensors and the capability to identify more scatterers than sensors. This is facilitated by the effective transmit-receive virtual array known as the sum co-array, which can have many more virtual sensors than the number of physical transmit or receive sensors. Herein, we focus on the design of low-redundancy sparse array configurations and on employing transmit-receive (Tx-Rx) beamforming using sparse arrays. We discuss the optimal, but computationally intractable Minimum-redundancy array, and a scalable symmetric array framework, which extends many well-known passive sparse array geometries to the active case. We also examine mitigating side lobes arising from spatial undersampling by a synthetic beamforming method known as image addition. We briefly present approaches for finding the physical beamforming weights synthesizing a desired Tx-Rx beampattern, and consider related spatio-temporal trade-offs. We conclude by discussing selected applications of sparse arrays in active sensing."
  },
  {
    "date": "2026-01-21",
    "title": "Comment on \"Application of the three-dimensional telegraph equation to cosmic-ray transport\" (arXiv:1606.08272)",
    "authors": "Andrei Galiautdinov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15125v1",
    "source": "arXiv",
    "abstract": "In a recent publication [R. C. Tautz and I. Lerche, Res. Astron. Astrophys. 16, 162 (2016); arXiv:1606.08272], the authors present a derivation of the Green's function for the three-dimensional telegraph equation (also known as the heat wave equation, or relativistic heat conduction equation). We demonstrate that the closed-form expression derived in their Appendix A is incorrect. Specifically, the published solution lacks a Dirac delta term representing the ballistic wavefront and contains an algebraic error in the prefactor of the wake term. These omissions arise from the neglect of distributional derivatives when differentiating a Heaviside step function. We provide a rigorous derivation of the Green's function using the Fourier transform method, verify the correct limiting behavior as the damping vanishes, and pinpoint the exact mathematical step where the original derivation failed."
  },
  {
    "date": "2026-01-21",
    "title": "WavLink: Compact Audio--Text Embeddings with a Global Whisper Token",
    "authors": "Gokul Karthik Kumar, Ludovick Lepauloux, Hakim Hacid",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15118v1",
    "source": "arXiv",
    "abstract": "Whisper has become the de-facto encoder for extracting general-purpose audio features in large audio-language models, where a 30-second clip is typically represented by 1500 frame features projected into an LLM. In contrast, audio-text embedding models like CLAP-based models have largely relied on alternative audio encoders (e.g., HTS-AT, PaSST), and have not leveraged Whisper effectively. We present WavLink, a compact audio-text embedding model that augments Whisper encoder with a learnable global token, trained jointly with a text encoder. Through a systematic study of design choices, including pretrained text encoders, loss functions, training modes, and data mixtures, we identify configurations that yield state-of-the-art retrieval performance. Our two-stage training recipe across three model sizes, combined with Matryoshka-style supervision, improves scalability, enabling 8x smaller embeddings with minimal performance drop. WavLink also demonstrates competitive performance on AIR-Bench with MCQs and zero-shot classification."
  },
  {
    "date": "2026-01-21",
    "title": "Auditing Language Model Unlearning via Information Decomposition",
    "authors": "Anmol Goel, Alan Ritter, Iryna Gurevych",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15111v1",
    "source": "arXiv",
    "abstract": "We expose a critical limitation in current approaches to machine unlearning in language models: despite the apparent success of unlearning algorithms, information about the forgotten data remains linearly decodable from internal representations. To systematically assess this discrepancy, we introduce an interpretable, information-theoretic framework for auditing unlearning using Partial Information Decomposition (PID). By comparing model representations before and after unlearning, we decompose the mutual information with the forgotten data into distinct components, formalizing the notions of unlearned and residual knowledge. Our analysis reveals that redundant information, shared across both models, constitutes residual knowledge that persists post-unlearning and correlates with susceptibility to known adversarial reconstruction attacks. Leveraging these insights, we propose a representation-based risk score that can guide abstention on sensitive inputs at inference time, providing a practical mechanism to mitigate privacy leakage. Our work introduces a principled, representation-level audit for unlearning, offering theoretical insight and actionable tools for safer deployment of language models."
  },
  {
    "date": "2026-01-21",
    "title": "Stiffness induced structures and morphological transitions in semiflexible polymers",
    "authors": "Biman Bagchi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15095v1",
    "source": "arXiv",
    "abstract": "Semiflexible polymers in poor solvents exhibit a rich variety of collapsed morphologies, including globules, toroids, and rodlike bundles, arising from the competition between attractive interactions and chain stiffness. Computer simulations and experiments on stiff and conjugated polymers have revealed complex morphological crossovers, yet a unified theoretical description remains incomplete. Here we develop a coarse-grained, field-theoretic free-energy framework for linear polymers with variable stiffness that captures these morphologies and their transitions within a common description. The theory is built on three key ingredients: a density field describing monomer attraction and excluded-volume effects, a nematic order parameter accounting for orientational ordering in dense regions, and the bending rigidity of a worm-like chain. Using simple variational ansatzes for competing morphologies, we derive analytic expressions for their free energies and identify the boundaries separating coil, globule, toroidal, and rodlike conformational regimes as functions of the reduced attraction strength and the effective persistence length. The resulting phase-diagram topology provides a transparent free-energy-based framework for interpreting morphology diagrams observed in simulations and experiments on semiflexible polymers in poor solvents. We find the possibility of the existence of a triple point involving globules, rods and toroids."
  },
  {
    "date": "2026-01-21",
    "title": "Influence of Operator Expertise on Robot Supervision and Intervention",
    "authors": "Yanran Jiang, Pavan Sikka, Leimin Tian, Dana Kuliic, Cecile Paris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15069v1",
    "source": "arXiv",
    "abstract": "With increasing levels of robot autonomy, robots are increasingly being supervised by users with varying levels of robotics expertise. As the diversity of the user population increases, it is important to understand how users with different expertise levels approach the supervision task and how this impacts performance of the human-robot team. This exploratory study investigates how operators with varying expertise levels perceive information and make intervention decisions when supervising a remote robot. We conducted a user study (N=27) where participants supervised a robot autonomously exploring four unknown tunnel environments in a simulator, and provided waypoints to intervene when they believed the robot had encountered difficulties. By analyzing the interaction data and questionnaire responses, we identify differing patterns in intervention timing and decision-making strategies across novice, intermediate, and expert users."
  },
  {
    "date": "2026-01-21",
    "title": "The Responsibility Vacuum: Organizational Failure in Scaled Agent Systems",
    "authors": "Oleg Romanchuk, Roman Bondar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15059v1",
    "source": "arXiv",
    "abstract": "Modern CI/CD pipelines integrating agent-generated code exhibit a structural failure in responsibility attribution. Decisions are executed through formally correct approval processes, yet no entity possesses both the authority to approve those decisions and the epistemic capacity to meaningfully understand their basis. We define this condition as responsibility vacuum: a state in which decisions occur, but responsibility cannot be attributed because authority and verification capacity do not coincide. We show that this is not a process deviation or technical defect, but a structural property of deployments where decision generation throughput exceeds bounded human verification capacity. We identify a scaling limit under standard deployment assumptions, including parallel agent generation, CI-based validation, and individualized human approval gates. Beyond a throughput threshold, verification ceases to function as a decision criterion and is replaced by ritualized approval based on proxy signals. Personalized responsibility becomes structurally unattainable in this regime. We further characterize a CI amplification dynamic, whereby increasing automated validation coverage raises proxy signal density without restoring human capacity. Under fixed time and attention constraints, this accelerates cognitive offloading in the broad sense and widens the gap between formal approval and epistemic understanding. Additional automation therefore amplifies, rather than mitigates, the responsibility vacuum. We conclude that unless organizations explicitly redesign decision boundaries or reassign responsibility away from individual decisions toward batch- or system-level ownership, responsibility vacuum remains an invisible but persistent failure mode in scaled agent deployments."
  },
  {
    "date": "2026-01-21",
    "title": "One- and three-dimensional identical charged-kaon femtoscopic correlations in Pb--Pb collisions at $\\mathbf{ \\sqrt{s_\\mathrm{NN}}=5.02}$ TeV",
    "authors": "ALICE Collaboration",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15054v1",
    "source": "arXiv",
    "abstract": "The identical charged-kaon correlations induced by quantum-statistics effects and final-state interactions are measured in Pb$-$Pb collisions at $\\sqrt{s_{\\rm NN}} = 5.02$ TeV. The results of one- (1D) and three-dimensional (3D) analyses show that the obtained system-size parameters (radii) are smaller for more peripheral collisions and decrease with increasing pair transverse momentum $k_{\\rm T}$. The 1D parameters agree within uncertainties with those obtained in Pb$-$Pb collisions at $\\sqrt{s_{\\rm NN}}=2.76$ TeV. The observed power-law dependence of the extracted 3D radii as a function of the pair transverse momentum is a signature of the collective flow in the particle-emitting system created in Pb$-$Pb collisions. This dependence is well reproduced by the integrated hydrokinetic model calculations except for the outward projection of the radius (measured in the longitudinally co-moving system) for the most central collisions. The time of maximal emission for kaons is extracted from the 3D analysis in a wide collision centrality range from 0 to 90%. Its reduction with decreasing charged-particle multiplicity is well reproduced by the hydrokinetic model predictions, and means that kaons are emitted earlier in more peripheral events."
  },
  {
    "date": "2026-01-21",
    "title": "Resolving the band alignment of InAs/InAsSb mid-wave-infrared type-II superlattices",
    "authors": "Michał Rygała, Julian Zanon, Anderas Bader, Tristan Smołka, Fabian Hartmann, Sven Höfling, Michael Flatté, Marcin Motyka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15053v1",
    "source": "arXiv",
    "abstract": "In this work, three InAs/InAs$_{0.65}$Sb$_{0.35}$ superlattices with different periods were investigated using photoluminescence and photoreflectance measurements and their band structure was simulated using a 14 bulk-band kp model. The structures were studied by analyzing the evolution of the spectral features in temperature and excitation power to determine the origin of optical transitions. After identifying which of these are related to the superlattice mini-bands, a rich collection of observed higher-order optical transitions was compared with refractive-index calculations. This procedure was used to adjust the parameters of the theoretical model, namely the bowing parameters of the InAsSb valence band offset and bandgap. It was also shown that the spectroscopy of the higher-order states combined with numerical modeling of the refractive index is a powerful tool for improvement of the material parameters, presenting a new approach to material studies of advanced semiconductor heterostructures."
  },
  {
    "date": "2026-01-21",
    "title": "Coupled gas and bubble dynamics at the solidification front",
    "authors": "Bastien Isabella, Cécile Monteux, Sylvain Deville",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15045v1",
    "source": "arXiv",
    "abstract": "The formation and entrapment of gas bubbles during solidification significantly influence the microstructure and mechanical properties of materials, from metallic alloys to ice. While gas segregation at the solidification front is well-documented, the real-time dynamics of bubble nucleation, growth, and engulfment-and their dependence on solidification velocity-remain poorly understood. In this study, we use in situ cryo-confocal fluorescence microscopy to investigate the coupled gas-bubble dynamics at the solidification front of carbonated water, systematically varying the solidification velocity ($V = 1-20 μm/s$) while maintaining a constant thermal gradient ($G = 15 K/mm$). Our experiments reveal that bubble nucleation is governed by a characteristic nucleation time, which emerges from the interplay between gas diffusion ahead of the front, nucleation kinetics, and bubble growth, all competing with the advancing solidification front. These results allow us to estimate the critical gas concentration for bubbles nucleation in carbonated water. These results offer a detailed understanding of the mechanisms controlling bubble nucleation and entrapment during solidification at constant thermal gradient. They contribute to the development of strategies to control bubble formation in industrial processes where the presence of bubbles can either be detrimental or intentionally harnessed."
  },
  {
    "date": "2026-01-21",
    "title": "On isoperimetric local-Bollobás-Thomason inequalities",
    "authors": "Luis J. Alías, Bernardo González Merino, Beatriz Marín Gimeno",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15044v1",
    "source": "arXiv",
    "abstract": "We prove the following isoperimetric-type inequality: for every convex body $K$ in $\\mathbb R^n$ and some $σ\\subset[n]:=\\{1,\\dots,n\\}$ there exists a suitable Hanner polytope $B_K$ with the same volume as $K$ and such that the volume of each of its orthogonal projections onto every subspace whose basis is formed by the canonical vectors $\\{e_i:i\\inτ\\cup([n]\\setminusσ)\\}$, for every $τ\\subseteqσ$, bounds from below the volume of the corresponding projections of $K$."
  },
  {
    "date": "2026-01-21",
    "title": "Bottom spectrum and Llarull's theorem on complete noncompact manifolds",
    "authors": "Daoqiang Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15043v1",
    "source": "arXiv",
    "abstract": "In this paper, we prove an extension of the noncompact version of Llarull's theorem due to Zhang and Li-Su-Wang-Zhang, giving an upper bound for the infimum of scalar curvature in terms of the bottom spectrum of the Laplacian. Moreover, we extend the theorem to manifolds with boundary, relaxing the strict positivity condition on the scalar curvature near the boundary that was required by Liu-Liu. Our approach is based on deformed Dirac operators."
  },
  {
    "date": "2026-01-21",
    "title": "Electrical Design of a Clean Offshore Heat and Power (CleanOFF) Hub",
    "authors": "Maiken Borud Omtveit, Qian Long, Valentin Chabaud, Marte Ruud-Olsen, Steinar Halsne, Tor-Christian Ystgaard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15040v1",
    "source": "arXiv",
    "abstract": "This paper presents an innovative offshore solution where oil & gas platform clusters are powered by a wind farm and a hydrogen hub. The results show a feasible off-grid design as an alternative to conventional electrification solutions. To address the challenges of design and operation of such a system, a power system model of the equipment and control was developed in a power system simulator called Process Power Simulator (PPSim). Power fluctuations in the wind farm are modelled using a state-of-the-art method encompassing turbulence and wakes. Various operation scenarios were used to evaluate the system design and find the right equipment size. An expensive component to over dimension is the battery energy storage system (BESS). The BESS power rating and energy capacity were found by running a combination of scenarios with extreme and natural wind variations, and contingencies. The control strategy and ramp rates of electrolyzers have significant impact on both system performance and design. A ramp rate in the order of seconds as opposed to minutes will decrease the required BESS size by 60-70%. Choosing synchronized control of the electrolyzers can further reduce the BESS size by 15-20%. The simulations also revealed challenges to achieve self-sufficiency of hydrogen and potential design improvements are suggested."
  },
  {
    "date": "2026-01-21",
    "title": "A Curriculum-Based Deep Reinforcement Learning Framework for the Electric Vehicle Routing Problem",
    "authors": "Mertcan Daysalilar, Fuat Uyguroglu, Gabriel Nicolosi, Adam Meyers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15038v1",
    "source": "arXiv",
    "abstract": "The electric vehicle routing problem with time windows (EVRPTW) is a complex optimization problem in sustainable logistics, where routing decisions must minimize total travel distance, fleet size, and battery usage while satisfying strict customer time constraints. Although deep reinforcement learning (DRL) has shown great potential as an alternative to classical heuristics and exact solvers, existing DRL models often struggle to maintain training stability-failing to converge or generalize when constraints are dense. In this study, we propose a curriculum-based deep reinforcement learning (CB-DRL) framework designed to resolve this instability. The framework utilizes a structured three-phase curriculum that gradually increases problem complexity: the agent first learns distance and fleet optimization (Phase A), then battery management (Phase B), and finally the full EVRPTW (Phase C). To ensure stable learning across phases, the framework employs a modified proximal policy optimization algorithm with phase-specific hyperparameters, value and advantage clipping, and adaptive learning-rate scheduling. The policy network is built upon a heterogeneous graph attention encoder enhanced by global-local attention and feature-wise linear modulation. This specialized architecture explicitly captures the distinct properties of depots, customers, and charging stations. Trained exclusively on small instances with N=10 customers, the model demonstrates robust generalization to unseen instances ranging from N=5 to N=100, significantly outperforming standard baselines on medium-scale problems. Experimental results confirm that this curriculum-guided approach achieves high feasibility rates and competitive solution quality on out-of-distribution instances where standard DRL baselines fail, effectively bridging the gap between neural speed and operational reliability."
  },
  {
    "date": "2026-01-21",
    "title": "A General Theory of Chiral Splitting of Magnons in Two-Dimensional Magnets",
    "authors": "Yu Xie, Dinghui Wang, Chao Li, Xiaofan Shen, Junting Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15031v1",
    "source": "arXiv",
    "abstract": "Magnons in antiferromagnets exhibit two chiral modes, providing an intrinsic degree of freedom for magnon-based computing architectures and spintronic devices. Electrical control of chiral splitting is crucial for applications, but remains challenging. Here, we propose the concept of extrinsic chiral splitting, involving alternating and ferrimagnet-like types, which can be induced and controlled by an electric field. A symmetry framework based on 464 collinear spin layer groups is established to classify chiral splitting characteristics and electric field responses in two-dimensional magnets. We further elucidate how the spin layer group determines the type of alternating chiral splitting and the dominant lowest-order magnetic exchange interaction. We demonstrate electric-field control over the magnitude and sign of the chiral splitting, enabling control of the spin Seebeck and Nernst effects related to thermal spin transport. This work provides a general theory for electric field manipulation of magnon chirality, paving the way for low-power magnonic logic devices."
  },
  {
    "date": "2026-01-21",
    "title": "Rank-one Riemannian Subspace Descent for Nonlinear Matrix Equations",
    "authors": "Yogesh Darmwal, Ketan Rajawat",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14933v1",
    "source": "arXiv",
    "abstract": "We propose a rank-one Riemannian subspace descent algorithm for computing symmetric positive definite (SPD) solutions to nonlinear matrix equations arising in control theory, dynamic programming, and stochastic filtering. For solution matrices of size $n\\times n$, standard approaches for dense matrix equations typically incur $\\mathcal{O}(n^3)$ cost per-iteration, while the efficient $\\mathcal{O}(n^2)$ methods either rely on sparsity or low-rank solutions, or have iteration counts that scale poorly. The proposed method entails updating along the dominant eigen-component of a transformed Riemannian gradient, identified using at most $\\mathcal{O}(\\log(n))$ power iterations. The update structure also enables exact step-size selection in many cases at minimal additional cost. For objectives defined as compositions of standard matrix operations, each iteration can be implemented using only matrix--vector products, yielding $\\mathcal{O}(n^2)$ arithmetic cost. We prove an $\\mathcal{O}(n)$ iteration bound under standard smoothness assumptions, with improved bounds under geodesic strong convexity. Numerical experiments on large-scale CARE, DARE, and other nonlinear matrix equations show that the proposed algorithm solves instances (up to $n=10{,}000$ in our tests) for which the compared solvers, including MATLAB's \\texttt{icare}, structure-preserving doubling, and subspace-descent baselines fail to return a solution. These results demonstrate that rank-one manifold updates provide a practical approach for high-dimensional and dense SPD-constrained matrix equations. MATLAB code implementation is publicly available on GitHub : \\href{https://github.com/yogeshd-iitk/nonlinear_matrix_equation_R1RSD}{\\textcolor{blue}{https://github.com/yogeshd-iitk/nonlinear\\_matrix \\_equation\\_R1RSD}}"
  },
  {
    "date": "2026-01-21",
    "title": "Explaining the advantage of quantum-enhanced physics-informed neural networks",
    "authors": "Nils Klement, Veronika Eyring, Mierk Schwabe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15046v1",
    "source": "arXiv",
    "abstract": "Partial differential equations (PDEs) form the backbone of simulations of many natural phenomena, for example in climate modeling, material science, and even financial markets. The application of physics-informed neural networks to accelerate the solution of PDEs is promising, but not competitive with numerical solvers yet. Here, we show how quantum computing can improve the ability of physics-informed neural networks to solve partial differential equations. For this, we develop hybrid networks consisting of quantum circuits combined with classical layers and systematically test them on various non linear PDEs and boundary conditions in comparison with purely classical networks. We demonstrate that the advantage of using quantum networks lies in their ability to achieve an accurate approximation of the solution in substantially fewer training epochs, particularly for more complex problems. These findings provide the basis for targeted developments of hybrid quantum neural networks with the goal to significantly accelerate numerical modeling."
  },
  {
    "date": "2026-01-21",
    "title": "RadixMLP -- Intra-batch Deduplication for Causal Transformers",
    "authors": "Michael Feil, Julius Lipp",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15013v1",
    "source": "arXiv",
    "abstract": "Batch inference workloads for causal transformer models frequently process sequences that share common prefixes, such as system prompts, few-shot examples, or shared queries. Standard inference engines treat each sequence independently, redundantly recomputing identical MLP activations for every copy of the shared prefix. We introduce RadixMLP, a technique that exploits the position-wise nature of MLPs, LayerNorms, linear projections, and embeddings to eliminate this redundancy. RadixMLP dynamically maps batches to a prefix trie, gathering shared segments into a compressed representation for position-wise computation and scattering results back only at attention boundaries. RadixMLP is stateless and operates within a single forward pass. In end-to-end serving benchmarks on MS~MARCO v1.1 with Qwen3 models (0.6B to 8B parameters), RadixMLP achieves 1.44-1.59$\\times$ speedups in realistic reranking workloads, with up to $5\\times$ speedups on synthetic benchmarks with longer shared prefixes. Our code is available at https://github.com/michaelfeil/radix-mlp."
  },
  {
    "date": "2026-01-21",
    "title": "Practical prescribed-time prescribed performance control with asymptotic convergence -- A vanishing sigma-modification approach",
    "authors": "Mehdi Golestani, Yongduan Song, Weizhen Liu, Guangren Duan, He Kong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14882v1",
    "source": "arXiv",
    "abstract": "In this paper, we present a method capable of ensuring practical prescribed-time control with guaranteed performance for a class of nonlinear systems in the presence of time-varying parametric and dynamic uncertainties, and uncertain control coefficients. Our design consists of two key steps. First, we construct a performance-rate function that freezes at and after a user-specified time T, playing a crucial role in achieving desired precision within prescribed time T and dealing with unmodeled dynamics. Next, based on this function and a sigma-modification strategy in which the leakage term starts to vanish at t > T, we develop an adaptive dynamic surface control framework to reduce control complexity, deal with uncertainties, ensure prescribed performance, practical prescribed-time convergence to a specific region, and ultimately achieve asymptotic convergence. The effectiveness of the proposed control method is validated through numerical simulations."
  },
  {
    "date": "2026-01-21",
    "title": "Phenomenology of a doble dilaton soft-wall model: Alpha strong from Ricci flow and pion Form Factors at intermediate-energy region",
    "authors": "Héctor Cancio, Pere Masjuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14829v1",
    "source": "arXiv",
    "abstract": "Through a holographic model of QCD, we present a phenomenological approach to study the running of the strong coupling constant α_s in both non-perturbative and perturbative regimes. The renormalization of the metric tensor, driven by the Ricci Flow, and the breaking of conformal and chiral symmetries -- thanks to introducing a double dilaton model and large-$N_c$ corrections -- allow us to relate the existence of an infrared fixed point in the coupling constant with a smooth matching to pQCD well above 2 GeV. This is done through a model with two fit parameters and one matching point. The proposed dilaton model yields linear Regge trajectories and decay constants for scalar, vector, and tensor meson families similar to their experimental counterparts. We finally study neutral and charged pion form factors to show an application of the running coupling constant obtained."
  },
  {
    "date": "2026-01-21",
    "title": "The puzzle of composition of cosmic rays with energies (2-12.5) EeV according to muon detectors data of the Yakutsk EAS array",
    "authors": "A. V. Glushkov, L. T. Ksenofontov, K. G. Lebedev, A. V. Sabourov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14739v1",
    "source": "arXiv",
    "abstract": "The results of a study of the cosmic ray composition in individual events in the energy range (2-12.5) EeV using the muon correlation method is presented. The considered sample included showers with zenith angles less than 60 degrees recorded in the period 1974-2018. The existence of four separate groups of primary particles with different origins is confirmed. The obtained results have potential importance for understanding the composition of cosmic rays in the specified primary energy range."
  },
  {
    "date": "2026-01-21",
    "title": "Scaling Enhancement in Distributed Quantum Sensing via Causal Order Switching",
    "authors": "Binke Xia, Zhaotong Cui, Jingzheng Huang, Yuxiang Yang, Guihua Zeng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14708v1",
    "source": "arXiv",
    "abstract": "Sensing networks underpin applications from fundamental physics to real-world engineering. Recently, distributed quantum sensing (DQS) has been investigated to boost the sensing performance, yet current schemes typically rely on entangled probes that are fragile to noise and difficult to scale. Here, we propose a DQS protocol that incorporates a causal-order switch into a cyclic network, enabling a single probe to sequentially query N independent sensors in a coherent superposition or a probabilistic mixture of opposite causal orders. By exploiting the noncommutativity between propagation and sensing processes, our scheme achieves a 1/N^2-scaling precision limit without involving entangled probes. Importantly, our approach utilizes a classical mixture of causal orders rather than a quantum switch, making it more feasible for practical realization. We experimentally implement this scheme for distributed beam tilts sensing in a free-space quantum optical network comprising up to 9 sensors, achieving picoradian-scale precision in estimating tilt angle. Our results demonstrate a robust and scalable DQS protocol that surpasses the conventional 1/N Heisenberg scaling in precision, advancing the practical deployment of quantum sensing networks."
  },
  {
    "date": "2026-01-21",
    "title": "Iterative Refinement Improves Compositional Image Generation",
    "authors": "Shantanu Jaiswal, Mihir Prabhudesai, Nikash Bhardwaj, Zheyang Qin, Amir Zadeh, Chuan Li, Katerina Fragkiadaki, Deepak Pathak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15286v1",
    "source": "arXiv",
    "abstract": "Text-to-image (T2I) models have achieved remarkable progress, yet they continue to struggle with complex prompts that require simultaneously handling multiple objects, relations, and attributes. Existing inference-time strategies, such as parallel sampling with verifiers or simply increasing denoising steps, can improve prompt alignment but remain inadequate for richly compositional settings where many constraints must be satisfied. Inspired by the success of chain-of-thought reasoning in large language models, we propose an iterative test-time strategy in which a T2I model progressively refines its generations across multiple steps, guided by feedback from a vision-language model as the critic in the loop. Our approach is simple, requires no external tools or priors, and can be flexibly applied to a wide range of image generators and vision-language models. Empirically, we demonstrate consistent gains on image generation across benchmarks: a 16.9% improvement in all-correct rate on ConceptMix (k=7), a 13.8% improvement on T2I-CompBench (3D-Spatial category) and a 12.5% improvement on Visual Jenga scene decomposition compared to compute-matched parallel sampling. Beyond quantitative gains, iterative refinement produces more faithful generations by decomposing complex prompts into sequential corrections, with human evaluators preferring our method 58.7% of the time over 41.3% for the parallel baseline. Together, these findings highlight iterative self-correction as a broadly applicable principle for compositional image generation. Results and visualizations are available at https://iterative-img-gen.github.io/"
  },
  {
    "date": "2026-01-21",
    "title": "Walk through Paintings: Egocentric World Models from Internet Priors",
    "authors": "Anurag Bagchi, Zhipeng Bao, Homanga Bharadhwaj, Yu-Xiong Wang, Pavel Tokmakov, Martial Hebert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15284v1",
    "source": "arXiv",
    "abstract": "What if a video generation model could not only imagine a plausible future, but the correct one, accurately reflecting how the world changes with each action? We address this question by presenting the Egocentric World Model (EgoWM), a simple, architecture-agnostic method that transforms any pretrained video diffusion model into an action-conditioned world model, enabling controllable future prediction. Rather than training from scratch, we repurpose the rich world priors of Internet-scale video models and inject motor commands through lightweight conditioning layers. This allows the model to follow actions faithfully while preserving realism and strong generalization. Our approach scales naturally across embodiments and action spaces, ranging from 3-DoF mobile robots to 25-DoF humanoids, where predicting egocentric joint-angle-driven dynamics is substantially more challenging. The model produces coherent rollouts for both navigation and manipulation tasks, requiring only modest fine-tuning. To evaluate physical correctness independently of visual appearance, we introduce the Structural Consistency Score (SCS), which measures whether stable scene elements evolve consistently with the provided actions. EgoWM improves SCS by up to 80 percent over prior state-of-the-art navigation world models, while achieving up to six times lower inference latency and robust generalization to unseen environments, including navigation inside paintings."
  },
  {
    "date": "2026-01-21",
    "title": "LuxRemix: Lighting Decomposition and Remixing for Indoor Scenes",
    "authors": "Ruofan Liang, Norman Müller, Ethan Weber, Duncan Zauss, Nandita Vijaykumar, Peter Kontschieder, Christian Richardt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15283v1",
    "source": "arXiv",
    "abstract": "We present a novel approach for interactive light editing in indoor scenes from a single multi-view scene capture. Our method leverages a generative image-based light decomposition model that factorizes complex indoor scene illumination into its constituent light sources. This factorization enables independent manipulation of individual light sources, specifically allowing control over their state (on/off), chromaticity, and intensity. We further introduce multi-view lighting harmonization to ensure consistent propagation of the lighting decomposition across all scene views. This is integrated into a relightable 3D Gaussian splatting representation, providing real-time interactive control over the individual light sources. Our results demonstrate highly photorealistic lighting decomposition and relighting outcomes across diverse indoor scenes. We evaluate our method on both synthetic and real-world datasets and provide a quantitative and qualitative comparison to state-of-the-art techniques. For video results and interactive demos, see https://luxremix.github.io."
  },
  {
    "date": "2026-01-21",
    "title": "Optimality of Staircase Mechanisms for Vector Queries under Differential Privacy",
    "authors": "James Melbourne, Mario Diaz, Shahab Asoodeh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14597v1",
    "source": "arXiv",
    "abstract": "We study the optimal design of additive mechanisms for vector-valued queries under $ε$-differential privacy (DP). Given only the sensitivity of a query and a norm-monotone cost function measuring utility loss, we ask which noise distribution minimizes expected cost among all additive $ε$-DP mechanisms. Using convex rearrangement theory, we show that this infinite-dimensional optimization problem admits a reduction to a one-dimensional compact and convex family of radially symmetric distributions whose extreme points are the staircase distributions. As a consequence, we prove that for any dimension, any norm, and any norm-monotone cost function, there exists an $ε$-DP staircase mechanism that is optimal among all additive mechanisms. This result resolves a conjecture of Geng, Kairouz, Oh, and Viswanath, and provides a geometric explanation for the emergence of staircase mechanisms as extremal solutions in differential privacy."
  },
  {
    "date": "2026-01-21",
    "title": "Information mechanics: conservation and exchange",
    "authors": "Takuya Isomura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15028v1",
    "source": "arXiv",
    "abstract": "Inference and learning are commonly cast in terms of optimisation, yet the fundamental constraints governing uncertainty reduction remain unclear. This work presents a first-principles framework inherent to Bayesian updating, termed information mechanics (infomechanics). Any pointwise reduction in posterior surprisal is exactly balanced by information gained from data, independently of algorithms, dynamics, or implementation. Imposing additivity, symmetry, and robustness collapses the freedom of this identity to only two independent conservation relations. One governs the global redistribution of uncertainty and recovers Shannon entropy. The other captures a complementary local geometric component, formalised as Fisher information. Together, these conserved quantities motivate a non-additive state function, the information potential $Φ$, which isolates structural degrees of freedom beyond entropy while remaining invariant under reparametrisation. $Φ$ quantifies local sharpness and ruggedness in posterior beliefs and vanishes uniquely for isotropic Gaussian distributions. In a low-temperature regime, $Φ$ scales logarithmically with the effective number of local optima, linking information geometry to computational complexity. This formalises an information-computation exchange, whereby information acquisition reshapes the inference landscape and reduces computational demands. By separating invariant informational constraints from inference mechanisms, this framework provides a unified, algorithm-independent foundation for inference, learning, and computation across biological and artificial systems."
  },
  {
    "date": "2026-01-21",
    "title": "Construction of mirror pairs Calabi-Yau orbifolds of the Berglund-Hubsch type",
    "authors": "Sergei Aleshin, Alexander Belavin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15027v1",
    "source": "arXiv",
    "abstract": "In this paper we have developed general algorithm for finding all orbifolds of Berglund-Hubsch-type Calabi-Yau manifolds and their mirrors. An explicit construction is formulated for finding all admissible deformations and groups defining mirror pairs of orbifolds. Then using our algorithm for one of the Calabi-Yau manifolds, defined by a Fermat-type polynomial, we found all mirror pairs of orbifolds. For this model, for each pair of orbifolds, the number of generations and the number of singlets i.e. particles participating only in gravitational interactions (dark matter particles) were found."
  },
  {
    "date": "2026-01-21",
    "title": "Quasisymmetry Enriched Gapless Criticality at Chern Insulator Transitions",
    "authors": "Jiayu Li, Feng-Ren Fan, Wang Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15011v1",
    "source": "arXiv",
    "abstract": "In continuous topological phase transitions (CTPTs), the low-energy physics is governed by gap-closing subspaces, where approximate \"higher\" symmetries, termed quasisymmetries, may emerge. Here, we introduce the notion of quasisymmetry enrichment of these transitions. Focusing on paradigmatic normal-to-Chern insulator transitions, we identify quasisymmetries in the gapless subspaces, which subdivide CTPTs of the same universality class according to quasisymmetry charges. Gapless criticalities with nontrivial charges exhibit regulated phenomena, including intrinsic correlations between charge and pseudospin currents and continuous generalized Hall conductivities governed by the generalized Středa formula, both conventionally exclusive to gapped phases. These features arise as quasisymmetry forbids certain matrix elements, rendering the generalized Berry curvature integrable. By establishing quasisymmetry as a fundamental classifying ingredient, our work adds a new dimension for understanding the rich landscape of quantum phase transitions."
  },
  {
    "date": "2026-01-21",
    "title": "Pseudo-Riemannian Algebraic Ricci Solitons on Four-Dimensional Lie Groups",
    "authors": "Youssef Ayad",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15008v1",
    "source": "arXiv",
    "abstract": "We investigate the conditions under which pseudo-Riemannian inner products induce pseudo-Riemannian algebraic Ricci solitons on four-dimensional Lie algebras. By analyzing the algebraic Ricci soliton equation for each four-dimensional Lie algebra, we obtain a complete description of when such pseudo-Riemannian algebraic Ricci solitons arise in dimension four. We present two applications of our formalism on a chosen four-dimensional Lie algebra by exhibiting a pseudo-Riemannian algebraic Ricci soliton and a flat pseudo-Riemannian inner product, which is a trivial algebraic Ricci soliton."
  },
  {
    "date": "2026-01-21",
    "title": "DWPP: Dynamic Window Pure Pursuit Considering Velocity and Acceleration Constraints",
    "authors": "Fumiya Ohnishi, Masaki Takahashi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15006v1",
    "source": "arXiv",
    "abstract": "Pure pursuit and its variants are widely used for mobile robot path tracking owing to their simplicity and computational efficiency. However, many conventional approaches do not explicitly account for velocity and acceleration constraints, resulting in discrepancies between commanded and actual velocities that result in overshoot and degraded tracking performance. To address this problem, this paper proposes dynamic window pure pursuit (DWPP), which fundamentally reformulates the command velocity computation process to explicitly incorporate velocity and acceleration constraints. Specifically, DWPP formulates command velocity computation in the velocity space (the $v$-$ω$ plane) and selects the command velocity as the point within the dynamic window that is closest to the line $ω= κv$. Experimental results demonstrate that DWPP avoids constraint-violating commands and achieves superior path-tracking accuracy compared with conventional pure pursuit methods. The proposed method has been integrated into the official Nav2 repository and is publicly available (https://github.com/ros-navigation/navigation2)."
  },
  {
    "date": "2026-01-21",
    "title": "LiDRoSIS: An Automated MATLAB-Python Platform for Image Processing and Quantitative Analysis of Lipid Droplets and ROS in Irradiated Cells",
    "authors": "Marco Ferreira, Ana Belchior, Teresa Pinheiro, Gil Alves, Maria Lopes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14999v1",
    "source": "arXiv",
    "abstract": "LiDRoSIS is an automated MATLAB-Python software suite for the segmentation and quantification of lipid droplets (LDs) and reactive oxygen species (ROS) in fluorescence microscopy images of irradiated A549 and MCF7 cells exposed to gold-based nanoparticles. It combines classical image processing algorithms with statistical post-analysis through a companion Python tool, StatLysis. The platform enables reproducible, high-throughput analysis of morphological and spectral parameters linked to nanoparticle-enhanced radiobiological responses. By bridging imaging and quantitative analytics, LiDRoSIS provides a robust framework for nanomedicine and radiation biology research."
  },
  {
    "date": "2026-01-21",
    "title": "Precise Computation of Forced Response Backbone Curves of Frictional Structures Using Analytical Hessian Tensor of Contact Elements",
    "authors": "Wei Wen, Wenkai Qi, Weidong Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14990v1",
    "source": "arXiv",
    "abstract": "Predicting the forced vibration response of nonlinear mechanical systems with friction is critical for engineering applications. Accurately determining the backbone curve of resonance peaks is pivotal for the design of friction devices. However, the prediction of these curves is computationally challenging owing to the nonconservative and nonsmooth nature of friction nonlinearity. Although techniques such as damped nonlinear normal modes (dNNMs) and phase resonance methods have been applied, they often suffer from convergence issues, and their computational accuracy is compromised under certain conditions. This study proposes a novel method for computing the forced response backbone curves of structures with frictional contact interfaces. The method accurately tracks the backbone curve through a parameter continuation scheme, formulated via Lagrange multipliers and accelerated by incorporating a derived analytical Hessian Tensor of contact elements. This approach yields highly accurate numerical results and enables numerical singularities on the curve to be identified and robustly traversed. The proposed method is validated using an Euler-Bernoulli beam finite-element model and a lumped-parameter blade-damper-blade model. The results demonstrate superior accuracy compared to conventional dNNMs and phase resonance methods, particularly in cases involving either high structural damping or strong frictional damping. This work provides a robust computational tool and presents a detailed comparative analysis that clarifies the applicability and limitations of the proposed and conventional methods."
  },
  {
    "date": "2026-01-21",
    "title": "Two-Class Joint Source-Channel Coding: Expurgated Exponents with i.i.d. Distributions",
    "authors": "Seyed AmirPouya Moeini, Albert Guillén i Fàbregas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14985v1",
    "source": "arXiv",
    "abstract": "This paper studies expurgated exponents for joint source-channel coding of discrete memoryless sources and channels under i.i.d. random coding. We show that a two-class partitioning of source sequences, where the codeword distribution depends on the source type, achieves an exponent at least as high as that of optimal single-class coding, in which the codeword distribution is independent of the source message."
  },
  {
    "date": "2026-01-21",
    "title": "Parallel Collaborative ADMM Privacy Computing and Adaptive GPU Acceleration for Distributed Edge Networks",
    "authors": "Mengchun Xia, Zhicheng Dong, Donghong Cai, Fang Fang, Lisheng Fan, Pingzhi Fan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14980v1",
    "source": "arXiv",
    "abstract": "Distributed computing has been widely applied in distributed edge networks for reducing the processing burden of high-dimensional data centralization, where a high-dimensional computational task is decomposed into multiple low-dimensional collaborative processing tasks or multiple edge nodes use distributed data to train a global model. However, the computing power of a single-edge node is limited, and collaborative computing will cause information leakage and excessive communication overhead. In this paper, we design a parallel collaborative distributed alternating direction method of multipliers (ADMM) and propose a three-phase parallel collaborative ADMM privacy computing (3P-ADMM-PC2) algorithm for distributed computing in edge networks, where the Paillier homomorphic encryption is utilized to protect data privacy during interactions. Especially, a quantization method is introduced, which maps the real numbers to a positive integer interval without affecting the homomorphic operations. To address the architectural mismatch between large-integer and Graphics Processing Unit (GPU) computing, we transform high-bitwidth computations into low-bitwidth matrix and vector operations. Thus the GPU can be utilized to implement parallel encryption and decryption computations with long keys. Finally, a GPU-accelerated 3P-ADMM-PC2 is proposed to optimize the collaborative computing tasks. Meanwhile, large-scale computational tasks are conducted in network topologies with varying numbers of edge nodes. Experimental results demonstrate that the proposed 3P-ADMM-PC2 has excellent mean square error performance, which is close to that of distributed ADMM without privacy-preserving. Compared to centralized ADMM and distributed ADMM implemented with Central Processing Unit (CPU) computation, the proposed scheme demonstrates a significant speedup ratio."
  },
  {
    "date": "2026-01-21",
    "title": "The relativistic restricted three-body problem: geometry and motion around tidally perturbed black holes",
    "authors": "Takuya Katagiri, Vitor Cardoso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14979v1",
    "source": "arXiv",
    "abstract": "We investigate the geometry of a tidally deformed, rotating black hole and timelike geodesics in its vicinity. Our framework provides a local picture of the structural evolution of a relativistic restricted three-body problem around a deformed black hole in an adiabatically evolving binary, motivated by various astrophysical settings including disk dynamics and extreme mass-ratio inspirals. As the tidal-field strength is increased, initially regular, bound geodesics undergo four stages: (i) weak chaos emerges within the bound motion; (ii) a subset of trajectories plunges into the black hole; (iii) a fraction of the remaining trajectories becomes unbound; and (iv) no bound trajectories persist. We provide semi-analytic estimates for the critical tidal amplitudes associated with each transition. Our estimates indicate that, within the frequency band of ground-based gravitational-wave detectors, the matter flow around black holes may already be depleted, whereas LISA and (B-)DECIGO could probe the earlier stages. Our results suggest that an object orbiting a tidally deformed massive BH may remain near resonances over a wide range of separations, indicating an accumulated, non-negligible impact on the gravitational-wave phase. Tidal perturbations can also introduce nonlinear couplings among epicyclic oscillations of geodesics, offering a potential avenue to resonant excitation of quasi-periodic oscillations in X-ray light curves from accreting black holes."
  },
  {
    "date": "2026-01-21",
    "title": "InstructTime++: Time Series Classification with Multimodal Language Modeling via Implicit Feature Enhancement",
    "authors": "Mingyue Cheng, Xiaoyu Tao, Huajian Zhang, Qi Liu, Enhong Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14968v1",
    "source": "arXiv",
    "abstract": "Most existing time series classification methods adopt a discriminative paradigm that maps input sequences directly to one-hot encoded class labels. While effective, this paradigm struggles to incorporate contextual features and fails to capture semantic relationships among classes. To address these limitations, we propose InstructTime, a novel framework that reformulates time series classification as a multimodal generative task. Specifically, continuous numerical sequences, contextual textual features, and task instructions are treated as multimodal inputs, while class labels are generated as textual outputs by tuned language models. To bridge the modality gap, InstructTime introduces a time series discretization module that converts continuous sequences into discrete temporal tokens, together with an alignment projection layer and a generative self-supervised pre-training strategy to enhance cross-modal representation alignment. Building upon this framework, we further propose InstructTime++, which extends InstructTime by incorporating implicit feature modeling to compensate for the limited inductive bias of language models. InstructTime++ leverages specialized toolkits to mine informative implicit patterns from raw time series and contextual inputs, including statistical feature extraction and vision-language-based image captioning, and translates them into textual descriptions for seamless integration. Extensive experiments on multiple benchmark datasets demonstrate the superior performance of InstructTime++."
  },
  {
    "date": "2026-01-21",
    "title": "VCNAC: A Variable-Channel Neural Audio Codec for Mono, Stereo, and Surround Sound",
    "authors": "Florian Grötschla, Arunasish Sen, Alessandro Lombardi, Guillermo Cámbara, Andreas Schwarz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14960v1",
    "source": "arXiv",
    "abstract": "We present VCNAC, a variable channel neural audio codec. Our approach features a single encoder and decoder parametrization that enables native inference for different channel setups, from mono speech to cinematic 5.1 channel surround audio. Channel compatibility objectives ensure that multi-channel content maintains perceptual quality when decoded to fewer channels. The shared representation enables training of generative language models on a single set of codebooks while supporting inference-time scalability across modalities and channel configurations. Evaluation using objective spatial audio metrics and subjective listening tests demonstrates that our unified approach maintains high reconstruction quality across mono, stereo, and surround audio configurations."
  },
  {
    "date": "2026-01-21",
    "title": "CorpusQA: A 10 Million Token Benchmark for Corpus-Level Analysis and Reasoning",
    "authors": "Zhiyuan Lu, Chenliang Li, Yingcheng Shi, Weizhou Shen, Ming Yan, Fei Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14952v1",
    "source": "arXiv",
    "abstract": "While large language models now handle million-token contexts, their capacity for reasoning across entire document repositories remains largely untested. Existing benchmarks are inadequate, as they are mostly limited to single long texts or rely on a \"sparse retrieval\" assumption-that answers can be derived from a few relevant chunks. This assumption fails for true corpus-level analysis, where evidence is highly dispersed across hundreds of documents and answers require global integration, comparison, and statistical aggregation. To address this critical gap, we introduce CorpusQA, a new benchmark scaling up to 10 million tokens, generated via a novel data synthesis framework. By decoupling reasoning from textual representation, this framework creates complex, computation-intensive queries with programmatically guaranteed ground-truth answers, challenging systems to perform holistic reasoning over vast, unstructured text without relying on fallible human annotation. We further demonstrate the utility of our framework beyond evaluation, showing that fine-tuning on our synthesized data effectively enhances an LLM's general long-context reasoning capabilities. Extensive experiments reveal that even state-of-the-art long-context LLMs struggle as input length increases, and standard retrieval-augmented generation systems collapse entirely. Our findings indicate that memory-augmented agentic architectures offer a more robust alternative, suggesting a critical shift is needed from simply extending context windows to developing advanced architectures for global information synthesis."
  },
  {
    "date": "2026-01-21",
    "title": "Erosion Attack for Adversarial Training to Enhance Semantic Segmentation Robustness",
    "authors": "Yufei Song, Ziqi Zhou, Menghao Deng, Yifan Hu, Shengshan Hu, Minghui Li, Leo Yu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14950v1",
    "source": "arXiv",
    "abstract": "Existing segmentation models exhibit significant vulnerability to adversarial attacks.To improve robustness, adversarial training incorporates adversarial examples into model training. However, existing attack methods consider only global semantic information and ignore contextual semantic relationships within the samples, limiting the effectiveness of adversarial training. To address this issue, we propose EroSeg-AT, a vulnerability-aware adversarial training framework that leverages EroSeg to generate adversarial examples. EroSeg first selects sensitive pixels based on pixel-level confidence and then progressively propagates perturbations to higher-confidence pixels, effectively disrupting the semantic consistency of the samples. Experimental results show that, compared to existing methods, our approach significantly improves attack effectiveness and enhances model robustness under adversarial training."
  },
  {
    "date": "2026-01-21",
    "title": "Communication-Efficient Multi-Modal Edge Inference via Uncertainty-Aware Distributed Learning",
    "authors": "Hang Zhao, Hongru Li, Dongfang Xu, Shenghui Song, Khaled B. Letaief",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14942v1",
    "source": "arXiv",
    "abstract": "Semantic communication is emerging as a key enabler for distributed edge intelligence due to its capability to convey task-relevant meaning. However, achieving communication-efficient training and robust inference over wireless links remains challenging. This challenge is further exacerbated for multi-modal edge inference (MMEI) by two factors: 1) prohibitive communication overhead for distributed learning over bandwidth-limited wireless links, due to the \\emph{multi-modal} nature of the system; and 2) limited robustness under varying channels and noisy multi-modal inputs. In this paper, we propose a three-stage communication-aware distributed learning framework to improve training and inference efficiency while maintaining robustness over wireless channels. In Stage~I, devices perform local multi-modal self-supervised learning to obtain shared and modality-specific encoders without device--server exchange, thereby reducing the communication cost. In Stage~II, distributed fine-tuning with centralized evidential fusion calibrates per-modality uncertainty and reliably aggregates features distorted by noise or channel fading. In Stage~III, an uncertainty-guided feedback mechanism selectively requests additional features for uncertain samples, optimizing the communication--accuracy tradeoff in the distributed setting. Experiments on RGB--depth indoor scene classification show that the proposed framework attains higher accuracy with far fewer training communication rounds and remains robust to modality degradation or channel variation, outperforming existing self-supervised and fully supervised baselines."
  },
  {
    "date": "2026-01-21",
    "title": "Nonclassical symmetries of polynomial equations and test problems with parameters for computer algebra systems",
    "authors": "Inna K. Shingareva, Andrei D. Polyanin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14940v1",
    "source": "arXiv",
    "abstract": "Nonclassical symmetries and reductions of polynomial equations and systems of polynomial equations are considered. It is shown that specific polynomial equations having \"hidden\" symmetries can be reduced to classical symmetric systems of polynomial equations by introducing a new additional variable. It has been established that symmetric systems of polynomial equations of mixed type, consisting of symmetric and anti-symmetric polynomials, can be transformed into simpler systems. A method is presented for solving nonclassical symmetric systems of two polynomial equations that change places when the unknowns are permuted. We study polynomial equations containing the second iteration of a given polynomial, which are reduced to nonclassical symmetric systems of equations. New higher-degree polynomial equations containing free parameters that admit solutions in radicals are found. Three such equations of the sixth and ninth degrees are further used as test problems with parameters for analyzing the capabilities of two leading computer algebra systems. It is shown that currently, the Maple and Mathematica systems do not allow us to efficiently find analytical solutions (in radicals) of polynomial equations with free parameters, but they allow us to obtain numerical solutions of equations for fixed numerical values of the parameters. The results of this work and the proposed test problems with parameters can be used to further improve existing computer algebra systems."
  },
  {
    "date": "2026-01-21",
    "title": "Geostatistics from Elliptic Boundary-Value Problems: Green Operators, Transmission Conditions, and Schur Complements",
    "authors": "Juan J. Segura",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14937v1",
    "source": "arXiv",
    "abstract": "Classical geostatistics encodes spatial dependence by prescribing variograms or covariance kernels on Euclidean domains, whereas the SPDE--GMRF paradigm specifies Gaussian fields through an elliptic precision operator whose inverse is the corresponding Green operator. We develop an operator-based formulation of Gaussian spatial random fields on bounded domains and manifolds with internal interfaces, treating boundary and transmission conditions as explicit components of the statistical model. Starting from coercive quadratic energy functionals, variational theory yields a precise precision--covariance correspondence and shows that variograms are derived quadratic functionals of the Green operator, hence depend on boundary conditions and domain geometry. Conditioning and kriging follow from standard Gaussian update identities in both covariance and precision form, with hard constraints represented equivalently by exact interpolation constraints or by distributional source terms. Interfaces are modelled via surface penalty terms; taking variations produces flux-jump transmission conditions and induces controlled attenuation of cross-interface covariance. Finally, boundary-driven prediction and domain reduction are formulated through Dirichlet-to-Neumann operators and Schur complements, providing an operator language for upscaling, change of support, and subdomain-to-boundary mappings. Throughout, we use tools standard in spatial statistics and elliptic PDE theory to keep boundary and interface effects explicit in covariance modeling and prediction."
  },
  {
    "date": "2026-01-21",
    "title": "Modelling the Time-variable Broadband Emission and Correlation Study of FSRQ S5 1044+71",
    "authors": "Sajad Ahanger, Shah Zahir, Sunder Sahayanathan, Naseer Iqbal, Zahoor Malik, Aaqib Manzoor",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14929v1",
    "source": "arXiv",
    "abstract": "We present a detailed temporal and spectral analysis of the blazar S5\\,1044+71 using multi-wavelength data obtained from the \\emph{Fermi}-LAT and Swift-XRT/UVOT telescopes. Applying the Bayesian block algorithm to the 3-day binned $γ$-ray lightcurve, we identify pronounced variability, including four major outbursts marked by significant flux enhancements. The highest flux recorded was $(1.1 \\pm 0.2)\\times 10^{-6}\\,\\text{ph}\\,\\text{cm}^{-2}\\,\\text{s}^{-1}$ on 57868.5 MJD. Each outburst comprises multiple components, and lightcurve profile analysis indicates predominantly symmetric temporal structures. The shortest variability timescale of 4.5 hours constrains the emission region to be located within 0.03 pc of the central engine, likely near the broad-line region (BLR). Additionally, two highest-energy photons were detected with energies of 46.4 GeV (on 57739.6 MJD) and 42.5 GeV (on 59161.9 MJD), observed outside the peak flaring activity. The fractional variability shows an overall increasing trend from UV/optical to $γ$-ray bands, with a noticeable dip in the X-ray range, consistent with the shape of the broadband spectral energy distribution (SED). The flux distributions during flares exhibit log-normal or double log-normal behavior, suggesting multiplicative variability processes and evolving emission zones. Cross-correlation analysis reveals a strong positive correlation between the $γ$-ray and X-ray bands, with X-rays lagging by 42.5 days. Broadband SED modeling across different flux states supports a one-zone leptonic scenario, with $γ$-ray emission produced via external Compton scattering of IR and BLR photons. High-flux states show harder electron spectra, elevated break energies, and reduced magnetic fields-features consistent with efficient particle acceleration and Compton dominance."
  },
  {
    "date": "2026-01-21",
    "title": "Operationalising DAO Sustainability KPIs: A Multi-Chain Dashboard for Governance Analytics",
    "authors": "Silvio Meneguzzo, Claudio Schifanella, Valentina Gatteschi, Giuseppe Destefanis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14927v1",
    "source": "arXiv",
    "abstract": "We present DAO Portal, a production-grade analytics pipeline and interactive dashboard for assessing the sustainability of Decentralised Autonomous Organisations (DAOs) through Key Performance Indicators (KPIs) derived from on-chain governance and token events. Building on our previous work, which defined and validated a multidimensional KPI framework for DAO sustainability, this paper moves from theory to practice by operationalising that framework in software infrastructure designed for finance and FinTech contexts. The system ingests governance and treasury data from major EVM networks, harmonises the outputs, and computes sustainability scores across four dimensions: participation, accumulated funds, voting efficiency, and decentralisation. A composite 0 to 12 score is then derived using transparent thresholds that are applied client-side in the browser. Using a curated snapshot of more than 50 active DAOs covering 6,930 proposals and 317,317 unique voting addresses, we show how the platform surfaces recurring patterns such as persistently low participation and concentration of proposal activity. These results demonstrate how DAO Portal supports the diagnosis of governance risks and the comparison of design choices across DAOs. To promote reproducibility and adoption, we release source code, data schema, and dashboard implementation. By turning governance traces into measurable and explainable KPIs, DAO Portal provides auditable evidence of DAO sustainability and contributes software engineering infrastructure for financial applications where treasuries and decision-making rights involve significant assets."
  },
  {
    "date": "2026-01-21",
    "title": "Semileptonic decays $D_{(s)} \\to η^{(\\prime)} \\ell^+ ν_\\ell$ from QCD Light-Cone Sum Rules",
    "authors": "Xiao-En Huang, Shan Cheng, De-Liang Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14915v1",
    "source": "arXiv",
    "abstract": "In light of recent precision measurements from BESIII, we reanalyze the $D, D_s \\to η^{(\\prime)}$ transition form factors using QCD light-cone sum rules, incorporating high-twist contributions and well-established next-to-leading-order QCD corrections. Our analysis confirms the chiral enhancement effect arising from twist-3 light-cone distribution amplitudes of the pseudoscalar mesons, and demonstrates a rapid convergence of the operator product expansion. The resulting high-accuracy form factors enable us to determine the optimal $η$-$η^\\prime$ mixing parameters from the precise experimental data for the $D, D_s \\to η^{(\\prime)} \\ell^+ ν_\\ell$ (with $\\ell = e, μ$) differential decay rates. We find that the BESIII data strongly favor a set of mixing parameters, characterized by small decay constants and a large mixing angle, in the quark flavor basis. Notably, the light-cone-sum-rule predictions for the decays $D \\to η^{(\\prime)} \\ell^+ ν_\\ell$, induced by weak $c\\to d$ current, reach a precision comparable to the BESIII experimental results. Nevertheless, further refined measurements and more accurate form-factor determinations will be essential to scrutinize the potential role of gluonic components in charmed meson semileptonic decays."
  },
  {
    "date": "2026-01-21",
    "title": "Language-Coupled Reinforcement Learning for Multilingual Retrieval-Augmented Generation",
    "authors": "Rui Qi, Fengran Mo, Yufeng Chen, Xue Zhang, Shuo Wang, Hongliang Li, Jinan Xu, Meng Jiang, Jian-Yun Nie, Kaiyu Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14896v1",
    "source": "arXiv",
    "abstract": "Multilingual retrieval-augmented generation (MRAG) requires models to effectively acquire and integrate beneficial external knowledge from multilingual collections. However, most existing studies employ a unitive process where queries of equivalent semantics across different languages are processed through a single-turn retrieval and subsequent optimization. Such a ``one-size-fits-all'' strategy is often suboptimal in multilingual settings, as the models occur to knowledge bias and conflict during the interaction with the search engine. To alleviate the issues, we propose LcRL, a multilingual search-augmented reinforcement learning framework that integrates a language-coupled Group Relative Policy Optimization into the policy and reward models. We adopt the language-coupled group sampling in the rollout module to reduce knowledge bias, and regularize an auxiliary anti-consistency penalty in the reward models to mitigate the knowledge conflict. Experimental results demonstrate that LcRL not only achieves competitive performance but is also appropriate for various practical scenarios such as constrained training data and retrieval over collections encompassing a large number of languages. Our code is available at https://github.com/Cherry-qwq/LcRL-Open."
  },
  {
    "date": "2026-01-21",
    "title": "The CHI26 Workshop on the Future of Cognitive Personal Informatics",
    "authors": "Christina Schneegass, Francesco Chiossi, Anna L. Cox, Dimitra Dritsa, Teodora Mitrevska, Stephen Rainey, Max L. Wilson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14891v1",
    "source": "arXiv",
    "abstract": "Research on Cognitive Personal Informatics (CPI) is steadily growing as new wearable cognitive tracking technologies emerge on the consumer market, claiming to measure stress, focus, and other cognitive factors. At the same time, with generative AI offering new ways to analyse, visualize, and interpret cognitive data, we hypothesize that cognitive tracking will soon become as simple as measuring your heart rate during a run. Yet, cognitive data remains inherently more complex, context-dependent, and less well understood than physical activity data. This workshop brings together HCI experts to discuss critical questions, including: How can complex cognitive data be translated into meaningful metrics? How can AI support users' data sensemaking without over-simplifying cognitive insights? How can we design inclusive CPI technologies that consider inter-personal variance and neurodiversity? We will map"
  },
  {
    "date": "2026-01-21",
    "title": "Small scale turbulence alongside with large scale turbulence in a z~sim 2 star Forming Galaxy with outflowing wind, revealed by Multi-point structure functions",
    "authors": "Itzhak Goldman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14887v1",
    "source": "arXiv",
    "abstract": "Recently, Goldman (2024) obtained evidence for a large scale compressible, Burgers turbulence in the ism of a gravitationally lensed, star-forming galaxy at $z = 1.87$, with an outflowing wind. The turbulent timescale on the largest spatial scale has been found to be ~500 Myr . This together with the large spatial scale of~ 6.4 kpc suggest a large scale generating mechanism (such as tidal interaction or merger) that lasted for ~500 Myr. On the other hand, the outflowing wind is much younger and is probably the result of the intense star formation. Therefore, could it be that the star formation drives also turbulence on small scales? In the present work we utilize multi-point second order structure functions to find whether there exists also a small scale turbulence in this galaxy, and if so, try to identify its drivers. We obtained evidence for small scale turbulence whose largest spatial scale ~240 pc for the nebular gas velocity field and ~ 290 pc$ for the outflowing wind velocity field. These values suggest that stellar sub clumps or giant star clusters with an high concentration of young massive stars could be responsible for both the outflow and for the small scale turbulence."
  },
  {
    "date": "2026-01-21",
    "title": "The Pieri Rule at Infinity",
    "authors": "Ivan Penkov, Pablo Zadunaisky",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14879v1",
    "source": "arXiv",
    "abstract": "We study the structure of tensor products of $\\mathfrak{gl}(\\infty) = \\varinjlim \\mathfrak{gl}(n)$-modules $\\mathbf L(\\mathbf λ) \\otimes \\mathbf F$ where $\\mathbf L(\\mathbf λ)$ is a simple integrable highest weight module and $\\mathbf F$ is a simple integrable weight multiplicity-free module. Both $\\mathbf L(\\mathbf λ)$ and $\\mathbf F$ are infinite dimensional, in particular $\\mathbf F$ can be a Fock module. Similar tensor products of $\\mathfrak{gl}(n)$-modules are semisimple and their simple constituents are described by the classical Pieri rule. We prove that a $\\mathfrak{gl}(\\infty)$-module $\\mathbf M:= \\mathbf L(\\mathbf λ) \\otimes \\mathbf F$ is semisimple only in relatively trivial cases, and is indecomposable otherwise. Our main results are a description of the simple constituents of $\\mathbf M$, and the construction of a linkage filtration on $\\mathbf M$ that provides information on when two simple constituents of $\\mathbf M$ are linked. Using the linkage filtration, we compute the socle and radical filtrations of $\\mathbf M$, and determine when $\\mathbf M$ is rigid."
  },
  {
    "date": "2026-01-21",
    "title": "GAT-NeRF: Geometry-Aware-Transformer Enhanced Neural Radiance Fields for High-Fidelity 4D Facial Avatars",
    "authors": "Zhe Chang, Haodong Jin, Ying Sun, Yan Song, Hui Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14875v1",
    "source": "arXiv",
    "abstract": "High-fidelity 4D dynamic facial avatar reconstruction from monocular video is a critical yet challenging task, driven by increasing demands for immersive virtual human applications. While Neural Radiance Fields (NeRF) have advanced scene representation, their capacity to capture high-frequency facial details, such as dynamic wrinkles and subtle textures from information-constrained monocular streams, requires significant enhancement. To tackle this challenge, we propose a novel hybrid neural radiance field framework, called Geometry-Aware-Transformer Enhanced NeRF (GAT-NeRF) for high-fidelity and controllable 4D facial avatar reconstruction, which integrates the Transformer mechanism into the NeRF pipeline. GAT-NeRF synergistically combines a coordinate-aligned Multilayer Perceptron (MLP) with a lightweight Transformer module, termed as Geometry-Aware-Transformer (GAT) due to its processing of multi-modal inputs containing explicit geometric priors. The GAT module is enabled by fusing multi-modal input features, including 3D spatial coordinates, 3D Morphable Model (3DMM) expression parameters, and learnable latent codes to effectively learn and enhance feature representations pertinent to fine-grained geometry. The Transformer's effective feature learning capabilities are leveraged to significantly augment the modeling of complex local facial patterns like dynamic wrinkles and acne scars. Comprehensive experiments unequivocally demonstrate GAT-NeRF's state-of-the-art performance in visual fidelity and high-frequency detail recovery, forging new pathways for creating realistic dynamic digital humans for multimedia applications."
  },
  {
    "date": "2026-01-21",
    "title": "On-the-fly hand-eye calibration for the da Vinci surgical robot",
    "authors": "Zejian Cui, Ferdinando Rodriguez y Baena",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14871v1",
    "source": "arXiv",
    "abstract": "In Robot-Assisted Minimally Invasive Surgery (RMIS), accurate tool localization is crucial to ensure patient safety and successful task execution. However, this remains challenging for cable-driven robots, such as the da Vinci robot, because erroneous encoder readings lead to pose estimation errors. In this study, we propose a calibration framework to produce accurate tool localization results through computing the hand-eye transformation matrix on-the-fly. The framework consists of two interrelated algorithms: the feature association block and the hand-eye calibration block, which provide robust correspondences for key points detected on monocular images without pre-training, and offer the versatility to accommodate various surgical scenarios by adopting an array of filter approaches, respectively. To validate its efficacy, we test the framework extensively on publicly available video datasets that feature multiple surgical instruments conducting tasks in both in vitro and ex vivo scenarios, under varying illumination conditions and with different levels of key point measurement accuracy. The results show a significant reduction in tool localization errors under the proposed calibration framework, with accuracies comparable to other state-of-the-art methods while being more time-efficient."
  },
  {
    "date": "2026-01-21",
    "title": "Significance of the dispersion force for ferroelectric switching in ZnO and related materials",
    "authors": "Lingyao Zhang, Musen Li, Nisha Metha, Carla Verdi, Wei Ren, Jeffrey R. Reimers",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14847v1",
    "source": "arXiv",
    "abstract": "Wurtzite-ZnO is a wide-bandgap polar material with a ferroelectric-switching barrier that is too high to utilize, but the barrier can be reduced and switching observed in substituted materials such as Zn0.5Mg0.5O. Here, we seek to understand atomic-scale features that control concerted polarization switching in these and related systems, focusing on the planar hexagonal structures h-ZnO and Zn0.5Mg0.5O that may act as metastable intermediate phases along the switching pathway. Consensus is obtained by considering a range of pure and dispersion-corrected density-functional theory (DFT) computational approaches, as well as ab initio Hartree-Fock (HF), Møller-Plesset perturbation-theory (MP2), and random-phase approximation (RPA) calculations. The perceived stability of h-ZnO is found to be strongly influenced by the dispersion correction, with the consensus being that dispersion interactions are insufficient to stabilize h-ZnO as a metastable phase in infinite crystals. In contrast, h-Zn0.5Mg0.5O is consistently predicted to be at least metastable, with some dispersion-corrected DFT approaches predicting it to be more stable than its wurtzite form; all DFT methods overestimate its stability compared to MP2 and RPA. Dispersion forces are found to be most significant for hypothetical planar hexagonal structures constrained to the lattice vectors of the wurtzite phases. In general, our results demonstrate that an accurate treatment of dispersion forces is essential when describing polarization switching and ferroelectric behavior in wurtzite-structured materials."
  },
  {
    "date": "2026-01-21",
    "title": "A Category-Theoretic Framework for Dependent Effect Systems",
    "authors": "Satoshi Kura, Marco Gaboardi, Taro Sekiyama, Hiroshi Unno",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14846v1",
    "source": "arXiv",
    "abstract": "Graded monads refine traditional monads using effect annotations in order to describe quantitatively the computational effects that a program can generate. They have been successfully applied to a variety of formal systems for reasoning about effectful computations. However, existing categorical frameworks for graded monads do not support effects that may depend on program values, which we call dependent effects, thereby limiting their expressiveness. We address this limitation by introducing indexed graded monads, a categorical generalization of graded monads inspired by the fibrational \"indexed\" view and by classical categorical semantics of dependent type theories. We show how indexed graded monads provide semantics for a refinement type system with dependent effects. We also show how this type system can be instantiated with specific choices of parameters to obtain several formal systems for reasoning about specific program properties. These instances include, in particular, cost analysis, probability-bound reasoning, expectation-bound reasoning, and temporal safety verification."
  },
  {
    "date": "2026-01-21",
    "title": "CAG-Avatar: Cross-Attention Guided Gaussian Avatars for High-Fidelity Head Reconstruction",
    "authors": "Zhe Chang, Haodong Jin, Yan Song, Hui Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14844v1",
    "source": "arXiv",
    "abstract": "Creating high-fidelity, real-time drivable 3D head avatars is a core challenge in digital animation. While 3D Gaussian Splashing (3D-GS) offers unprecedented rendering speed and quality, current animation techniques often rely on a \"one-size-fits-all\" global tuning approach, where all Gaussian primitives are uniformly driven by a single expression code. This simplistic approach fails to unravel the distinct dynamics of different facial regions, such as deformable skin versus rigid teeth, leading to significant blurring and distortion artifacts. We introduce Conditionally-Adaptive Gaussian Avatars (CAG-Avatar), a framework that resolves this key limitation. At its core is a Conditionally Adaptive Fusion Module built on cross-attention. This mechanism empowers each 3D Gaussian to act as a query, adaptively extracting relevant driving signals from the global expression code based on its canonical position. This \"tailor-made\" conditioning strategy drastically enhances the modeling of fine-grained, localized dynamics. Our experiments confirm a significant improvement in reconstruction fidelity, particularly for challenging regions such as teeth, while preserving real-time rendering performance."
  },
  {
    "date": "2026-01-21",
    "title": "MTFlow: Time-Conditioned Flow Matching for Microtubule Segmentation in Noisy Microscopy Images",
    "authors": "Sidi Mohamed Sid El Moctar, Achraf Ait Laydi, Yousef El Mourabit, Hélène Bouvrais",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14841v1",
    "source": "arXiv",
    "abstract": "Microtubules are cytoskeletal filaments that play essential roles in many cellular processes and are key therapeutic targets in several diseases. Accurate segmentation of microtubule networks is critical for studying their organization and dynamics but remains challenging due to filament curvature, dense crossings, and image noise. We present MTFlow, a novel time-conditioned flow-matching model for microtubule segmentation. Unlike conventional U-Net variants that predict masks in a single pass, MTFlow learns vector fields that iteratively transport noisy masks toward the ground truth, enabling interpretable, trajectory-based refinement. Our architecture combines a U-Net backbone with temporal embeddings, allowing the model to capture the dynamics of uncertainty resolution along filament boundaries. We trained and evaluated MTFlow on synthetic and real microtubule datasets and assessed its generalization capability on public biomedical datasets of curvilinear structures such as retinal blood vessels and nerves. MTFlow achieves competitive segmentation accuracy comparable to state-of-the-art models, offering a powerful and time-efficient tool for filamentous structure analysis with more precise annotations than manual or semi-automatic approaches."
  },
  {
    "date": "2026-01-21",
    "title": "Implementing Knowledge Representation and Reasoning with Object Oriented Design",
    "authors": "Abdelrhman Bassiouny, Tom Schierenbeck, Sorin Arion, Benjamin Alt, Naren Vasantakumaar, Giang Nguyen, Michael Beetz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14840v1",
    "source": "arXiv",
    "abstract": "This paper introduces KRROOD, a framework designed to bridge the integration gap between modern software engineering and Knowledge Representation & Reasoning (KR&R) systems. While Object-Oriented Programming (OOP) is the standard for developing complex applications, existing KR&R frameworks often rely on external ontologies and specialized languages that are difficult to integrate with imperative code. KRROOD addresses this by treating knowledge as a first-class programming abstraction using native class structures, bridging the gap between the logic programming and OOP paradigms. We evaluate the system on the OWL2Bench benchmark and a human-robot task learning scenario. Experimental results show that KRROOD achieves strong performance while supporting the expressive reasoning required for real-world autonomous systems."
  },
  {
    "date": "2026-01-21",
    "title": "Casselman-Wallach property for homological theta lifting",
    "authors": "Zhibin Geng, Hang Xue",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14832v1",
    "source": "arXiv",
    "abstract": "In this paper, we establish the Casselman-Wallach property for homological theta lifting over archimedean local fields. As a consequence, the Euler-Poincaré characteristic is a well-defined element in the Grothendieck group of Casselman-Wallach representations. Our main tool is a corank-one parabolic stable filtration on the Weil representation."
  },
  {
    "date": "2026-01-21",
    "title": "A proof for the conjecture on superlinear problems with Ambrosetti-Rabinowitz condition",
    "authors": "Chong Li, Shujie Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14825v1",
    "source": "arXiv",
    "abstract": "This paper is devoted to exploring a new minimax approach by introducing a characteristic mapping family which is invariant under the smooth descending flow for initial value. The minimax approach is self-contained, and its features are markedly different from standard ones, as it identifies the existence of critical points and intrinsically presents a lower-bound estimate for the generalized Morse index at the corresponding critical point. This quantity can be effectively viewed as an alternative to the group action. As applications, under the Ambrosetti-Rabinowitz condition we offer a positive answer to the long-standing open problem on the existence of infinitely many distinct solutions for superlinear elliptic equations without symmetric hypothesis."
  },
  {
    "date": "2026-01-21",
    "title": "Archives, archival bond, and digital representation: A case study with the International Image Interoperability Framework",
    "authors": "Martin Critelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14823v1",
    "source": "arXiv",
    "abstract": "Within the archival sector, digitization has long been a strategic initiative to ensure greater availability of historical documents. In recent years, the promotion of guidelines and standards, combined with technological advancements, has established methodologies and best practices and developed tools to facilitate massive digitization projects. However, despite the availability of technological solutions and guidelines, digitization is intended mostly to scan documents and make the outcome images available online. This practice can be problematic in representing the complex fonds structure made of relations, the archival bond that establishes the natural ordering of documents into archival units. This is particularly relevant when the fonds also has a multimedia component, such as an audiovisual component, that is often reproduced on different platforms disconnected from textual documents. This article addresses the challenges linked to digitization in the archival sector and proposes a methodological framework for representing fonds with respect to their native organization. For this purpose, the International Image Interoperability Framework (IIIF) is employed to configure a specific model that respects the archive's hierarchical structure. In particular, this model is configured to maintain the archival bond and enhance the resource's semantic aspect to make the IIIF model semantically interoperable. To demonstrate the adaptability of the framework to the archival domain, in this work, the ''PCI-Unitelefilm'' fonds of the Fondazione Archivio Audiovisivo del Movimento Operaio e Democratico (AAMOD) served as the case study."
  },
  {
    "date": "2026-01-21",
    "title": "ICLF: An Immersive Code Learning Framework based on Git for Teaching and Evaluating Student Programming Projects",
    "authors": "Pierre Schaus, Guillaume Derval, Augustin Delecluse",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14814v1",
    "source": "arXiv",
    "abstract": "Programming projects are essential in computer science education for bridging theory with practice and introducing students to tools like Git, IDEs, and debuggers. However, designing and evaluating these projects (especially in MOOCs)can be challenging. We propose the Immersive Code Learning Framework (ICLF), a scalable Git-based organizational pipeline for managing and evaluating student programming project. Students begin with an existing code base, a practice that is crucial for mirroring real-world software development. Students then iteratively complete tasks that pass predefined tests. The instructor only manages a hidden parent repository containing solutions, which is used to generate an intermediate public repository with these solutions removed via a templating system. Students are invited collaborators on private forks of this intermediate repository, possibly updated throughout the semester whenever the teacher changes the parent repository. This approach reduces grading platform dependency, supports automated feedback, and allows the project to evolve without disrupting student work. Successfully tested over several years, including in an edX MOOC, this organizational pipeline provides transparent evaluation, plagiarism detection, and continuous progress tracking for each student."
  },
  {
    "date": "2026-01-21",
    "title": "Emergence of multiple zero modes bound to vortices in extended topological Josephson junctions",
    "authors": "Adrian Reich, Kiryl Piasotski, Eytan Grosfeld, Alexander Shnirman",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14808v1",
    "source": "arXiv",
    "abstract": "We study planar Josephson junctions formed on the surface of a three-dimensional topological insulator (Fu-Kane proposal) and examine the experimentally relevant parameter regimes in which the effective velocity of the emergent one-dimensional Majorana modes approaches zero. We show that the frequently employed Fu-Kane effective theory breaks down in this case. As parameters like the chemical potential or the width of the junction are tuned, instances of vanishing effective velocity mark the emergence of additional 'Dirac cones' at zero energy and finite momentum. If the junction is subjected to an external magnetic field, Josephson vortices may then bind a number of zero modes in addition to the topological Majorana mode. The additional zero modes are 'symmetry-protected' and can be lifted by a broken mirror symmetry (which is to be expected in realistic scenarios) as well as by an in-plane magnetization (or Zeeman field). We note that the ensuing presence of additional low-energy Andreev states can significantly contribute to measured quantities like the Josephson current or microwave absorption spectra."
  },
  {
    "date": "2026-01-21",
    "title": "Minimizing Submodular Functions over Hierarchical Families",
    "authors": "Ryuhei Mizutani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14805v1",
    "source": "arXiv",
    "abstract": "This paper considers submodular function minimization (SFM) restricted to a family of subsets. We show that SFM over complements of families with certain hierarchical structures can be solved in polynomial-time. This yields a polynomial-time algorithm for SFM over complements of various families, such as intersecting families, crossing families, and the unions of lattices. Moreover, this tractability result partially settles the open question posed by Nägele, Sudakov, and Zenklusen on polynomial-solvability of SFM over the intersection of parity families. Furthermore, our tractability result implies that for a constant positive integer k, the k-th smallest value of a submodular function can be obtained in polynomial-time."
  },
  {
    "date": "2026-01-21",
    "title": "Reflecting in the Reflection: Integrating a Socratic Questioning Framework into Automated AI-Based Question Generation",
    "authors": "Ondřej Holub, Essi Ryymin, Rodrigo Alves",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14798v1",
    "source": "arXiv",
    "abstract": "Designing good reflection questions is pedagogically important but time-consuming and unevenly supported across teachers. This paper introduces a reflection-in-reflection framework for automated generation of reflection questions with large language models (LLMs). Our approach coordinates two role-specialized agents, a Student-Teacher and a Teacher-Educator, that engage in a Socratic multi-turn dialogue to iteratively refine a single question given a teacher-specified topic, key concepts, student level, and optional instructional materials. The Student-Teacher proposes candidate questions with brief rationales, while the Teacher-Educator evaluates them along clarity, depth, relevance, engagement, and conceptual interconnections, responding only with targeted coaching questions or a fixed signal to stop the dialogue. We evaluate the framework in an authentic lower-secondary ICT setting on the topic, using GPT-4o-mini as the backbone model and a stronger GPT- 4-class LLM as an external evaluator in pairwise comparisons of clarity, relevance, depth, and overall quality. First, we study how interaction design and context (dynamic vs.fixed iteration counts; presence or absence of student level and materials) affect question quality. Dynamic stopping combined with contextual information consistently outperforms fixed 5- or 10-step refinement, with very long dialogues prone to drift or over-complication. Second, we show that our two-agent protocol produces questions that are judged substantially more relevant and deeper, and better overall, than a one-shot baseline using the same backbone model."
  },
  {
    "date": "2026-01-21",
    "title": "Integrated Sensing, Communication and Control enabled Agile UAV Swarm",
    "authors": "Zhiqing Wei, Yucong Du, Zhiyong Feng, Haotian Liu, Yanpeng Cui, Tao Zhang, Ying Zhou, Huici Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14783v1",
    "source": "arXiv",
    "abstract": "Uncrewed aerial vehicle (UAV) swarms are pivotal in the applications such as disaster relief, aerial base station (BS) and logistics transportation. These scenarios require the capabilities in accurate sensing, efficient communication and flexible control for real-time and reliable task execution. However, sensing, communication and control are studied independently in traditional research, which limits the overall performance of UAV swarms. To overcome this disadvantage, we propose a deeply coupled scheme of integrated sensing, communication and control (ISCC) for UAV swarms, which is a systemic paradigm that transcends traditional isolated designs of sensing, communication and control by establishing a tightly-coupled closed-loop through the co-optimization of sensing, communication and control. In this article, we firstly analyze the requirements of scenarios and key performance metrics. Subsequently, the enabling technologies are proposed, including communication-and-control-enhanced sensing, sensing-and-control-enhanced communication, and sensing-and-communication-enhanced control. Simulation results validate the performance of the proposed ISCC framework, demonstrating its application potential in the future."
  },
  {
    "date": "2026-01-21",
    "title": "Self-organized flows break morphological symmetry in active/passive systems",
    "authors": "Rainer Backofen, Axel Voigt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15001v1",
    "source": "arXiv",
    "abstract": "We consider a phase-separating mixture of active and passive fluids and explore morphological asymmetries of the emerging dominantly bicontinous dynamic emulsion. Two-dimensional numerical simulations reveal that the geometric and topological asymmetries can solely be explained by self-organized flows in the active region. As in inertial turbulence an inverse energy cascade in the active region leads to the formation of condensates. The size of these mesocales vortices is determined by the locally available space in the emulsion. As these condensates accumulate energy they impact the fluctuation of the surrounding interface and thus form a tight coupling between the flow field and the dynamic morphology. While explored for active/passive systems the symmetry-breaking mechanism can be generalized to heterogeneous active systems and proposes a way to control the morphology of various functional soft materials."
  },
  {
    "date": "2026-01-21",
    "title": "QDK/Chemistry: A Modular Toolkit for Quantum Chemistry Applications",
    "authors": "Nathan A. Baker, Brian Bilodeau, Chi Chen, Yingrong Chen, Marco Eckhoff, Alexandra Efimovskaya, Piero Gasparotto, Puck van Gerwen, Rushi Gong, Kevin Hoang, Zahra Hooshmand, Andrew J. Jenkins, Conrad S. N. Johnston, Run R. Li, Jiashu Liang, Hongbin Liu, Alexis Mills, Maximilian Mörchen, George Nishibuchi, Chong Sun, Bill Ticehurst, Matthias Troyer, Jan P. Unsleber, Stefan Wernli, David B. Williams-Young, Boqin Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15253v1",
    "source": "arXiv",
    "abstract": "We present QDK/Chemistry, a software toolkit for quantum chemistry workflows targeting quantum computers. The toolkit addresses a key challenge in the field: while quantum algorithms for chemistry have matured considerably, the infrastructure connecting classical electronic structure calculations to quantum circuit execution remains fragmented. QDK/Chemistry provides this infrastructure through a modular architecture that separates data representations from computational methods, enabling researchers to compose workflows from interchangeable components. In addition to providing native implementations of targeted algorithms in the quantum-classical pipeline, the toolkit builds upon and integrates with widely used open-source quantum chemistry packages and quantum computing frameworks through a plugin system, allowing users to combine methods from different sources without modifying workflow logic. This paper describes the design philosophy, current capabilities, and role of QDK/Chemistry as a foundation for reproducible quantum chemistry experiments."
  },
  {
    "date": "2026-01-21",
    "title": "Partial Hölder regularity for fully nonlinear nonlocal parabolic equations with integrable kernels",
    "authors": "Minhyun Kim, Luke Schleef, Russell W. Schwab",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15096v1",
    "source": "arXiv",
    "abstract": "In this work, we consider solutions to (fully nonlinear) parabolic integro-differential equations with integrable interaction kernels. A typical equation would be that obtained by starting with, for $s\\in(0,1)$, the $s$-fractional heat equation, but replacing the interaction kernel in the integro-differential term with one which has been truncated, for $ρ>0$, at the value $ρ^{-d-2s}$, hence integrable. We show that solutions to these equations have a partial regularity estimate which captures differences of the solution up to the scale at which the kernel has a truncation in its singularity. The estimates we provide are robust with respect to the truncation parameter, and they include the existing results for the original operators without truncation. There are some earlier results for linear and elliptic cases of this situation of integrable interaction kernels, and so our work is a generalization of those to the nonlinear and parabolic setting."
  },
  {
    "date": "2026-01-21",
    "title": "Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning",
    "authors": "Oleg Shchendrigin, Egor Cherepanov, Alexey K. Kovalev, Aleksandr I. Panov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15086v1",
    "source": "arXiv",
    "abstract": "Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critical ability of memory rewriting largely unexplored. To address this gap, we introduce a benchmark that explicitly tests continual memory updating under partial observability, i.e. the natural setting where an agent must rely on memory rather than current observations, and use it to compare recurrent, transformer-based, and structured memory architectures. Our experiments reveal that classic recurrent models, despite their simplicity, demonstrate greater flexibility and robustness in memory rewriting tasks than modern structured memories, which succeed only under narrow conditions, and transformer-based agents, which often fail beyond trivial retention cases. These findings expose a fundamental limitation of current approaches and emphasize the necessity of memory mechanisms that balance stable retention with adaptive updating. Our work highlights this overlooked challenge, introduces benchmarks to evaluate it, and offers insights for designing future RL agents with explicit and trainable forgetting mechanisms. Code: https://quartz-admirer.github.io/Memory-Rewriting/"
  },
  {
    "date": "2026-01-21",
    "title": "Generalized preconditioned conjugate gradients for adaptive FEM with optimal complexity",
    "authors": "Paula Hilbert, Ani Miraçi, Dirk Praetorius",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14911v1",
    "source": "arXiv",
    "abstract": "We consider adaptive finite element methods (AFEMs) with inexact algebraic solver for second-order symmetric linear elliptic diffusion problems. We formulate and analyze a non-linear and non-symmetric geometric multigrid preconditioner for the generalized preconditioned conjugate gradient method (GPCG) used to solve the arising finite element systems. Moreover, a linear and symmetric variant of the geometric multigrid preconditioner that is suitable for the (standard) preconditioned conjugate gradient method (PCG) is provided and analyzed. We show that both preconditioners are optimal in the sense that, first, the resulting algebraic solvers admit a contraction factor that is independent of the local mesh size h and the polynomial degree p, and, second, that they can be applied with linear computational complexity. Related to this, quasi-optimal computational cost of the overall adaptive finite element method is addressed. Numerical experiments underline the theoretical findings."
  },
  {
    "date": "2026-01-21",
    "title": "Ionic transport in spontaneously ion-intercalated van der Waals layered structures",
    "authors": "Ata Utku Özkan, Talip Serkan Kasırga, Aykut Erbaş",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14836v1",
    "source": "arXiv",
    "abstract": "Understanding ionic transport under strong confinement is crucial for the design of next-generation energy, catalytic, and information-processing materials; however, repeated field-driven ion motion often degrades conventional solid electrolytes. Van der Waals layered materials offer an alternative by providing structurally resilient ion-transport channels, yet the microscopic origins of their nonequilibrium transport behavior remain poorly understood. Here, we investigate field-driven ionic conduction in sodium-intercalated layered MnO$_2$ as a model self-intercalated van der Waals solid, using all-atom nonequilibrium molecular dynamics simulations that explicitly capture ion-water correlations and layer morphology. We demonstrate that ionic conductivity depends nonlinearly on the applied electric field, interlayer spacing, water content, and lattice flexibility. The applied electric field induces spatial segregation of water coupled to distortions of the MnO$_2$ sheets, producing coexisting regions populated by highly hydrated and weakly hydrated ions with suppressed conductivity. Concurrently, ionic transport exhibits a nonmonotonic dependence on the total amount of intercalated water, with boundary domains of weakly hydrated ions displaying relatively higher mobility. In fluctuation-free layers, ion transport transitions from single-particle motion to a collective conduction regime characterized by elongated, same-charge ionic clusters that violate Nernst-Einstein behavior. Together, these findings provide a molecular-level mechanism linking confinement-induced electrostatic correlations and structural response to the emergent nonlinear transport observed experimentally in ion-intercalated MnO$_2$, and suggest general design principles for robust, water-assisted ionic conductors."
  },
  {
    "date": "2026-01-21",
    "title": "Semantic-Guided Unsupervised Video Summarization",
    "authors": "Haizhou Liu, Haodong Jin, Yiming Wang, Hui Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14773v1",
    "source": "arXiv",
    "abstract": "Video summarization is a crucial technique for social understanding, enabling efficient browsing of massive multimedia content and extraction of key information from social platforms. Most existing unsupervised summarization methods rely on Generative Adversarial Networks (GANs) to enhance keyframe selection and generate coherent, video summaries through adversarial training. However, such approaches primarily exploit unimodal features, overlooking the guiding role of semantic information in keyframe selection, and often suffer from unstable training. To address these limitations, we propose a novel Semantic-Guided Unsupervised Video Summarization method. Specifically, we design a novel frame-level semantic alignment attention mechanism and integrate it into a keyframe selector, which guides the Transformer-based generator within the adversarial framework to better reconstruct videos. In addition, we adopt an incremental training strategy to progressively update the model components, effectively mitigating the instability of GAN training. Experimental results demonstrate that our approach achieves superior performance on multiple benchmark datasets."
  },
  {
    "date": "2026-01-21",
    "title": "Realization of staircase topological Anderson phase transitions",
    "authors": "Marwa Mannai, Yaoyao Shu, Sonia Haddad, Mina Ren, Hong Chen, Yong Sun, Hisham Sati",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14769v1",
    "source": "arXiv",
    "abstract": "One-dimensional topological Anderson insulators provide a paradigm for disorder-induced topological phases in which the underlying system turns from a trivial to a topological phase. It is widely recognized that the latter vanishes at large disorder amplitude. Here, and contrary to the general belief, we provide evidence for a successive disorder-driven topological transitions in a single-wall nanotube, culminating in a topological Anderson phase that remains unexpectedly robust at strong disorder. This phenomenon is confirmed by analysis of the corresponding topological invariant, which increases stepwise as disorder increases, giving evidence for the emergence of edge states. We experimentally implement these topological Anderson staircase phase transitions in a one-dimensional topolectrical circuit, where the persistence of edge states is revealed by node-voltage measurements. The robustness of the edge states is corroborated by numerical calculations of their localization properties. Our work opens the road to topological disordertronics, where topological phases can be tuned by disorder."
  },
  {
    "date": "2026-01-21",
    "title": "ReinPath: A Multimodal Reinforcement Learning Approach for Pathology",
    "authors": "Kangcheng Zhou, Jun Jiang, Qing Zhang, Shuang Zheng, Qingli Li, Shugong Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14757v1",
    "source": "arXiv",
    "abstract": "Interpretability is significant in computational pathology, leading to the development of multimodal information integration from histopathological image and corresponding text data.However, existing multimodal methods have limited interpretability due to the lack of high-quality dataset that support explicit reasoning and inference and simple reasoning process.To address the above problems, we introduce a novel multimodal pathology large language model with strong reasoning capabilities.To improve the generation of accurate and contextually relevant textual descriptions, we design a semantic reward strategy integrated with group relative policy optimization.We construct a high-quality pathology visual question answering (VQA) dataset, specifically designed to support complex reasoning tasks.Comprehensive experiments conducted on this dataset demonstrate that our method outperforms state-of-the-art methods, even when trained with only 20% of the data.Our method also achieves comparable performance on downstream zero-shot image classification task compared with CLIP."
  },
  {
    "date": "2026-01-21",
    "title": "Marcinkiewicz--Zygmund-type SLLN for mixed moving average processes",
    "authors": "Danijel Grahovac, Péter Kevei, Dominik Mihalčić",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14748v1",
    "source": "arXiv",
    "abstract": "The Marcinkiewicz--Zygmund theorem is a fundamental result in probability theory that establishes rates of convergence in the strong law of large numbers (SLLN). Although numerous extensions have been developed for dependent sequences, many classes of processes, particularly those exhibiting strong dependence, remain unexplored. In this paper, we present a Marcinkiewicz--Zygmund-type SLLN for a class of mixed moving average processes, which form a large and flexible class of stationary infinitely divisible processes. In contrast to the classical case, where moments determine the asymptotic behavior, the present setting additionally involves key objects that characterize both dependence and marginal distributions."
  },
  {
    "date": "2026-01-21",
    "title": "Unlocking Large Audio-Language Models for Interactive Language Learning",
    "authors": "Hongfu Liu, Zhouying Cui, Xiangming Gu, Ye Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14744v1",
    "source": "arXiv",
    "abstract": "Achieving pronunciation proficiency in a second language (L2) remains a challenge, despite the development of Computer-Assisted Pronunciation Training (CAPT) systems. Traditional CAPT systems often provide unintuitive feedback that lacks actionable guidance, limiting its effectiveness. Recent advancements in audio-language models (ALMs) offer the potential to enhance these systems by providing more user-friendly feedback. In this work, we investigate ALMs for chat-based pronunciation training by introducing L2-Arctic-plus, an English dataset with detailed error explanations and actionable suggestions for improvement. We benchmark cascaded ASR+LLMs and existing ALMs on this dataset, specifically in detecting mispronunciation and generating actionable feedback. To improve the performance, we further propose to instruction-tune ALMs on L2-Arctic-plus. Experimental results demonstrate that our instruction-tuned models significantly outperform existing baselines on mispronunciation detection and suggestion generation in terms of both objective and human evaluation, highlighting the value of the proposed dataset."
  },
  {
    "date": "2026-01-21",
    "title": "Cosmological Constraints on f(T,B) Gravity from Observations of Early and Late Universe",
    "authors": "Yahia Al-Omar, Majida Nahili, Nidal Chamoun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14729v1",
    "source": "arXiv",
    "abstract": "We present a unified framework that combines early- and late-Universe observations to constrain three functional realizations of f(T,B) gravity: the linear, quadratic, and general power-law models. First, constraints on deviations from the standard weak interaction freeze-out temperature are derived using the most recent measurements of the primordial helium-4 mass fraction. Second, we perform a joint analysis incorporating five priors: Type Ia supernovae, baryon acoustic oscillations, cosmic chronometers, Big Bang Nucleosynthesis, and Cosmic Microwave Background in order to place bounds on the model parameters. The joint likelihood analysis significantly tightens the constraints compared to individual datasets. Third, we test the null, strong, and dominant energy conditions to evaluate the physical viability of the best-fit solutions across the cosmic redshift range. Our results show that all three f(T,B) models are consistent with current observations and exhibit stable behavior under the energy-condition criteria, supporting torsion-boundary modified gravity as a robust and viable alternative to General Relativity."
  },
  {
    "date": "2026-01-21",
    "title": "HERMES: KV Cache as Hierarchical Memory for Efficient Streaming Video Understanding",
    "authors": "Haowei Zhang, Shudong Yang, Jinlan Fu, See-Kiong Ng, Xipeng Qiu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14724v1",
    "source": "arXiv",
    "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) have demonstrated significant improvement in offline video understanding. However, extending these capabilities to streaming video inputs, remains challenging, as existing models struggle to simultaneously maintain stable understanding performance, real-time responses, and low GPU memory overhead. To address this challenge, we propose HERMES, a novel training-free architecture for real-time and accurate understanding of video streams. Based on a mechanistic attention investigation, we conceptualize KV cache as a hierarchical memory framework that encapsulates video information across multiple granularities. During inference, HERMES reuses a compact KV cache, enabling efficient streaming understanding under resource constraints. Notably, HERMES requires no auxiliary computations upon the arrival of user queries, thereby guaranteeing real-time responses for continuous video stream interactions, which achieves 10$\\times$ faster TTFT compared to prior SOTA. Even when reducing video tokens by up to 68% compared with uniform sampling, HERMES achieves superior or comparable accuracy across all benchmarks, with up to 11.4% gains on streaming datasets."
  },
  {
    "date": "2026-01-21",
    "title": "Systematic study of the strong decays of the $P_c$ states and their possible isospin cousins via the QCD sum rules",
    "authors": "Xiu-Wu Wang, Xin Li, Zhi-Gang Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14723v1",
    "source": "arXiv",
    "abstract": "In the present work, the strong decays of the discovered $P_c(4380)$, $P_c(4440)$, $P_c(4457)$ and their possible isospin cousins are systematically studied via the assignment that they are the meson-baryon molecular states. In detail, the strong decay constants, partial decay widths of their decay channels are calculated under the framework of QCD sum rules. The decay withes of the discovered $P_c(4380)$, $P_c(4440)$ and $P_c(4457)$ are in good agreement with the experiments. The predictions of the decays of these three related possible isospin cousins are presented which would shed light for their findings in experiment, in return, this may testify the assignments of the discovered $P_c$ states."
  },
  {
    "date": "2026-01-21",
    "title": "Physicochemical properties of lunar regolith simulant for in situ oxygen production",
    "authors": "Alyssa Ang De Guzman, Anish Mathai Varghese, Saif Alshalloudi, Lance Kosca, Kyriaki Polychronopoulou, Marko Gacesa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14719v1",
    "source": "arXiv",
    "abstract": "Permanent lunar settlements will rely on in situ oxygen production from regolith for life support and propulsion. While oxygen is abundant in lunar materials, it is chemically bound within metal oxides whose extractability depends strongly on regolith composition and processing strategy. In this study, we validate and characterize high-fidelity lunar regolith simulants representative of the lunar highlands and south pole using scanning electron microscopy with energy-dispersive X-ray spectroscopy, X-ray diffraction, Brunauer-Emmett-Teller surface area and pore structure analysis, and hydrogen temperature-programmed reduction. The simulants exhibit strong mineralogical and compositional fidelity to returned Apollo and Chang'e samples, with ilmenite confirmed as the most readily reducible oxygen-bearing phase. However, despite low ilmenite abundance, bulk highland simulants display favorable reduction behavior arising from distributed Fe-bearing silicate and glassy phases, as well as surface and microstructural properties that influence gas-solid interactions. Adsorption experiments with gases (H2, CH4, and CO2) and water indicate that mineralogical heterogeneity and pore accessibility influence their uptake in simulants. These results indicate that oxygen extraction behavior in realistic lunar regolith is governed by whole-regolith response rather than ilmenite content alone, supporting the option of whole-regolith processing strategies for oxygen production in lunar in situ resource utilization architectures."
  },
  {
    "date": "2026-01-21",
    "title": "Context Patch Fusion With Class Token Enhancement for Weakly Supervised Semantic Segmentation",
    "authors": "Yiyang Fu, Hui Li, Wangyu Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14718v1",
    "source": "arXiv",
    "abstract": "Weakly Supervised Semantic Segmentation (WSSS), which relies only on image-level labels, has attracted significant attention for its cost-effectiveness and scalability. Existing methods mainly enhance inter-class distinctions and employ data augmentation to mitigate semantic ambiguity and reduce spurious activations. However, they often neglect the complex contextual dependencies among image patches, resulting in incomplete local representations and limited segmentation accuracy. To address these issues, we propose the Context Patch Fusion with Class Token Enhancement (CPF-CTE) framework, which exploits contextual relations among patches to enrich feature representations and improve segmentation. At its core, the Contextual-Fusion Bidirectional Long Short-Term Memory (CF-BiLSTM) module captures spatial dependencies between patches and enables bidirectional information flow, yielding a more comprehensive understanding of spatial correlations. This strengthens feature learning and segmentation robustness. Moreover, we introduce learnable class tokens that dynamically encode and refine class-specific semantics, enhancing discriminative capability. By effectively integrating spatial and semantic cues, CPF-CTE produces richer and more accurate representations of image content. Extensive experiments on PASCAL VOC 2012 and MS COCO 2014 validate that CPF-CTE consistently surpasses prior WSSS methods."
  },
  {
    "date": "2026-01-21",
    "title": "Adaptive Fidelity Estimation for Quantum Programs with Graph-Guided Noise Awareness",
    "authors": "Tingting Li, Ziming Zhao, Jianwei Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14713v1",
    "source": "arXiv",
    "abstract": "Fidelity estimation is a critical yet resource-intensive step in testing quantum programs on noisy intermediate-scale quantum (NISQ) devices, where the required number of measurements is difficult to predefine due to hardware noise, device heterogeneity, and transpilation-induced circuit transformations. We present QuFid, an adaptive and noise-aware framework that determines measurement budgets online by leveraging circuit structure and runtime statistical feedback. QuFid models a quantum program as a directed acyclic graph (DAG) and employs a control-flow-aware random walk to characterize noise propagation along gate dependencies. Backend-specific effects are captured via transpilation-induced structural deformation metrics, which are integrated into the random-walk formulation to induce a noise-propagation operator. Circuit complexity is then quantified through the spectral characteristics of this operator, providing a principled and lightweight basis for adaptive measurement planning. Experiments on 18 quantum benchmarks executed on IBM Quantum backends show that QuFid significantly reduces measurement cost compared to fixed-shot and learning-based baselines, while consistently maintaining acceptable fidelity bias."
  },
  {
    "date": "2026-01-21",
    "title": "FEcMD: A multi-physics and multi-scale computational program for dynamic coupling molecular dynamics simulations with transient electric field and heat conduction in metal nanostructures",
    "authors": "Bing Xiao, Nan Li, Wenqian Kong, Rui Chu, Hongyu Zhang, Guodong Meng, Kai Wu, Yonghong Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14712v1",
    "source": "arXiv",
    "abstract": "Field emission coupled with molecular dynamics simulation (FEcMD) software package is a computational tool for studying atomic structure evolution, structural deformation, phase transitions, recrystallization as well as electron emission characteristics of micro- and nano-protrusions and nanowires consisting of elemental metals or multi-component alloys by means of multi-physics and multi-scale methodology. Current implementations of molecular dynamics simulation coupled with multi-scale electrodynamics (ED) and heat conduction (HC) in FEcMD program are advanced mainly in the two aspects as follows. In electrodynamics, the FEcMD program incorporates the space charge interactions (space charge potential and exchange-correlation effects) in the self-consistent solved Poisson-Schrödinger equation with Wentzel-Kramers-Brillouin-Jeffreys (WKBJ) approximation to evaluate the field emission current density and the related resistive heating process more reliably for nanowires or nano-protrusions especially for nano-gaps between two metal electrodes. Meanwhile, the two-temperature heat conduction model is implemented in electrodynamics coupled with molecular dynamics simulations (ED-MD), providing more dedicated descriptions for the hierarchical electron-phonon two-channel heat conduction mechanism and the temperature evolutions of electron and phonon subsystems under the radiofrequency (RF) or pulse electric fields. Benchmark tests are performed for some key implementations in FEcMD software to validate the numerical results, and also to demonstrate the use of program to study the atomic structure evolution of metal nano-structures under electric field and heating processes."
  },
  {
    "date": "2026-01-21",
    "title": "DARA: Few-shot Budget Allocation in Online Advertising via In-Context Decision Making with RL-Finetuned LLMs",
    "authors": "Mingxuan Song, Yusen Huo, Bohan Zhou, Shenglin Yin, Zhen Xiao, Jieyi Long, Zhilin Zhang, Chuan Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14711v1",
    "source": "arXiv",
    "abstract": "Optimizing the advertiser's cumulative value of winning impressions under budget constraints poses a complex challenge in online advertising, under the paradigm of AI-Generated Bidding (AIGB). Advertisers often have personalized objectives but limited historical interaction data, resulting in few-shot scenarios where traditional reinforcement learning (RL) methods struggle to perform effectively. Large Language Models (LLMs) offer a promising alternative for AIGB by leveraging their in-context learning capabilities to generalize from limited data. However, they lack the numerical precision required for fine-grained optimization. To address this limitation, we introduce GRPO-Adaptive, an efficient LLM post-training strategy that enhances both reasoning and numerical precision by dynamically updating the reference policy during training. Built upon this foundation, we further propose DARA, a novel dual-phase framework that decomposes the decision-making process into two stages: a few-shot reasoner that generates initial plans via in-context prompting, and a fine-grained optimizer that refines these plans using feedback-driven reasoning. This separation allows DARA to combine LLMs' in-context learning strengths with precise adaptability required by AIGB tasks. Extensive experiments on both real-world and synthetic data environments demonstrate that our approach consistently outperforms existing baselines in terms of cumulative advertiser value under budget constraints."
  },
  {
    "date": "2026-01-21",
    "title": "Case-Guided Sequential Assay Planning in Drug Discovery",
    "authors": "Tianchi Chen, Jan Bima, Sean L. Wu, Otto Ritter, Bingjia Yang, Xiang Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14710v1",
    "source": "arXiv",
    "abstract": "Optimally sequencing experimental assays in drug discovery is a high-stakes planning problem under severe uncertainty and resource constraints. A primary obstacle for standard reinforcement learning (RL) is the absence of an explicit environment simulator or transition data $(s, a, s')$; planning must rely solely on a static database of historical outcomes. We introduce the Implicit Bayesian Markov Decision Process (IBMDP), a model-based RL framework designed for such simulator-free settings. IBMDP constructs a case-guided implicit model of transition dynamics by forming a nonparametric belief distribution using similar historical outcomes. This mechanism enables Bayesian belief updating as evidence accumulates and employs ensemble MCTS planning to generate stable policies that balance information gain toward desired outcomes with resource efficiency. We validate IBMDP through comprehensive experiments. On a real-world central nervous system (CNS) drug discovery task, IBMDP reduced resource consumption by up to 92\\% compared to established heuristics while maintaining decision confidence. To rigorously assess decision quality, we also benchmarked IBMDP in a synthetic environment with a computable optimal policy. Our framework achieves significantly higher alignment with this optimal policy than a deterministic value iteration alternative that uses the same similarity-based model, demonstrating the superiority of our ensemble planner. IBMDP offers a practical solution for sequential experimental design in data-rich but simulator-poor domains."
  },
  {
    "date": "2026-01-21",
    "title": "AutoDriDM: An Explainable Benchmark for Decision-Making of Vision-Language Models in Autonomous Driving",
    "authors": "Zecong Tang, Zixu Wang, Yifei Wang, Weitong Lian, Tianjian Gao, Haoran Li, Tengju Ru, Lingyi Meng, Zhejun Cui, Yichen Zhu, Qi Kang, Kaixuan Wang, Yu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14702v1",
    "source": "arXiv",
    "abstract": "Autonomous driving is a highly challenging domain that requires reliable perception and safe decision-making in complex scenarios. Recent vision-language models (VLMs) demonstrate reasoning and generalization abilities, opening new possibilities for autonomous driving; however, existing benchmarks and metrics overemphasize perceptual competence and fail to adequately assess decision-making processes. In this work, we present AutoDriDM, a decision-centric, progressive benchmark with 6,650 questions across three dimensions - Object, Scene, and Decision. We evaluate mainstream VLMs to delineate the perception-to-decision capability boundary in autonomous driving, and our correlation analysis reveals weak alignment between perception and decision-making performance. We further conduct explainability analyses of models' reasoning processes, identifying key failure modes such as logical reasoning errors, and introduce an analyzer model to automate large-scale annotation. AutoDriDM bridges the gap between perception-centered and decision-centered evaluation, providing guidance toward safer and more reliable VLMs for real-world autonomous driving."
  },
  {
    "date": "2026-01-21",
    "title": "AdaTIR: Adaptive Tool-Integrated Reasoning via Difficulty-Aware Policy Optimization",
    "authors": "Zhaiyu Fang, Ruipeng Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14696v1",
    "source": "arXiv",
    "abstract": "Tool-Integrated Reasoning (TIR) has significantly enhanced the capabilities of Large Language Models (LLMs), yet current agents tend to exhibit cognitive offloading, redundantly invoking external tools even for simple tasks. In this paper, we suggest that true agentic intelligence requires not just tool invocation, but the adaptive wisdom to discern when to use them. We propose AdaTIR, a framework that shifts the paradigm from static tool invocation to difficulty-aware reasoning internalization. By introducing a difficulty-aware efficiency reward, AdaTIR dynamically adjusts tool budgets based on task complexity--internalizing reasoning for simple tasks while selectively invoking tools for complex tasks. Furthermore, we identify a sign reversal problem where tool penalties outweigh correctness rewards, mistakenly penalizing correct rollouts with negative advantages. To resolve this, we propose Clipped Advantage Shaping (CAS), which ensures that correctness remains the primary objective while using efficiency as a secondary constraint. Empirical results demonstrate that AdaTIR reduces tool calls by up to 97.6% on simple tasks and 28.2% on complex challenges while maintaining or enhancing accuracy. Notably, AdaTIR successfully internalizes reasoning, outperforming baselines by 4.8% on AIME 2024 even when tool access is strictly disabled."
  },
  {
    "date": "2026-01-21",
    "title": "Beyond Error-Based Optimization: Experience-Driven Symbolic Regression with Goal-Conditioned Reinforcement Learning",
    "authors": "Jianwen Sun, Xinrui Li, Fuqing Li, Xiaoxuan Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14693v1",
    "source": "arXiv",
    "abstract": "Symbolic Regression aims to automatically identify compact and interpretable mathematical expressions that model the functional relationship between input and output variables. Most existing search-based symbolic regression methods typically rely on the fitting error to inform the search process. However, in the vast expression space, numerous candidate expressions may exhibit similar error values while differing substantially in structure, leading to ambiguous search directions and hindering convergence to the underlying true function. To address this challenge, we propose a novel framework named EGRL-SR (Experience-driven Goal-conditioned Reinforcement Learning for Symbolic Regression). In contrast to traditional error-driven approaches, EGRL-SR introduces a new perspective: leveraging precise historical trajectories and optimizing the action-value network to proactively guide the search process, thereby achieving a more robust expression search. Specifically, we formulate symbolic regression as a goal-conditioned reinforcement learning problem and incorporate hindsight experience replay, allowing the action-value network to generalize common mapping patterns from diverse input-output pairs. Moreover, we design an all-point satisfaction binary reward function that encourages the action-value network to focus on structural patterns rather than low-error expressions, and concurrently propose a structure-guided heuristic exploration strategy to enhance search diversity and space coverage. Experiments on public benchmarks show that EGRL-SR consistently outperforms state-of-the-art methods in recovery rate and robustness, and can recover more complex expressions under the same search budget. Ablation results validate that the action-value network effectively guides the search, with both the reward function and the exploration strategy playing critical roles."
  },
  {
    "date": "2026-01-21",
    "title": "Morphology-, Noise-, and Resolution-Robust Ultrasound Elasticity Imaging with Fourier Neural Operators",
    "authors": "Heekyu Kim, Hugon LEe, Minwoo Park, Seunghwa Ryu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14692v1",
    "source": "arXiv",
    "abstract": "Ultrasound-based elasticity imaging is a non-invasive technique for estimating tissue stiffness fields from displacement fields obtained by comparing ultrasound signals before and after compression. While recent deep learning approaches have enabled faster and more accurate elasticity estimation compared to traditional methods, several challenges remain for clinical translation. In this study, we employ finite element simulations of free-hand palpation to investigate the applicability of the Fourier neural operator (FNO). Four practical scenarios were investigated: (1) prediction across diverse lesion morphologies, (2) generalization to cases with lesion counts differing from those in the training data, (3) robustness to noise in measured displacement fields, and (4) resilience to variations in ultrasound device resolution. Across these tasks, FNO consistently outperformed baseline models such as U-Net and DeepONet in predictive accuracy and generalization, while maintaining robustness under noise and resolution changes. Validated through in silico simulations, these findings demonstrate the potential of FNO as a framework that could facilitate translation of elasticity imaging toward clinical practice."
  },
  {
    "date": "2026-01-21",
    "title": "Closed-Form Statistical Relations Between Projected Separation, Semimajor Axis, Companion Mass, and Host Acceleration",
    "authors": "Timothy D Brandt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14688v1",
    "source": "arXiv",
    "abstract": "I derive the statistical relationship between a radial velocity or astrometric acceleration (a trend), a companion's mass, and the projected separation of the companion. These relationships, expressed as probability density functions, are analytic and independent of all Keplerian orbital elements so long as orbits are randomly oriented in space. I also derive a closed-form expression for the probability distribution of the ratio of the projected separation to the semimajor axis at fixed eccentricity. This expression can be numerically integrated over eccentricity for an arbitrary distribution of eccentricities. I verify my results with empirical comparisons to equivalent but more complex expressions in the literature based on the equations of Keplerian orbits. The closed-formed expressions derived here would be especially useful for any calculation that requires derivatives, e.g., Hamiltonian Monte Carlo. I also provide a Jupyter notebook including all figures and calculations."
  },
  {
    "date": "2026-01-21",
    "title": "IB-GRPO: Aligning LLM-based Learning Path Recommendation with Educational Objectives via Indicator-Based Group Relative Policy Optimization",
    "authors": "Shuai Wang, Yaoming Yang, Bingdong Li, Hao Hao, Aimin Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14686v1",
    "source": "arXiv",
    "abstract": "Learning Path Recommendation (LPR) aims to generate personalized sequences of learning items that maximize long-term learning effect while respecting pedagogical principles and operational constraints. Although large language models (LLMs) offer rich semantic understanding for free-form recommendation, applying them to long-horizon LPR is challenging due to (i) misalignment with pedagogical objectives such as the Zone of Proximal Development (ZPD) under sparse, delayed feedback, (ii) scarce and costly expert demonstrations, and (iii) multi-objective interactions among learning effect, difficulty scheduling, length controllability, and trajectory diversity. To address these issues, we propose IB-GRPO (Indicator-Based Group Relative Policy Optimization), an indicator-guided alignment approach for LLM-based LPR. To mitigate data scarcity, we construct hybrid expert demonstrations via Genetic Algorithm search and teacher RL agents and warm-start the LLM with supervised fine-tuning. Building on this warm-start, we design a within-session ZPD alignment score for difficulty scheduling. IB-GRPO then uses the $I_{ε+}$ dominance indicator to compute group-relative advantages over multiple objectives, avoiding manual scalarization and improving Pareto trade-offs. Experiments on ASSIST09 and Junyi using the KES simulator with a Qwen2.5-7B backbone show consistent improvements over representative RL and LLM baselines."
  },
  {
    "date": "2026-01-21",
    "title": "Local Language Models for Context-Aware Adaptive Anonymization of Sensitive Text",
    "authors": "Aisvarya Adeseye, Jouni Isoaho, Seppo Virtanen, Mohammad Tahir",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14683v1",
    "source": "arXiv",
    "abstract": "Qualitative research often contains personal, contextual, and organizational details that pose privacy risks if not handled appropriately. Manual anonymization is time-consuming, inconsistent, and frequently omits critical identifiers. Existing automated tools tend to rely on pattern matching or fixed rules, which fail to capture context and may alter the meaning of the data. This study uses local LLMs to build a reliable, repeatable, and context-aware anonymization process for detecting and anonymizing sensitive data in qualitative transcripts. We introduce a Structured Framework for Adaptive Anonymizer (SFAA) that includes three steps: detection, classification, and adaptive anonymization. The SFAA incorporates four anonymization strategies: rule-based substitution, context-aware rewriting, generalization, and suppression. These strategies are applied based on the identifier type and the risk level. The identifiers handled by the SFAA are guided by major international privacy and research ethics standards, including the GDPR, HIPAA, and OECD guidelines. This study followed a dual-method evaluation that combined manual and LLM-assisted processing. Two case studies were used to support the evaluation. The first includes 82 face-to-face interviews on gamification in organizations. The second involves 93 machine-led interviews using an AI-powered interviewer to test LLM awareness and workplace privacy. Two local models, LLaMA and Phi were used to evaluate the performance of the proposed framework. The results indicate that the LLMs found more sensitive data than a human reviewer. Phi outperformed LLaMA in finding sensitive data, but made slightly more errors. Phi was able to find over 91% of the sensitive data and 94.8% kept the same sentiment as the original text, which means it was very accurate, hence, it does not affect the analysis of the qualitative data."
  },
  {
    "date": "2026-01-21",
    "title": "The K-theory of maximal and reduced Roe algebras for Hecke pairs with equivariant coarse embeddings",
    "authors": "Liang Guo, Hang Wang, Xiufeng Yao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14682v1",
    "source": "arXiv",
    "abstract": "In this paper, we generalize the Dirac-dual-Dirac method to Hecke pairs with equivariant coarse embeddings and establish the K-theoretic isomorphisms between the maximal and reduced equivariant Roe algebras. We also extend these results to prove the Baum--Connes conjecture in this context."
  },
  {
    "date": "2026-01-21",
    "title": "Optimal Methods for Unknown Piecewise Smooth Problems I: Convex Optimization",
    "authors": "Zhenwei Lin, Zhe Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14680v1",
    "source": "arXiv",
    "abstract": "We introduce an optimal and nearly parameter-free algorithm for minimizing piecewise smooth (PWS) convex functions under the quadratic growth (QG) condition, where the locations and structure of the smooth regions are entirely \\textit{unknown}. Our algorithm, \\apex{} (Accelerated Prox-Level method for Exploring Piecewise Smoothness), is an accelerated bundle-level method designed to adaptively exploit the underlying PWS structure. APEX enjoys optimal theoretical guarantees, achieving a tight oracle complexity bound that matches the lower bound established in this work for convex PWS optimization. Furthermore, APEX generates a verifiable and accurate termination certificate, enabling a robust, almost parameter-free implementation. To the best of our knowledge, APEX is the first algorithm to simultaneously achieve the optimal convergence rate for PWS optimization and provide certificate guarantees."
  },
  {
    "date": "2026-01-21",
    "title": "HCVR Scene Generation: High Compatibility Virtual Reality Environment Generation for Extended Redirected Walking",
    "authors": "Yiran Zhang, Xingpeng Sun, Aniket Bera",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14679v1",
    "source": "arXiv",
    "abstract": "Natural walking enhances immersion in virtual environments (VEs), but physical space limitations and obstacles hinder exploration, especially in large virtual scenes. Redirected Walking (RDW) techniques mitigate this by subtly manipulating the virtual camera to guide users away from physical collisions within pre-defined VEs. However, RDW efficacy diminishes significantly when substantial geometric divergence exists between the physical and virtual environments, leading to unavoidable collisions. Existing scene generation methods primarily focus on object relationships or layout aesthetics, often neglecting the crucial aspect of physical compatibility required for effective RDW. To address this, we introduce HCVR (High Compatibility Virtual Reality Environment Generation), a novel framework that generates virtual scenes inherently optimized for alignment-based RDW controllers. HCVR first employs ENI++, a novel, boundary-sensitive metric to evaluate the incompatibility between physical and virtual spaces by comparing rotation-sensitive visibility polygons. Guided by the ENI++ compatibility map and user prompts, HCVR utilizes a Large Language Model (LLM) for context-aware 3D asset retrieval and initial layout generation. The framework then strategically adjusts object selection, scaling, and placement to maximize coverage of virtually incompatible regions, effectively guiding users towards RDW-feasible paths. User studies evaluating physical collisions and layout quality demonstrate HCVR's effectiveness with HCVR-generated scenes, resulting in 22.78 times fewer physical collisions and received 35.89\\% less on ENI++ score compared to LLM-based generation with RDW, while also receiving 12.5\\% higher scores on user feedback to layout design."
  },
  {
    "date": "2026-01-21",
    "title": "Transfer Learning from One Cancer to Another via Deep Learning Domain Adaptation",
    "authors": "Justin Cheung, Samuel Savine, Calvin Nguyen, Lin Lu, Alhassan S. Yasin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14678v1",
    "source": "arXiv",
    "abstract": "Supervised deep learning models often achieve excellent performance within their training distribution but struggle to generalize beyond it. In cancer histopathology, for example, a convolutional neural network (CNN) may classify cancer severity accurately for cancer types represented in its training data, yet fail on related but unseen types. Although adenocarcinomas from different organs share morphological features that might support limited cross-domain generalization, addressing domain shift directly is necessary for robust performance. Domain adaptation offers a way to transfer knowledge from labeled data in one cancer type to unlabeled data in another, helping mitigate the scarcity of annotated medical images. This work evaluates cross-domain classification performance among lung, colon, breast, and kidney adenocarcinomas. A ResNet50 trained on any single adenocarcinoma achieves over 98% accuracy on its own domain but shows minimal generalization to others. Ensembling multiple supervised models does not resolve this limitation. In contrast, converting the ResNet50 into a domain adversarial neural network (DANN) substantially improves performance on unlabeled target domains. A DANN trained on labeled breast and colon data and adapted to unlabeled lung data reaches 95.56% accuracy. We also examine the impact of stain normalization on domain adaptation. Its effects vary by target domain: for lung, accuracy drops from 95.56% to 66.60%, while for breast and colon targets, stain normalization boosts accuracy from 49.22% to 81.29% and from 78.48% to 83.36%, respectively. Finally, using Integrated Gradients reveals that DANNs consistently attribute importance to biologically meaningful regions such as densely packed nuclei, indicating that the model learns clinically relevant features and can apply them to unlabeled cancer types."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient reformulations of ReLU deep neural networks for surrogate modelling in power system optimisation",
    "authors": "Yogesh Pipada Sunil Kumar, S. Ali Pourmousavi, Jon A. R. Liisberg, Julian Lesmos-Vinasco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14673v1",
    "source": "arXiv",
    "abstract": "The ongoing decarbonisation of power systems is driving an increasing reliance on distributed energy resources, which introduces complex and nonlinear interactions that are difficult to capture in conventional optimisation models. As a result, machine learning based surrogate modelling has emerged as a promising approach, but integrating machine learning models such as ReLU deep neural networks (DNNs) directly into optimisation often results in nonconvex and computationally intractable formulations. This paper proposes a linear programming (LP) reformulation for a class of convexified ReLU DNNs with non-negative weight matrices beyond the first layer, enabling a tight and tractable embedding of learned surrogate models in optimisation. We evaluate the method using a case study on learning the prosumer's responsiveness within an aggregator bidding problem in the Danish tertiary capacity market. The proposed reformulation is benchmarked against state-of-the-art alternatives, including piecewise linearisation (PWL), MIP-based embedding, and other LP relaxations. Across multiple neural network architectures and market scenarios, the convexified ReLU DNN achieves solution quality comparable to PWL and MIP-based reformulations while significantly improving computational performance and preserving model fidelity, unlike penalty-based reformulations. The results demonstrate that convexified ReLU DNNs offer a scalable and reliable methodology for integrating learned surrogate models in optimisation, with applicability to a wide range of emerging power system applications."
  },
  {
    "date": "2026-01-21",
    "title": "In-Situ Inverse Design of a Plasma Metamaterial Beam Steering Device",
    "authors": "Katherine P. Bronstein, Noah A. Harris, Aleczander J. Harder, Jennay L. Edmondson, Jesse A. Rodríguez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14670v1",
    "source": "arXiv",
    "abstract": "Inverse design is a commonly used methodology for creating devices that manipulate electromagnetic (EM) waves by algorithmically modifying device parameters to achieve a desired functionality. Utilizing plasma, a dynamically tunable medium, allows the optimization of the design process to be conducted directly on the experimental hardware (in-situ). A key advantage of this method is the creation of devices that are inherently switchable and dynamically reconfigurable. Bayesian optimization is used to tune the plasma density of 91 independent discharges that make up a plasma metamaterial (PMM) device to steer incoming EM waves to desired exit waveguides. Measurements were conducted in an automated loop where a vector network analyzer records the PMM transmission characteristics for each device setting. By relying only on measured scattering parameters, this gradient-free approach is robust to experimental drift and noise and does not require complex full-wave models. Significant performance improvements over traditional simulation-based (in-silico) inverse design are demonstrated, with in-situ Bayesian optimization achieving up to 10,000x higher isolation between ports than the best in-silico design at the same target frequency. This work also presents guidelines for applying Bayesian optimization to noisy, high-dimensional physical systems."
  },
  {
    "date": "2026-01-21",
    "title": "READ-Net: Clarifying Emotional Ambiguity via Adaptive Feature Recalibration for Audio-Visual Depression Detection",
    "authors": "Chenglizhao Chen, Boze Li, Mengke Song, Dehao Feng, Xinyu Liu, Shanchen Pang, Jufeng Yang, Hui Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14651v1",
    "source": "arXiv",
    "abstract": "Depression is a severe global mental health issue that impairs daily functioning and overall quality of life. Although recent audio-visual approaches have improved automatic depression detection, methods that ignore emotional cues often fail to capture subtle depressive signals hidden within emotional expressions. Conversely, those incorporating emotions frequently confuse transient emotional expressions with stable depressive symptoms in feature representations, a phenomenon termed \\emph{Emotional Ambiguity}, thereby leading to detection errors. To address this critical issue, we propose READ-Net, the first audio-visual depression detection framework explicitly designed to resolve Emotional Ambiguity through Adaptive Feature Recalibration (AFR). The core insight of AFR is to dynamically adjust the weights of emotional features to enhance depression-related signals. Rather than merely overlooking or naively combining emotional information, READ-Net innovatively identifies and preserves depressive-relevant cues within emotional features, while adaptively filtering out irrelevant emotional noise. This recalibration strategy significantly clarifies feature representations, and effectively mitigates the persistent challenge of emotional interference. Additionally, READ-Net can be easily integrated into existing frameworks for improved performance. Extensive evaluations on three publicly available datasets show that READ-Net outperforms state-of-the-art methods, with average gains of 4.55\\% in accuracy and 1.26\\% in F1-score, demonstrating its robustness to emotional disturbances and improving audio-visual depression detection."
  },
  {
    "date": "2026-01-21",
    "title": "Spatially Generalizable Mobile Manipulation via Adaptive Experience Selection and Dynamic Imagination",
    "authors": "Ping Zhong, Liangbai Liu, Bolei Chen, Tao Wu, Jiazhi Xia, Chaoxu Mu, Jianxin Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14649v1",
    "source": "arXiv",
    "abstract": "Mobile Manipulation (MM) involves long-horizon decision-making over multi-stage compositions of heterogeneous skills, such as navigation and picking up objects. Despite recent progress, existing MM methods still face two key limitations: (i) low sample efficiency, due to ineffective use of redundant data generated during long-term MM interactions; and (ii) poor spatial generalization, as policies trained on specific tasks struggle to transfer to new spatial layouts without additional training. In this paper, we address these challenges through Adaptive Experience Selection (AES) and model-based dynamic imagination. In particular, AES makes MM agents pay more attention to critical experience fragments in long trajectories that affect task success, improving skill chain learning and mitigating skill forgetting. Based on AES, a Recurrent State-Space Model (RSSM) is introduced for Model-Predictive Forward Planning (MPFP) by capturing the coupled dynamics between the mobile base and the manipulator and imagining the dynamics of future manipulations. RSSM-based MPFP can reinforce MM skill learning on the current task while enabling effective generalization to new spatial layouts. Comparative studies across different experimental configurations demonstrate that our method significantly outperforms existing MM policies. Real-world experiments further validate the feasibility and practicality of our method."
  },
  {
    "date": "2026-01-21",
    "title": "TRSVR: An Adaptive Stochastic Trust-Region Method with Variance Reduction",
    "authors": "Yuchen Fang, Xinshou Zheng, Javad Lavaei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14647v1",
    "source": "arXiv",
    "abstract": "We propose a stochastic trust-region method for unconstrained nonconvex optimization that incorporates stochastic variance-reduced gradients (SVRG) to accelerate convergence. Unlike classical trust-region methods, the proposed algorithm relies solely on stochastic gradient information and does not require function value evaluations. The trust-region radius is adaptively adjusted based on a radius-control parameter and the stochastic gradient estimate. Under mild assumptions, we establish that the algorithm converges in expectation to a first-order stationary point. Moreover, the method achieves iteration and sample complexity bounds that match those of SVRG-based first-order methods, while allowing stochastic and potentially gradient-dependent second-order information. Extensive numerical experiments demonstrate that incorporating SVRG accelerates convergence, and that the use of trust-region methods and Hessian information further improves performance. We also highlight the impact of batch size and inner-loop length on efficiency, and show that the proposed method outperforms SGD and Adam on several machine learning tasks."
  },
  {
    "date": "2026-01-21",
    "title": "DesignBridge: Bridging Designer Expertise and User Preferences through AI-Enhanced Co-Design for Fashion",
    "authors": "Yuheng Shao, Yuansong Xu, Yifan Jin, Shuhao Zhang, Wenxin Gu, Quan Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14639v1",
    "source": "arXiv",
    "abstract": "Effective collaboration between designers and users is important for fashion design, which can increase the user acceptance of fashion products and thereby create value. However, it remains an enduring challenge, as traditional designer-centric approaches restrict meaningful user participation, while user-driven methods demand design proficiency, often marginalizing professional creative judgment. Current co-design practices, including workshops and AI-assisted frameworks, struggle with low user engagement, inefficient preference collection, and difficulties in balancing user feedback with design considerations. To address these challenges, we conducted a formative study with designers and users experienced in co-design (N=7), identifying critical challenges for current collaboration between designers and users in the co-design process, and their requirements. Informed by these insights, we introduce DesignBridge, a multi-platform AI-enhanced interactive system that bridges designer expertise and user preferences through three stages: (1) Initial Design Framing, where designers define initial concepts. (2) Preference Expression Collection, where users intuitively articulate preferences via interactive tools. (3) Preference-Integrated Design, where designers use AI-assisted analytics to integrate feedback into cohesive designs. A user study demonstrates that DesignBridge significantly enhances user preference collection and analysis, enabling designers to integrate diverse preferences with professional expertise."
  },
  {
    "date": "2026-01-21",
    "title": "A classification of regular maps with Euler characteristic $-pq$",
    "authors": "Xiaogang Li, Yao Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14635v1",
    "source": "arXiv",
    "abstract": "In this paper, we give a classification of regular maps with Euler characteristic $-pq$ for distinct primes $q>p\\geq 5$. This together with previous classification of regular maps with Euler characteristic $-2p,-3p$ and $-p^2$ completes the classification of regular maps with Euler characteristic $-pq$ for two primes $p$ and $q$. An interesting consequence is that, for every pair of twin primes $p$ and $q$ greater than $5$, there exist three regular maps with solvable automorphism groups and Euler characteristic $-pq$, up to duality and isomorphism."
  },
  {
    "date": "2026-01-21",
    "title": "Semi-Supervised Mixture Models under the Concept of Missing at Radom with Margin Confidence and Aranda Ordaz Function",
    "authors": "Jinyang Liao, Ziyang Lyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14631v1",
    "source": "arXiv",
    "abstract": "This paper presents a semi-supervised learning framework for Gaussian mixture modelling under a Missing at Random (MAR) mechanism. The method explicitly parameterizes the missingness mechanism by modelling the probability of missingness as a function of classification uncertainty. To quantify classification uncertainty, we introduce margin confidence and incorporate the Aranda Ordaz (AO) link function to flexibly capture the asymmetric relationships between uncertainty and missing probability. Based on this formulation, we develop an efficient Expectation Conditional Maximization (ECM) algorithm that jointly estimates all parameters appearing in both the Gaussian mixture model (GMM) and the missingness mechanism, and subsequently imputes the missing labels by a Bayesian classifier derived from the fitted mixture model. This method effectively alleviates the bias induced by ignoring the missingness mechanism while enhancing the robustness of semi-supervised learning. The resulting uncertainty-aware framework delivers reliable classification performance in realistic MAR scenarios with substantial proportions of missing labels."
  },
  {
    "date": "2026-01-21",
    "title": "SETI Observations of k-Hz Periodic Radio Signals from Five Nearby Stars with FAST at L Band",
    "authors": "Yu Hu, Bo-Lun Huang, Vishal Gajjar, Xiao-Hang Luan, Zhen-Zhao Tao, Tong-Jie Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14630v1",
    "source": "arXiv",
    "abstract": "We report a radio SETI search for periodic, kHz-wide signals from five of the nearest stars observable with the Five-hundred-meter Aperture Spherical radio Telescope (FAST). Using the 19-beam L-band receiver (1.05-1.45 GHz), we obtained 1200 s tracking observations of Groombridge 34 A/B, Ross 248, 61 Cygni B, and Ross 128. Dynamic spectra from all beams and both linear polarisations were searched channel by channel with a fast-folding algorithm sensitive to periods between 1.1 and 300 s. A multi-layer RFI-mitigation pipeline exploits multi-beam occupancy, cross-target bad-channel statistics, XX/YY polarisation coincidence, broad frequency masks, and narrow site-specific RFI exclusion zones, followed by clustering in period-frequency space. The pipeline is validated on FAST observations of PSR B0329+54, where we recover the known 0.714 s spin period and harmonic structure in the expected beam. For the stellar sample, successive cuts reduce the raw FFA hit lists (> 10^6 hits per target) to a small number of cluster-level candidates, all of which exhibit clear radio-frequency interference signatures in phase-time and phase-frequency diagnostics. We therefore report no convincing detections of periodic transmitters in our searched parameter space. Using the radiometer equation with our adopted detection threshold (S/N = 25) and assuming a duty cycle delta = 0.1, we obtain upper limits of approximately (7-9) x 10^9 W on the isotropic-equivalent EIRP of kHz-wide periodic beacons at these stars, among the most stringent constraints to date on periodic radio emission from nearby stellar systems."
  },
  {
    "date": "2026-01-21",
    "title": "A Brain-inspired Embodied Intelligence for Fluid and Fast Reflexive Robotics Control",
    "authors": "Weiyu Guo, He Zhang, Pengteng Li, Tiefu Cai, Ziyang Chen, Yandong Guo, Xiao He, Yongkui Yang, Ying Sun, Hui Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14628v1",
    "source": "arXiv",
    "abstract": "Recent advances in embodied intelligence have leveraged massive scaling of data and model parameters to master natural-language command following and multi-task control. In contrast, biological systems demonstrate an innate ability to acquire skills rapidly from sparse experience. Crucially, current robotic policies struggle to replicate the dynamic stability, reflexive responsiveness, and temporal memory inherent in biological motion. Here we present Neuromorphic Vision-Language-Action (NeuroVLA), a framework that mimics the structural organization of the bio-nervous system between the cortex, cerebellum, and spinal cord. We adopt a system-level bio-inspired design: a high-level model plans goals, an adaptive cerebellum module stabilizes motion using high-frequency sensors feedback, and a bio-inspired spinal layer executes lightning-fast actions generation. NeuroVLA represents the first deployment of a neuromorphic VLA on physical robotics, achieving state-of-the-art performance. We observe the emergence of biological motor characteristics without additional data or special guidance: it stops the shaking in robotic arms, saves significant energy(only 0.4w on Neuromorphic Processor), shows temporal memory ability and triggers safety reflexes in less than 20 milliseconds."
  },
  {
    "date": "2026-01-21",
    "title": "Above Room Temperature Ferroelectricity in Epitaxially Strained KTaO3",
    "authors": "Tobias Schwaigert, Salva Salmani-Rezaie, Sankalpa Hazra, Utkarsh Saha, Maya Ramesh, Aiden Ross, Betul Pamuk, Long-Qing Chen, David A. Muller, Darrell G. Schlom, Venkatraman Gopalan, Kaveh Ahadi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14627v1",
    "source": "arXiv",
    "abstract": "Epitaxial strain is a powerful means to engineer emergent phenomena in thin films and heterostructures. Here, we demonstrate that KTaO3, a cubic perovskite in bulk form, can be epitaxially strained into a highly tunable ferroelectric. KTaO3 films grown commensurate to SrTiO3 (001) substrates experience an in-plane strain of -2.1 % that transforms the cubic structure into a tetragonal polar phase with transition temperature of 475 K, consistent with our thermodynamic calculations. We show that the Curie temperature and the spontaneous electric polarization can be system- atically controlled with epitaxial strain. Scanning transmission electron microscopy reveals cooperative polar displacements of the potassium columns with respect to the neighboring tantalum columns at room temperature. Optical second-harmonic generation results are described by a tetragonal polar point group (4mm), indicating the emergence of a global polar ground state. We observe a ferroelectric hysteresis response, using metal-insulator-metal capacitor test structures. The results demon- strate a robust intrinsic ferroelectric state in epitaxially strained KTaO3 thin films."
  },
  {
    "date": "2026-01-21",
    "title": "Biological Sequence Clustering: A Survey",
    "authors": "Simeng Zhang, Xinying Liu, Jun Lou, Mudi Jiang, Quan Zou, Zengyou He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14624v1",
    "source": "arXiv",
    "abstract": "The rapid development of high-throughput sequencing technologies has led to an explosive increase in biological sequence data, making sequence clustering a fundamental task in large-scale bioinformatics analyses. Unlike traditional clustering problems, biological sequence clustering faces unique challenges due to the lack of direct similarity measures, strict biological constraints, and demanding requirements for both scalability and accuracy. Over the past decades, a wide variety of methods have been developed, differing in how they model sequence similarity, construct clusters, and prioritize optimization objectives. In this review, we provide a comprehensive methodological overview of biological sequence clustering algorithms. We begin by summarizing the main strategies for modeling sequence similarity, which can be divided into three stages: sequence encoding, feature generation, and similarity measurement. Next, we discuss the major clustering paradigms, including greedy incremental, hierarchical, graph-based, model-based, partitional, and deep learning approaches, highlighting their methodological characteristics and practical trade-offs. We then discuss clustering objectives from three key perspectives: scalability and resource efficiency, biological interpretability, and robustness and clustering quality. Organizing existing methods along these dimensions allows us to explore the trade-offs in biological sequence clustering and clarify the contexts in which different approaches are most appropriate. Finally, we identify current limitations and challenges, providing guidance for researchers and directions for future method development."
  },
  {
    "date": "2026-01-21",
    "title": "UniCon: A Unified System for Efficient Robot Learning Transfers",
    "authors": "Yunfeng Lin, Li Xu, Yong Yu, Jiangmiao Pang, Weinan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14617v1",
    "source": "arXiv",
    "abstract": "Deploying learning-based controllers across heterogeneous robots is challenging due to platform differences, inconsistent interfaces, and inefficient middleware. To address these issues, we present UniCon, a lightweight framework that standardizes states, control flow, and instrumentation across platforms. It decomposes workflows into execution graphs with reusable components, separating system states from control logic to enable plug-and-play deployment across various robot morphologies. Unlike traditional middleware, it prioritizes efficiency through batched, vectorized data flow, minimizing communication overhead and improving inference latency. This modular, data-oriented approach enables seamless sim-to-real transfer with minimal re-engineering. We demonstrate that UniCon reduces code redundancy when transferring workflows and achieves higher inference efficiency compared to ROS-based systems. Deployed on over 12 robot models from 7 manufacturers, it has been successfully integrated into ongoing research projects, proving its effectiveness in real-world scenarios."
  },
  {
    "date": "2026-01-21",
    "title": "Implementing Substance Over Form: A Novel Metric for Taxing E-commerce to Address Deterritorialization",
    "authors": "Li Tuobang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14616v1",
    "source": "arXiv",
    "abstract": "Against the backdrop of e-commerce restructuring consumption patterns, last-mile delivery stations have substantially fulfilled the function of community retail distribution. However, the current tax system only levies a low labor service tax on delivery fees, resulting in a tax contribution from the massive circulating goods value that is significantly lower than that of retail supermarkets of equivalent scale. This disparity not only triggers local tax base erosion but also fosters unfair competition. Based on the \"substance over form\" principle, this paper proposes a tax rate calculation method using \"delivery fee plus insurance premium\" as the base, corrected through \"goods value conversion.\" This method aims to align the substantive tax burden of e-commerce with that of community retail at the terminal stage, effectively internalizing the high negative externalities of delivery stations through fiscal instruments, addressing E-commerce Deterritorialization."
  },
  {
    "date": "2026-01-21",
    "title": "Towards Cybersecurity Superintelligence: from AI-guided humans to human-guided AI",
    "authors": "Víctor Mayoral-Vilches, Stefan Rass, Martin Pinzger, Endika Gil-Uriarte, Unai Ayucar-Carbajo, Jon Ander Ruiz-Alcalde, Maite del Mundo de Torres, Luis Javier Navarrete-Lozano, María Sanz-Gómez, Francesco Balassone, Cristóbal R. J. Veas-Chavez, Vanesa Turiel, Alfonso Glera-Picón, Daniel Sánchez-Prieto, Yuri Salvatierra, Paul Zabalegui-Landa, Ruffino Reydel Cabrera-Álvarez, Patxi Mayoral-Pizarroso",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14614v1",
    "source": "arXiv",
    "abstract": "Cybersecurity superintelligence -- artificial intelligence exceeding the best human capability in both speed and strategic reasoning -- represents the next frontier in security. This paper documents the emergence of such capability through three major contributions that have pioneered the field of AI Security. First, PentestGPT (2023) established LLM-guided penetration testing, achieving 228.6% improvement over baseline models through an architecture that externalizes security expertise into natural language guidance. Second, Cybersecurity AI (CAI, 2025) demonstrated automated expert-level performance, operating 3,600x faster than humans while reducing costs 156-fold, validated through #1 rankings at international competitions including the $50,000 Neurogrid CTF prize. Third, Generative Cut-the-Rope (G-CTR, 2026) introduces a neurosymbolic architecture embedding game-theoretic reasoning into LLM-based agents: symbolic equilibrium computation augments neural inference, doubling success rates while reducing behavioral variance 5.2x and achieving 2:1 advantage over non-strategic AI in Attack & Defense scenarios. Together, these advances establish a clear progression from AI-guided humans to human-guided game-theoretic cybersecurity superintelligence."
  },
  {
    "date": "2026-01-21",
    "title": "Seeing to Think? How Source Transparency Design Shapes Interactive Information Seeking and Evaluation in Conversational AI",
    "authors": "Jiangen He, Jiqun Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14611v1",
    "source": "arXiv",
    "abstract": "Conversational AI systems increasingly function as primary interfaces for information seeking, yet how they present sources to support information evaluation remains under-explored. This paper investigates how source transparency design shapes interactive information seeking, trust, and critical engagement. We conducted a controlled between-subjects experiment (N=372) comparing four source presentation interfaces - Collapsible, Hover Card, Footer, and Aligned Sidebar - varying in visibility and accessibility. Using fine-grained behavioral analysis and automated critical thinking assessment, we found that interface design fundamentally alters exploration strategies and evidence integration. While the Hover Card interface facilitated seamless, on-demand verification during the task, the Aligned Sidebar uniquely mitigated the negative effects of information overload: as citation density increased, Sidebar users demonstrated significantly higher critical thinking and synthesis scores compared to other conditions. Our results highlight a trade-off between designs that support workflow fluency and those that enforce reflective verification, offering practical implications for designing adaptive and responsible conversational AI that fosters critical engagement with AI generated content."
  },
  {
    "date": "2026-01-21",
    "title": "SeisBind: Physics-Aware Tri-Modal Representation Binding for Seismic Data via Contrastive Learning",
    "authors": "Chaohua Liang, Jun Matsushima",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14607v1",
    "source": "arXiv",
    "abstract": "This letter proposes a physics-aware multi-modal contrastive learning framework designed to transform complex seismic wavefields into human-readable physical representations. Traditional data-driven inversion methods often focus on pixel-wise mapping, which lacks physical grounding and interpretability. To address this, we introduce a novel framework that jointly aligns seismic shot gathers, subsurface velocity models, and explicit physical descriptors (e.g., mean velocity and gradients) in a shared latent space. By introducing these descriptors as a third modality, our approach encourages the learned embeddings to capture intrinsic geological semantics rather than superficial signal correlations. Experiments on the OpenFWI dataset demonstrate that the proposed method not only achieves robust seismic-to-velocity retrieval but also preserves meaningful physical semantics, enabling cross-modal inference of interpretable attributes. This representation-centric perspective provides a flexible foundation for expert-guided subsurface characterization."
  },
  {
    "date": "2026-01-21",
    "title": "An LLM Agent-based Framework for Whaling Countermeasures",
    "authors": "Daisuke Miyamoto, Takuji Iimura, Narushige Michishita",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14606v1",
    "source": "arXiv",
    "abstract": "With the spread of generative AI in recent years, attacks known as Whaling have become a serious threat. Whaling is a form of social engineering that targets important high-authority individuals within organizations and uses sophisticated fraudulent emails. In the context of Japanese universities, faculty members frequently hold positions that combine research leadership with authority within institutional workflows. This structural characteristic leads to the wide public disclosure of high-value information such as publications, grants, and detailed researcher profiles. Such extensive information exposure enables the construction of highly precise target profiles using generative AI. This raises concerns that Whaling attacks based on high-precision profiling by generative AI will become prevalent. In this study, we propose a Whaling countermeasure framework for university faculty members that constructs personalized defense profiles and uses large language model (LLM)-based agents. We design agents that (i) build vulnerability profiles for each target from publicly available information on faculty members, (ii) identify potential risk scenarios relevant to Whaling defense based on those profiles, (iii) construct defense profiles corresponding to the vulnerabilities and anticipated risks, and (iv) analyze Whaling emails using the defense profiles. Furthermore, we conduct a preliminary risk-assessment experiment. The results indicate that the proposed method can produce judgments accompanied by explanations of response policies that are consistent with the work context of faculty members who are Whaling targets. The findings also highlight practical challenges and considerations for future operational deployment and systematic evaluation."
  },
  {
    "date": "2026-01-21",
    "title": "Holmes: An Evidence-Grounded LLM Agent for Auditable DDoS Investigation in Cloud Networks",
    "authors": "Haodong Chen, Ziheng Zhang, Jinghui Jiang, Qiang Su, Qiao Xiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14601v1",
    "source": "arXiv",
    "abstract": "Cloud environments face frequent DDoS threats due to centralized resources and broad attack surfaces. Modern cloud-native DDoS attacks further evolve rapidly and often blend multi-vector strategies, creating an operational dilemma: defenders need wire-speed monitoring while also requiring explainable, auditable attribution for response. Existing rule-based and supervised-learning approaches typically output black-box scores or labels, provide limited evidence chains, and generalize poorly to unseen attack variants; meanwhile, high-quality labeled data is often difficult to obtain in cloud settings. We present Holmes (DDoS Detective), an LLM-based DDoS detection agent that reframes the model as a virtual SRE investigator rather than an end-to-end classifier. Holmes couples a funnel-like hierarchical workflow (counters/sFlow for continuous sensing and triage; PCAP evidence collection triggered only on anomaly windows) with an Evidence Pack abstraction that converts binary packets into compact, reproducible, high-signal structured evidence. On top of this evidence interface, Holmes enforces a structure-first investigation protocol and strict JSON/quotation constraints to produce machine-consumable reports with auditable evidence anchors. We evaluate Holmes on CICDDoS2019 reflection/amplification attacks and script-triggered flooding scenarios. Results show that Holmes produces attribution decisions grounded in salient evidence anchors across diverse attack families, and when errors occur, its audit logs make the failure source easy to localize, demonstrating the practicality of an LLM agent for cost-controlled and traceable DDoS investigation in cloud operations."
  },
  {
    "date": "2026-01-21",
    "title": "How Threshold Effects in Spectroscopic Factors Influence Heavy-Ion Knockout Reactions",
    "authors": "M. R. Xie, J. G. Li, C. A. Bertulani, N. Michel, Y. Z. Sun, W. Zuo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14596v1",
    "source": "arXiv",
    "abstract": "A two-decade-old puzzle in heavy-ion one-nucleon knockout reactions is the strong correlation between the reduction factor $R_s=σ_{\\rm exp}/σ_{\\rm th}$ and the Fermi surface asymmetry $ΔS$. Theoretical cross sections typically rely on spectroscopic factors (SFs) from shell model (SM) calculations, which neglect continuum coupling effects. Here, we employ the Gamow shell model (GSM), which explicitly incorporates continuum coupling, to compute SFs for $p$-shell nuclei and predict corresponding theoretical cross sections. Systematic calculations demonstrate that using GSM-derived SFs substantially reduces discrepancies between theoretical and experimental results. This improvement is particularly significant for deeply bound nucleon knockout in nuclei near the dripline, where traditional SM-based calculations fall short. As a result, using GSM SFs, the ratio $R_s$ exhibits no pronounced dependence on $ΔS$. Furthermore, both the ratio of GSM SFs to SM SFs and their corresponding reaction cross sections ratios exhibit a strong $ΔS$ dependence. We have also compared GSM SFs and cross sections with those from the no-core shell model calculations, giving a similar pronounced sensitivity to $ΔS$. Detailed analysis attributes these correlations to threshold effects for SFs in weakly bound systems. Overall, incorporating continuum coupling via GSM enhances the reliability of SF predictions for exotic, weakly bound nuclei and provides key insights toward resolving the enduring puzzle in heavy-ion knockout reactions from a nuclear structure perspective."
  },
  {
    "date": "2026-01-21",
    "title": "IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference",
    "authors": "Qiyue Mei, Michael Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14595v1",
    "source": "arXiv",
    "abstract": "Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase."
  },
  {
    "date": "2026-01-21",
    "title": "From Volumes to Slices: Computationally Efficient Contrastive Learning for Sequential Abdominal CT Analysis",
    "authors": "Po-Kai Chiu, Hung-Hsuan Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14593v1",
    "source": "arXiv",
    "abstract": "The requirement for expert annotations limits the effectiveness of deep learning for medical image analysis. Although 3D self-supervised methods like volume contrast learning (VoCo) are powerful and partially address the labeling scarcity issue, their high computational cost and memory consumption are barriers. We propose 2D-VoCo, an efficient adaptation of the VoCo framework for slice-level self-supervised pre-training that learns spatial-semantic features from unlabeled 2D CT slices via contrastive learning. The pre-trained CNN backbone is then integrated into a CNN-LSTM architecture to classify multi-organ injuries. In the RSNA 2023 Abdominal Trauma dataset, 2D-VoCo pre-training significantly improves mAP, precision, recall, and RSNA score over training from scratch. Our framework provides a practical method to reduce the dependency on labeled data and enhance model performance in clinical CT analysis. We release the code for reproducibility. https://github.com/tkz05/2D-VoCo-CT-Classifier"
  },
  {
    "date": "2026-01-21",
    "title": "FBApro: A fast, simple linear transformation for diverse metabolic modeling tasks",
    "authors": "Ariel Bruner, Mona Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14577v1",
    "source": "arXiv",
    "abstract": "Constraint-based metabolic modeling is the predominant framework for simulating cellular metabolism. The central assumption of these models is that metabolism operates at a steady state, meaning that the production and consumption rates of each metabolite are balanced. This assumption imposes linear constraints on the fluxes of biochemical reactions. Flux Balance Analysis (FBA), a fundamental method in the field, is formulated as an optimization problem maximizing a cellular objective (e.g., growth) over the resulting linear subspace of steady state fluxes. Many other methods in the field are expressed either as a modification to FBA, or use FBA as a black box within an algorithm. Here, we propose a simple and general alternative to optimization that, for any flux vector, finds the closest flux distribution within the steady-state subspace. This operation corresponds to an orthogonal projection that enforces the steady-state assumption. We further introduce extensions to handle cases involving unknown or fixed fluxes through modified projections and tailored affine subspaces. The overall approach is computationally efficient, does not require a cellular objective, and is easy to implement. We validate our method and its variants on both synthetic and experimental datasets, demonstrating their speed and utility for denoising and imputing metabolic flux data, and for predicting steady-state fluxes from more readily available types of data. Code availability: The code implementing FBApro is available at https://github.com/Singh-Lab/FBApro. All code required to reproduce the figures in the paper is available, although the data used must be sourced separately. The repository also contains toy models and examples."
  },
  {
    "date": "2026-01-21",
    "title": "Place with Intention: An Empirical Attendance Predictive Study of Expo 2025 Osaka, Kansai, Japan",
    "authors": "Xiaojie Yang, Dizhi Huang, Hangli Ge, Masahiro Sano, Takeaki Ohdake, Kazuma Hatano, Noboru Koshizuka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14570v1",
    "source": "arXiv",
    "abstract": "Accurate forecasting of daily attendance is vital for managing transportation, crowd flows, and services at large-scale international events such as Expo 2025 Osaka, Kansai, Japan. However, existing approaches often rely on multi-source external data (such as weather, traffic, and social media) to improve accuracy, which can lead to unreliable results when historical data are insufficient. To address these challenges, we propose a Transformer-based framework that leverages reservation dynamics, i.e., ticket bookings and subsequent updates within a time window, as a proxy for visitors' attendance intentions, under the assumption that such intentions are eventually reflected in reservation patterns. This design avoids the complexity of multi-source integration while still capturing external influences like weather and promotions implicitly embedded in reservation dynamics. We construct a dataset combining entrance records and reservation dynamics and evaluate the model under both single-channel (total attendance) and two-channel (separated by East and West gates) settings. Results show that separately modeling East and West gates consistently improves accuracy, particularly for short- and medium-term horizons. Ablation studies further confirm the importance of the encoder-decoder structure, inverse-style embedding, and adaptive fusion module. Overall, our findings indicate that reservation dynamics offer a practical and informative foundation for attendance forecasting in large-scale international events."
  },
  {
    "date": "2026-01-21",
    "title": "Signatures of a Tidally Induced Spiral Arm at the Anticenter of the Milky Way and a Kinematically Extended Anticenter Stream Using DESI DR2",
    "authors": "Mika Lambert, Constance M. Rockosi, Sergey E. Koposov, Ting S. Li, Monica Valluri, Leandro Beraldo e Silva, Songting Li, Joaõ A. S. Amarante, Amanda Byström, Gustavo E. Medina, Nathan R. Sandford, Joan Najita, Namitha Kizhuprakkat, Jessica N. Aguilar, Steven Ahlen, Davide Bianchi, David Brooks, Todd Claybaugh, Kyle Dawson, Axel de la Macorra, Peter Doel, Jaime E. Forero-Romero, Enrique Gaztañaga, Satya Gontcho A Gontcho, Gaston Gutierrez, Dick Joyce, Anthony Kremin, Claire Lamman, Martin Landriau, Laurent Le Guillou, Marc Manera, Aaron Meisner, Ramon Miquel, John Moustakas, Adam Myers, Seshadri Nadathur, Will Percival, Francisco Prada, Ignasi Perez-Rafols, Graziano Rossi, Eusebio Sanchez, David Schlegel, Michael Schubnell, Joseph H. Silber, David Sprayberry, Gregory Tarle, Benjamin A. Weaver, Rongpu Zhou, Hu Zou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14562v1",
    "source": "arXiv",
    "abstract": "Using the Dark Energy Spectroscopic Instrument Milky Way Survey (DESI MWS), we examine the 6D space of the anticenter region of the stellar disk (150$^\\circ$ $<$ Galactic longitude $<$ 220$^\\circ$) using 61,883 main sequence turn-off stars. We focus on two well-known stellar overdensities in the anticenter, the Monoceros Ring (MRi) and Anticenter Stream (ACS). We find that the MRi overdensity has kinematics consistent with a tidally induced spiral arm, a type of dynamic spiral arm created by an interaction with a satellite galaxy, most likely the Sagittarius Dwarf Spheroidal galaxy (Sgr). We use the kinematics of the MRi to calculate the two most recent passage times of Sgr are 0.25 $\\pm$ 0.09 Gyrs and 1.10 $\\pm$ 0.23 Gyrs from the present day. We validate that the ACS is kinematically decoupled from the MRi because they are moving in opposite radial and vertical directions. We find that the kinematics associated with the ACS are not confined to our defined overdensity. The features we see in the ACS region are likely part of a broader distribution of stars with the same kinematic signature as detected in other places, like the vertical wave in the outer disk and phase spiral."
  },
  {
    "date": "2026-01-21",
    "title": "Evaluating Preattentive Features for Detecting Changes in Virtual Environments",
    "authors": "DongHoon Kim, Isaac Cho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14561v1",
    "source": "arXiv",
    "abstract": "Visual perception plays a critical role in detecting changes within immersive Virtual Reality (VR) environments. However, as visual complexity increases, perceptual performance declines, making it more difficult to detect changes quickly and accurately. This study examines how visual features, known for facilitating preattentive processing, impact a change detection task in immersive 3D environments, with a focus on visual complexity, object attributes, and spatial proximity. Our results demonstrate that preattentive processing enhances change detection, particularly when the altered object is spatially isolated and not perceptually grouped with similar surrounding objects. Changes to isolated objects were detected more reliably, suggesting that perceptual isolation reduces cognitive load and draws more attention. Conversely, when a changed object was surrounded by visually similar elements, participants were less likely to detect the change, indicating that perceptual grouping hinders individual object recognition in complex scenes. These results provide guidelines for designing VR applications that strategically utilize spatial isolation and visual features to improve the user experience."
  },
  {
    "date": "2026-01-21",
    "title": "IRMaGiC: Extending Luminous Red Galaxy Selection into the infrared with joint LSST and Roman HLIS Data",
    "authors": "Zhiyuan Guo, Chris. W. Walter, Eli S. Rykoff",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14554v1",
    "source": "arXiv",
    "abstract": "We introduce IRMaGiC, an algorithm built based on RedMaGiC desgined to enhance the selection of Luminous Red Galaxies (LRGs) across the redshift range $1 \\leq z \\leq 2$. We show that this method extends the capabilities of the redMaGiC algorithm by applying it to simulated photometric data from the Vera C. Rubin Observatory's Legacy Survey of Space and Time (LSST) and the Nancy Grace Roman Space Telescope's High Latitude Wide Area Survey (HLWAS). By integrating infrared band coverage from Roman HLWAS with LSST's optical bands, IRMaGiC enables red-sequence calibration at higher redshifts. We demonstrate that IRMaGiC reduces scatter and bias in photometric redshift estimates for LRGs at higher redshift, providing more accurate redshift assessments compared to existing methods. Our findings suggest that incorporating infrared data can considerably improve the selection and redshift estimation of LRGs at higher redshift, offering substantial benefits for future cosmological surveys."
  },
  {
    "date": "2026-01-21",
    "title": "A Cordes framework for stationary Fokker--Planck--Kolmogorov equations",
    "authors": "Timo Sprekeler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14548v1",
    "source": "arXiv",
    "abstract": "We first review the Cordes condition for nondivergence-form differential operators through the lens of Campanato's theory of near operators. We then survey a recently proposed Cordes framework that guarantees the existence and uniqueness of $L^2$ solutions to stationary Fokker--Planck--Kolmogorov equations subject to periodic boundary conditions, and that allows for the construction of a simple finite element method for its numerical approximation. Finally, we propose a Cordes framework for stationary Fokker--Planck--Kolmogorov-type equations subject to a homogeneous Dirichlet boundary condition."
  },
  {
    "date": "2026-01-21",
    "title": "Active interference suppression in frequency-division-multiplexed quantum gates via off-resonant microwave tones",
    "authors": "Haruki Mitarai, Yukihiro Tadokoro, Hiroya Tanaka",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14547v1",
    "source": "arXiv",
    "abstract": "An increase in the number of control lines between the quantum processors and the external electronics constitutes a major bottleneck in the realization of large-scale quantum computers. Frequency-division multiplexing is expected to enable multiple qubits to be controlled through a single microwave cable; however, interference from off-resonant microwave tones hinders precise qubit control. Here, we propose an active interference suppression method for frequency-division-multiplexed simultaneous gate operations. We demonstrate that deliberate incorporation of off-resonant microwave tones improves the accuracy of single-qubit gates. Specifically, we find that by incorporating off-resonant orthogonal or quasi-orthogonal microwave tones, the gate infidelity decreases proportionally to the inverse square of the number of microwave tones. Furthermore, we show that fast oscillations neglected under the rotating wave approximation degrade gate fidelity, and that this degradation can be mitigated through optimized frequency allocation. Our approach is simple yet effective for improving the performance of frequency-division-multiplexed quantum gates."
  },
  {
    "date": "2026-01-21",
    "title": "SpatialV2A: Visual-Guided High-fidelity Spatial Audio Generation",
    "authors": "Yanan Wang, Linjie Ren, Zihao Li, Junyi Wang, Tian Gan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15017v1",
    "source": "arXiv",
    "abstract": "While video-to-audio generation has achieved remarkable progress in semantic and temporal alignment, most existing studies focus solely on these aspects, paying limited attention to the spatial perception and immersive quality of the synthesized audio. This limitation stems largely from current models' reliance on mono audio datasets, which lack the binaural spatial information needed to learn visual-to-spatial audio mappings. To address this gap, we introduce two key contributions: we construct BinauralVGGSound, the first large-scale video-binaural audio dataset designed to support spatially aware video-to-audio generation; and we propose a end-to-end spatial audio generation framework guided by visual cues, which explicitly models spatial features. Our framework incorporates a visual-guided audio spatialization module that ensures the generated audio exhibits realistic spatial attributes and layered spatial depth while maintaining semantic and temporal alignment. Experiments show that our approach substantially outperforms state-of-the-art models in spatial fidelity and delivers a more immersive auditory experience, without sacrificing temporal or semantic consistency. All datasets, code, and model checkpoints will be publicly released to facilitate future research."
  },
  {
    "date": "2026-01-21",
    "title": "Lineup Regularized Adjusted Plus-Minus (L-RAPM): Basketball Lineup Ratings with Informed Priors",
    "authors": "Christos Petridis, Konstantinos Pelechrinis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15000v1",
    "source": "arXiv",
    "abstract": "Identifying combinations of players (that is, lineups) in basketball - and other sports - that perform well when they play together is one of the most important tasks in sports analytics. One of the main challenges associated with this task is the frequent substitutions that occur during a game, which results in highly sparse data. In particular, a National Basketball Association (NBA) team will use more than 600 lineups during a season, which translates to an average lineup having seen the court in approximately 25-30 possessions. Inevitably, any statistics that one collects for these lineups are going to be noisy, with low predictive value. Yet, there is no existing work (in the public at least) that addresses this problem. In this work, we propose a regression-based approach that controls for the opposition faced by each lineup, while it also utilizes information about the players making up the lineups. Our experiments show that L-RAPM provides improved predictive power than the currently used baseline, and this improvement increases as the sample size for the lineups gets smaller."
  },
  {
    "date": "2026-01-21",
    "title": "Filtered 2D Contour-Based Reconstruction of 3D STL Model from CT-DICOM Images",
    "authors": "K. Punnam Chandar, Y. Ravi Kumar",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14997v1",
    "source": "arXiv",
    "abstract": "Reconstructing a 3D Stereo-lithography (STL) Model from 2D Contours of scanned structure in Digital Imaging and Communication in Medicine (DICOM) images is crucial to understand the geometry and deformity. Computed Tomography (CT) images are processed to enhance the contrast, reduce the noise followed by smoothing. The processed CT images are segmented using thresholding technique. 2D contour data points are extracted from segmented CT images and are used to construct 3D STL Models. The 2D contour data points may contain outliers as a result of segmentation of low resolution images and the geometry of the constructed 3D structure deviate from the actual. To cope with the imperfections in segmentation process, in this work we propose to use filtered 2D contour data points to reconstruct 3D STL Model. The filtered 2D contour points of each image are delaunay triangulated and joined layer-by-layer to reconstruct the 3D STL model. The 3D STL Model reconstruction is verified on i) 2D Data points of basic shapes and ii) Region of Interest (ROI) of human pelvic bone and are presented as case studies. The 3D STL model constructed from 2D contour data points of ROI of segmented pelvic bone with and without filtering are presented. The 3D STL model reconstructed from filtered 2D data points improved the geometry of model compared to the model reconstructed without filtering 2D data points."
  },
  {
    "date": "2026-01-21",
    "title": "Low-frequency fiber-optic vibration sensing with a Floquet-engineered optical lattice clock",
    "authors": "Mojuan Yin, Ruohui Wang, Rui Zhou, Xueguang Qiao, Shougang Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14995v1",
    "source": "arXiv",
    "abstract": "We propose a Floquet-engineered optical lattice clock based demodulation scheme to enhance the low-frequency performance of wound fiber-optic vibration sensors. Vibration-induced phase variations in the sensing fiber are demodulated by the Floquet-engineered Rabi spectra of the clock transition. The lattice depth with the fiber length and the Floquet-engineered Rabi spectra under the vibration from 200 Hz down to 0.5 Hz are simulated. With a fiber length of 4 km and transmission loss of 2 dB/km, a phase change sensitivity higher than 6 * 10^3 rad per g is achieved at both vibration frequencies of 200 Hz and 0.5 Hz."
  },
  {
    "date": "2026-01-21",
    "title": "Computing higher limits over the fusion orbit category via amalgams",
    "authors": "Marco Praderio Bova",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14983v1",
    "source": "arXiv",
    "abstract": "We study higher limits over the centric orbit category of a fusion system realized by an amalgamated product. In so doing we provide a novel technique for studying the Diaz-Park sharpness conjecture and prove it (in the case of the cohomology Mackey functors) for all the Clelland-Parker and Parker-Stroth fusion systems. This complements previous work from Henke, Libmand and Lynd. We further use the developed technique to study the Benson-Solomon fusion systems thus relating higher limits over the centric fusion orbit category of these systems with the signalizer functors described by Aschbacher and Chermak. We believe that the proposed technique can, in future work, be used as a first step in an induction argument that can bring us closer to providing an answer to this conjecture."
  },
  {
    "date": "2026-01-21",
    "title": "Interoperable Architecture for Digital Identity Delegation for AI Agents with Blockchain Integration",
    "authors": "David Ricardo Saavedra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14982v1",
    "source": "arXiv",
    "abstract": "Verifiable delegation in digital identity systems remains unresolved across centralized, federated, and self-sovereign identity (SSI) environments, particularly where both human users and autonomous AI agents must exercise and transfer authority without exposing primary credentials or private keys. We introduce a unified framework that enables bounded, auditable, and least-privilege delegation across heterogeneous identity ecosystems. The framework includes four key elements: Delegation Grants (DGs), first-class authorization artefacts that encode revocable transfers of authority with enforced scope reduction; a Canonical Verification Context (CVC) that normalizes verification requests into a single structured representation independent of protocols or credential formats; a layered reference architecture that separates trust anchoring, credential and proof validation, policy evaluation, and protocol mediation via a Trust Gateway; and an explicit treatment of blockchain anchoring as an optional integrity layer rather than a structural dependency. Together, these elements advance interoperable delegation and auditability and provide a foundation for future standardization, implementation, and integration of autonomous agents into trusted digital identity infrastructures."
  },
  {
    "date": "2026-01-21",
    "title": "Fractional Diffusion on Graphs: Superposition of Laplacian Semigroups and Memory",
    "authors": "Nikita Deniskin, Ernesto Estrada",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14977v1",
    "source": "arXiv",
    "abstract": "Subdiffusion on graphs is often modeled by time-fractional diffusion equations, yet its structural and dynamical consequences remain unclear. We show that subdiffusive transport on graphs is a memory-driven process generated by a random time change that compresses operational time, produces long-tailed waiting times, and breaks Markovianity while preserving linearity and mass conservation. We prove that Mittag-Leffler graph dynamics admit an exact convex, mass-preserving representation as a superposition of classical heat semigroups evaluated at rescaled times, revealing fractional diffusion as ordinary diffusion acting across multiple intrinsic time scales. This framework uncovers heterogeneous, vertex-dependent memory effects and induces transport biases absent in classical diffusion, including algebraic relaxation, degree-dependent waiting times, and early-time asymmetries between sources and neighbors. These features define a subdiffusive geometry on graphs enabling particles to locally discover global shortest paths while favoring high-degree regions. Finally, we show that time-fractional diffusion arises as a singular limit of multi-rate diffusion."
  },
  {
    "date": "2026-01-21",
    "title": "MSA-3D: Connecting the Chemical and Kinematic Structures of Galaxies at $z \\sim 1$",
    "authors": "Mengting Ju, Xin Wang, Tucker Jones, Ivana Barišić, Juan M. Espejo Salcedo, Karl Glazebrook, Danail Obreschkow, Takafumi Tsukui, Qianqiao Zhou, Kevin Bundy, Alaina Henry, Matthew A. Malkan, Themiya Nanayakkara, Namrata Roy, Xunda Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14976v1",
    "source": "arXiv",
    "abstract": "We investigate the connection between ionized gas kinematics and gas-phase metallicity gradients in 21 star-forming galaxies at $0.5 < z < 1.7$ from the MSA-3D survey, using spatially resolved JWST/NIRSpec slit-stepping observations. Galaxy kinematics are characterized by the ratio of rotational velocity to intrinsic velocity dispersion, $v/σ$, measured at $1.5\\,R_e$, where $R_e$ is the effective radius. We find that dynamically hotter disks exhibit systematically flatter metallicity gradients, with a moderate anti-correlation between metallicity gradient and $v/σ$ (Pearson $r=-0.43$, $p=0.05$) and a linear fit yields a slope of $\\sim 0.005$ dex per dex in $v/σ$, weaker than the dependence on stellar mass. A significantly stronger anti-correlation is observed with $R_e/σ$, interpreted as a proxy for the radial mixing timescale ($r=-0.59$, $p=0.005$), indicating that cumulative radial mixing more directly regulates chemical stratification. The metallicity gradients in our sample are uniformly shallow, indicating that efficient turbulent mixing in kinematically settled disks regulates the chemical structure of typical star-forming galaxies at $z\\sim1$."
  },
  {
    "date": "2026-01-21",
    "title": "Robust Machine Learning for Regulatory Sequence Modeling under Biological and Technical Distribution Shifts",
    "authors": "Yiyao Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14969v1",
    "source": "arXiv",
    "abstract": "Robust machine learning for regulatory genomics is studied under biologically and technically induced distribution shifts. Deep convolutional and attention based models achieve strong in distribution performance on DNA regulatory sequence prediction tasks but are usually evaluated under i.i.d. assumptions, even though real applications involve cell type specific programs, evolutionary turnover, assay protocol changes, and sequencing artifacts. We introduce a robustness framework that combines a mechanistic simulation benchmark with real data analysis on a massively parallel reporter assay (MPRA) dataset to quantify performance degradation, calibration failures, and uncertainty based reliability. In simulation, motif driven regulatory outputs are generated with cell type specific programs, PWM perturbations, GC bias, depth variation, batch effects, and heteroscedastic noise, and CNN, BiLSTM, and transformer models are evaluated. Models remain accurate and reasonably calibrated under mild GC content shifts but show higher error, severe variance miscalibration, and coverage collapse under motif effect rewiring and noise dominated regimes, revealing robustness gaps invisible to standard i.i.d. evaluation. Adding simple biological structural priors motif derived features in simulation and global GC content in MPRA improves in distribution error and yields consistent robustness gains under biologically meaningful genomic shifts, while providing only limited protection against strong assay noise. Uncertainty-aware selective prediction offers an additional safety layer that risk coverage analyses on simulated and MPRA data show that filtering low confidence inputs recovers low risk subsets, including under GC-based out-of-distribution conditions, although reliability gains diminish when noise dominates."
  },
  {
    "date": "2026-01-21",
    "title": "Resonant Excitation Induced Vibronic Mollow Triplets",
    "authors": "Devashish Pandey, Corne Koks, Martijn Wubs, Nicolas Stenger, Jake Iles-Smith",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14963v1",
    "source": "arXiv",
    "abstract": "The Mollow triplet is the definitive spectral signature of an optically dressed quantum emitter. We predict that for emitters coupled to localized phonons, this signature is not confined to the zero-phonon line. Under a strong resonant drive, we show that Mollow triplets are strikingly replicated on the associated phonon sidebands -a surprising result, given that phonon sidebands are typically viewed as incoherent, inelastic scattering pathways. These vibronic Mollow triplets are a direct fingerprint of dynamically generated dressed states that hybridize the emitter's electronic, photonic, and vibrational degrees of freedom. We develop a scalable analytical formalism to model this effect in complex, multi-mode molecular systems, such as dibenzoterrylene. Our work provides the precise driving conditions for observing these novel spectral features, establishing a new signature of coherence in vibronically coupled systems."
  },
  {
    "date": "2026-01-21",
    "title": "Central subspace data depth",
    "authors": "Giacomo Francisci, Claudio Agostinelli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14947v1",
    "source": "arXiv",
    "abstract": "Statistical data depth plays an important role in the analysis of multivariate data sets. The main outcome is a center-outward ordering of the observations that can be used both to highlight features of the underlying distribution of the data and as input to further statistical analysis. An important property of data depth is related to symmetric distributions as the point with the highest depth value, the center, coincides with the point of symmetry. However, there are applications in which it is more natural to consider symmetry with respect to a subspace of a certain dimension rather than to a point, i.e. a subspace of dimension zero. We provide a general framework to construct statistical data depths which attain maximum value in a subspace, providing a center-outward ordering from that subspace. We refer to these data depths as central subspace data depths. Moreover, if the distribution is symmetric with respect to a subspace, then the depth is maximized at that subspace. We introduce general notions of symmetry about a subspace for distributions, study the properties of central subspace data depths and provide asymptotic convergence for the corresponding sample versions. Additionally, we discuss connections with projection pursuit and dimension reduction. An application based on custom data fraud detection shows the importance of the proposed approach and strengthens its potential."
  },
  {
    "date": "2026-01-21",
    "title": "The GDN-CC Dataset: Automatic Corpus Clarification for AI-enhanced Democratic Citizen Consultations",
    "authors": "Pierre-Antoine Lequeu, Léo Labat, Laurène Cave, Gaël Lejeune, François Yvon, Benjamin Piwowarski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14944v1",
    "source": "arXiv",
    "abstract": "LLMs are ubiquitous in modern NLP, and while their applicability extends to texts produced for democratic activities such as online deliberations or large-scale citizen consultations, ethical questions have been raised for their usage as analysis tools. We continue this line of research with two main goals: (a) to develop resources that can help standardize citizen contributions in public forums at the pragmatic level, and make them easier to use in topic modeling and political analysis; (b) to study how well this standardization can reliably be performed by small, open-weights LLMs, i.e. models that can be run locally and transparently with limited resources. Accordingly, we introduce Corpus Clarification as a preprocessing framework for large-scale consultation data that transforms noisy, multi-topic contributions into structured, self-contained argumentative units ready for downstream analysis. We present GDN-CC, a manually-curated dataset of 1,231 contributions to the French Grand Débat National, comprising 2,285 argumentative units annotated for argumentative structure and manually clarified. We then show that finetuned Small Language Models match or outperform LLMs on reproducing these annotations, and measure their usability for an opinion clustering task. We finally release GDN-CC-large, an automatically annotated corpus of 240k contributions, the largest annotated democratic consultation dataset to date."
  },
  {
    "date": "2026-01-21",
    "title": "State of the Art of LLM-Enabled Interaction with Visualization",
    "authors": "Mathis Brossier, Tobias Isenberg, Konrad Schönborn, Jonas Unger, Mario Romero, Johanna Björklund, Anders Ynnerman, Lonni Besançon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14943v1",
    "source": "arXiv",
    "abstract": "We report on a systematic, PRISMA-guided survey of research at the intersection of LLMs and visualization, with a particular focus on visio-verbal interaction -- where verbal and visual modalities converge to support data sense-making. The emergence of Large Language Models (LLMs) has introduced new paradigms for interacting with data visualizations through natural language, leading to intuitive, multimodal, and accessible interfaces. We analyze 48 papers across six dimensions: application domain, visualization task, visualization representation, interaction modality, LLM integration, and system evaluation. Our classification framework maps LLM roles across the visualization pipeline, from data querying and transformation to visualization generation, explanation, and navigation. We highlight emerging design patterns, identify gaps in accessibility and visualization reading, and discuss the limitations of current LLMs in spatial reasoning and contextual grounding. We further reflect on evaluations of combined LLM-visualization systems, highlighting how current research projects tackle this challenge and discuss current gaps in conducting meaningful evaluations of such systems. With our survey we aim to guide future research and system design in LLM-enhanced visualization, supporting broad audiences and intelligent, conversational interfaces."
  },
  {
    "date": "2026-01-21",
    "title": "Impossible Counterfactuals, Discrete Hilbert Space and Bell's Theorem",
    "authors": "Tim Palmer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14941v1",
    "source": "arXiv",
    "abstract": "Negating the Measurement Independence assumption (MI) is often referred to as the `third way' to account for the experimental violation of Bell's inequality. However, this route is generally viewed as ludicrously contrived, implying some implausible conspiracy where experimenters are denied the freedom to choose measurement settings as they like. Here, a locally realistic model of quantum physics is developed (Rational Mechanics - RaQM - based on a gravitational discretisation of Hilbert Space) which violates MI without denying free will. Crucially, RaQM distinguishes experimenters' ability to freely choose measurement settings to some nominal accuracy, from an inability to choose exact settings, which were never under their control anyway. In RaQM, Hilbert states are necessarily undefined in bases where squared amplitudes and/or complex phases are irrational numbers. Such `irrational' bases correspond to conceivable but necessarily impossible counterfactual measurements, and are shown to play a ubiquitous role in the analysis of both single- and entangled-particle quantum physics. It is concluded that violation of Bell inequalities can be understood with none of the strange processes historically associated with it. Instead, using concepts from (non-classical) $p$-adic number theory, we relate RaQM to Bohm and Hiley's concept of a holistic Machian-like Undivided Universe. If this interpretation of Bell's Theorem is correct, building more and more energetic particle accelerators to probe smaller and smaller scales, in the search for a theory which synthesises quantum and gravitational physics and hence a Theory of Everything, may be a fruitless exercise."
  },
  {
    "date": "2026-01-21",
    "title": "AGN in Gaia Alerts: from flares to Changing Look Quasars",
    "authors": "M. Dennefeld, T. Pursimo, C. Carvalho, E. Biancalani, M. A. Diaz Teodori, O. Durfeldt Pedros, M. A. Fetzner Keniger, A. Kasikov, N. Koivisto, J. Martikainen, K. Matilainen, J. Sinkbak Thomsen, J. Terwel, A. Viitanen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14932v1",
    "source": "arXiv",
    "abstract": "The Gaia Alerts system is providing alerts on a variety of objects displaying a significant photometric change detected by the Gaia satellite from one passage to the next one over the same region of the sky. Among the over 22000 alerts published until the end of 2022, around 13 percent concern AGN or quasar candidates. We have embarked on a spectroscopic ground-based follow-up of some of those (including some selected by a different method specifically in galactic nuclei), to establish their true nature, and reveal the various phenomena leading to a change in magnitude of those AGN. The present paper deals with radio-quiet objects, while the radio-loud ones will be described in a companion paper. We confirm, on one hand, the AGN/quasar nature of 64 new candidates alerted by Gaia, and, on the other hand, obtained second-epoch spectra of over 200 known AGN also alerted for large photometric variations. The observed phenomena show a large variety: from Flares to Tidal Disruption Events (TDEs) and a large number of Changing Look Quasars (CLQs, 56 secure ones, plus 23 probable ones), not forgetting some rarer events like SNe, microlensing events or Extreme Coronal Line Emitters. This sample shows that variability is an excellent tool to detect new quasars, especially radio-quiet ones that otherwise would be undetected, and that a significant fraction of variable AGN/quasars, around 10 percent, presents the CLQ phenomenon. Some of the new CLQs are followed-up to monitor further changes and measure time scales."
  },
  {
    "date": "2026-01-21",
    "title": "Spin-orbit-driven quarter semimetals in rhombohedral graphene",
    "authors": "Jing Ding, Hanxiao Xiang, Naitian Liu, Wenqiang Zhou, Xinjie Fang, Zhangyuan Chen, Le Zhang, Kenji Watanabe, Takashi Taniguchi, Shuigang Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14930v1",
    "source": "arXiv",
    "abstract": "Semimetals exhibit intriguing characteristics attributed to the coexistence of both electrons and holes. In rhombohedral multilayer graphene, a strong trigonal warping effect gives rise to a semi-metallic state near the Fermi surface, offering unique opportunities to explore the interplay of semi-metallic properties with strong correlations and topologies. Here, the observation of quarter semimetals in rhombohedral multilayer graphene by introducing spin-orbit coupling (SOC) is reported. The semi-metallic characteristics of rhombohedral graphene manifest as nearly vanished Hall resistance and parabolic longitudinal resistance. The strong correlations arising from the surface flat band lead to spontaneous symmetry breaking. SOC proximitized by WSe2 further lifts the valley degeneracy, resulting in the spontaneous time-reversal symmetry breaking, as evidenced by the hysteretic anomalous Hall effect. The coexistence of fully polarized electrons and holes allows for the observation of a non-monotonic temperature dependence of the anomalous Hall resistance. Furthermore, the application of moderate magnetic fields induces a phase transition from quarter semimetals to Chern insulators. These findings establish rhombohedral multilayer graphene as an ideal platform for studying strong correlations and topologies in semimetals."
  },
  {
    "date": "2026-01-21",
    "title": "On Implementing Hybrid Post-Quantum End-to-End Encryption",
    "authors": "Aditi Gandhi, Aakankshya Das, Aswani Kumar Cherukuri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14926v1",
    "source": "arXiv",
    "abstract": "The emergence of quantum computing poses a fundamental threat to current public key cryptographic systems. This threat is necessitating a transition to quantum resistant cryptographic alternatives in all the applications. In this work, we present the implementation of a practical hybrid end-to-end encryption system that combines classical and post-quantum cryptographic primitives to achieve both security and efficiency. Our system employs CRYSTALS-Kyber, a NIST-standardized lattice-based key encapsulation mechanism, for quantum-safe key exchange, coupled with AES-256-GCM for efficient authenticated symmetric encryption and SHA-256 for deterministic key derivation. The architecture follows a zero-trust model where a relay server facilitates communication without accessing plaintext messages or cryptographic keys. All encryption and decryption operations occur exclusively at client endpoints. The system demonstrates that NIST standardized post-quantum cryptography can be effectively integrated into practical messaging systems with acceptable performance characteristics, offering protection against both classical and quantum adversaries. As our focus is on implementation rather than on novelty, we also provide an open-source implementation to facilitate reproducibility and further research in post quantum secure communication systems."
  },
  {
    "date": "2026-01-21",
    "title": "Fast-ULCNet: A fast and ultra low complexity network for single-channel speech enhancement",
    "authors": "Nicolás Arrieta Larraza, Niels de Koeijer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14925v1",
    "source": "arXiv",
    "abstract": "Single-channel speech enhancement algorithms are often used in resource-constrained embedded devices, where low latency and low complexity designs gain more importance. In recent years, researchers have proposed a wide variety of novel solutions to this problem. In particular, a recent deep learning model named ULCNet is among the state-of-the-art approaches in this domain. This paper proposes an adaptation of ULCNet, by replacing its GRU layers with FastGRNNs, to reduce both computational latency and complexity. Furthermore, this paper shows empirical evidence on the performance decay of FastGRNNs in long audio signals during inference due to internal state drifting, and proposes a novel approach based on a trainable complementary filter to mitigate it. The resulting model, Fast-ULCNet, performs on par with the state-of-the-art original ULCNet architecture on a speech enhancement task, while reducing its model size by more than half and decreasing its latency by 34% on average."
  },
  {
    "date": "2026-01-21",
    "title": "Application-level observability for adaptive Edge to Cloud continuum systems",
    "authors": "Kaddour Sidi, Daniel Balouek, Baptiste Jonglez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14923v1",
    "source": "arXiv",
    "abstract": "Modern Edge-to-Cloud (E2C) systems require fine-grained observability to ensure adaptive behavior and compliance with performance objectives across heterogeneous and dynamic environments. This work introduces an application-level observability framework that integrates developer-driven instrumentation and SLO-aware feedback for autonomous adaptation. By combining OpenTelemetry, Prometheus, K3s, and Chaos Mesh, the framework enables real-time monitoring and adaptive control across the continuum. A video processing use case demonstrates how application-level metrics guide automatic adjustments to maintain target frame rate, latency, and detection accuracy under variable workloads and injected faults. Preliminary results highlight improved scalability, fault tolerance, and responsiveness, providing a practical foundation for adaptive, SLO-compliant E2C applications."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient reversal of transductions of sparse graph classes",
    "authors": "Jan Dreier, Jakub Gajarský, Michał Pilipczuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14906v1",
    "source": "arXiv",
    "abstract": "(First-order) transductions are a basic notion capturing graph modifications that can be described in first-order logic. In this work, we propose an efficient algorithmic method to approximately reverse the application of a transduction, assuming the source graph is sparse. Precisely, for any graph class $\\mathcal{C}$ that has structurally bounded expansion (i.e., can be transduced from a class of bounded expansion), we give an $O(n^4)$-time algorithm that given a graph $G\\in \\mathcal{C}$, computes a vertex-colored graph $H$ such that $G$ can be recovered from $H$ using a first-order interpretation and $H$ belongs to a graph class $\\mathcal{D}$ of bounded expansion. This answers an open problem raised by Gajarský et al. In fact, for our procedure to work we only need to assume that $\\mathcal{C}$ is monadically stable (i.e., does not transduce the class of all half-graphs) and has inherently linear neighborhood complexity (i.e., the neighborhood complexity is linear in all graph classes transducible from $\\mathcal{C}$). This renders the conclusion that the graph classes satisfying these two properties coincide with classes of structurally bounded expansion."
  },
  {
    "date": "2026-01-21",
    "title": "On the testing of grain shape corrections to bedload transport equations with grain-resolved numerical simulations",
    "authors": "Yulan Chen, Orencio Durán, Thomas Pähtz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14892v1",
    "source": "arXiv",
    "abstract": "Using grain-resolved LES-DEM simulations, Zhang et al. (J. Geophys. Res. Earth Surf. 130, e2024JF007937, 2025) aimed to validate a grain-shape-corrected bedload transport equation proposed earlier by the same group. It states that grain shape effects are captured through a modified Shields number that depends, among others, on the drag coefficient, $C_{D_\\mathrm{settle}}$, determined from the force balance for a grain settling in a fluid at rest. To independently vary $C_{D_\\mathrm{settle}}$ in their simulations, the authors changed the boundary conditions on the grains' surfaces: By artificially shifting the locations of the no-slip conditions from the actual grain surface to a virtual surface a distance $l$ into the grain interior, they hoped to well approximate Navier-slip conditions with a slip length $l$. Here, we argue that this approximation is appropriate only if the thickness of the boundary layer that forms around the virtual surface is much larger than $l$, which we demonstrate was not the case for the authors' simulations. In particular, using independent DNS-DEM grain settling simulations for the same hydrodynamic conditions, we directly show that this approximation substantially overestimates the value of $C_{D_\\mathrm{settle}}$ of a Navier-slip sphere. This implies that the conditions created with their artificial method do not correspond to physically realistic scenarios and therefore do not support the authors' grain shape correction. To support this conclusion, we demonstrate that their entire numerical data can be alternatively explained by a simple null hypothesis model, without grain shape correction, based on the virtual-grain rather than the actual-grain size."
  },
  {
    "date": "2026-01-21",
    "title": "5G NR Non-Terrestrial Networks: Open Challenges for Full-Stack Protocol Design",
    "authors": "Francesco Rossato, Mattia Figaro, Alessandro Traspadini, Takayuki Shimizu, Chinmay Mahabal, Sanjeewa Herath, Chunghan Lee, Dogan Kutay Pekcan, Michele Zorzi, Marco Giordani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14883v1",
    "source": "arXiv",
    "abstract": "As 5th generation (5G) networks continue to evolve, there is a growing interest toward the integration of Terrestrial Networks (TNs) and Non-Terrestrial Networks (NTNs). Specifically, NTNs leverage space/air base stations such as satellites, High Altitude Platforms (HAPs), and Unmanned Aerial Vehicles (UAVs) for expanding wireless coverage to underserved rural/remote areas, supporting emergency communications, and offloading traffic in highly congested urban environments. In this paper we focus on the 3GPP 5G NR-NTN standard in the context of satellite communication networks, and highlight critical challenges that must be addressed for proper full-stack protocol design, with considerations related to the PHY, MAC, and higher layers. We also present simulation results in ns-3 to demonstrate the impact of some of these challenges on the network, as an initial step toward more advanced standardization activities on 3GPP 5G NR-NTN."
  },
  {
    "date": "2026-01-21",
    "title": "ExoMiner++ 2.0: Vetting TESS Full-Frame Image Transit Signals",
    "authors": "Miguel J. S. Martinho, Hamed Valizadegan, Jon M. Jenkins, Douglas A. Caldwell, Joseph D. Twicken, Ben Tofflemire, Marziye Jafariyazani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14877v1",
    "source": "arXiv",
    "abstract": "The Transiting Exoplanet Survey Satellite (TESS) Full-Frame Images (FFIs) provide photometric time series for millions of stars, enabling transit searches beyond the limited set of pre-selected 2-minute targets. However, FFIs present additional challenges for transit identification and vetting. In this work, we apply ExoMiner++ 2.0, an adaptation of the ExoMiner++ framework originally developed for TESS 2-minute data, to FFI light curves. The model is used to perform large-scale planet versus non-planet classification of Threshold Crossing Events across the sectors analyzed in this study. We construct a uniform vetting catalog of all evaluated signals and assess model performance under different observing conditions. We find that ExoMiner++ 2.0 generalizes effectively to the FFI domain, providing robust discrimination between planetary signals, astrophysical false positives, and instrumental artifacts despite the limitations inherent to longer cadence data. This work extends the applicability of ExoMiner++ to the full TESS dataset and supports future population studies and follow-up prioritization."
  },
  {
    "date": "2026-01-21",
    "title": "Dark Energy Survey Year 6 Results: Weak Lensing and Galaxy Clustering Cosmological Analysis Framework",
    "authors": "D. Sanchez-Cid, A. Ferté, J. Blazek, S. Samuroff, A. Amon, F. Andrade-Oliveira, J. M. Coloma-Nadal, J. Muir, A. Porredon, J. Prat, N. Weaverdyck, M. Yamamoto, D. Anbajagane, M. R. Becker, P. Carrilho, C. Chang, M. Crocce, G. Giannini, W. d'Assignies, J. DeRose, S. Dodelson, E. Krause, E. Legnani, J. Mena-Fernández, N. MacCrann, A. Pourtsidou, C. Preston, P. Rogozenski, M. Rodriguez-Monroy, R. Rosenfeld, E. Sanchez, I. Sevilla-Noarbe, M. Soares-Santos, C. To, M. A. Troxel, M. Tsedrik, B. Yin, J. Zuntz, T. M. C. Abbott, M. Aguena, S. Allam, O. Alves, S. Avila, D. Bacon, K. Bechtol, E. Bertin, S. Bocquet, D. Brooks, H. Camacho, R. Camilleri, A. Campos, A. Carnero Rosell, J. Carretero, F. J. Castander, R. Cawthon, A. Choi, L. N. da Costa, M. E. da Silva Pereira, T. M. Davis, J. De Vicente, S. Desai, C. Doux, A. Drlica-Wagner, T. Eifler, J. Elvin-Poole, S. Everett, A. E. Evrard, B. Flaugher, P. Fosalba, J. Frieman, J. García-Bellido, M. Gatti, E. Gaztanaga, P. Giles, K. Glazebrook, D. Gruen, G. Gutierrez, I. Harrison, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, D. Huterer, B. Jain, D. J. James, N. Jeffrey, T. Kacprzak, K. Kuehn, O. Lahav, S. Lee, J. L. Marshall, F. Menanteau, R. Miquel, J. J. Mohr, J. Myles, R. C. Nichol, R. L. C. Ogando, A. Palmese, M. Paterno, W. J. Percival, A. A. Plazas Malagón, M. Raveri, A. Roodman, C. Sánchez, T. Schutt, E. Sheldon, N. Sherman, T. Shin, M. Smith, E. Suchyta, M. E. C. Swanson, M. Tabbutt, G. Tarle, D. Thomas, D. L. Tucker, V. Vikram, A. R. Walker, B. Yanny",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14859v1",
    "source": "arXiv",
    "abstract": "We present the methodology for the weak lensing and galaxy clustering analyses of the Dark Energy Survey (DES) Year 6 data set. In this work, we design and validate the analysis pipeline for the cosmic shear, galaxy clustering plus galaxy$-$galaxy lensing ($2 \\times 2$pt), and the joint analysis in the $3 \\times 2$pt. Our framework accounts for key theoretical uncertainties, such as baryonic feedback and galaxy bias, incorporating both linear and non-linear models. We apply scale cuts in regimes where theoretical modeling becomes unreliable. The robustness of the pipeline is validated using mock data and simulations, confirming unbiased cosmological constraints and highlighting the importance of posterior projection effects in the validation process. As a result, we deliver robust and validated analysis pipelines for cosmic shear, $2 \\times 2$pt, and $3 \\times 2$pt in $Λ$CDM and $w$CDM scenarios, including a well-defined set of scales suitable for real data analysis, a robust prescription for theoretical systematics, and the theoretical covariance of the signal. This comprehensive methodology also lays the groundwork for future galaxy surveys such as the Vera C. Rubin Observatory Legacy Survey of Space and Time."
  },
  {
    "date": "2026-01-21",
    "title": "Effective normal basis theorem",
    "authors": "Pascal Autissier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14856v1",
    "source": "arXiv",
    "abstract": "Let K be a finite Galois extension of Q. The normal basis theorem provides an element of K whose conjugates form a Q-basis of K. Here we obtain such an element with controlled size. This improves a recent result by Fukshansky and Jeong. By the way, we estimate Minkowski's minima of ideals of integers of number fields."
  },
  {
    "date": "2026-01-21",
    "title": "Ho3+-doped CALGO crystals for high-power ultrafast 2.1-μm lasers",
    "authors": "Anna Suzuki, Pavel Loiko, Weichao Yao, Parisa Baghery, Martin Hoffmann, Kirill Eremeev, Patrice Camy, Alain Braud, Sergei Tomilov, Yicheng Wang, Clara J. Saraceno",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14854v1",
    "source": "arXiv",
    "abstract": "Ho3+-doped disordered CaAlGdO4 (CALGO) crystals have recently emerged as a promising gain material platform for next-generation high-power ultrafast 2.1-μm laser systems. This laser gain material offers a unique combination of high-gain, small quantum defect, inhomogeneously broadened spectra, and good thermal conductivity, enabling ultrashort pulse generation and amplification at high-average power and high pulse energy. Many systems, including mode-locked oscillators and amplifiers with state-of-the-art performance, have been demonstrated in the last few years that promise to meet growing application demands for efficient ultrafast laser technology in this wavelength region. In this review paper, we summarize recent achievements using this gain material both in oscillators and amplifiers and place these results in the state-of-the-art of 2-μm ultrafast laser technology, present detailed spectroscopic characterization of this material, and discuss future perspectives of further performance scaling of Ho:CALGO lasers."
  },
  {
    "date": "2026-01-21",
    "title": "Graphical model-based clustering of categorical data",
    "authors": "Laura Ferrini, Federico Castelletti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14849v1",
    "source": "arXiv",
    "abstract": "Clustering multivariate data is a pervasive task in many applied problems, particularly in social studies and life science. Model-based approaches to clustering rely on mixture models, where each mixture component corresponds to the kernel of a distribution characterizing a latent sub-group. Current methods developed within this framework employ multivariate distributions built under the assumption of independence among variables given the cluster allocation. Accordingly, possible dependence structures characterizing differences across groups are not directly accounted for during the clustering process. In this paper we consider multivariate categorical data, and introduce a model-based clustering method which employs graphical models as a tool to encode dependencies between variables. Specifically, we consider a Dirichlet Process mixture of categorical graphical models, which clusters individuals into groups that are homogeneous in terms of dependence (graphical) structure and allied parameters. We provide full Bayesian inference for the model and develop a Markov chain Monte Carlo scheme for posterior analysis. Our method is evaluated through simulations and applied to real case studies, including the analysis of genomic data and voting records. Results reveal the merits of a graphical model-based clustering, in comparison with approaches that do not explicitly account for dependencies in the multivariate distribution of variables."
  },
  {
    "date": "2026-01-21",
    "title": "Contactomorphic vertically convex domains",
    "authors": "Jan Eyll, Jonas Fritsch, Kai Zehmisch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14842v1",
    "source": "arXiv",
    "abstract": "We consider the standard Darboux space equipped with the radial symmetric contact form. We study co-orientation preserving contactomorphisms between relatively compact domains up to the boundary. We determine the contactomorphism classes among all strict vertically convex domains over a round ball in the Liouville hyperplane that are radially symmetric about the Reeb axis and whose boundary coincide along a neighbourhood of the common equator. The total invariant is the mean curvature of the bounding sphere at the umbilic points with the same sign. Replacing the Liouville hyperplane by codisc bundles of closed non-Besse Riemannian manifolds or finite symplectisations of closed non-Besse strict contact manifolds analogous results are formulated in terms of characteristic length and total characteristic action, resp."
  },
  {
    "date": "2026-01-21",
    "title": "On Dimension Varying Control Systems: A Universal State Space Approach",
    "authors": "Daizhan Cheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14839v1",
    "source": "arXiv",
    "abstract": "A cross-dimensional Euclidian space ($Ω$) is proposed for the state space of dimension varying (control) systems. It is shown that the topological structure of $Ω$ is consistent with all $\\mathbb{R}^n$, which are the state spaces of each component modes of a dimension varying system. Using the universal metric from $Ω$, the switching laws are assumed to be Lipschitz. Some reasonable conventional switching laws are proposed. Under the topology deduced by the metric on $Ω$ some fundamental properties of dimension varying dynamic systems, such as stability and robustness, are investigated. Then some control problems of dimension varying control systems, including controllability, observability, stabilization, disturbance decoupling, etc. are investigated. Finally, an aggregation approach for large scale hierarchical dimension varying networks is proposed."
  },
  {
    "date": "2026-01-21",
    "title": "Electric field induced by radial redistribution of the energetic ion pressure in a fusion plasma",
    "authors": "Shaojie Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14834v1",
    "source": "arXiv",
    "abstract": "It is found by using the gyrokinetic theory that significant radial electric fields, or zonal flows, can be generated by the radial redistribution of energetic ion pressure in a tokamak fusion device. Trapped energetic ions are more effective to generate the radial electric field than the isotropic energetic ions. This suggests that the energetic $α$ particles produced by DT fusion may induce significant radial electric field and thus help to improve the core plasma confinement in a fusion reactor."
  },
  {
    "date": "2026-01-21",
    "title": "Absorption mode broadband 2D MS for proteomics and metabolomics",
    "authors": "Maria A van Agthoven, Marek Polák, Jan Fiala, Claude Nelcy Ounounou, Petr Halada, Michael Palasser, Anne Briot-Dietsch, Alan Kádek, Kathrin Breuker, Petr Novák, Carlos Afonso, Marc-André Delsuc",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14820v1",
    "source": "arXiv",
    "abstract": "Two-dimensional mass spectrometry (2D MS) is a method for tandem mass spectrometry that enables the correlation between precursor and fragment ions without the need for ion isolation. On a Fourier transform ion cyclotron resonance mass spectrometer, the phase correction functions for absorption mode data processing were found to be linear in the precursor ion dimension and quadratic in the fragment ion dimension. Absorption mode data processing on limited data sets has previously shown improvements in signal-to-noise ratio and resolving power by a factor of 2. Here, we have expanded absorption mode data processing to 2D mass spectra regardless of size and frequency range. We have applied absorption mode 2D MS to top-down analysis of variously oxidized ubiquitin proteoforms generated by fast photochemical oxidation of proteins (FPOP) and to an extract of ergot alkaloids. We show that absorption mode data processing significantly improves both the signal-to-noise ratio and the resolving power of the 2D mass spectrum compared to standard magnitude mode in terms of sequence coverage in top-down proteomics, as well as the accuracy of precursor-fragment correlation in metabolomics."
  },
  {
    "date": "2026-01-21",
    "title": "Zero-inflated binary Tree Pólya splitting regression for multivariate count data",
    "authors": "Fabrice Moudjieu, Jean Peyhardi, Maxime Réjou-Méchain, Patrice Soh Takam, Frédéric Mortier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14815v1",
    "source": "arXiv",
    "abstract": "Species distribution models (SDMs) are widely used to assess the effects of environmental factors on species distributions. However, classical SDMs ignore inter-species dependencies. Multivariate SDMs (MSDMs), especially those based on latent Gaussian fields such as the multivariate Poisson log-normal (MPLN), address this limitation but face challenges related to computation, dimensionality, and interpretability. Pólya-splitting (PS) distributions offer an alternative, combining a model for total abundance with a multivariate allocation structure, and have natural interpretations from ecological process models. Yet, they lack flexibility in modeling correlation structures. Tree Pólya-splitting (TPS) distributions overcome this by introducing hierarchical structure such as a phylogenetic tree. In this paper, we extend TPS to account for zero-inflation, leading to the zero-inflated tree Pólya-splitting (Z-TPS) family. We detail its statistical properties, show how standard software enables efficient inference, and illustrate its ecological relevance using tree abundance data from over 180 genera across the Congo Basin tropical rainforest."
  },
  {
    "date": "2026-01-21",
    "title": "A lifting theorem for Grothendieck-Verdier categories",
    "authors": "Max Demirdilek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14812v1",
    "source": "arXiv",
    "abstract": "We identify additional structure on a conservative lax monoidal functor from a closed monoidal category $\\mathcal{C}$ to a Grothendieck-Verdier category $\\mathcal{D}$, such that the Grothendieck-Verdier structure of $\\mathcal{D}$ lifts to $\\mathcal{C}$ and the functor becomes Frobenius linearly distributive. As an application, we recover and extend conditions under which modules over Hopf monads and Hopf algebroids inherit Grothendieck-Verdier structures. We also characterize when categories of bimodules, modules, and local modules over (commutative) algebras internal to a Grothendieck-Verdier category admit such structures. Our results apply to quantales, smash product algebras, skew group algebras, and enveloping algebras of Lie-Rinehart algebras. For applications of the lifting theorem, we construct a strict $2$-equivalence between a $2$-category of Grothendieck-Verdier categories and one of linearly distributive categories with negation, and extend this $2$-equivalence to the braided setting."
  },
  {
    "date": "2026-01-21",
    "title": "Near-Atomic-Scale Compositional Complexity in a 2D Transition Metal Oxide",
    "authors": "Mathias Krämer, Bar Favelukis, J. Manoj Prabhakar, Aleksander Albrecht, Brian A. Rosen, Noam Eliaz, Maxim Sokol, Baptiste Gault",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14807v1",
    "source": "arXiv",
    "abstract": "2D materials hold transformative promise for next-generation nanoelectronics. However, successfully integrating these materials from laboratory-scale discoveries into real-world devices depends on precisely controlling their properties, which are fundamentally determined by their composition. Detailed characterisation using atom probe tomography of 2D Ti0.87O2, a candidate high-$κ$ dielectric, reveals deviations from its commonly assumed stoichiometry. Compositional analysis and comparison with the bulk K0.8[Ti1.73Li0.27]O4 precursor evidences an oxygen deficit indicative of oxygen vacancy formation in the 2D material, as well as the retention of low concentrations of alkali metals that were presumed to be removed during synthesis. Such deviations from stoichiometry indicate a reconstruction mechanism that mitigates the effect of the characteristic, negatively charged vacancies on the titanium sublattice, thereby influencing the local electronic structure and, consequently, functional properties. These findings underscore the importance of a detailed compositional analysis in both understanding and optimizing the extraordinary functional properties of 2D materials, opening pathways to tailored functionalities in next-generation nanoelectronics."
  },
  {
    "date": "2026-01-21",
    "title": "FastFI: Enhancing API Call-Site Robustness in Microservice-Based Systems with Fault Injection",
    "authors": "Yuzhen Tan, Jian Wang, Shuaiyu Xie, Bing Li, Yunqing Yong, Neng Zhang, Shaolin Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14800v1",
    "source": "arXiv",
    "abstract": "Fault injection is a key technique for assessing software reliability, enabling proactive detection of system defects before they manifest in production. However, the increasing complexity of microservice architectures leads to exponential growth in the fault-injection space, rendering traditional random injection inefficient. Recent lineage-driven approaches mitigate this problem through heuristic pruning, but they face two limitations. First, combinatorial-fault discovery remains bottlenecked by general-purpose SAT solvers, which fail to exploit the monotone and low-overlap structure of derived CNF formulas and typically rely on a static upper bound on fault size. Second, existing techniques provide limited post-injection guidance beyond reporting detected faults. To address these challenges, we propose FastFI, a fault-injection-guided framework to enhance the robustness of API call sites in microservice-based systems. FastFI features a DFS-based solver with dynamic fault injection to discover all valid combinatorial faults, and it leverages fault-injection results to identify critical APIs whose call sites should be hardened for robustness. Experiments on four representative microservice benchmarks show that FastFI reduces end-to-end fault-injection time by an average of 76.12\\% compared to state-of-the-art baselines while maintaining acceptable resource overhead. Moreover, FastFI accurately identifies high-impact APIs and provides actionable guidance for call-site hardening."
  },
  {
    "date": "2026-01-21",
    "title": "A Practical Guide to Modern Imputation",
    "authors": "Jeffrey Näf",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14796v1",
    "source": "arXiv",
    "abstract": "This guide based on recent papers should help researchers avoid some of the most common pitfalls of missing value imputation imputation."
  },
  {
    "date": "2026-01-21",
    "title": "Testing the equivalence to thermal states via extractable work under LOCC",
    "authors": "Toshihiro Yada, Nobuyuki Yoshioka, Takahiro Sagawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14789v1",
    "source": "arXiv",
    "abstract": "Understanding the thermal behavior of quantum many-body pure states is one of the most fundamental issues in quantum thermodynamics. It is widely known that typical pure states yield vanishing work, just as thermal states do, when one restricts to local operations that cannot access correlations among subsystems. However, it remains unclear whether this equivalence to thermal states persists under LOCC (local operations and classical communication), where classically accessible correlations can be exploited for work extraction. In this work, we establish criteria for determining whether many-body pure states remain equivalent to thermal states even under LOCC, and show that this thermal equivalence is governed by their multipartite quantum correlation structure. We show that states with asymptotically maximal multipartite entanglement, such as Haar-random states, cannot yield extensive work under LOCC, whereas some states with limited multipartite entanglement, such as constant-degree graph states, allow extensive work extraction despite being locally indistinguishable from thermal states. Thus, our work provides a refined operational notion of thermal equivalence beyond the traditional local regime, which is becoming increasingly important due to the recent expansion of experimentally accessible operations."
  },
  {
    "date": "2026-01-21",
    "title": "Training-Efficient Text-to-Music Generation with State-Space Modeling",
    "authors": "Wei-Jaw Lee, Fang-Chih Hsieh, Xuanjun Chen, Fang-Duo Tsai, Yi-Hsuan Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14786v1",
    "source": "arXiv",
    "abstract": "Recent advances in text-to-music generation (TTM) have yielded high-quality results, but often at the cost of extensive compute and the use of large proprietary internal data. To improve the affordability and openness of TTM training, an open-source generative model backbone that is more training- and data-efficient is needed. In this paper, we constrain the number of trainable parameters in the generative model to match that of the MusicGen-small benchmark (with about 300M parameters), and replace its Transformer backbone with the emerging class of state-space models (SSMs). Specifically, we explore different SSM variants for sequence modeling, and compare a single-stage SSM-based design with a decomposable two-stage SSM/diffusion hybrid design. All proposed models are trained from scratch on a purely public dataset comprising 457 hours of CC-licensed music, ensuring full openness. Our experimental findings are three-fold. First, we show that SSMs exhibit superior training efficiency compared to the Transformer counterpart. Second, despite using only 9% of the FLOPs and 2% of the training data size compared to the MusicGen-small benchmark, our model achieves competitive performance in both objective metrics and subjective listening tests based on MusicCaps captions. Finally, our scaling-down experiment demonstrates that SSMs can maintain competitive performance relative to the Transformer baseline even at the same training budget (measured in iterations), when the model size is reduced to four times smaller. To facilitate the democratization of TTM research, the processed captions, model checkpoints, and source code are available on GitHub via the project page: https://lonian6.github.io/ssmttm/."
  },
  {
    "date": "2026-01-21",
    "title": "Towards Bound Consistency for the No-Overlap Constraint Using MDDs",
    "authors": "Amaury Guichard, Laurent Michel, Hélène Verhaeghe, Pierre Schaus",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14784v1",
    "source": "arXiv",
    "abstract": "Achieving bound consistency for the no-overlap constraint is known to be NP-complete. Therefore, several polynomial-time tightening techniques, such as edge finding, not-first-not-last reasoning, and energetic reasoning, have been introduced for this constraint. In this work, we derive the first bound-consistent algorithm for the no-overlap constraint. By building on the no-overlap MDD defined by Ciré and van Hoeve, we extract bounds of the time window of the jobs, allowing us to tighten start and end times in time polynomial in the number of nodes of the MDD. Similarly, to bound the size and time-complexity, we limit the width of the MDD to a threshold, creating a relaxed MDD that can also be used to relax the bound-consistent filtering. Through experiments on a sequencing problem with time windows and a just-in-time objective ($1 \\mid r_j, d_j, \\bar{d}_j \\mid \\sum E_j + \\sum T_j$), we observe that the proposed filtering, even with a threshold on the width, achieves a stronger reduction in the number of nodes visited in the search tree compared to the previously proposed precedence-detection algorithm of Ciré and van Hoeve. The new filtering also appears to be complementary to classical propagation methods for the no-overlap constraint, allowing a substantial reduction in both the number of nodes and the solving time on several instances."
  },
  {
    "date": "2026-01-21",
    "title": "Dynamics of self-maps in their primal topologies",
    "authors": "Jose C. Martin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15264v1",
    "source": "arXiv",
    "abstract": "We study a series of dynamical concepts for self-maps in the primal topology induced by them. Among the concepts studied are non-wandering points, limit points, recurrent points, minimal sets, transitive points and self-maps, topologically ergodic self-maps, weakly mixing self-maps, strongly mixing self-maps, Lyapunov stable self-maps, chaotic self-maps in the sense of Auslander-Yorke, chaotic self-maps in the sense of Devaney, asymptotic pairs, proximal pairs, and syndetically proximal pairs. Some results are given in the more general context of continuous self-maps in an Alexandroff topological space. We prove that a continuous self-map of an Alexandroff space is always Lyapunov stable."
  },
  {
    "date": "2026-01-21",
    "title": "Distributed Agent-Constrained Truthful Facility Location",
    "authors": "Argyrios Deligkas, Panagiotis Kanellopoulos, Alexandros A. Voudouris",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15258v1",
    "source": "arXiv",
    "abstract": "We study a distributed facility location problem in which a set of agents, each with a private position on the real line, is partitioned into a collection of fixed, disjoint groups. The goal is to open $k$ facilities at locations chosen from the set of positions reported by the agents. This decision is made by mechanisms that operate in two phases. In Phase 1, each group selects the position of one of its agents to serve as the group's representative location. In Phase 2, $k$ representatives are chosen as facility locations. Once the facility locations are determined, each agent incurs an individual cost, defined either as the sum of its distances to all facilities (sum-variant) or as the distance to its farthest facility (max-variant). We focus on the class of strategyproof mechanisms, which preclude the agents from benefiting through strategic misreporting, and establish tight bounds on the approximation ratio with respect to the social cost (the total individual agent cost) in both variants."
  },
  {
    "date": "2026-01-21",
    "title": "FlowSSC: Universal Generative Monocular Semantic Scene Completion via One-Step Latent Diffusion",
    "authors": "Zichen Xi, Hao-Xiang Chen, Nan Xue, Hongyu Yan, Qi-Yuan Feng, Levent Burak Kara, Joaquim Jorge, Qun-Ce Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15250v1",
    "source": "arXiv",
    "abstract": "Semantic Scene Completion (SSC) from monocular RGB images is a fundamental yet challenging task due to the inherent ambiguity of inferring occluded 3D geometry from a single view. While feed-forward methods have made progress, they often struggle to generate plausible details in occluded regions and preserve the fundamental spatial relationships of objects. Such accurate generative reasoning capability for the entire 3D space is critical in real-world applications. In this paper, we present FlowSSC, the first generative framework applied directly to monocular semantic scene completion. FlowSSC treats the SSC task as a conditional generation problem and can seamlessly integrate with existing feed-forward SSC methods to significantly boost their performance. To achieve real-time inference without compromising quality, we introduce Shortcut Flow-matching that operates in a compact triplane latent space. Unlike standard diffusion models that require hundreds of steps, our method utilizes a shortcut mechanism to achieve high-fidelity generation in a single step, enabling practical deployment in autonomous systems. Extensive experiments on SemanticKITTI demonstrate that FlowSSC achieves state-of-the-art performance, significantly outperforming existing baselines."
  },
  {
    "date": "2026-01-21",
    "title": "Single Pixel Imaging and Compressive Sensing: A Practical Tutorial",
    "authors": "Dennis Scheidt",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15248v1",
    "source": "arXiv",
    "abstract": "Single Pixel Imaging is an emerging imaging technique that employs a bucket detector (photodiode) to sample a spatially modulated light field, rather than measuring the spatial distribution with an array of detectors. This approach provides a low-cost alternative for imaging at unconventional wavelengths and enables improved signal collection in noisy measurement environments. Furthermore, it allows the application of compressive sensing to reduce the amount of acquired data and measurement time, facilitating live or in vivo imaging applications. This tutorial presents the experimental implementation of measurement bases and compressive sensing reconstruction methods, including both deterministic algorithms and deep learning approaches. Accompanying Python notebooks guide readers through the reproduction of the presented results and support the application of the methods to their own work."
  },
  {
    "date": "2026-01-21",
    "title": "WeDefense: A Toolkit to Defend Against Fake Audio",
    "authors": "Lin Zhang, Johan Rohdin, Xin Wang, Junyi Peng, Tianchi Liu, You Zhang, Hieu-Thi Luong, Shuai Wang, Chengdong Liang, Anna Silnova, Nicholas Evans",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15240v1",
    "source": "arXiv",
    "abstract": "The advances in generative AI have enabled the creation of synthetic audio which is perceptually indistinguishable from real, genuine audio. Although this stellar progress enables many positive applications, it also raises risks of misuse, such as for impersonation, disinformation and fraud. Despite a growing number of open-source fake audio detection codes released through numerous challenges and initiatives, most are tailored to specific competitions, datasets or models. A standardized and unified toolkit that supports the fair benchmarking and comparison of competing solutions with not just common databases, protocols, metrics, but also a shared codebase, is missing. To address this, we propose WeDefense, the first open-source toolkit to support both fake audio detection and localization. Beyond model training, WeDefense emphasizes critical yet often overlooked components: flexible input and augmentation, calibration, score fusion, standardized evaluation metrics, and analysis tools for deeper understanding and interpretation. The toolkit is publicly available at https://github.com/zlin0/wedefense with interactive demos for fake audio detection and localization."
  },
  {
    "date": "2026-01-21",
    "title": "Metadata Conditioned Large Language Models for Localization",
    "authors": "Anjishnu Mukherjee, Ziwei Zhu, Antonios Anastasopoulos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15236v1",
    "source": "arXiv",
    "abstract": "Large language models are typically trained by treating text as a single global distribution, often resulting in geographically homogenized behavior. We study metadata conditioning as a lightweight approach for localization, pre-training 31 models (at 0.5B and 1B parameter scales) from scratch on large-scale English news data annotated with verified URLs, country tags, and continent tags, covering 4 continents and 17 countries. Across four controlled experiments, we show that metadata conditioning consistently improves in-region performance without sacrificing cross-region generalization, enables global models to recover localization comparable to region-specific models, and improves learning efficiency. Our ablation studies demonstrate that URL-level metadata alone captures much of the geographic signal, while balanced regional data coverage remains essential, as metadata cannot fully compensate for missing regions. Finally, we introduce a downstream benchmark of 800 localized news MCQs and show that after instruction tuning, metadata conditioned global models achieve accuracy comparable to LLaMA-3.2-1B-Instruct, despite being trained on substantially less data. Together, these results establish metadata conditioning as a practical and compute-efficient approach for localization of language models."
  },
  {
    "date": "2026-01-21",
    "title": "Exact general solutions for cosmological scalar field evolution in a vacuum-energy dominated expansion",
    "authors": "Patrick Hu, Robert J. Scherrer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15226v1",
    "source": "arXiv",
    "abstract": "We derive exact general solutions (as opposed to attractor particular solutions) for the evolution of a scalar field $φ$ in a universe dominated by a background fluid with equation of state parameter $w_B = -1$, extending earlier work on exact solutions with $w_B > -1$. Straightfoward exact solutions exist when the evolution is described by a linear differential equation, corresponding to constant, linear, and quadratic potentials. In the nonlinear case, exact solutions are derived for $V = V_0\\ln φ$, $V = V_0 φ^{1/2}$ and $V = V_0/φ$, and the logarithmic potential also yields an exact first integral. These complicated parametric solutions are considerably less useful than those derived previously for a universe dominated by a barotropic fluid such as matter or radiation with $w_B > -1$. However, we generalize the slow-roll approximation and show that it applies to all sufficiently flat potentials in the case of a vacuum-dominated expansion, while it never applies when the universe is dominated by a background fluid with $w_B > -1$."
  },
  {
    "date": "2026-01-21",
    "title": "The phenomenon of resonance in the continuous phase transition of finite-size systems: A passage from Classical World to Quantum World through the resonance?",
    "authors": "Yiannis F. Contoyiannis, Stelios M. Potirakis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15225v1",
    "source": "arXiv",
    "abstract": "In finite-size systems undergoing a continuous phase transition, the passage from the symmetric phase to the broken-symmetry phase is accomplished through a hysteresis zone, up to spontaneous symmetry breaking (SSB). In the present work, we find that a resonance phenomenon takes place within this zone. This resonance is manifested as a maximization of the mean waiting time as a function of temperature inside the hysteresis region. An interesting issue concerns how this resonance is connected with the existence of particles (tachyons) or quasiparticles (kink solitons) within the hysteresis zone. Finally, we introduce the idea that this resonance delineates a continuous passage from a \"classical\" phase to a \"quantum\" phase for a binary system, such as the three-dimensional Ising model, which belongs to the same universality class as a fermion-antifermion system or, more generally, a matter-antimatter system."
  },
  {
    "date": "2026-01-21",
    "title": "PROGRESSLM: Towards Progress Reasoning in Vision-Language Models",
    "authors": "Jianshu Zhang, Chengxuan Qian, Haosen Sun, Haoran Lu, Dingcheng Wang, Letian Xue, Han Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15224v1",
    "source": "arXiv",
    "abstract": "Estimating task progress requires reasoning over long-horizon dynamics rather than recognizing static visual content. While modern Vision-Language Models (VLMs) excel at describing what is visible, it remains unclear whether they can infer how far a task has progressed from partial observations. To this end, we introduce Progress-Bench, a benchmark for systematically evaluating progress reasoning in VLMs. Beyond benchmarking, we further explore a human-inspired two-stage progress reasoning paradigm through both training-free prompting and training-based approach based on curated dataset ProgressLM-45K. Experiments on 14 VLMs show that most models are not yet ready for task progress estimation, exhibiting sensitivity to demonstration modality and viewpoint changes, as well as poor handling of unanswerable cases. While training-free prompting that enforces structured progress reasoning yields limited and model-dependent gains, the training-based ProgressLM-3B achieves consistent improvements even at a small model scale, despite being trained on a task set fully disjoint from the evaluation tasks. Further analyses reveal characteristic error patterns and clarify when and why progress reasoning succeeds or fails."
  },
  {
    "date": "2026-01-21",
    "title": "Rate of convergence of random attractors towards deterministic singleton attractor for a class of non-Newtonian fluids of differential type",
    "authors": "Kush Kinra",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15217v1",
    "source": "arXiv",
    "abstract": "In this article, we investigate the long-term dynamics of a class of two- and three-dimensional non-Newtonian fluids of differential type, known as third-grade fluids. We first show that when the external forcing is sufficiently small, the global attractor of the underlying system (which characterizes its asymptotic behavior) reduces to a single point. We then consider the system under stochastic perturbations, specifically infinite-dimensional additive white noise. In this random setting, we do not find conclusive evidence that the corresponding random attractor remains a single point, as in the deterministic case. However, we are able to estimate the rate at which the random attractor approaches the deterministic singleton attractor as the intensity of the stochastic noise tends to zero."
  },
  {
    "date": "2026-01-21",
    "title": "Real-time Facial Communication Restores Cooperation After Defection in Social Dilemmas",
    "authors": "Mayada Oudah, John Wooders",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15211v1",
    "source": "arXiv",
    "abstract": "Facial expressions are central to human interaction, yet their role in strategic decision-making has received limited attention. We investigate how real-time facial communication influences cooperation in repeated social dilemmas. In a laboratory experiment, participants play a repeated Prisoner's Dilemma game under two conditions: in one, they observe their counterpart's facial expressions via gender-neutral avatars, and in the other no facial cues are available. Using state-of-the-art biometric technology to capture and display emotions in real-time, we find that facial communication significantly increases overall cooperation and, notably, promotes cooperation following defection. This restorative effect suggests that facial expressions help participants interpret defections less harshly, fostering forgiveness and the resumption of cooperation. While past actions remain the strongest predictor of behavior, our findings highlight the communicative power of facial expressions in shaping strategic outcomes. These results offer practical insights for designing emotionally responsive virtual agents and digital platforms that sustain cooperation in the absence of physical presence."
  },
  {
    "date": "2026-01-21",
    "title": "Penalty-Based Smoothing of Convex Nonsmooth Supremum Functions with Accelerated Inertial Dynamics",
    "authors": "Samir Adly, Juan José Maulén, Emilio Vilches",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15208v1",
    "source": "arXiv",
    "abstract": "We propose a penalty-based smoothing framework for convex nonsmooth functions with a supremum structure. The regularization yields a differentiable surrogate with controlled approximation error, a single-valued dual maximizer, and explicit gradient formulas. We then study an accelerated inertial dynamic with vanishing damping driven by a time-dependent regularized function whose parameter decreases to zero. Under mild integrability and boundedness conditions on the regularization schedule, we establish an accelerated $\\mathcal{O}(t^{-2})$ decay estimate for the regularized residual and, in the regime $α>3$, a sharper $o(t^{-2})$ decay together with weak convergence of trajectories to a minimizer of the original nonsmooth problem via an Opial-type argument. Applications to multiobjective optimization (through Chebyshev/max scalarization) and to distributionally robust optimization (via entropic regularization over ambiguity sets) illustrate the scope of the framework."
  },
  {
    "date": "2026-01-21",
    "title": "Embeddings of $L^p$-operator algebras",
    "authors": "Eusebio Gardella, Jan Gundelach",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15204v1",
    "source": "arXiv",
    "abstract": "We study embeddings of $L^p$-operator algebras arising from (twisted) étale groupoids, with particular emphasis on rigidity phenomena for $p\\neq 2$. Our methods rely on a detailed analysis of core normalizers and their functorial behavior under algebra homomorphisms. Using the notion of actors between groupoids, we show that under natural hypotheses, embeddings between reduced $L^p$-groupoid algebras can be described entirely in terms of morphisms of the underlying groupoids. We further show that embeddings of $L^p$-groupoid algebras induce embeddings of the associated topological full groups. Our results provide new tools for studying embeddability questions in the $L^p$-setting, and are particularly helpful when ruling out the existence of embeddings. As applications, we obtain strong rigidity results for (spatial) $L^p$-AF-embeddability, showing that, for $p\\neq 2$, an $L^p$-groupoid algebra embeds into a spatial $L^p$-AF-algebra if and only if the underlying groupoid is AF. In particular, irrational rotation $L^p$-operator algebras do not embed into spatial $L^p$-AF-algebras. We apply these results to tensor products of $L^p$-Cuntz algebras and prove that, for $p\\neq 2$, there is no unital contractive homomorphism from $\\mathcal{O}_2^p \\otimes_p \\mathcal{O}_2^p$ into $\\mathcal{O}_2^p$, showing that there is no $L^p$-analog of Kirchberg's $\\mathcal{O}_2$-embedding theorem."
  },
  {
    "date": "2026-01-21",
    "title": "Entropy of Soft Random Geometric Graphs in General Geometries",
    "authors": "Oliver Baker, Carl P. Dettmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15194v1",
    "source": "arXiv",
    "abstract": "We study the effect of the choice of embedding geometry on the entropy of random geometric graph ensembles with soft connection functions. First we show that when the connection range is small, the entropy is dependent only on the dimension of the geometry and not the shape, but for large connection ranges the boundaries of the domain matter. Next, we formulate the problem of estimating entropy as a problem of estimating the average degree of a graph with the binary entropy function as its connection function. We use this formulation to study the effect of boundaries on the entropy, and to estimate the entropy of soft random geometric graphs in complicated geometries where a closed form pair distance density is not available."
  },
  {
    "date": "2026-01-21",
    "title": "An update on multicolor Ramsey lower bounds",
    "authors": "Marcelo Campos, Cosmin Pohoata",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15183v1",
    "source": "arXiv",
    "abstract": "Building upon previous works by Conlon-Ferber and Wigderson, Sawin showed a few years ago that upper bounds on the minimum density of independent sets in a $K_t$-free $G$ can be used to provide lower bounds for multicolor Ramsey numbers. In this note, we observe how a further improved upper bound on this parameter directly follows from a recent spherical random geometric graph construction of Ma-Shen-Xie. As a consequence, we derive a small exponential improvement over the best known lower bounds for multicolor Ramsey numbers."
  },
  {
    "date": "2026-01-21",
    "title": "Dynamic Management of a Deep Learning-Based Anomaly Detection System for 5G Networks",
    "authors": "Lorenzo Fernández Maimó, Alberto Huertas Celdrán, Manuel Gil Pérez, Félix J. García Clemente, Gregorio Martínez Pérez",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15177v1",
    "source": "arXiv",
    "abstract": "Fog and mobile edge computing (MEC) will play a key role in the upcoming fifth generation (5G) mobile networks to support decentralized applications, data analytics and management into the network itself by using a highly distributed compute model. Furthermore, increasing attention is paid to providing user-centric cybersecurity solutions, which particularly require collecting, processing and analyzing significantly large amount of data traffic and huge number of network connections in 5G networks. In this regard, this paper proposes a MEC-oriented solution in 5G mobile networks to detect network anomalies in real-time and in autonomic way. Our proposal uses deep learning techniques to analyze network flows and to detect network anomalies. Moreover, it uses policies in order to provide an efficient and dynamic management system of the computing resources used in the anomaly detection process. The paper presents relevant aspects of the deployment of the proposal and experimental results to show its performance."
  },
  {
    "date": "2026-01-21",
    "title": "Assessing Orbital Optimization in Variational and Diffusion Monte Carlo",
    "authors": "Cody A. Melton, Jaron T. Krogel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15169v1",
    "source": "arXiv",
    "abstract": "In this work, we investigate the fidelity of orbital optimization in variational Monte Carlo to improve diffusion Monte Carlo results on correlated magnetic systems, using CrSBr as a model system. We compare the performance of different optimization methods, showing that stochastic reconfiguration is a robust and reliable optimizer. We show that short range Jastrow factors are important for improving diffusion Monte Carlo, regardless of the quality of orbitals. Large active spaces are required to converge the variational energy, but ulitmately orbital optimization produces worse diffusion Monte Carlo energies when compared to standard orbitals from density functional theory. We show that this increased bias is due to larger locality errors from the use of pseudopotentials, while the fixed-node error is actually improved by using orbital optimization. Additionally, for observables other than energy, orbital optimization produces a systematically smaller mixed-estimator bias. Ultimately, we believe orbital optimization provides a reliable method to improve variational and pure fixed-node energies as well as lower mixed-estimator bias."
  },
  {
    "date": "2026-01-21",
    "title": "DeGAS: Gradient-Based Optimization of Probabilistic Programs without Sampling",
    "authors": "Francesca Randone, Romina Doz, Mirco Tribastone, Luca Bortolussi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15167v1",
    "source": "arXiv",
    "abstract": "We present DeGAS, a differentiable Gaussian approximate semantics for loopless probabilistic programs that enables sample-free, gradient-based optimization in models with both continuous and discrete components. DeGAS evaluates programs under a Gaussian-mixture semantics and replaces measure-zero predicates and discrete branches with a vanishing smoothing, yielding closed-form expressions for posterior and path probabilities. We prove differentiability of these quantities with respect to program parameters, enabling end-to-end optimization via standard automatic differentiation, without Monte Carlo estimators. On thirteen benchmark programs, DeGAS achieves accuracy and runtime competitive with variational inference and MCMC. Importantly, it reliably tackles optimization problems where sampling-based baselines fail to converge due to conditioning involving continuous variables."
  },
  {
    "date": "2026-01-21",
    "title": "How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework",
    "authors": "Choro Ulan uulu, Mikhail Kulyabin, Iris Fuhrmann, Jan Joosten, Nuno Miguel Martins Pacheco, Filippos Petridis, Rebecca Johnson, Jan Bosch, Helena Holmström Olsson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15153v1",
    "source": "arXiv",
    "abstract": "Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software engineering framework to capture human domain knowledge for engineering AI agents in simulation data visualization by augmenting a Large Language Model (LLM) with a request classifier, Retrieval-Augmented Generation (RAG) system for code generation, codified expert rules, and visualization design principles unified in an agent demonstrating autonomous, reactive, proactive, and social behavior. Evaluation across five scenarios spanning multiple engineering domains with 12 evaluators demonstrates 206% improvement in output quality, with our agent achieving expert-level ratings in all cases versus baseline's poor performance, while maintaining superior code quality with lower variance. Our contributions are: an automated agent-based system for visualization generation and a validated framework for systematically capturing human domain knowledge and codifying tacit expert knowledge into AI agents, demonstrating that non-experts can achieve expert-level outcomes in specialized domains."
  },
  {
    "date": "2026-01-21",
    "title": "A Theory of transmission spectroscopy of planetary winds: Spectral-line saturation and limits on mass-loss inference",
    "authors": "Leonardos Gkouvelis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15152v1",
    "source": "arXiv",
    "abstract": "Transmission spectroscopy is a key technique in the characterization of exoplanet atmospheres and has been widely applied to planets undergoing hydrodynamic escape. While a robust analytic theory exists for transmission spectra of hydrostatic atmospheres, the corresponding interpretation for escaping atmospheres has so far relied on numerical modeling. In this work, we develop a theory of transmission spectroscopy in hydrodynamically escaping atmospheres by coupling the standard transmission geometry to a steady-state, spherically symmetric, isothermal outflow. This approach yields closed-form expressions and allows the optical depth inversion problem to be examined. The analytic solution reveals that transmission spectroscopy of planetary winds naturally separates into two regimes. In an opacity-limited regime, transmission depths retain sensitivity to the atmospheric mass-loss rate. Beyond a critical threshold, however, spectral-line cores become saturated and no longer provide a unique constraint on the mass flux. This transition is marked by a sharp analytic boundary of the form $σ(λ)\\times \\dot M \\le C_{sat}$, where $C_{sat}$ is a constant set by the thermodynamic and geometric properties of the wind. This condition specifies when the inversion between transmission depth and mass-loss rate admits a real solution. Once it is violated, the effective transit radius is no longer controlled by opacity or mass loss, but by the geometric extent of the absorbing wind. These results demonstrate that spectral-line saturation in transmission spectroscopy corresponds to a fundamental loss of invertibility between absorption and atmospheric mass loss, rather than a gradual weakening of sensitivity. The theory provides a physically transparent explanation for why strong transmission line cores often fail to constrain mass-loss rates, while weaker lines and line wings remain diagnostic."
  },
  {
    "date": "2026-01-21",
    "title": "Pipeline Automation Framework for Reusable High-throughput Network Applications on FPGA",
    "authors": "Jean Bruant, Pierre-Henri Horrein, Olivier Muller, Frédéric Pétrot",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15151v1",
    "source": "arXiv",
    "abstract": "In a context of ever-growing worldwide communication traffic, cloud service providers aim at deploying scalable infrastructures to address heterogeneous needs. Part of the network infrastructure, FPGAs are tailored to guarantee low-latency and high-throughput packet processing. However, slowness of the hardware design process impairs FPGA ability to be part of an agile infrastructure under constant evolution, from incident response to long-term transformation. Deploying and maintaining network functionalities across a wide variety of FPGAs raises the need to fine-tune hardware designs for several FPGA targets. To address this issue, we introduce PAF, an open-source architectural parameterization framework based on a pipeline-oriented design methodology. PAF (Pipeline Automation Framework) implementation is based on Chisel, a Scala-embedded Hardware Construction Language (HCL), that we leverage to interface with circuit elaboration. Applied to industrial network packet classification systems, PAF demonstrates efficient parameterization abilities, enabling to reuse and optimize the same pipelined design on several FPGAs. In addition, PAF focuses the pipeline description on the architectural intent, incidentally reducing the number of lines of code to express complex functionalities. Finally, PAF confirms that automation does not imply any loss of tight control on the architecture by achieving on par performance and resource usage with equivalent exhaustively described implementations."
  },
  {
    "date": "2026-01-21",
    "title": "Graph Recognition via Subgraph Prediction",
    "authors": "André Eberhard, Gerhard Neumann, Pascal Friederich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15133v1",
    "source": "arXiv",
    "abstract": "Despite tremendous improvements in tasks such as image classification, object detection, and segmentation, the recognition of visual relationships, commonly modeled as the extraction of a graph from an image, remains a challenging task. We believe that this mainly stems from the fact that there is no canonical way to approach the visual graph recognition task. Most existing solutions are specific to a problem and cannot be transferred between different contexts out-of-the box, even though the conceptual problem remains the same. With broad applicability and simplicity in mind, in this paper we develop a method, \\textbf{Gra}ph Recognition via \\textbf{S}ubgraph \\textbf{P}rediction (\\textbf{GraSP}), for recognizing graphs in images. We show across several synthetic benchmarks and one real-world application that our method works with a set of diverse types of graphs and their drawings, and can be transferred between tasks without task-specific modifications, paving the way to a more unified framework for visual graph recognition."
  },
  {
    "date": "2026-01-21",
    "title": "Decomposing Determinantal Varieties from Statistics via Matroid Theory",
    "authors": "Per Alexandersson, Yulia Alexandr, Emiliano Liwski, Fatemeh Mohammadi, Pardis Semnani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15128v1",
    "source": "arXiv",
    "abstract": "We study determinantal varieties from conditional independence models with hidden variables, focusing on their irreducible decompositions, dimensions, degrees, and Gröbner bases. Each variety encodes a collection of matroids, whose flats capture algebraic dependencies among variables. Using this approach, we provide a systematic description of the components, their dimensions, and defining equations, and introduce a combinatorial framework for computing the degree of the determinantal variety. Our approach highlights the central role of matroidal structures in the study of determinantal varieties and extends beyond the reach of current computational techniques."
  },
  {
    "date": "2026-01-21",
    "title": "DeepFedNAS: A Unified Framework for Principled, Hardware-Aware, and Predictor-Free Federated Neural Architecture Search",
    "authors": "Bostan Khan, Masoud Daneshtalab",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15127v1",
    "source": "arXiv",
    "abstract": "Federated Neural Architecture Search (FedNAS) aims to automate model design for privacy-preserving Federated Learning (FL) but currently faces two critical bottlenecks: unguided supernet training that yields suboptimal models, and costly multi-hour pipelines for post-training subnet discovery. We introduce DeepFedNAS, a novel, two-phase framework underpinned by a principled, multi-objective fitness function that synthesizes mathematical network design with architectural heuristics. Enabled by a re-engineered supernet, DeepFedNAS introduces Federated Pareto Optimal Supernet Training, which leverages a pre-computed Pareto-optimal cache of high-fitness architectures as an intelligent curriculum to optimize shared supernet weights. Subsequently, its Predictor-Free Search Method eliminates the need for costly accuracy surrogates by utilizing this fitness function as a direct, zero-cost proxy for accuracy, enabling on-demand subnet discovery in mere seconds. DeepFedNAS achieves state-of-the-art accuracy (e.g., up to 1.21% absolute improvement on CIFAR-100), superior parameter and communication efficiency, and a substantial ~61x speedup in total post-training search pipeline time. By reducing the pipeline from over 20 hours to approximately 20 minutes (including initial cache generation) and enabling 20-second individual subnet searches, DeepFedNAS makes hardware-aware FL deployments instantaneous and practical. The complete source code and experimental scripts are available at: https://github.com/bostankhan6/DeepFedNAS"
  },
  {
    "date": "2026-01-21",
    "title": "Brjuno-Like Functions for nonlinear expanding maps: Fractional Derivatives and Regularity Dichotomies",
    "authors": "Stefano Marmi, Daniel Smania",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15105v1",
    "source": "arXiv",
    "abstract": "Cohomological equations appear frequently in dynamical systems. One of the most classical examples is the Livšic equation $$ v(x) = α\\circ F(x) - α(x).$$ The existence and regularity of its solutions $α$ is well understood when $F$ is a hyperbolic dynamical system (for instance an expanding map of the circle) and $v$ is a Hölder function. The $\\textbf{twisted cohomological equation}$ $$ v(x) = α\\circ F(x) - (DF(x))^β\\, α(x) $$ is much less well understood. Functions similar to the famous Brjuno, Weierstrass, and Takagi functions appear as solutions of this equation. This functional equation also appears in the work of M. Lyubich, and of Avila, Lyubich, and de Melo in their study of deformations of quadratic-like and real-analytic maps. Nevertheless, there are some striking results concerning the (lack of) regularity of solutions $α$ when $F$ is a linear endomorphism of the circle and $v$ is very regular. Notable contributions include works by Berry and Lewis; Ledrappier; Przytycki and Urbański, and more recently by Barański, Bárány and Romanowska, as well as by Shen, and by Ren and Shen, on Takagi and Weierstrass (and Weierstrass-like) functions. We study the regularity of solutions $α$ when $F$ is a $\\textbf{nonlinear}$ expanding map of the circle and $v$ is not differentiable or even continuous, a setting in which previously used transversality techniques do not appear to be applicable. The new approach uses fractional derivatives to reduce the study of the twisted cohomological equation to that of a corresponding Livšic cohomological equation, and to show that the resulting distributional solutions (in the sense of Schwartz) satisfy certain Central Limit Theorem."
  },
  {
    "date": "2026-01-21",
    "title": "A Myhill-Nerode Characterization and Active Learning for One-Clock Timed Automata",
    "authors": "Kyveli Doveri, Pierre Ganty, B. Srivathsan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15104v1",
    "source": "arXiv",
    "abstract": "We present a Myhill-Nerode style characterization for languages recognized by one-clock deterministic timed automata (1-DTA). Although there is only one clock, distinct automata may reset it differently along the same word. This adds a significant challenge in the search for a canonical automaton. Our characterization is based on a new perspective of 1-DTAs in terms of \"half-integral\" words that they accept, along with the reset information encoded by them. We apply our results to develop L* style algorithms that learn the canonical 1-DTA."
  },
  {
    "date": "2026-01-21",
    "title": "Bose condensation and Bogoliubov excitation in resonator-embedded superconducting qubit network",
    "authors": "Patrick Navez, Valentina Di Meo, Berardo Ruggiero, Claudio Gatti, Fabio Chiarello, Alessandro D'Elia, Alessio Rettaroli, Emanuele Enrico, Luca Fasolo, Mikhail Fistul, Ilya Eremin, Alexandre Zagoskin, Paolo Vanacore, Paolo Silvestrini, Mikhail Lisitskiy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15101v1",
    "source": "arXiv",
    "abstract": "Superconducting qubit networks (SQNs) embedded in a low-dissipative resonator is a promising device allowing one not only to establish the collective quantum dynamics on a macroscopic scale but also to greatly enhance the sensitivity of detectors of microwave photons. A quantum ac Stark effect provided by coupling between an SQN and microwave photons of a resonator, leads to a strong nonlinear interaction between photons. Here, we present a two-tone spectroscopy experiment in which a set of 10 superconducting flux qubits is coupled to the input R- resonator and the output T- transmission line. An external microwave pump field close to the resonance frequency populates macroscopically the resonator mode as a Bose-Einstein condensate, while a second probe beam scans the resonances referred also as Bogoliubov-like excitations. The corresponding excitation frequency measured from the transmission coefficient, |S21(f)| displays an abrupt change of the resonant dip position once the power of the pump field overcomes a critical value Pcr. This sharp shift occurs in a narrow region of pump frequencies, and can be tuned by an applied magnetic field. It is a signature of bistability of the photon number inside the resonator, in agreement with theory."
  },
  {
    "date": "2026-01-21",
    "title": "Instantaneous Frequency in Power Systems using the Teager-Kaiser Energy Operator",
    "authors": "A. Vaca, J. Gutierrez Florensa, F. Milano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15099v1",
    "source": "arXiv",
    "abstract": "This paper develops an instantaneous-frequency (IF) local estimator calculated with the complex Teager-Kaiser energy operator (CTKEO) and the dynamic-signal identity. The contribution is a novel IF expression that makes the envelope-curvature terms explicit, thus correcting the bias that affects conventional estimators used in power systems. The estimator aligns with complex-frequency (CF) kinematics and admits a geometric interpretation (curvature/torsion) without phase unwrapping. Simulations and data-driven examples demonstrate the accuracy of the proposed approach."
  },
  {
    "date": "2026-01-21",
    "title": "Three-dimensional visualization of X-ray micro-CT with large-scale datasets: Efficiency and accuracy for real-time interaction",
    "authors": "Yipeng Yin, Rao Yao, Qingying Li, Dazhong Wang, Hong Zhou, Zhijun Fang, Jianing Chen, Longjie Qian, Mingyue Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15098v1",
    "source": "arXiv",
    "abstract": "As Micro-CT technology continues to refine its characterization of material microstructures, industrial CT ultra-precision inspection is generating increasingly large datasets, necessitating solutions to the trade-off between accuracy and efficiency in the 3D characterization of defects during ultra-precise detection. This article provides a unique perspective on recent advances in accurate and efficient 3D visualization using Micro-CT, tracing its evolution from medical imaging to industrial non-destructive testing (NDT). Among the numerous CT reconstruction and volume rendering methods, this article selectively reviews and analyzes approaches that balance accuracy and efficiency, offering a comprehensive analysis to help researchers quickly grasp highly efficient and accurate 3D reconstruction methods for microscopic features. By comparing the principles of computed tomography with advancements in microstructural technology, this article examines the evolution of CT reconstruction algorithms from analytical methods to deep learning techniques, as well as improvements in volume rendering algorithms, acceleration, and data reduction. Additionally, it explores advanced lighting models for high-accuracy, photorealistic, and efficient volume rendering. Furthermore, this article envisions potential directions in CT reconstruction and volume rendering. It aims to guide future research in quickly selecting efficient and precise methods and developing new ideas and approaches for real-time online monitoring of internal material defects through virtual-physical interaction, for applying digital twin model to structural health monitoring (SHM)."
  },
  {
    "date": "2026-01-21",
    "title": "Parameter-Efficient Multi-Task Fine-Tuning in Code-Related Tasks",
    "authors": "Md Zahidul Haque, Saima Afrin, Antonio Mastropaolo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15094v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have proven highly effective in automating software engineering tasks, bridging natural language and code semantics to achieve notable results in code generation and summarization. However, their scale incurs substantial computational costs, making full fine-tuning impractical. Parameter-Efficient Fine-Tuning (PEFT) methods like QLoRA enable efficient specialization with lower resource demands. Recent studies show QLoRA-optimized Large Code Models (LCMs) perform strongly across diverse tasks, yet it remains unclear whether this effectiveness persists when a single model is QLoRA fine-tuned for multiple code-related tasks. The interaction between Multi-task fine-tuning and QLoRA optimization, and how transfer learning affects correctness and quality of generated artifacts, remains largely unexplored. We investigate Multi-task QLoRA fine-tuning across three representative tasks: code generation, translation, and summarization. We evaluate functional correctness through execution-based and similarity-based metrics, complemented by comprehensive code quality analysis--an aspect largely overlooked in prior work. Our findings show that Multi-task QLoRA effectively leverages transfer learning, achieving competitive or superior performance relative to both Single-task QLoRA and Multi-task full fine-tuning. Larger models demonstrate more consistent balance between correctness and quality, whereas smaller models preserve functionality but exhibit a higher incidence of quality-related issues."
  },
  {
    "date": "2026-01-21",
    "title": "Federated Incremental Subgradient Method for Convex Bilevel Optimization Problems",
    "authors": "Sudkobfa Boontawee, Mootta Prangprakhon, Nimit Nimana",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15092v1",
    "source": "arXiv",
    "abstract": "In this letter, we consider a bilevel optimization problem in which the outer-level objective function is strongly convex, whereas the inner-level problem consists of a finite sum of convex functions. Bilevel optimization problems arise in situations where the inner-level problem does not have a unique solution. This has led to the idea of introducing an outer-level objective function to select a solution with the specific desired properties. We propose an iterative method that combines an incremental algorithm with a broadcast algorithm, both based on the principles of federated learning. Under appropriate assumptions, we establish the convergence results of the proposed algorithm. To demonstrate its performance, we present two numerical examples related to binary classification and a location problem."
  },
  {
    "date": "2026-01-21",
    "title": "The Hadron-Parton Bridge, From the QCD Vacuum to Partons",
    "authors": "Edward Shuryak, Ismail Zahed",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15085v1",
    "source": "arXiv",
    "abstract": "Quantum Chromodynamics (QCD) exhibits complementary descriptions of hadrons: a rest-frame picture based on confinement, chiral symmetry breaking and interquark forces, and a high-energy light-front picture expressed through parton distributions (PDFs,TMDs,GPDs) and form factors. This review develops a unified framework that connects these two domains. It is based mostly on multiple studies by the authors in the past few years. Using the Instanton Liquid Model (ILM) to capture essential nonperturbative features of the QCD vacuum, we derive effective interactions for mesons, baryons, and multiquark states, construct their wave functions in hyperspherical coordinates, and boost them to the light front. The resulting light-front Hamiltonians, incorporating both perturbative and instanton-induced dynamics in the Wilsonian spirit, provide realistic nonperturbative inputs for computing PDFs, DAs, GPDs, quasi-distributions, and gravitational form factors at a well-defined low scale. The connection to perturbative QCD is then established by matching gradient-flow-renormalized operators and LF wave functions to the standard $\\overline{\\rm MS}$ scheme. Perturbative DGLAP and ERBL evolution then connects these predictions to experimentally accessible regimes. % This approach is applied to quarkonia, glueballs, light mesons, baryons, tetraquarks, pentaquarks, and higher multiquark hadrons, yielding consistent descriptions of both their spectra and partonic structure. Special emphasis is placed on the energy-momentum tensor and the mechanical properties of hadrons, which emerge naturally from the same dynamical ingredients. Overall, the framework demonstrates a clear continuity between hadronic spectroscopy and partonic observables, offering a coherent multiscale picture of hadron structure rooted in the underlying dynamics of QCD."
  },
  {
    "date": "2026-01-21",
    "title": "LoRAP: Low-Rank Aggregation Prompting for Quantized Graph Neural Networks Training",
    "authors": "Chenyu Liu, Haige Li, Luca Rossi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15079v1",
    "source": "arXiv",
    "abstract": "Graph Neural Networks (GNNs) are neural networks that aim to process graph data, capturing the relationships and interactions between nodes using the message-passing mechanism. GNN quantization has emerged as a promising approach for reducing model size and accelerating inference in resource-constrained environments. Compared to quantization in LLMs, quantizing graph features is more emphasized in GNNs. Inspired by the above, we propose to leverage prompt learning, which manipulates the input data, to improve the performance of quantization-aware training (QAT) for GNNs. To mitigate the issue that prompting the node features alone can only make part of the quantized aggregation result optimal, we introduce Low-Rank Aggregation Prompting (LoRAP), which injects lightweight, input-dependent prompts into each aggregated feature to optimize the results of quantized aggregations. Extensive evaluations on 4 leading QAT frameworks over 9 graph datasets demonstrate that LoRAP consistently enhances the performance of low-bit quantized GNNs while introducing a minimal computational overhead."
  },
  {
    "date": "2026-01-21",
    "title": "Exceptionally High Carrier Mobility in Hexagonal Diamond",
    "authors": "Zirui He, Shang-Peng Gao, Meng Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15076v1",
    "source": "arXiv",
    "abstract": "Hexagonal diamond (h-diamond), or Lonsdaleite, has been reported to be a wide-bandgap semiconductor with high thermal conductivity and hardness. Our $ab initio$ calculations show that h-diamond has exceptionally high carrier mobility. Along $xy$ and $z$ directions, the hole mobilities at 300 K are 5631 and 5552 cm$^2$V$^{-1}$s$^{-1}$, and the room-temperature electron mobilities are 11462 and 28464 cm$^2$V$^{-1}$s$^{-1}$, respectively. These values are superior to the mobility of most known semiconductors including cubic diamond (c-diamond). The small effective masses in h-diamond, comparable to those in c-diamond, cannot explain the mobility difference between the two phases. For holes, scattering induced by transverse acoustic phonons is the predominant mechanism near room temperature in c-diamond, whereas considerably suppressed in d-diamond by selection rules. The high electron mobility in h-diamond can be attributed to the wavefunction at the conduction band minimum, which is extended and distributed primarily in the lattice interstitial, leading to weak coupling with scattering potentials. The temperature dependence of h-diamond is investigated as well, which deviates from the power-law relationship due to the significantly increased occupation of optical modes at elevated temperatures. Consequently, our findings reveal h-diamond as a promising high-mobility semiconductor, and elucidate the microscopic origin in terms of the carrier-phonon scattering mechanisms beyond conventional understandings based on simple parameters such as effective mass."
  },
  {
    "date": "2026-01-21",
    "title": "Economic Warehouse Lot Scheduling: Breaking the 2-Approximation Barrier",
    "authors": "Danny Segev",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15068v1",
    "source": "arXiv",
    "abstract": "The economic warehouse lot scheduling problem is a foundational inventory-theory model, capturing computational challenges in dynamically coordinating replenishment decisions for multiple commodities subject to a shared capacity constraint. Even though this model has generated a vast body of literature over the last six decades, our algorithmic understanding has remained surprisingly limited. Indeed, for general problem instances, the best-known approximation guarantees have remained at a factor of $2$ since the mid-1990s. These guarantees were attained by the now-classic work of Anily [Operations Research, 1991] and Gallego, Queyranne, and Simchi-Levi [Operations Research, 1996] via the highly-structured class of \"stationary order sizes and stationary intervals\" (SOSI) policies, thereby avoiding direct competition against fully dynamic policies. The main contribution of this paper resides in developing new analytical foundations and algorithmic techniques that enable such direct comparisons, leading to the first provable improvement over the $2$-approximation barrier. Leveraging these ideas, we design a constructive approach that allows us to balance cost and capacity at a finer granularity than previously possible via SOSI-based methods. Consequently, given any economic warehouse lot scheduling instance, we present a polynomial-time construction of a random capacity-feasible dynamic policy whose expected long-run average cost is within factor $2-\\frac{17}{5000} + ε$ of optimal."
  },
  {
    "date": "2026-01-21",
    "title": "A Novel Cross-Domain Channel Estimation Scheme for OFDM",
    "authors": "Mingcheng Nie, Ruoxi Chong, Shuangyang Li, Weijie Yuan, Derrick Wing Kwan Ng, Michail Matthaiou, Giuseppe Caire, Yonghui Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15067v1",
    "source": "arXiv",
    "abstract": "In this paper, we propose a novel cross-domain channel estimation (CDCE) algorithm for orthogonal frequency division multiplexing (OFDM) systems, leveraging the unique characteristics of the delay-Doppler (DD) domain channel. Specifically, the proposed algorithm transforms the time-frequency (TF) domain pilot sequence of OFDM into the DD domain and applies a two-dimensional (2D) twisted-convolution for acquiring a coarse estimation of the underlying channel delay and Doppler. Then, the OFDM channel estimation is formulated as a sparse signal recovery problem in the TF domain according to the dictionary derived based on the obtained delay and Doppler estimates. Furthermore, a low-complexity $\\ell_1$-regularized least-square estimator is proposed to effectively solve this problem. Moreover, we further develop a performance analysis framework of the proposed scheme based on the ambiguity function (AF) of the adopted pilot sequence. Our numerical results demonstrate noticeable estimation performance improvement compared to conventional OFDM channel estimation methods, particularly in the presence of high channel mobility."
  },
  {
    "date": "2026-01-21",
    "title": "Differential Privacy Image Generation with Reconstruction Loss and Noise Injection Using an Error Feedback SGD",
    "authors": "Qiwei Ma, Jun Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15061v1",
    "source": "arXiv",
    "abstract": "Traditional data masking techniques such as anonymization cannot achieve the expected privacy protection while ensuring data utility for privacy-preserving machine learning. Synthetic data plays an increasingly important role as it generates a large number of training samples and prevents information leakage in real data. The existing methods suffer from the repeating trade-off processes between privacy and utility. We propose a novel framework for differential privacy generation, which employs an Error Feedback Stochastic Gradient Descent(EFSGD) method and introduces a reconstruction loss and noise injection mechanism into the training process. We generate images with higher quality and usability under the same privacy budget as the related work. Extensive experiments demonstrate the effectiveness and generalization of our proposed framework for both grayscale and RGB images. We achieve state-of-the-art results over almost all metrics on three benchmarks: MNIST, Fashion-MNIST, and CelebA."
  },
  {
    "date": "2026-01-21",
    "title": "Rigidity of the Suris' potential in the Frenkel-Kontorova Model",
    "authors": "Corentin Fierobe, Daniel Tsodikovich",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15058v1",
    "source": "arXiv",
    "abstract": "The goal of this paper is to establish a local rigidity result for the integrability of standard-like maps. The main focus of the paper is the remarkable integrable potential discovered by Suris in the 80's. We show that locally, the integrability of this potential is rigid. The proof relies on a similar strategy that was used for billiards in an ellipse, and involves developing the action-angle coordinates for this system, and exploiting it to construct a Riesz basis for $L^2$. As a corollary, we obtain a spectral rigidity result for this setting. Finally, we study the integrability question in the setting of potentials that are periodic."
  },
  {
    "date": "2026-01-21",
    "title": "Systematic Evaluation of Hip Exoskeleton Assistance Parameters for Enhancing Gait Stability During Ground Slip Perturbations",
    "authors": "Maria T. Tagliaferri, Inseung Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15056v1",
    "source": "arXiv",
    "abstract": "Falls are the leading cause of injury related hospitalization and mortality among older adults. Consequently, mitigating age-related declines in gait stability and reducing fall risk during walking is a critical goal for assistive devices. Lower-limb exoskeletons have the potential to support users in maintaining stability during walking. However, most exoskeleton controllers are optimized to reduce the energetic cost of walking rather than to improve stability. While some studies report stability benefits with assistance, the effects of specific parameters, such as assistance magnitude and duration, remain unexplored. To address this gap, we systematically modulated the magnitude and duration of torque provided by a bilateral hip exoskeleton during slip perturbations in eight healthy adults, quantifying stability using whole-body angular momentum (WBAM). WBAM responses were governed by a significant interaction between assistance magnitude and duration, with duration determining whether exoskeleton assistance was stabilizing or destabilizing relative to not wearing the exoskeleton device. Compared to an existing energy-optimized controller, experimentally identified stability-optimal parameters reduced WBAM range by 25.7% on average. Notably, substantial inter-subject variability was observed in the parameter combinations that minimized WBAM during perturbations. We found that optimizing exoskeleton assistance for energetic outcomes alone is insufficient for improving reactive stability during gait perturbations. Stability-focused exoskeleton control should prioritize temporal assistance parameters and include user-specific personalization. This study represents an important step toward personalized, stability-focused exoskeleton control, with direct implications for improving stability and reducing fall risk in older adults."
  },
  {
    "date": "2026-01-21",
    "title": "Factorizable joint shift revisited",
    "authors": "Dirk Tasche",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15036v1",
    "source": "arXiv",
    "abstract": "Factorizable joint shift (FJS) was proposed as a type of distribution shift (or dataset shift) that comprises both covariate and label shift. Recently, it has been observed that FJS actually arises from consecutive label and covariate (or vice versa) shifts. Research into FJS so far has been confined to the case of categorical label spaces. We propose a framework for analysing distribution shift in the case of general label spaces, thus covering both classification and regression models. Based on the framework, we generalise existing results on FJS to general label spaces and propose a related extension of the expectation maximisation (EM) algorithm for class prior probabilities. We also take a fresh look at generalized label shift (GLS) in the case of general label spaces."
  },
  {
    "date": "2026-01-21",
    "title": "Generic real Jordan canonical forms",
    "authors": "Fernando De Terán, Froilán M. Dopico",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15033v1",
    "source": "arXiv",
    "abstract": "We obtain the generic real Jordan canonical forms for $n\\times n$ matrices with real entries. More precisely, we prove that the set of $n\\times n$ real matrices is the union of the closures of $\\lfloor n/2\\rfloor+1$ sets, which are called generic bundles, as they are particular \"bundles\". In general, a bundle is the set of $n\\times n$ real matrices with the same real Jordan canonical form, up to the values of the eigenvalues, provided that the eigenvalues which are distinct in one matrix of the bundle remain distinct in any other matrix of the same bundle. The $k$th generic bundle, for $0\\leq k\\leq\\lfloor n/2\\rfloor$, contains the $n\\times n$ real matrices having $k$ different pairs of non-real conjugate eigenvalues and $n-2k$ different real eigenvalues. We prove that each of the $\\lfloor n/2\\rfloor+1$ generic bundles is an open subset of the set of $n\\times n$ real matrices. Some numerical experiments are carried out with large sets of random matrices of different sizes to confirm that all the generic bundles show up, and only these ones."
  },
  {
    "date": "2026-01-21",
    "title": "Three-dimensional GRMHD simulations of jet formation and propagation in self-gravitating collapsing stars",
    "authors": "Piotr Płonka, Agnieszka Janiuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15030v1",
    "source": "arXiv",
    "abstract": "We investigate collapsar models with and without self-gravity under identical initial conditions to directly compare the effects of self-gravity on jet properties, such as opening angle, jet power, terminal Lorentz factor, and its variability. We compute a suite of time-dependent, three-dimensional GRMHD simulations of collapsars in evolving spacetime. We update the Kerr metric components due to the growth of the black hole mass and changes its angular momentum. The self-gravity is considered via perturbative terms. We present for the first time the process of jet formation in self-gravitating collapsars. We find that self-gravity leads to temporary jet quenching, which can explain some features in the gamma-ray burst prompt emission. We find no substantial difference in jet launching times between models with and without self-gravity. We observe that in the absence of self-gravity, the jet can extract more rotational energy from the black hole, while self-gravitating models produce narrower jet opening angles. We show that under certain conditions, self-gravity can interrupt the jet formation process, resulting in a failed burst. Our computations show that self-gravity significantly modifies the process of jet propagation, resulting in notably different jet properties. We show that the timescales, variability, and opening angle of jet depend on whether self-gravity is included or not. We argue that self-gravity can potentially explain certain prompt emission properties due to the jet quenching."
  },
  {
    "date": "2026-01-21",
    "title": "Tracing the Galactic Disk with Gaia DR3: A Deep Study of Berkeley 17, 18, and 39 Open Star Clusters",
    "authors": "A. Ahmed, W. H. Elsanhoury, D. C. Çınar, S. Taşdemir, R. Canbay, A. A. Haroon, M. S. Alenazi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15289v1",
    "source": "arXiv",
    "abstract": "We report a detailed investigation of three intermediate-to-old age open clusters, Berkeley 17, Berkeley 18, and Berkeley 39, utilizing precise astrometric and photometric data from Gaia DR3. Cluster membership was robustly determined through a probabilistic proper-motion analysis, yielding statistically significant samples of 600, 1042, and 907 stars, respectively. From the mean parallaxes of these members, we determine astrometric distances ranging from approximately 3.40 kpc for Berkeley 17 to 5.80 kpc for Berkeley 18. Isochrone fitting applied to the decontaminated color-magnitude diagrams constrains the cluster ages to 9.12 +/- 1.00 Gyr, 3.36 +/- 0.50 Gyr, and 5.10 +/- 0.50 Gyr, respectively. Interstellar reddening spans a wide range, from E(B-V) = 0.17 mag in Berkeley 39 to 0.58 mag in Berkeley 17. Structural parameters derived from King model fits to the radial density profiles, combined with mass function analyses, indicate that the clusters are dynamically relaxed systems with mass distributions broadly consistent with the canonical Salpeter slope. Our kinematic analysis reveals that Berkeley 17, Berkeley 18, and Berkeley 39 are part of the outer disk population."
  },
  {
    "date": "2026-01-21",
    "title": "StableWorld: Towards Stable and Consistent Long Interactive Video Generation",
    "authors": "Ying Yang, Zhengyao Lv, Tianlin Pan, Haofan Wang, Binxin Yang, Hubery Yin, Chen Li, Ziwei Liu, Chenyang Si",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15281v1",
    "source": "arXiv",
    "abstract": "In this paper, we explore the overlooked challenge of stability and temporal consistency in interactive video generation, which synthesizes dynamic and controllable video worlds through interactive behaviors such as camera movements and text prompts. Despite remarkable progress in world modeling, current methods still suffer from severe instability and temporal degradation, often leading to spatial drift and scene collapse during long-horizon interactions. To better understand this issue, we initially investigate the underlying causes of instability and identify that the major source of error accumulation originates from the same scene, where generated frames gradually deviate from the initial clean state and propagate errors to subsequent frames. Building upon this observation, we propose a simple yet effective method, \\textbf{StableWorld}, a Dynamic Frame Eviction Mechanism. By continuously filtering out degraded frames while retaining geometrically consistent ones, StableWorld effectively prevents cumulative drift at its source, leading to more stable and temporal consistency of interactive generation. Promising results on multiple interactive video models, \\eg, Matrix-Game, Open-Oasis, and Hunyuan-GameCraft, demonstrate that StableWorld is model-agnostic and can be applied to different interactive video generation frameworks to substantially improve stability, temporal consistency, and generalization across diverse interactive scenarios."
  },
  {
    "date": "2026-01-21",
    "title": "Facilitating Proactive and Reactive Guidance for Decision Making on the Web: A Design Probe with WebSeek",
    "authors": "Yanwei Huang, Arpit Narechania",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15100v1",
    "source": "arXiv",
    "abstract": "Web AI agents such as ChatGPT Agent and GenSpark are increasingly used for routine web-based tasks, yet they still rely on text-based input prompts, lack proactive detection of user intent, and offer no support for interactive data analysis and decision making. We present WebSeek, a mixed-initiative browser extension that enables users to discover and extract information from webpages to then flexibly build, transform, and refine tangible data artifacts-such as tables, lists, and visualizations-all within an interactive canvas. Within this environment, users can perform analysis-including data transformations such as joining tables or creating visualizations-while an in-built AI both proactively offers context-aware guidance and automation, and reactively responds to explicit user requests. An exploratory user study (N=15) with WebSeek as a probe reveals participants' diverse analysis strategies, underscoring their desire for transparency and control during human-AI collaboration."
  },
  {
    "date": "2026-01-21",
    "title": "Large orbits of nilpotent subgroups of linear groups",
    "authors": "Yuchen Xu, Yong Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14618v1",
    "source": "arXiv",
    "abstract": "Suppose that $G$ is a finite solvable group and $V$ is a finite, faithful and completely reducible $G$-module. Let $N$ be a nilpotent subgroup of $G$, then there exits $v \\in V$ such that $|\\bC_N(v)| \\leq (|N|/p)^{1/p}$, where $p$ is the smallest prime divisor of $|N|$."
  },
  {
    "date": "2026-01-21",
    "title": "Shear and bulk viscosities of gluon plasma across the transition temperature from lattice QCD",
    "authors": "Heng-Tong Ding, Hai-Tao Shu, Cheng Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14967v1",
    "source": "arXiv",
    "abstract": "We investigate the temperature dependence of the shear viscosity ($η$) and bulk viscosity ($ζ$) of the gluon plasma using lattice QCD over the range 0.76--2.25 $T_c$, extending from below the transition temperature $T_c$ across the transition region and into the deconfined phase. At each temperature, we employ three large, fine lattices, which enables controlled continuum extrapolations of the energy-momentum tensor correlators. Using gradient flow together with a recently developed blocking technique, we achieve percent level precision for these correlators, providing strong constraints for a model-based spectral analysis. Since the inversion to real-time information is intrinsically ill posed, we extract viscosities by fitting spectral functions whose ultraviolet behavior is matched to the best available perturbative result, while the infrared region is described by a Lorentzian transport peak. The dominant modeling uncertainty associated with the transport-peak width is bracketed by varying it over a physically motivated range set by thermal scales. We find that the shear-viscosity-to-entropy-density ratio, $η/s$, exhibits a minimum near the transition temperature $T_c$ and increases for $T>T_c$, whereas the bulk-viscosity-to-entropy-density ratio, $ζ/s$, decreases monotonically over the entire temperature range studied."
  },
  {
    "date": "2026-01-21",
    "title": "Urysohn width and macroscopic scalar curvature",
    "authors": "Aditya Kumar, Balarka Sen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14669v1",
    "source": "arXiv",
    "abstract": "We show that the macroscopic version of Gromov's Urysohn width conjecture for scalar curvature is false in dimensions four and above. This is based on (1) a novel estimate on the codimension two Urysohn width of circle bundles over manifolds with large hypersphericity radius, and (2) a notion of ruling for Riemannian manifolds that yields circle bundles with total spaces admitting metrics of positive macroscopic scalar curvature. Along the way, we also show that Urysohn width is not continuous under Cheeger-Gromov collapsing limits. This article is a continuation of our study of metric invariants and scalar curvature for circle bundles over large Riemannian manifolds initiated in [KS25]."
  },
  {
    "date": "2026-01-21",
    "title": "MIND: Empowering Mental Health Clinicians with Multimodal Data Insights through a Narrative Dashboard",
    "authors": "Ruishi Zou, Shiyu Xu, Margaret E Morris, Jihan Ryu, Timothy D. Becker, Nicholas Allen, Anne Marie Albano, Randy Auerbach, Dan Adler, Varun Mishra, Lace Padilla, Dakuo Wang, Ryan Sultan, Xuhai \"Orson\" Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14641v1",
    "source": "arXiv",
    "abstract": "Advances in data collection enable the capture of rich patient-generated data: from passive sensing (e.g., wearables and smartphones) to active self-reports (e.g., cross-sectional surveys and ecological momentary assessments). Although prior research has demonstrated the utility of patient-generated data in mental healthcare, significant challenges remain in effectively presenting these data streams along with clinical data (e.g., clinical notes) for clinical decision-making. Through co-design sessions with five clinicians, we propose MIND, a large language model-powered dashboard designed to present clinically relevant multimodal data insights for mental healthcare. MIND presents multimodal insights through narrative text, complemented by charts communicating underlying data. Our user study (N=16) demonstrates that clinicians perceive MIND as a significant improvement over baseline methods, reporting improved performance to reveal hidden and clinically relevant data insights (p<.001) and support their decision-making (p=.004). Grounded in the study results, we discuss future research opportunities to integrate data narratives in broader clinical practices."
  },
  {
    "date": "2026-01-21",
    "title": "The Pictorial Cortex: Zero-Shot Cross-Subject fMRI-to-Image Reconstruction via Compositional Latent Modeling",
    "authors": "Jingyang Huo, Yikai Wang, Yanwei Fu, Jianfeng Feng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15071v1",
    "source": "arXiv",
    "abstract": "Decoding visual experiences from human brain activity remains a central challenge at the intersection of neuroscience, neuroimaging, and artificial intelligence. A critical obstacle is the inherent variability of cortical responses: neural activity elicited by the same visual stimulus differs across individuals and trials due to anatomical, functional, cognitive, and experimental factors, making fMRI-to-image reconstruction non-injective. In this paper, we tackle a challenging yet practically meaningful problem: zero-shot cross-subject fMRI-to-image reconstruction, where the visual experience of a previously unseen individual must be reconstructed without subject-specific training. To enable principled evaluation, we present a unified cortical-surface dataset -- UniCortex-fMRI, assembled from multiple visual-stimulus fMRI datasets to provide broad coverage of subjects and stimuli. Our UniCortex-fMRI is particularly processed by standardized data formats to make it possible to explore this possibility in the zero-shot scenario of cross-subject fMRI-to-image reconstruction. To tackle the modeling challenge, we propose PictorialCortex, which models fMRI activity using a compositional latent formulation that structures stimulus-driven representations under subject-, dataset-, and trial-related variability. PictorialCortex operates in a universal cortical latent space and implements this formulation through a latent factorization-composition module, reinforced by paired factorization and re-factorizing consistency regularization. During inference, surrogate latents synthesized under multiple seen-subject conditions are aggregated to guide diffusion-based image synthesis for unseen subjects. Extensive experiments show that PictorialCortex improves zero-shot cross-subject visual reconstruction, highlighting the benefits of compositional latent modeling and multi-dataset training."
  },
  {
    "date": "2026-01-21",
    "title": "Numerical study of multiple solar flare induced modulation of Very Low Frequency (VLF) diurnal profile",
    "authors": "Sourav Palit, Subhajit Bhattacharyya, Taraknath Bera, Sandip K. Chakrabarti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14948v1",
    "source": "arXiv",
    "abstract": "Earth's ionosphere is a perpetual detector of ionizing radiation received from celestial objects, particularly the Sun. Solar ionizing radiation in the form of extreme ultraviolet (EUV) and X-rays during both quiet and active phase of the Sun, and charged particles associated with a solar wind imprint their ionization signatures on the ionosphere. Although due to the bipolar nature of the geomagnetic field, the events, such as the solar coronal mass ejections (CMEs) and associated solar wind enhancement, usually disturb the polar ionosphere only, the UV and X-rays from the solar flares produce sudden ionospheric disturbances (SIDs) in low-mid-latitude part of the earth's ionosphere. Such ionospheric disturbances are studied with the help of the influence they exert on radio waves propagating through earth-ionosphere waveguide. For the lower part of the ionosphere, called the D region, prominent modification in electron-ion density during solar flares can be observed via deviation in earth bound Very Low Frequency (VLF) wave signal from its ambient diurnal profile. In earlier work, successful model of the deviation in VLF amplitude due to different classes of solar flares was formulated. There, calculation of rate of ionization with Monte Carlo simulation and ion-chemistry evaluation of plasma density enhancement followed by a radio propagation simulation was used. Presently, we attempt to numerically reconstruct the modulation in VLF signal from its diurnal pattern produced by multiple solar flares occurring over a single day. Successful reconstruction of the VLF signal modulation for such a complex flaring scenario points to the accuracy of our understanding of the ionization effect due to solar activity on the lower ionosphere, and strengthen our claim to use earth's ionosphere as a high energy space transient event detector."
  },
  {
    "date": "2026-01-21",
    "title": "Role of Defects in the Paramagnetism of Fe-doped Cs$_{2}$AgBiBr$_{6}$ Double Perovskite",
    "authors": "Volodymyr Vasylkovskyi, Olga Trukhina, Patrick Dörflinger, Mykola Slipchenko, Wolf Gero Schmidt, Timur Biktagirov, Anastasiia Kultaeva, Yakov Kopelevich, Vladimir Dyakonov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14885v1",
    "source": "arXiv",
    "abstract": "Transition-metal doping enables the introduction of spin functionality into halide double perovskites, while simultaneously modifying optical properties. Here, we combine controlled single-crystal growth, optical characterization, comprehensive electron paramagnetic resonance (EPR) spectroscopy, and first-principles modeling to identify the microscopic nature of Fe-related centers in Fe-doped Cs$_{2}$AgBiBr$_{6}$. Single crystals with nominal Fe$^{3+}$ concentrations up to 15% in the precursor stage were grown using a controlled-cooling method, yielding reproducible Fe incorporation up to 0.1% w.r.t. Bi, without secondary phases. Despite this low concentration, Fe doping introduces electronic states that influence optical absorption and photoluminescence. EPR measurements reveal an S = 5/2 Fe$^{3+}$-related center whose anisotropy follows the cubic-to-tetragonal phase transition below 120 K. Angular-dependent EPR resolves two configurations of this nearly axial spin center, with principal axes rotated by 90$^\\circ$ and aligned with the $a/b$ plane of the tetragonal lattice. Density-functional calculations attribute these centers to impurity-vacancy complexes, most likely Fe$_{\\rm Bi}$-V$_{\\rm Br}$, that stabilise in a basal configuration of the low-temperature phase. This approach resolves vacancy-coupled defect orientations, narrowing possible models to Fe$^{3+}$-vacancy complexes and establishing them as stable, orientation-sensitive spin probes of structural symmetry in halide double perovskites, while providing a microscopic basis for tuning their magnetic and optical responses."
  },
  {
    "date": "2026-01-21",
    "title": "Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips",
    "authors": "Naoya Onizawa, Daisaku Katagiri, Warren J. Gross, Takahiro Hanyu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14640v1",
    "source": "arXiv",
    "abstract": "This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) device for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check (LDPC) decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To realize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area-efficiently converted to stochastic signals to mitigate the signal-conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the signal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90nm CMOS and 100nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices."
  },
  {
    "date": "2026-01-21",
    "title": "WebAssembly Based Portable and Secure Sensor Interface for Internet of Things",
    "authors": "Botong Ou, Baijian Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14555v1",
    "source": "arXiv",
    "abstract": "As the expansion of IoT connectivity continues to provide quality-of-life improvements around the world, they simultaneously introduce increasing privacy and security concerns. The lack of a clear definition in managing shared and protected access to IoT sensors offer channels by which devices can be compromised and sensitive data can be leaked. In recent years, WebAssembly has received considerable attention for its efficient application sandboxing suitable for embedded systems, making it a prime candidate for exploring a secure and portable sensor interface. This paper introduces the first WebAssembly System Interface (WASI) extension offering a secure, portable, and low-footprint sandbox enabling multi-tenant access to sensor data across heterogeneous embedded devices. The runtime extensions provide application memory isolation, ensure appropriate resource privileges by intercepting sensor access, and offer an MQTT-SN interface enabling in-network access control. When targeting the WebAssembly byte-code with the associated runtime extensions implemented atop the Zephyr RTOS, our evaluation of sensor access indicates a latency overhead of 6% with an additional memory footprint of 5% when compared to native execution. As MQTT-SN requests are dominated by network delays, the WASI-SN implementation of MQTT-SN introduces less than 1% additional latency with similar memory footprint."
  },
  {
    "date": "2026-01-21",
    "title": "Acoustic phonons in a magnetized vacuum? First-principle lattice results on the mass spectrum of the electroweak model in a strong magnetic field",
    "authors": "M. N. Chernodub, V. A. Goy, A. V. Molochkov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14573v1",
    "source": "arXiv",
    "abstract": "We use numerical Monte Carlo simulations to determine the mass spectrum of the bosonic sector of the electroweak model in an external magnetic field of the electroweak-scale strength ($10^{20}\\,{\\rm T}$) at zero temperature. It is known that as the magnetic field gets stronger, the electroweak vacuum undergoes two consecutive crossover-type transitions, passing from (i) the conventional symmetry-broken homogeneous phase to (ii) an intermediate inhomogeneous vortex phase characterized by a (superconducting) condensate of electrically charged $W$ bosons and then to (iii) a homogeneous phase with a restored electroweak symmetry. We show that the spin component of the $W$ boson aligned with the direction of the magnetic field is the lightest excitation in all three phases. Its mass continuously decreases in the low-field broken phase and becomes very small in the intermediate phase. We argue that this nearly massless excitation corresponds to a Goldstone acoustic phonon mode associated with vibrations of the lattice of electroweak vortices. In the high-field symmetry-restored phase, where the vortices disappear, the lightest $W$ mass rises again. Neither Higgs nor $Z$ boson masses vanish across all studied phases and crossover transitions."
  },
  {
    "date": "2026-01-21",
    "title": "Probing Heavily Obscured AGN in Major Galaxy Mergers Using the mm-X-ray Correlation",
    "authors": "M. Droguett-Callejas, E. Treister, L. Barcos-Muñoz, M. Johnstone, F. E. Bauer, T. Kawamuro, N. Torres-Albà, C. Ricci, M. Koss, Y. Song, A. Pecca, A. Evans, J. González",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15186v1",
    "source": "arXiv",
    "abstract": "The study of heavily obscured supermassive black hole (SMBH) growth in late-stage galaxy mergers is challenging: column densities $N_{\\mathrm{H}}>10^{24},\\mathrm{cm}^{-2}$ can block most nuclear emission, leaving significant gaps in the SMBH growth census. Millimeter-wave continuum emission offers a potential window into this obscured phase, as it can trace Active Galactic Nuclei (AGN) activity through mechanisms less affected by dust extinction. In this work, we test whether the observed correlation between millimeter ($\\sim200,\\mathrm{GHz}$) and hard X-ray (14 - 150,keV) luminosities can be used to plausibly identify hidden AGN in local (Ultra)Luminous Infrared Galaxies (U)LIRGs, including systems hosting confirmed dual AGN. We identify three sources -- one confirmed AGN and two strong candidates -- presenting significant evidence of AGN activity. The confirmed dual AGN lie within $\\sim3σ$ of the mm--X-ray correlation, suggesting this relation can be used to identify hidden pairs. By combining the position of each source relative to this correlation with independent star formation rate constraints, we propose a method to disentangle AGN and star formation contributions for sources with measured column densities. While our analysis is based on a small, heterogeneous local sample and relies on empirical scaling relations, these results indicate that millimeter continuum emission may provide a useful complementary diagnostic for obscured SMBH growth. ALMA observations at high angular resolutions are particularly valuable for this approach, while future facilities such as the ngVLA will be essential to test its robustness in larger and more distant samples."
  },
  {
    "date": "2026-01-21",
    "title": "Exploring Performance-Productivity Trade-offs in AMT Runtimes: A Task Bench Study of Itoyori, ItoyoriFBC, HPX, and MPI",
    "authors": "Torben R. Lahnor, Mia Reitz, Jonas Posner, Patrick Diehl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14608v1",
    "source": "arXiv",
    "abstract": "Asynchronous Many-Task (AMT) runtimes offer a productive alternative to the Message Passing Interface (MPI). However, the diverse AMT landscape makes fair comparisons challenging. Task Bench, proposed by Slaughter et al., addresses this challenge through a parameterized framework for evaluating parallel programming systems. This work integrates two recent cluster AMTs, Itoyori and ItoyoriFBC, into Task Bench for comprehensive evaluation against MPI and HPX. Itoyori employs a Partitioned Global Address Space (PGAS) model with RDMA-based work stealing, while ItoyoriFBC extends it with futurebased synchronization. We evaluate these systems in terms of both performance and programmer productivity. Performance is assessed across various configurations, including compute-bound kernels, weak scaling, and both imbalanced and communication-intensive patterns. Performance is quantified using application efficiency, i.e., the percentage of maximum performance achieved, and the Minimum Effective Task Granularity (METG), i.e., the smallest task duration before runtime overheads dominate. Programmer productivity is quantified using Lines of Code (LOC) and the Number of Library Constructs (NLC). Our results reveal distinct trade-offs. MPI achieves the highest efficiency for regular, communication-light workloads but requires verbose, lowlevel code. HPX maintains stable efficiency under load imbalance across varying node counts, yet ranks last in productivity metrics, demonstrating that AMTs do not inherently guarantee improved productivity over MPI. Itoyori achieves the highest efficiency in communication-intensive configurations while leading in programmer productivity. ItoyoriFBC exhibits slightly lower efficiency than Itoyori, though its future-based synchronization offers potential for expressing irregular workloads."
  },
  {
    "date": "2026-01-21",
    "title": "Emergent, not Immanent: A Baradian Reading of Explainable AI",
    "authors": "Fabio Morreale, Joan Serrà, Yuki Mistufuji",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15029v1",
    "source": "arXiv",
    "abstract": "Explainable AI (XAI) is frequently positioned as a technical problem of revealing the inner workings of an AI model. This position is affected by unexamined onto-epistemological assumptions: meaning is treated as immanent to the model, the explainer is positioned outside the system, and a causal structure is presumed recoverable through computational techniques. In this paper, we draw on Barad's agential realism to develop an alternative onto-epistemology of XAI. We propose that interpretations are material-discursive performances that emerge from situated entanglements of the AI model with humans, context, and the interpretative apparatus. To develop this position, we read a comprehensive set of XAI methods through agential realism and reveal the assumptions and limitations that underpin several of these methods. We then articulate the framework's ethical dimension and propose design directions for XAI interfaces that support emergent interpretation, using a speculative text-to-music interface as a case study."
  },
  {
    "date": "2026-01-21",
    "title": "Interval Scheduling Games",
    "authors": "Vipin Ravindran Vijayalakshmi, Marc Schroder, Tami Tamir",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15148v1",
    "source": "arXiv",
    "abstract": "We consider a game-theoretic variant of an interval scheduling problem. Every job is associated with a length, a weight, and a color. Each player controls all the jobs of a specific color, and needs to decide on a processing interval for each of its jobs. Jobs of the same color can be processed simultaneously by the machine. A job is covered if the machine is configured to its color during its whole processing interval. The goal of the machine is to maximize the sum of weights of all covered jobs, and the goal of each player is to place its jobs such that the sum of weights of covered jobs from its color is maximized. The study of this game is motivated by several applications like antenna scheduling for wireless networks. We first show that given a strategy profile of the players, the machine scheduling problem can be solved in polynomial time. We then study the game from the players' point of view. We analyze the existence of Nash equilibria, its computation, and inefficiency. We distinguish between instances of the classical interval scheduling problem, in which every player controls a single job, and instances in which color sets may include multiple jobs."
  },
  {
    "date": "2026-01-21",
    "title": "Learning and extrapolating scale-invariant processes",
    "authors": "Anaclara Alvez-Canepa, Cyril Furtlehner, François Landes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14810v1",
    "source": "arXiv",
    "abstract": "Machine Learning (ML) has deeply changed some fields recently, like Language and Vision and we may expect it to be relevant also to the analysis of of complex systems. Here we want to tackle the question of how and to which extent can one regress scale-free processes, i.e. processes displaying power law behavior, like earthquakes or avalanches? We are interested in predicting the large ones, i.e. rare events in the training set which therefore require extrapolation capabilities of the model. For this we consider two paradigmatic problems that are statistically self-similar. The first one is a 2-dimensional fractional Gaussian field obeying linear dynamics, self-similar by construction and amenable to exact analysis. The second one is the Abelian sandpile model, exhibiting self-organized criticality. The emerging paradigm of Geometric Deep Learning shows that including known symmetries into the model's architecture is key to success. Here one may hope to extrapolate only by leveraging scale invariance. This is however a peculiar symmetry, as it involves possibly non-trivial coarse-graining operations and anomalous scaling. We perform experiments on various existing architectures like U-net, Riesz network (scale invariant by construction), or our own proposals: a wavelet-decomposition based Graph Neural Network (with discrete scale symmetry), a Fourier embedding layer and a Fourier-Mellin Neural Operator. Based on these experiments and a complete characterization of the linear case, we identify the main issues relative to spectral biases and coarse-grained representations, and discuss how to alleviate them with the relevant inductive biases."
  },
  {
    "date": "2026-01-21",
    "title": "M2I2HA: A Multi-modal Object Detection Method Based on Intra- and Inter-Modal Hypergraph Attention",
    "authors": "Xiaofan Yang, Yubin Liu, Wei Pan, Guoqing Chu, Junming Zhang, Jie Zhao, Zhuoqi Man, Xuanming Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14776v1",
    "source": "arXiv",
    "abstract": "Recent advances in multi-modal detection have significantly improved detection accuracy in challenging environments (e.g., low light, overexposure). By integrating RGB with modalities such as thermal and depth, multi-modal fusion increases data redundancy and system robustness. However, significant challenges remain in effectively extracting task-relevant information both within and across modalities, as well as in achieving precise cross-modal alignment. While CNNs excel at feature extraction, they are limited by constrained receptive fields, strong inductive biases, and difficulty in capturing long-range dependencies. Transformer-based models offer global context but suffer from quadratic computational complexity and are confined to pairwise correlation modeling. Mamba and other State Space Models (SSMs), on the other hand, are hindered by their sequential scanning mechanism, which flattens 2D spatial structures into 1D sequences, disrupting topological relationships and limiting the modeling of complex higher-order dependencies. To address these issues, we propose a multi-modal perception network based on hypergraph theory called M2I2HA. Our architecture includes an Intra-Hypergraph Enhancement module to capture global many-to-many high-order relationships within each modality, and an Inter-Hypergraph Fusion module to align, enhance, and fuse cross-modal features by bridging configuration and spatial gaps between data sources. We further introduce a M2-FullPAD module to enable adaptive multi-level fusion of multi-modal enhanced features within the network, meanwhile enhancing data distribution and flow across the architecture. Extensive object detection experiments on multiple public datasets against baselines demonstrate that M2I2HA achieves state-of-the-art performance in multi-modal object detection tasks."
  },
  {
    "date": "2026-01-21",
    "title": "Influence of Charge Density Waves on the Hall coefficient in NiTi",
    "authors": "Adrian Braun, Henrik Dick, Timon Sieweke, Alexander Kunzmann, Klara Lünser, Gabi Schierning, Thomas Dahm",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14772v1",
    "source": "arXiv",
    "abstract": "We present a mean-field charge density wave theory for NiTi using density functional theory bandstructure as a starting point. We calculate the Hall coefficient as a function of temperature and compare with recent experimental results. We analyze the contributions to the Hall coefficient from different parts of the Fermi surface and find that the Hall coefficient is dominated by certain ``hot spots''. The analysis shows that these hot spots are mostly dominated by Ni d-orbitals. We demonstrate that the Hall coefficient is not well reproduced by Boltzmann transport theory within the constant relaxation time approximation without charge density waves. We consider both uniaxial and biaxial charge density waves and show that biaxial charge density waves can account well for the Hall coefficient, while uniaxial cannot. We also investigate the temperature dependence of the resistivity and the specific heat."
  },
  {
    "date": "2026-01-21",
    "title": "Blended Dynamics and Emergence in Open Quantum Networks",
    "authors": "Qinghao Wen, Zihao Ren, Lei Wang, Hyungbo Shim, Guodong Shi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14763v1",
    "source": "arXiv",
    "abstract": "In this paper, we develop a blended dynamics framework for open quantum networks with diffusive couplings. The network consists of qubits interconnected through Hamiltonian couplings, environmental dissipation, and consensus-like diffusive interactions. Such networks commonly arise in spontaneous emission processes and non-Hermitian quantum computing, and their evolution follows a Lindblad master equation. Blended dynamics theory is well established in the classical setting as a tool for analyzing emergent behaviors in heterogeneous networks with diffusive couplings. Its key insight is to blend the local dynamics rather than the trajectories of individual nodes. Perturbation analysis then shows that, under sufficiently strong coupling, all node trajectories tend to stay close to those of the blended system over time. We first show that this theory extends naturally to the reduced-state dynamics of quantum networks, revealing classical-like clustering phenomena in which qubits converge to a shared equilibrium or a common trajectory determined by the quantum blended reduced-state dynamics. We then extend the analysis to qubit coherent states using quantum Laplacians and induced graphs, proving orbit attraction of the network density operator toward the quantum blended coherent dynamics, establishing the emergence of intrinsically quantum and dynamically clustering behaviors. Finally, numerical examples validate the theoretical results."
  },
  {
    "date": "2026-01-21",
    "title": "Langmuir and Langmuir-Blodgett films of a maleic anhydride derivative: effect of subphase divalent cations",
    "authors": "Beatriz Martín-García, M. Mercedes Velázquez, Jose Antonio Pérez-Hernández, Juan Hernández-Toro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14761v1",
    "source": "arXiv",
    "abstract": "We report the study of the equilibrium and dynamic properties of Langmuir monolayers of poly (styrene-co-maleic anhydride) partial 2-buthoxy ethyl ester cumene terminated polymer and the effect of the Mg(NO3)2 addition in the water subphase on the film properties. Results show that the polymer monolayer becomes more expanded when the electrolyte concentration in the subphase increases. Dense polymer films aggregate at the interface. The aggregates are transferred onto Silicon wafers using the Langmuir-Blodgett methodology and the morphology is observed by AFM. The structure of aggregates depends on the subphase composition of the Langmuir film transferred onto the silicon wafer."
  },
  {
    "date": "2026-01-21",
    "title": "Improved GPR-Based CSI Acquisition via Spatial-Correlation Kernel",
    "authors": "Syed Luqman Shah, Nurul Huda Mahmood, Italo Atzeni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14759v1",
    "source": "arXiv",
    "abstract": "Accurate channel estimation with low pilot overhead and computational complexity is key to efficiently utilizing multi-antenna wireless systems. Motivated by the evolution from purely statistical descriptions toward physics- and geometry-aware propagation models, this work focuses on incorporating channel information into a Gaussian process regression (GPR) framework for improving the channel estimation accuracy. In this work, we propose a GPR-based channel estimation framework along with a novel Spatial-correlation (SC) kernel that explicitly captures the channel's second-order statistics. We derive a closed-form expression of the proposed SC-based GPR estimator and prove that its posterior mean is optimal in terms of minimum mean-square error (MMSE) under the same second-order statistics, without requiring the underlying channel distribution to be Gaussian. Our analysis reveals that, with up to 50% pilot overhead reduction, the proposed method achieves the lowest normalized mean-square error, the highest empirical 95% credible-interval coverage, and superior preservation of spectral efficiency compared to benchmark estimators, while maintaining lower computational complexity than the conventional MMSE estimator."
  },
  {
    "date": "2026-01-21",
    "title": "Mechanism Shift During Post-training from Autoregressive to Masked Diffusion Language Models",
    "authors": "Injin Kong, Hyoungjoon Lee, Yohan Jo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14758v1",
    "source": "arXiv",
    "abstract": "Post-training pretrained Autoregressive models (ARMs) into Masked Diffusion models (MDMs) has emerged as a cost-effective strategy to overcome the limitations of sequential generation. However, the internal algorithmic transformations induced by this paradigm shift remain unexplored, leaving it unclear whether post-trained MDMs acquire genuine bidirectional reasoning capabilities or merely repackage autoregressive heuristics. In this work, we address this question by conducting a comparative circuit analysis of ARMs and their MDM counterparts. Our analysis reveals a systematic \"mechanism shift\" dependent on the structural nature of the task. Structurally, we observe a distinct divergence: while MDMs largely retain autoregressive circuitry for tasks dominated by local causal dependencies, they abandon initialized pathways for global planning tasks, exhibiting distinct rewiring characterized by increased early-layer processing. Semantically, we identify a transition from sharp, localized specialization in ARMs to distributed integration in MDMs. Through these findings, we conclude that diffusion post-training does not merely adapt model parameters but fundamentally reorganizes internal computation to support non-sequential global planning."
  },
  {
    "date": "2026-01-21",
    "title": "Hydrogen Activation via Dihydride Formation on a Rh1/Fe3O4(001) Single-Atom Catalyst",
    "authors": "Chunlei Wang, Panukorn Sombut, Lena Puntscher, Nail Barama, Maosheng Hao, Florian Kraushofer, Jiri Pavelec, Matthias Meier, Florian Libisch, Michael Schmid, Ulrike Diebold, Cesare Franchini, Gareth S. Parkinson",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14756v1",
    "source": "arXiv",
    "abstract": "Hydrogen activation is a key elementary step in catalytic hydrogenation. In heterogeneous catalysis, it usually proceeds through dissociative adsorption on metal nanoparticles followed by surface diffusion or spillover, whereas homogeneous catalysts activate H2 through dihydride or dihydrogen intermediates at a single metal center. Here, we show that isolated Rh adatoms supported on Fe3O4(001) activate hydrogen through formation of a stable dihydride species without atomic H spillover. Temperature-programmed desorption, X-ray photoelectron spectroscopy, and scanning tunneling microscopy collectively reveal strong (approximately 1 eV) hydrogen adsorption exclusively at isolated Rh1 sites, while isotope-exchange experiments further demonstrate that hydrogen remains localized. Density-functional theory based calculations indicate a barrierless conversion from molecular H2 to the dihydride, and random-phase approximation calculations further confirm the relative stability of the dihydride. Together, these results show that single-atom Rh sites cleave and bind H2 through a dihydride pathway analogous to homogeneous complexes, establishing a mechanistic bridge between homogeneous and heterogeneous catalysis."
  },
  {
    "date": "2026-01-21",
    "title": "Inverse-Hessian Regularization for Continual Learning in ASR",
    "authors": "Steven Vander Eeckt, Hugo Van hamme",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14751v1",
    "source": "arXiv",
    "abstract": "Catastrophic forgetting remains a major challenge for continual learning (CL) in automatic speech recognition (ASR), where models must adapt to new domains without losing performance on previously learned conditions. Several CL methods have been proposed for ASR, and, recently, weight averaging - where models are averaged in a merging step after fine-tuning - has proven effective as a simple memory-free strategy. However, it is heuristic in nature and ignores the underlying loss landscapes of the tasks, hindering adaptability. In this work, we propose Inverse Hessian Regularization (IHR), a memory-free approach for CL in ASR that incorporates curvature information into the merging step. After fine-tuning on a new task, the adaptation is adjusted through a Kronecker-factored inverse Hessian approximation of the previous task, ensuring that the model moves primarily in directions less harmful to past performance, while keeping the method lightweight. We evaluate IHR on two CL benchmarks and show that it significantly outperforms state-of-the-art baselines, reducing forgetting while improving adaptability. Ablation studies and analyses further confirm its effectiveness."
  },
  {
    "date": "2026-01-21",
    "title": "Trajectory-Driven Multi-Product Influence Maximization in Billboard Advertising",
    "authors": "Dildar Ali, Suman Banerjee, Rajibul Islam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14737v1",
    "source": "arXiv",
    "abstract": "Billboard Advertising has emerged as an effective out-of-home advertising technique, where the goal is to select a limited number of slots and play advertisement content there, with the hope that it will be observed by many people and, effectively, a significant number of them will be influenced towards the brand. Given a trajectory and a billboard database and a positive integer $k$, how can we select $k$ highly influential slots to maximize influence? In this paper, we study a variant of this problem where a commercial house wants to make a promotion of multiple products, and there is an influence demand for each product. We have studied two variants of the problem. In the first variant, our goal is to select $k$ slots such that the respective influence demand of each product is satisfied. In the other variant of the problem, we are given with $\\ell$ integers $k_1,k_2, \\ldots, k_{\\ell}$, the goal here is to search for $\\ell$ many set of slots $S_1, S_2, \\ldots, S_{\\ell}$ such that for all $i \\in [\\ell]$, $|S_{i}| \\leq k_i$ and for all $i \\neq j$, $S_i \\cap S_j=\\emptyset$ and the influence demand of each of the products gets satisfied. We model the first variant of the problem as a multi-submodular cover problem and the second variant as its generalization. To solve the common-slot variant, we formulate the problem as a multi-submodular cover problem and design a bi-criteria approximation algorithm based on the continuous greedy framework and randomized rounding. For the disjoint-slot variant, we proposed a sampling-based approximation approach along with an efficient primal-dual greedy algorithm that enforces disjointness naturally. Extensive experiments with real-world trajectory and billboard datasets highlight the effectiveness and efficiency of the proposed solution approaches."
  },
  {
    "date": "2026-01-21",
    "title": "Optimizing FaaS Platforms for MCP-enabled Agentic Workflows",
    "authors": "Varad Kulkarni, Vaibhav Jha, Nikhil Reddy, Yogesh Simmhan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14735v1",
    "source": "arXiv",
    "abstract": "Agentic workflows that use autonomous AI Agents powered by Large Language Models (LLMs) and Model Context Protocol (MCP) servers is rapidly rising. This introduces challenges in scalable cloud deployment and state management. Traditional hosting on Virtual Machines (VMs) is resource-intensive and lacks elasticity. Functions-as-a-Service (FaaS) platforms offer modularity, autoscaling and cost efficiency but are inherently stateless. In this paper, we present the FAME, a FaaS-based architecture for orchestrating MCP-enabled agentic workflows. FAME decomposes agentic patterns such as ReAct into composable agents: Planner, Actor and Evaluator, that are each a FaaS function built using LangGraph and are orchestrated as a FaaS workflow. This enables modular composition as AWS Step Functions and avoids function timeouts seen for monolithic agentic workflows. To address context persistence across user requests in a conversation, FAME automates agent memory persistence and injection using DynamoDB. It also optimizes MCP server deployment through AWS Lambda wrappers, caches tool outputs in S3 and proposes function fusion strategies. We evaluate FAME on two representative applications, on research paper summarization and log analytics, under diverse memory and caching configurations. Results show up to 13x latency reduction, 88% fewer input tokens and 66% in cost savings, along with improved workflow completion rates. This demonstrates the viability of serverless platforms for hosting complex, multi-agent AI workflows at scale."
  },
  {
    "date": "2026-01-21",
    "title": "AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio Question Answering",
    "authors": "Chun-Yi Kuan, Kai-Wei Chang, Hung-yi Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14728v1",
    "source": "arXiv",
    "abstract": "Although text-to-audio generation has made remarkable progress in realism and diversity, the development of evaluation metrics has not kept pace. Widely-adopted approaches, typically based on embedding similarity like CLAPScore, effectively measure general relevance but remain limited in fine-grained semantic alignment and compositional reasoning. To address this, we introduce AQAScore, a backbone-agnostic evaluation framework that leverages the reasoning capabilities of audio-aware large language models (ALLMs). AQAScore reformulates assessment as a probabilistic semantic verification task; rather than relying on open-ended text generation, it estimates alignment by computing the exact log-probability of a \"Yes\" answer to targeted semantic queries. We evaluate AQAScore across multiple benchmarks, including human-rated relevance, pairwise comparison, and compositional reasoning tasks. Experimental results show that AQAScore consistently achieves higher correlation with human judgments than similarity-based metrics and generative prompting baselines, showing its effectiveness in capturing subtle semantic inconsistencies and scaling with the capability of underlying ALLMs."
  },
  {
    "date": "2026-01-21",
    "title": "Light propagation in atomic stratified media: breakdown of the transfer-matrix method at high density",
    "authors": "Igor M. Sokolov, William Guerin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14715v1",
    "source": "arXiv",
    "abstract": "The transfer-matrix method is a standard approach to wave propagation in stratified media. With the advent of cold-atom-based quantum and photonic technologies, several experiments and many proposals consider light propagation in one-dimensional optical lattices, using the transfer matrices as the main tool for the simulation. Here, we study the validity of this method by comparing its results to the microscopic coupled-dipole model, which is exact in the linear-optics regime. We show that the transfer-matrix method works very well at low density, even for thin disordered slices, and breaks down at high density because the dipole-dipole interaction induces a collective response from the atoms such that the properties of one layer are influenced by the others. We determine the boundary values of atomic densities for which this method is still applicable for describing experiments. Our findings are relevant for experimental realizations using ultra-cold atoms."
  },
  {
    "date": "2026-01-21",
    "title": "When Text-as-Vision Meets Semantic IDs in Generative Recommendation: An Empirical Study",
    "authors": "Shutong Qiao, Wei Yuan, Tong Chen, Xiangyu Zhao, Quoc Viet Hung Nguyen, Hongzhi Yin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14697v1",
    "source": "arXiv",
    "abstract": "Semantic ID learning is a key interface in Generative Recommendation (GR) models, mapping items to discrete identifiers grounded in side information, most commonly via a pretrained text encoder. However, these text encoders are primarily optimized for well-formed natural language. In real-world recommendation data, item descriptions are often symbolic and attribute-centric, containing numerals, units, and abbreviations. These text encoders can break these signals into fragmented tokens, weakening semantic coherence and distorting relationships among attributes. Worse still, when moving to multimodal GR, relying on standard text encoders introduces an additional obstacle: text and image embeddings often exhibit mismatched geometric structures, making cross-modal fusion less effective and less stable. In this paper, we revisit representation design for Semantic ID learning by treating text as a visual signal. We conduct a systematic empirical study of OCR-based text representations, obtained by rendering item descriptions into images and encoding them with vision-based OCR models. Experiments across four datasets and two generative backbones show that OCR-text consistently matches or surpasses standard text embeddings for Semantic ID learning in both unimodal and multimodal settings. Furthermore, we find that OCR-based Semantic IDs remain robust under extreme spatial-resolution compression, indicating strong robustness and efficiency in practical deployments."
  },
  {
    "date": "2026-01-21",
    "title": "FeedbackSTS-Det: Sparse Frames-Based Spatio-Temporal Semantic Feedback Network for Infrared Small Target Detection",
    "authors": "Yian Huang, Qing Qin, Aji Mao, Xiangyu Qiu, Liang Xu, Xian Zhang, Zhenming Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14690v1",
    "source": "arXiv",
    "abstract": "Infrared small target detection (ISTD) under complex backgrounds remains a critical yet challenging task, primarily due to the extremely low signal-to-clutter ratio, persistent dynamic interference, and the lack of distinct target features. While multi-frame detection methods leverages temporal cues to improve upon single-frame approaches, existing methods still struggle with inefficient long-range dependency modeling and insufficient robustness. To overcome these issues, we propose a novel scheme for ISTD, realized through a sparse frames-based spatio-temporal semantic feedback network named FeedbackSTS-Det. The core of our approach is a novel spatio-temporal semantic feedback strategy with a closed-loop semantic association mechanism, which consists of paired forward and backward refinement modules that work cooperatively across the encoder and decoder. Moreover, both modules incorporate an embedded sparse semantic module (SSM), which performs structured sparse temporal modeling to capture long-range dependencies with low computational cost. This integrated design facilitates robust implicit inter-frame registration and continuous semantic refinement, effectively suppressing false alarms. Furthermore, our overall procedure maintains a consistent training-inference pipeline, which ensures reliable performance transfer and increases model robustness. Extensive experiments on multiple benchmark datasets confirm the effectiveness of FeedbackSTS-Det. Code and models are available at: https://github.com/IDIP-Lab/FeedbackSTS-Det."
  },
  {
    "date": "2026-01-21",
    "title": "Mirai: Autoregressive Visual Generation Needs Foresight",
    "authors": "Yonghao Yu, Lang Huang, Zerun Wang, Runyi Li, Toshihiko Yamasaki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14671v1",
    "source": "arXiv",
    "abstract": "Autoregressive (AR) visual generators model images as sequences of discrete tokens and are trained with next token likelihood. This strict causality supervision optimizes each step only by its immediate next token, which diminishes global coherence and slows convergence. We ask whether foresight, training signals that originate from later tokens, can help AR visual generation. We conduct a series of controlled diagnostics along the injection level, foresight layout, and foresight source axes, unveiling a key insight: aligning foresight to AR models' internal representation on the 2D image grids improves causality modeling. We formulate this insight with Mirai (meaning \"future\" in Japanese), a general framework that injects future information into AR training with no architecture change and no extra inference overhead: Mirai-E uses explicit foresight from multiple future positions of unidirectional representations, whereas Mirai-I leverages implicit foresight from matched bidirectional representations. Extensive experiments show that Mirai significantly accelerates convergence and improves generation quality. For instance, Mirai can speed up LlamaGen-B's convergence by up to 10$\\times$ and reduce the generation FID from 5.34 to 4.34 on the ImageNet class-condition image generation benchmark. Our study highlights that visual autoregressive models need foresight."
  },
  {
    "date": "2026-01-21",
    "title": "INFA-Guard: Mitigating Malicious Propagation via Infection-Aware Safeguarding in LLM-Based Multi-Agent Systems",
    "authors": "Yijin Zhou, Xiaoya Lu, Dongrui Liu, Junchi Yan, Jing Shao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14667v1",
    "source": "arXiv",
    "abstract": "The rapid advancement of Large Language Model (LLM)-based Multi-Agent Systems (MAS) has introduced significant security vulnerabilities, where malicious influence can propagate virally through inter-agent communication. Conventional safeguards often rely on a binary paradigm that strictly distinguishes between benign and attack agents, failing to account for infected agents i.e., benign entities converted by attack agents. In this paper, we propose Infection-Aware Guard, INFA-Guard, a novel defense framework that explicitly identifies and addresses infected agents as a distinct threat category. By leveraging infection-aware detection and topological constraints, INFA-Guard accurately localizes attack sources and infected ranges. During remediation, INFA-Guard replaces attackers and rehabilitates infected ones, avoiding malicious propagation while preserving topological integrity. Extensive experiments demonstrate that INFA-Guard achieves state-of-the-art performance, reducing the Attack Success Rate (ASR) by an average of 33%, while exhibiting cross-model robustness, superior topological generalization, and high cost-effectiveness."
  },
  {
    "date": "2026-01-21",
    "title": "Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets",
    "authors": "Yogesh Pipada Sunil Kumar, S. Ali Pourmousavi, Jon A. R. Liisberg, Julian Lesmos-Vinasco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14663v1",
    "source": "arXiv",
    "abstract": "Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty."
  },
  {
    "date": "2026-01-21",
    "title": "NeuroFilter: Privacy Guardrails for Conversational LLM Agents",
    "authors": "Saswat Das, Ferdinando Fioretto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14660v1",
    "source": "arXiv",
    "abstract": "This work addresses the computational challenge of enforcing privacy for agentic Large Language Models (LLMs), where privacy is governed by the contextual integrity framework. Indeed, existing defenses rely on LLM-mediated checking stages that add substantial latency and cost, and that can be undermined in multi-turn interactions through manipulation or benign-looking conversational scaffolding. Contrasting this background, this paper makes a key observation: internal representations associated with privacy-violating intent can be separated from benign requests using linear structure. Using this insight, the paper proposes NeuroFilter, a guardrail framework that operationalizes contextual integrity by mapping norm violations to simple directions in the model's activation space, enabling detection even when semantic filters are bypassed. The proposed filter is also extended to capture threats arising during long conversations using the concept of activation velocity, which measures cumulative drift in internal representations across turns. A comprehensive evaluation across over 150,000 interactions and covering models from 7B to 70B parameters, illustrates the strong performance of NeuroFilter in detecting privacy attacks while maintaining zero false positives on benign prompts, all while reducing the computational inference cost by several orders of magnitude when compared to LLM-based agentic privacy defenses."
  },
  {
    "date": "2026-01-21",
    "title": "Multiple standing waves of Helmholtz equation with mixed dispersion concentrating in the high frequency limit",
    "authors": "Shaoxiong Chen, Fei Yuan, Fukun Zhao, Jiazheng Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14657v1",
    "source": "arXiv",
    "abstract": "In this paper, we study the nonlinear Helmholtz equation with mixed dispersion \\begin{equation*} Δ^2 u-βk^2\\, Δu+αk^4 u=W(x)\\, |u|^{p-2}u~\\text{in}~\\mathbb{R}^N, \\end{equation*} where the weight function $W(x)$ is continuous, nonnegative, and satisfies \\[ \\limsup_{|x|\\to\\infty} W(x) \\;<\\; \\sup_{x\\in\\mathbb{R}^N} W(x). \\] Within each of the following parameter ranges, \\begin{center} (a) $α<0$, $β\\in\\mathbb{R}$; \\qquad (b) $α>0$, $β<-2\\sqrtα$; \\qquad (c) $α=0$, $β<0$, \\end{center} After a suitable rescaling, we obtain the existence of dual ground state solutions, which concentrate along the global maximizers of $W$ as $k\\to\\infty$. In addition, we establish the existence of multiple solutions associated with the set of global maximum points of $W$, and we further characterize the precise concentration behavior of these solutions."
  },
  {
    "date": "2026-01-21",
    "title": "Transient Pauli blocking in a InN film as a mechanism for broadband ultrafast optical switching",
    "authors": "Junjun Jia, Minseok Kim, Yuzo Shigesato, Ryotaro Nakazawa, Keisuke Fukutani, Satoshi Kera, Toshiki Makimoto, Takashi Yagi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14656v1",
    "source": "arXiv",
    "abstract": "The transient Pauli blocking effect offers a promising route for achieving ultrafast optical switching in semiconductors, enabling a rapid switching from an initially opaque state to a relatively transparent state upon photoexcitation. Herein, we demonstrate broadband ultrafast optical switching in degenerate InN thin films, spanning the visible to near-infrared spectral range, using pump-probe transient transmittance measurements. To elucidate the underlying physical mechanism, we perform probe-energy-resolved analysis for ultrafast dynamics, and develop a theoretical model based on a quasi-equilibrium Fermi-Dirac distribution. The model successfully captures the experimental transients and yields an electron-phonon coupling constant of $1.0\\times10^{17}\\,\\mathrm{W\\,m^{-3}\\,K^{-1}}$, along with an electronic specific heat coefficient ranging from 1.52 to 2.02 $\\mathrm{mJ\\,mol^{-1}\\,K^{-2}}$, which allow direct prediction of the spectral switching window. Notably, we demonstrate that the Pauli blocking effect can be induced solely by a laser-excitation driven rise in electronic temperature, without requiring significant carrier injection into the conduction band in degenerate semiconductors. These findings offer new insights for designing ultrafast optical modulators, shutters, and photonic devices for next-generation communication and computing technologies."
  },
  {
    "date": "2026-01-21",
    "title": "Paraxial diffusion-field retrieval. II. Fokker-Planck generalization of the transport-of-intensity equation",
    "authors": "David M. Paganin, Kaye S. Morgan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14645v1",
    "source": "arXiv",
    "abstract": "The transport-of-intensity equation (TIE) has been very widely employed for phase retrieval. In particular, the TIE is an elliptic second-order partial differential equation which may be solved for the phase of a coherent paraxial field such as a monochromatic scalar optical beam, given the intensity and longitudinal intensity derivative in a plane perpendicular to the optical axis. We show how the coherent flow associated with the TIE may be augmented by a diffusive flow associated with a scalar or tensor diffusion field. Such diffusive flow can arise via scattering from unresolved spatially random microstructure within an illuminated sample, the blurring effects of an extended chaotic source that illuminates the sample, the resolution-reducing effect of shot noise in detected intensity images of the sample, and the sharpening effect (negative diffusion) associated with scattering from sharp sample edges. Augmenting the TIE's modeling of coherent flow with a diffuse-flow channel leads to a Fokker-Planck extension to this equation. Two different TIE augmentations are obtained, using three different derivations. The inverse problems of phase retrieval and diffusion-field retrieval are then studied, for both defocus-based imaging and mask-based imaging (structured-illumination imaging). When symmetric overfocus and underfocus images are employed for the purposes of phase retrieval, the diffusive term drops out and our Fokker-Planck formalism implies that any ensuing TIE-based phase-retrieval method needs no modification in light of our formalism. However, the same focal-series dataset -- which is typically an infocus image, a weakly overfocused image, and a weakly underfocused image -- may also be employed to access the additional channel of information associated with the Fokker-Planck diffusion field. Our formalism is applicable to visible light, x-rays, electrons, and neutrons."
  },
  {
    "date": "2026-01-21",
    "title": "The missing links: Evaluating contact tracing with incomplete data in large metropolitan areas during an epidemic",
    "authors": "Min-Kyung Chae, Woo-Sik Son, Sang Hoon Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14632v1",
    "source": "arXiv",
    "abstract": "Contact tracing (CT) plays a pivotal role in controlling early epidemic spread, particularly when a novel infectious disease emerges. However, the quantitative impact of missing information -- such as untraced cases or unnotified contacts -- on the effectiveness of CT remains insufficiently understood. Using a stochastic agent-based model with sociodemographics from metropolitan areas in South Korea, we simulate how different forms of information loss affect epidemic spreading dynamics. We construct information-loss scenarios based on two types: infector-omission (IO) and contact-omission (CO), including selective (SCO) and uniform (UCO) scenarios; IO corresponds to the omission of infected individuals (nodes) from the tracing process, leading to the loss of all movement trajectories and downstream transmission links originating from them, whereas CO corresponds to the omission of specific contact events (edges), in which infected individuals are identified but some of their transmission links fail to be detected or notified. The sensitivity of epidemic dynamics to increasing omission rates differs markedly between the two types: IO scenarios exhibit substantially stronger and more abrupt changes in transmission structure and epidemic outcomes, whereas CO scenarios produce more gradual effects. In both scenarios, the magnitude of these effects varies across cities, with a lower-population city (Busan) showing greater tolerance to information loss than the largest city (Seoul), underscoring the importance of regional tailoring in CT strategies. Both IO and CO scenarios also lead to an increase in the transmission network diameter as information loss grows, indicating that a small network diameter reflects effective contact tracing that limits the depth of transmission chains."
  },
  {
    "date": "2026-01-21",
    "title": "Dévissage for Algebraic K-theory of Small Stable $\\infty$-categories",
    "authors": "Chunhui Wei",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14626v1",
    "source": "arXiv",
    "abstract": "In this article, we extend Quillen's Dévissage Theorem to small stable $\\infty$-categories. To be precise, we establish sufficient conditions under which the non-negative $K$-groups of a small stable $\\infty$-category coincide with those of a stable subcategory thereof."
  },
  {
    "date": "2026-01-21",
    "title": "Scaling Ambiguity: Augmenting Human Annotation in Speech Emotion Recognition with Audio-Language Models",
    "authors": "Wenda Zhang, Hongyu Jin, Siyi Wang, Zhiqiang Wei, Ting Dang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14620v1",
    "source": "arXiv",
    "abstract": "Speech Emotion Recognition models typically use single categorical labels, overlooking the inherent ambiguity of human emotions. Ambiguous Emotion Recognition addresses this by representing emotions as probability distributions, but progress is limited by unreliable ground-truth distributions inferred from sparse human annotations. This paper explores whether Large Audio-Language Models (ALMs) can mitigate the annotation bottleneck by generating high-quality synthetic annotations. We introduce a framework leveraging ALMs to create Synthetic Perceptual Proxies, augmenting human annotations to improve ground-truth distribution reliability. We validate these proxies through statistical analysis of their alignment with human distributions and evaluate their impact by fine-tuning ALMs with the augmented emotion distributions. Furthermore, to address class imbalance and enable unbiased evaluation, we propose DiME-Aug, a Distribution-aware Multimodal Emotion Augmentation strategy. Experiments on IEMOCAP and MSP-Podcast show that synthetic annotations enhance emotion distribution, especially in low-ambiguity regions where annotation agreement is high. However, benefits diminish for highly ambiguous emotions with greater human disagreement. This work provides the first evidence that ALMs could address annotation scarcity in ambiguous emotion recognition, but highlights the need for more advanced prompting or generation strategies to handle highly ambiguous cases."
  },
  {
    "date": "2026-01-21",
    "title": "Communication-Efficient Federated Risk Difference Estimation for Time-to-Event Clinical Outcomes",
    "authors": "Ziwen Wang, Siqi Li, Marcus Eng Hock Ong, Nan Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14609v1",
    "source": "arXiv",
    "abstract": "Privacy-preserving model co-training in medical research is often hindered by server-dependent architectures incompatible with protected hospital data systems and by the predominant focus on relative effect measures (hazard ratios) which lack clinical interpretability for absolute survival risk assessment. We propose FedRD, a communication-efficient framework for federated risk difference estimation in distributed survival data. Unlike typical federated learning frameworks (e.g., FedAvg) that require persistent server connections and extensive iterative communication, FedRD is server-independent with minimal communication: one round of summary statistics exchange for the stratified model and three rounds for the unstratified model. Crucially, FedRD provides valid confidence intervals and hypothesis testing--capabilities absent in FedAvg-based frameworks. We provide theoretical guarantees by establishing the asymptotic properties of FedRD and prove that FedRD (unstratified) is asymptotically equivalent to pooled individual-level analysis. Simulation studies and real-world clinical applications across different countries demonstrate that FedRD outperforms local and federated baselines in both estimation accuracy and prediction performance, providing an architecturally feasible solution for absolute risk assessment in privacy-restricted, multi-site clinical studies."
  },
  {
    "date": "2026-01-21",
    "title": "\\textit{Ab initio} study of spectroscopic factors in $^{48}$K and neighboring $N=28$ isotones",
    "authors": "P. Y. Wang, M. R. Xie, Q. Yuan, W. J. Huang, J. G. Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14604v1",
    "source": "arXiv",
    "abstract": "A recent \\(^{47}\\text{K}(d,pγ)^{48}\\text{K}\\) transfer reaction measurement has identified new excited states in \\(^{48}\\text{K}\\) and extracted the corresponding spectroscopic factors (SFs)[\\href{https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.134.162504}{C. J. Paxman, \\textit{et al.} PhysRevLett.134.162504 (2025)}], but they exposed sizeable discrepancies with large-scale shell-model (LSSM) calculations-especially for the low-lying states-suggesting shortcomings in the proton-neutron interaction employed by the LSSM. In this work, we revisit the low-lying states and SFs of \\(^{48}\\text{K}\\) using the \\textit{ab initio} valence-space in-medium similarity renormalization group (VS-IMSRG) approach based on the chiral two- and three-nucleon forces. The calculated excitation energies reproduce the experimental data for \\(^{48}\\text{K}\\), whereas computed SFs systematically exceed experimental values. We trace this overestimation to missing reduction factors that account for non-idealities of the transfer reaction. After introducing a phenomenological reduction factor, our VS-IMSRG results and the LSSM calculations achieve agreement with experiment. We also perform the same analysis for the neutron SFs of $^{47}$Ar. Furthermore, we extend the \\textit{ab initio} calculations across the $N=28$ isotones, computing excitation energies and single-neutron transfer SFs from $N=29$ isotones ranging from $^{48}$K to $^{45}$S. By systematically removing protons from \\(^{48}\\text{K}\\) to \\(^{45}\\text{S}\\), we trace the evolution of the \\(N=28\\) shell strength via theoretical SFs values. Our results provide a microscopic pathway to quantify the weakening of the \\(N=28\\) shell closure."
  },
  {
    "date": "2026-01-21",
    "title": "Sobolev multipliers and fractional Gaussian fields on Lipschitz boundaries with applications to deterministic and random acoustic systems",
    "authors": "Illya M. Karabash",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14600v1",
    "source": "arXiv",
    "abstract": "Motivated by Applied Physics and Photonics studies of random resonators, we study in the stochastic part of this paper random acoustic operators in non-smooth bounded domains $G \\subset \\mathbb{R}^d$ and introduce m-dissipative impedance boundary conditions containing fractional Gaussian fields (FGFs). The deterministic part of the paper constructs and studies the spaces of pointwise multipliers on Lipschitz continuous boundaries $\\partial G$, as well as the spaces of Sobolev (distribution-type) multipliers on boundaries $\\partial G$ of better regularity. These multipliers are used as generalized impedance coefficients $ζ(x)$, $x \\in \\partial G$, in impedance boundary conditions accompanying the first order acoustic system. The main efforts are aimed on the m-dissipativity of associated acoustic operators and the discreteness of the related spectra under weakest possible assumptions on the regularity of $ζ$. In order to connect the deterministic results with the randomization, we introduce FGFs on Lipschitz boundaries $\\partial G$ and study their regularity. To this end, we prove that a rough Weyl-type asymptotics takes place for the Laplace-Beltrami eigenvalues on arbitrary compact boundary $\\partial G$ of $C^{0,1}$-regularity."
  },
  {
    "date": "2026-01-21",
    "title": "Star Decompositions of a Cyclic Polygon",
    "authors": "Tomoki Nakamigawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14585v1",
    "source": "arXiv",
    "abstract": "Let $V$ be a set of vertices on a circumference in the plane. Let $E$ be a set of directed line segments linking two vertices of $V$. If $E$ forms a set of closed cycles and for all two adjacent edges $uv$ and $vw$, the vertices $u$, $v$, $w$ are arranged in anti-clockwise order, we call $P(V,E)$ a cyclic polygon. A star decomposition $\\mathcal{S}$ of a cyclic polygon $P$ is a set of star polygons partitioning the region of $P$ with some additional diagonals. A star decomposition $\\mathcal{S}$ is called maximal if there is no other star decomposition $\\mathcal{S}'$ such that a set of diagonals of $\\mathcal{S}$ is a proper subset of that of $\\mathcal{S}'$. In this paper, it is shown that for any two maximal star decompositions $\\mathcal{S}_1$ and $\\mathcal{S}_2$ of a common cyclic polygon, $\\mathcal{S}_1$ can be transformed into $\\mathcal{S}_2$ by a finite sequence of diagonal flips. It is also shown that if a cyclic polygon $P$ admits a star decomposition, the number of diagonals contained in a maximal star decomposition of $P$ is $p - (n-2r)(n-2r-1)/2$, where $p$ is the number of all possible diagonals of $P$, $n$ is the number of vertices of $P$, and $r$ is the rotation number of $P$."
  },
  {
    "date": "2026-01-21",
    "title": "Anatomically Guided Latent Diffusion for Brain MRI Progression Modeling",
    "authors": "Cheng Wan, Bahram Jafrasteh, Ehsan Adeli, Miaomiao Zhang, Qingyu Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14584v1",
    "source": "arXiv",
    "abstract": "Accurately modeling longitudinal brain MRI progression is crucial for understanding neurodegenerative diseases and predicting individualized structural changes. Existing state-of-the-art approaches, such as Brain Latent Progression (BrLP), often use multi-stage training pipelines with auxiliary conditioning modules but suffer from architectural complexity, suboptimal use of conditional clinical covariates, and limited guarantees of anatomical consistency. We propose Anatomically Guided Latent Diffusion Model (AG-LDM), a segmentation-guided framework that enforces anatomically consistent progression while substantially simplifying the training pipeline. AG-LDM conditions latent diffusion by directly fusing baseline anatomy, noisy follow-up states, and clinical covariates at the input level, a strategy that avoids auxiliary control networks by learning a unified, end-to-end model that represents both anatomy and progression. A lightweight 3D tissue segmentation model (WarpSeg) provides explicit anatomical supervision during both autoencoder fine-tuning and diffusion model training, ensuring consistent brain tissue boundaries and morphometric fidelity. Experiments on 31,713 ADNI longitudinal pairs and zero-shot evaluation on OASIS-3 demonstrate that AG-LDM matches or surpasses more complex diffusion models, achieving state-of-the-art image quality and 15-20\\% reduction in volumetric errors in generated images. AG-LDM also exhibits markedly stronger utilization of temporal and clinical covariates (up to 31.5x higher sensitivity than BrLP) and generates biologically plausible counterfactual trajectories, accurately capturing hallmarks of Alzheimer's progression such as limbic atrophy and ventricular expansion. These results highlight AG-LDM as an efficient, anatomically grounded framework for reliable brain MRI progression modeling."
  },
  {
    "date": "2026-01-21",
    "title": "De novo design of protein binders targeting the human sweet taste receptor as potential sweet proteins",
    "authors": "Saisai Ding, Yi Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14574v1",
    "source": "arXiv",
    "abstract": "Excessive consumption of dietary sugars is a major contributor to metabolic disorders, driving global interest in finding alternative sweeteners with reduced caloric impact. Natural sweet proteins, such as brazzein, offer exceptional sweetness intensity with little caloric contribution. However, their widespread use is limited by restricted natural diversity, low stability, and high production costs. Recent advances in structural biology and de novo protein design provide new opportunities to overcome these limitations through rational engineering. In this study, we report an integrated computational pipeline for the de novo design of protein binders targeting the human sweet taste receptor subunit TAS1R2, a key component of the heterodimeric class C G protein-coupled receptor mediating sweetness perception. The workflow combines diffusion-based backbone generation (RFdiffusion), neural network-guided sequence design (ProteinMPNN), structure-based filtering using Boltz-1, and binding energy evaluation via MM/GBSA calculations. Using the recently resolved cryo-EM structure of the TAS1R2 receptor, protein binders were designed to target both the Venus Flytrap Domain and the cysteine-rich domain of TAS1R2. A few designed binders exhibited favorable structural confidence and predicted binding energetics. In particular, Binder2 exhibited brazzein-like structural plausibility through specific short-range CRD contacts, while Binder1 displayed the strongest predicted binding affinity. Structural analyses of the binder-receptor complex revealed distinct binding modes and secondary structure profiles among the designs. This study demonstrates the feasibility of de novo designing protein binders that emulate key functional properties of natural sweet proteins, establishing a computational framework for the rational development of next-generation protein-based sweeteners."
  },
  {
    "date": "2026-01-21",
    "title": "Scribble-Supervised Medical Image Segmentation with Dynamic Teacher Switching and Hierarchical Consistency",
    "authors": "Thanh-Huy Nguyen, Hoang-Loc Cao, Dat T. Chung, Mai-Anh Vu, Thanh-Minh Nguyen, Minh Le, Phat K. Huynh, Ulas Bagci",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14563v1",
    "source": "arXiv",
    "abstract": "Scribble-supervised methods have emerged to mitigate the prohibitive annotation burden in medical image segmentation. However, the inherent sparsity of these annotations introduces significant ambiguity, which results in noisy pseudo-label propagation and hinders the learning of robust anatomical boundaries. To address this challenge, we propose SDT-Net, a novel dual-teacher, single-student framework designed to maximize supervision quality from these weak signals. Our method features a Dynamic Teacher Switching (DTS) module to adaptively select the most reliable teacher. This selected teacher then guides the student via two synergistic mechanisms: high-confidence pseudo-labels, refined by a Pick Reliable Pixels (PRP) mechanism, and multi-level feature alignment, enforced by a Hierarchical Consistency (HiCo) module. Extensive experiments on the ACDC and MSCMRseg datasets demonstrate that SDT-Net achieves state-of-the-art performance, producing more accurate and anatomically plausible segmentation."
  },
  {
    "date": "2026-01-21",
    "title": "Dark Energy Survey Year 6 Results: Cosmological Constraints from Galaxy Clustering and Weak Lensing",
    "authors": "DES Collaboration, T. M. C. Abbott, M. Adamow, M. Aguena, A. Alarcon, S. S. Allam, O. Alves, A. Amon, D. Anbajagane, F. Andrade-Oliveira, S. Avila, D. Bacon, E. J. Baxter, J. Beas-Gonzalez, K. Bechtol, M. R. Becker, G. M. Bernstein, E. Bertin, J. Blazek, S. Bocquet, D. Brooks, D. Brout, H. Camacho, G. Camacho-Ciurana, R. Camilleri, G. Campailla, A. Campos, A. Carnero Rosell, M. Carrasco Kind, J. Carretero, P. Carrilho, F. J. Castander, R. Cawthon, C. Chang, A. Choi, J. M. Coloma-Nadal, M. Costanzi, M. Crocce, W. d'Assignies, L. N. da Costa, M. E. da Silva Pereira, T. M. Davis, J. De Vicente, J. DeRose, H. T. Diehl, S. Dodelson, C. Doux, A. Drlica-Wagner, T. F. Eifler, J. Elvin-Poole, J. Estrada, S. Everett, A. E. Evrard, J. Fang, A. Farahi, A. Ferté, B. Flaugher, P. Fosalba, J. Frieman, J. García-Bellido, M. Gatti, E. Gaztanaga, G. Giannini, P. Giles, K. Glazebrook, M. Gorsuch, D. Gruen, R. A. Gruendl, J. Gschwend, G. Gutierrez, I. Harrison, W. G. Hartley, E. Henning, K. Herner, S. R. Hinton, D. L. Hollowood, K. Honscheid, E. M. Huff, D. Huterer, B. Jain, D. J. James, M. Jarvis, N. Jeffrey, T. Jeltema, T. Kacprzak, S. Kent, A. Kovacs, E. Krause, R. Kron, K. Kuehn, O. Lahav, S. Lee, E. Legnani, C. Lidman, H. Lin, N. MacCrann, M. Manera, T. Manning, R. Marco, J. L. Marshall, S. Mau, J. McCullough, J. Mena-Fernández, F. Menanteau, R. Miquel, J. J. Mohr, J. Muir, J. Myles, R. C. Nichol, B. Nord, J. H. O'Donnell, R. L. C. Ogando, A. Palmese, M. Paterno, J. Peoples, W. J. Percival, D. Petravick, A. Pieres, A. A. Plazas Malagón, A. Porredon, A. Pourtsidou, J. Prat, C. Preston, M. Raveri, W. Riquelme, M. Rodriguez-Monroy, P. Rogozenski, A. K. Romer, A. Roodman, R. Rosenfeld, A. J. Ross, E. Rozo, E. S. Rykoff, S. Samuroff, C. Sánchez, E. Sanchez, D. Sanchez Cid, T. Schutt, I. Sevilla-Noarbe, E. Sheldon, N. Sherman, T. Shin, M. Smith, M. Soares-Santos, E. Suchyta, M. E. C. Swanson, M. Tabbutt, G. Tarle, D. Thomas, C. To, A. Tong, L. Toribio San Cipriano, M. A. Troxel, M. Tsedrik, D. L. Tucker, V. Vikram, A. R. Walker, N. Weaverdyck, R. H. Wechsler, D. H. Weinberg, J. Weller, V. Wetzell, A. Whyley, R. D. Wilkinson, P. Wiseman, H. -Y. Wu, M. Yamamoto, B. Yanny, B. Yin, G. Zacharegkas, Y. Zhang, J. Zuntz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14559v1",
    "source": "arXiv",
    "abstract": "We present cosmology results combining galaxy clustering and weak gravitational lensing measured in the full six years (Y6) of observations by the Dark Energy Survey (DES) covering $\\sim$5000 deg$^2$. We perform a large-scale structure analysis using three two-point correlation functions (3$\\times$2pt): (i) cosmic shear from 140 million source galaxy shapes, (ii) galaxy clustering of 9 million lens galaxy positions, and (iii) galaxy-galaxy lensing from their cross-correlation. We model the data in flat $Λ$CDM and $w$CDM cosmologies. The combined analysis yields $S_8\\equiv σ_8 (Ω_{\\rm m}/0.3)^{0.5} = 0.789^{+0.012}_{-0.012}$ and matter density $Ω_{\\rm m} = 0.333^{+0.023}_{-0.028}$ in $Λ$CDM (68\\% CL), where $σ_8$ is the clustering amplitude. These constraints show a (full-space) parameter difference of 1.8$σ$ from a combination of cosmic microwave background (CMB) primary anisotropy datasets from Planck 2018, ACT-DR6, and SPT-3G DR1. Projected only into $S_8$ the difference is $2.6σ$. In $w$CDM the Y6 3$\\times$2pt results yield $S_8 = 0.782^{+0.021}_{-0.020}$, $Ω_{\\rm m} = 0.325^{+0.032}_{-0.035}$, and dark energy equation-of-state parameter $w = -1.12^{+0.26}_{-0.20}$. For the first time, we combine all DES dark-energy probes: 3$\\times$2pt, SNe Ia, BAO and Clusters. In $Λ$CDM this combination yields a $2.8σ$ parameter difference from the CMB. When combining DES 3$\\times$2pt with other low-redshift datasets (DESI DR2 BAO, DES SNe Ia, SPT clusters), we find a 2.3$σ$ parameter difference with CMB. A joint fit of Y6 3$\\times$2pt, CMB, and those low-redshift datasets produces the tightest $Λ$CDM constraints to date: $S_8 = 0.806^{+0.006}_{-0.007}$, $Ω_{\\rm m} = 0.302^{+0.003}_{-0.003}$, $h = 0.683^{+0.003}_{-0.002}$, and $\\sum m_ν< 0.14$ eV (95\\% CL). In $w$CDM, this combination yields $w = -0.981^{+0.021}_{-0.022}$."
  },
  {
    "date": "2026-01-21",
    "title": "$L^2$-property for algebraic stacks over local non-archimedean fields",
    "authors": "David Kazhdan, Alexander Polishchuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14557v1",
    "source": "arXiv",
    "abstract": "We introduce an $L^2$-norm on the space of Schwartz half-densities over algebraic stacks over local non-archimedean fields. We show that these $L^2$-norms are finite for the stacks of $PGL_2$-bundles on $\\mathbb{P}^1$ with parabolic structures at $\\ge 3$ points. The latter property was conjectured in the context of the analytic Langlands correspondence of arXiv:2103.01509."
  },
  {
    "date": "2026-01-21",
    "title": "Self-Aligned Heterogeneous Quantum Photonic Integration",
    "authors": "Kinfung Ngan, Yeeun Choi, Chun-Chieh Chang, Dongyeon Daniel Kang, Shuo Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14552v1",
    "source": "arXiv",
    "abstract": "Integrated quantum photonics holds significant promise for scalable photonic quantum information processing, quantum repeaters, and quantum networks, but its development is hindered by the mismatch between materials hosting high-quality quantum emitters and those compatible with mature photonic technologies. Heterogeneous integration offers a potential solution to this challenge, yet practical implementations have been limited by inevitable insertion losses at material interfaces. Here, we present a self-aligned heterogeneous quantum photonic integration approach that can deterministically achieve near-unity coupling efficiency at the interface. To showcase our approach, we demonstrate Purcell enhancement of a silicon vacancy (SiV) center in diamond induced by a heterogeneous photonic crystal cavity defined by titanium dioxide (TiO2), as well as optical spin control and readout via a TiO2 photonic circuit. We further show that, when combined with inverse photonic design, our approach enables efficient and broadband collection of single photons from a color center into a heterogeneous waveguide. Our approach is not restricted to SiV centers or TiO2; it can be broadly applied to integrate diverse solid-state quantum emitters with thin-film photonic devices where conformal deposition is possible. Together, these results establish a practical route to scalable quantum photonic integrated circuits that combine high-quality quantum emitters with technologically mature photonic platforms."
  },
  {
    "date": "2026-01-21",
    "title": "TacUMI: A Multi-Modal Universal Manipulation Interface for Contact-Rich Tasks",
    "authors": "Tailai Cheng, Kejia Chen, Lingyun Chen, Liding Zhang, Yue Zhang, Yao Ling, Mahdi Hamad, Zhenshan Bing, Fan Wu, Karan Sharma, Alois Knoll",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14550v1",
    "source": "arXiv",
    "abstract": "Task decomposition is critical for understanding and learning complex long-horizon manipulation tasks. Especially for tasks involving rich physical interactions, relying solely on visual observations and robot proprioceptive information often fails to reveal the underlying event transitions. This raises the requirement for efficient collection of high-quality multi-modal data as well as robust segmentation method to decompose demonstrations into meaningful modules. Building on the idea of the handheld demonstration device Universal Manipulation Interface (UMI), we introduce TacUMI, a multi-modal data collection system that integrates additionally ViTac sensors, force-torque sensor, and pose tracker into a compact, robot-compatible gripper design, which enables synchronized acquisition of all these modalities during human demonstrations. We then propose a multi-modal segmentation framework that leverages temporal models to detect semantically meaningful event boundaries in sequential manipulations. Evaluation on a challenging cable mounting task shows more than 90 percent segmentation accuracy and highlights a remarkable improvement with more modalities, which validates that TacUMI establishes a practical foundation for both scalable collection and segmentation of multi-modal demonstrations in contact-rich tasks."
  },
  {
    "date": "2026-01-21",
    "title": "QMC: Efficient SLM Edge Inference via Outlier-Aware Quantization and Emergent Memories Co-Design",
    "authors": "Nilesh Prasad Pandey, Jangseon Park, Onat Gungor, Flavio Ponzina, Tajana Rosing",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14549v1",
    "source": "arXiv",
    "abstract": "Deploying Small Language Models (SLMs) on edge platforms is critical for real-time, privacy-sensitive generative AI, yet constrained by memory, latency, and energy budgets. Quantization reduces model size and cost but suffers from device noise in emerging non-volatile memories, while conventional memory hierarchies further limit efficiency. SRAM provides fast access but has low density, DRAM must simultaneously accommodate static weights and dynamic KV caches, which creates bandwidth contention, and Flash, although dense, is primarily used for initialization and remains inactive during inference. These limitations highlight the need for hybrid memory organizations tailored to LLM inference. We propose Outlier-aware Quantization with Memory Co-design (QMC), a retraining-free quantization with a novel heterogeneous memory architecture. QMC identifies inlier and outlier weights in SLMs, storing inlier weights in compact multi-level Resistive-RAM (ReRAM) while preserving critical outliers in high-precision on-chip Magnetoresistive-RAM (MRAM), mitigating noise-induced degradation. On language modeling and reasoning benchmarks, QMC outperforms and matches state-of-the-art quantization methods using advanced algorithms and hybrid data formats, while achieving greater compression under both algorithm-only evaluation and realistic deployment settings. Specifically, compared against SoTA quantization methods on the latest edge AI platform, QMC reduces memory usage by 6.3x-7.3x, external data transfers by 7.6x, energy by 11.7x, and latency by 12.5x when compared to FP16, establishing QMC as a scalable, deployment-ready co-design for efficient on-device inference."
  },
  {
    "date": "2026-01-21",
    "title": "Carroll hydrodynamics with spin",
    "authors": "Ashish Shukla, Rajeev Singh, Pushkar Soni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15023v1",
    "source": "arXiv",
    "abstract": "We formulate Carroll hydrodynamics with the inclusion of a spin current. Our strategy relies on the fact that the $c\\to 0$ limit of relativistic hydrodynamics yields the equations of Carroll hydrodynamics. Starting with the pre-ultralocal parametrization of the background geometry and the hydrodynamic degrees of freedom for a relativistic fluid endowed with a spin current, the $c\\to 0$ limit produces Carroll hydrodynamics with spin. It is known that boost-invariant hydrodynamic models for ultrarelativistic fluids relevant for the physics of quark-gluon plasma, such as Bjorken and Gubser flow, are manifestations of Carroll hydrodynamics under appropriate geometric choices for the underlying Carrollian structure. In this work, we further this mapping between such boost-invariant models and Carroll hydrodynamics, now with the inclusion of a spin current."
  },
  {
    "date": "2026-01-21",
    "title": "On the Bergman metric of symmettric spaces",
    "authors": "Andrea Loi, Matteo Palmieri",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15020v1",
    "source": "arXiv",
    "abstract": "We study bounded domains $Ω\\subset\\mathbb{C}^n$ whose Bergman metric is locally symmetric, i.e. its Riemannian curvature tensor is parallel with respect to the Levi-Civita connection. Following the strategy developed in \\cite{UnifThm2}, we obtain two rigidity results. If the Bergman metric of $Ω$ is complete, then $Ω$ is (globally) symmetric. If instead $Ω$ is pseudoconvex, then $Ω$ is biholomorphic to $\\widetildeΩ\\setminus E$, where $\\widetildeΩ\\subset\\mathbb{C}^n$ is a bounded symmetric domain and $E\\subset\\widetildeΩ$ is relatively closed and pluripolar. The proofs combine the structure theory of Hermitian symmetric spaces with Calabi's theory of Kähler immersions into the infinite dimensional complex projective space (in particular, rigidity and the hereditary property of the diastasis), together with analytic and pluripotential tools based on extension properties of square-integrable holomorphic functions and the Bergman kernel."
  },
  {
    "date": "2026-01-21",
    "title": "Risk Estimation for Automated Driving",
    "authors": "Leon Tolksdorf, Arturo Tejada, Jonas Bauernfeind, Christian Birkner, Nathan van de Wouw",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15018v1",
    "source": "arXiv",
    "abstract": "Safety is a central requirement for automated vehicles. As such, the assessment of risk in automated driving is key in supporting both motion planning technologies and safety evaluation. In automated driving, risk is characterized by two aspects. The first aspect is the uncertainty on the state estimates of other road participants by an automated vehicle. The second aspect is the severity of a collision event with said traffic participants. Here, the uncertainty aspect typically causes the risk to be non-zero for near-collision events. This makes risk particularly useful for automated vehicle motion planning. Namely, constraining or minimizing risk naturally navigates the automated vehicle around traffic participants while keeping a safety distance based on the level of uncertainty and the potential severity of the impending collision. Existing approaches to calculate the risk either resort to empirical modeling or severe approximations, and, hence, lack generalizability and accuracy. In this paper, we combine recent advances in collision probability estimation with the concept of collision severity to develop a general method for accurate risk estimation. The proposed method allows us to assign individual severity functions for different collision constellations, such as, e.g., frontal or side collisions. Furthermore, we show that the proposed approach is computationally efficient, which is beneficial, e.g., in real-time motion planning applications. The programming code for an exemplary implementation of Gaussian uncertainties is also provided."
  },
  {
    "date": "2026-01-21",
    "title": "Alternative Shapes of Modulation Schemes Detailed Exposition and Simulation Methodology",
    "authors": "Nipun Agarwal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15004v1",
    "source": "arXiv",
    "abstract": "Modulation constellation design is a core challenge in digital communications, especially under stringent demands on spectral efficiency, robustness, and energy consumption. Classical schemes like PSK and QAM, while analytically tractable, often lose optimality under realistic channels and nonlinear hardware constraints. This paper provides a unified study of constellation design from geometric, probabilistic, optimization, and machine learning perspectives, focusing on symbol error rate (SER), fading robustness, peak-to-average power ratio (PAPR), and energy efficiency. We evaluate classical, lattice-based, asymmetric, probabilistically shaped, Golden Angle, heuristic-optimized, and machine learning assisted constellations under AWGN and Rayleigh fading via large-scale Monte Carlo simulations. Incorporating PAPR-aware and power amplifier models reveals that SER-optimal designs are not always energy-optimal; small SER trade-offs can yield substantial energy savings. Machine learning approaches offer flexible joint optimization of reliability, robustness, and energy efficiency by embedding channel and hardware constraints into the learning objective."
  },
  {
    "date": "2026-01-21",
    "title": "Note on the multiplicity of solutions for nonlinear scalar field equations with a critical inverse-square potential",
    "authors": "Bartosz Bieganowski, Daniel Strzelecki",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15003v1",
    "source": "arXiv",
    "abstract": "We are interested in the multiplicity of solutions to the following scalar field equation $$ -Δu - \\frac{(N-2)^2}{4|x|^2} u = g(u), \\quad \\mbox{in } \\mathbb{R}^N \\setminus \\{0\\}. $$ We establish the existence of infinitely many radial and non-radial solutions."
  },
  {
    "date": "2026-01-21",
    "title": "Graph-Based Adaptive Planning for Coordinated Dual-Arm Robotic Disassembly of Electronic Devices (eGRAP)",
    "authors": "Adip Ranjan Das, Maria Koskinopoulou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14998v1",
    "source": "arXiv",
    "abstract": "E-waste is growing rapidly while recycling rates remain low. We propose an electronic-device Graph-based Adaptive Planning (eGRAP) that integrates vision, dynamic planning, and dual-arm execution for autonomous disassembly. A camera-equipped arm identifies parts and estimates their poses, and a directed graph encodes which parts must be removed first. A scheduler uses topological ordering of this graph to select valid next steps and assign them to two robot arms, allowing independent tasks to run in parallel. One arm carries a screwdriver (with an eye-in-hand depth camera) and the other holds or handles components. We demonstrate eGRAP on 3.5in hard drives: as parts are unscrewed and removed, the system updates its graph and plan online. Experiments show consistent full disassembly of each HDD, with high success rates and efficient cycle times, illustrating the method's ability to adaptively coordinate dual-arm tasks in real time."
  },
  {
    "date": "2026-01-21",
    "title": "Ab initio path-integral Monte Carlo results for the one-particle spectral function of the warm dense electron gas",
    "authors": "Paul Hamann, Michael Bonitz, Jan Vorberger, Tobias Dornheim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14992v1",
    "source": "arXiv",
    "abstract": "We compute quasi-exact \\emph{ab initio} path-integral Monte Carlo results for the Matsubara Green's function of the uniform electron gas (UEG) at finite temperature over a broad range of coupling strengths ($r_s=1,\\dots,10)$. This allows us to present approximation-free results for the static self-energy $Σ_\\infty(p)$ and spectral function $A(p,ω)$, and to benchmark previous approximate results for the UEG. In addition, our work opens up intriguing avenues to study the single-particle spectrum and density of states of real warm dense matter systems based on truly first principles."
  },
  {
    "date": "2026-01-21",
    "title": "Consistency of Honest Decision Trees and Random Forests",
    "authors": "Martin Bladt, Rasmus Frigaard Lemvig",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14991v1",
    "source": "arXiv",
    "abstract": "We study various types of consistency of honest decision trees and random forests in the regression setting. In contrast to related literature, our proofs are elementary and follow the classical arguments used for smoothing methods. Under mild regularity conditions on the regression function and data distribution, we establish weak and almost sure convergence of honest trees and honest forest averages to the true regression function, and moreover we obtain uniform convergence over compact covariate domains. The framework naturally accommodates ensemble variants based on subsampling and also a two-stage bootstrap sampling scheme. Our treatment synthesizes and simplifies existing analyses, in particular recovering several results as special cases. The elementary nature of the arguments clarifies the close relationship between data-adaptive partitioning and kernel-type methods, providing an accessible approach to understanding the asymptotic behavior of tree-based methods."
  },
  {
    "date": "2026-01-21",
    "title": "Dielectric formalism of the 2D uniform electron gas at finite temperatures",
    "authors": "Fotios Kalkavouras, Tobias Dornheim, Paul Hamann, Panagiotis Tolias",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14989v1",
    "source": "arXiv",
    "abstract": "We present a comprehensive analysis of the two-dimensional uniform electron gas (2D-UEG or more commonly 2DEG) at finite temperature, spanning a broad range of densities / coupling strengths ($0.01\\le{r}_s\\le20$) and temperatures / degeneracy parameters ($0.01\\leΘ= k_B T/E_F \\le 10$). Within the self-consistent dielectric formalism, we construct two-dimensional versions of the Singwi-Tosi-Land-Sjölander (STLS) and hypernetted-chain (HNC) approximation based schemes. We benchmark the accuracy of the STLS and the HNC schemes against new state-of-the-art path-integral Monte Carlo data. We also report structural and thermodynamic properties across the full $(r_s,Θ)$ phase diagram domain studied, identify regimes in which these schemes remain quantitatively reliable, and provide an accurate parametrization of the exchange--correlation free energy of the finite-temperature 2DEG."
  },
  {
    "date": "2026-01-21",
    "title": "Unified Multi-Dataset Training for TBPS",
    "authors": "Nilanjana Chatterjee, Sidharatha Garg, A V Subramanyam, Brejesh Lall",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14978v1",
    "source": "arXiv",
    "abstract": "Text-Based Person Search (TBPS) has seen significant progress with vision-language models (VLMs), yet it remains constrained by limited training data and the fact that VLMs are not inherently pre-trained for pedestrian-centric recognition. Existing TBPS methods therefore rely on dataset-centric fine-tuning to handle distribution shift, resulting in multiple independently trained models for different datasets. While synthetic data can increase the scale needed to fine-tune VLMs, it does not eliminate dataset-specific adaptation. This motivates a fundamental question: can we train a single unified TBPS model across multiple datasets? We show that naive joint training over all datasets remains sub-optimal because current training paradigms do not scale to a large number of unique person identities and are vulnerable to noisy image-text pairs. To address these challenges, we propose Scale-TBPS with two contributions: (i) a noise-aware unified dataset curation strategy that cohesively merges diverse TBPS datasets; and (ii) a scalable discriminative identity learning framework that remains effective under a large number of unique identities. Extensive experiments on CUHK-PEDES, ICFG-PEDES, RSTPReid, IIITD-20K, and UFine6926 demonstrate that a single Scale-TBPS model outperforms dataset-centric optimized models and naive joint training."
  },
  {
    "date": "2026-01-21",
    "title": "HumanDiffusion: A Vision-Based Diffusion Trajectory Planner with Human-Conditioned Goals for Search and Rescue UAV",
    "authors": "Faryal Batool, Iana Zhura, Valerii Serpiva, Roohan Ahmed Khan, Ivan Valuev, Issatay Tokmurziyev, Dzmitry Tsetserukou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14973v1",
    "source": "arXiv",
    "abstract": "Reliable human--robot collaboration in emergency scenarios requires autonomous systems that can detect humans, infer navigation goals, and operate safely in dynamic environments. This paper presents HumanDiffusion, a lightweight image-conditioned diffusion planner that generates human-aware navigation trajectories directly from RGB imagery. The system combines YOLO-11--based human detection with diffusion-driven trajectory generation, enabling a quadrotor to approach a target person and deliver medical assistance without relying on prior maps or computationally intensive planning pipelines. Trajectories are predicted in pixel space, ensuring smooth motion and a consistent safety margin around humans. We evaluate HumanDiffusion in simulation and real-world indoor mock-disaster scenarios. On a 300-sample test set, the model achieves a mean squared error of 0.02 in pixel-space trajectory reconstruction. Real-world experiments demonstrate an overall mission success rate of 80% across accident-response and search-and-locate tasks with partial occlusions. These results indicate that human-conditioned diffusion planning offers a practical and robust solution for human-aware UAV navigation in time-critical assistance settings."
  },
  {
    "date": "2026-01-21",
    "title": "Pristine and Doped MoS2 Monolayers as Potential HCN Gas Sensors: A DFT Study",
    "authors": "Neeraj Thakur, Anjna Bhardwaj, Arun Kumar, Amarjeet Singh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14972v1",
    "source": "arXiv",
    "abstract": "Two-dimensional transition metal dichalcogenides (TMDCs) have been extensively investigated due to their tunable properties. In this work, density functional theory (DFT) is employed to investigate the adsorption behavior and sensing characteristics of HCN on pristine and doped MoS2 monolayers (X-MoS2, where X = P, N, Si, Al, B, Cl). The structural, electronic, and optical characteristics of all systems are examined to study the sensing properties of various doped MoS2 monolayers. In particular, the Al-MoS2 system demonstrates the strongest adsorption characterized by chemisorption, while the remaining systems show interactions of physisorption type. Recovery time and changes in electronic and optical properties reveal that Si-MoS2 possesses an ultrafast response of the order of microseconds, while Al-MoS2 exhibits a significantly longer recovery time, making it unsuitable for reusable sensors. P-MoS2, Si-MoS2, and Al-MoS2 monolayers show pronounced changes in their properties after HCN adsorption. To explore tunability in adsorption strength and recovery behavior, systems with two and three dopant atoms are further studied for P, Si, and Al doping. The results indicate that double doping enhances adsorption strength, whereas triple symmetric doping weakens it. Based on adsorption energy, recovery time, and electronic response, 2P-MoS2 and 3Al-MoS2 are identified as promising candidates for electrochemical and chemiresistive sensing of HCN. Additionally, the observed optical response in the ultraviolet region highlights their potential in UV-range optical sensor design."
  },
  {
    "date": "2026-01-21",
    "title": "Fine-Grained Traceability for Transparent ML Pipelines",
    "authors": "Liping Chen, Mujie Liu, Haytham Fayek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14971v1",
    "source": "arXiv",
    "abstract": "Modern machine learning systems are increasingly realised as multistage pipelines, yet existing transparency mechanisms typically operate at a model level: they describe what a system is and why it behaves as it does, but not how individual data samples are operationally recorded, tracked, and verified as they traverse the pipeline. This absence of verifiable, sample-level traceability leaves practitioners and users unable to determine whether a specific sample was used, when it was processed, or whether the corresponding records remain intact over time. We introduce FG-Trac, a model-agnostic framework that establishes verifiable, fine-grained sample-level traceability throughout machine learning pipelines. FG-Trac defines an explicit mechanism for capturing and verifying sample lifecycle events across preprocessing and training, computes contribution scores explicitly grounded in training checkpoints, and anchors these traces to tamper-evident cryptographic commitments. The framework integrates without modifying model architectures or training objectives, reconstructing complete and auditable data-usage histories with practical computational overhead. Experiments on a canonical convolutional neural network and a multimodal graph learning pipeline demonstrate that FG-Trac preserves predictive performance while enabling machine learning systems to furnish verifiable evidence of how individual samples were used and propagated during model execution."
  },
  {
    "date": "2026-01-21",
    "title": "Beyond directions: Rotation sets for triaxial diffusion encoding by geometric filter optimization (GFO)",
    "authors": "Sune Nørhøj Jespersen, Filip Szczepankiewicz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14970v1",
    "source": "arXiv",
    "abstract": "Purpose: We aim to improve the accuracy of the diffusion-weighted powder average signal for diffusion encoding with arbitrary shape. This enables a categorical improvement in all quantification based on, for example, tensor-valued diffusion encoding at no additional cost to acquisition time. Methods: We propose a method to generate optimal rotation sets that are applied to the diffusion encoding gradient waveform to yield powder averages with maximal accuracy. The method, termed ``Geometric Filter Optimization'' (GFO), amounts to designing an appropriate sampling filter which is approximately flat in the relevant part of the associated frequency space. We characterize the filter properties and benchmark the performance in terms of the accuracy and precision of powder averages and higher order rotational invariants. Results: GFO filters were found to have much smaller spectral leakage than other designs. We found that GFO leads to marked improvements in precision and accuracy in powder averaging over generic diffusion encoding objects, and similarly in higher order rotational invariants, although for sufficiently high $b$ and $N$, accuracy, but not precision, deteriorated compared to electrostatic repulsion. Conclusion: GFO provides an efficient recipe for obtaining orientations for powder averaging of signals with non-axisymmetric diffusion encoding. It places no additional demands on gradient system performance and can be used to shorten scan time."
  },
  {
    "date": "2026-01-21",
    "title": "Power-Law Scaling in the Classification Performance of Small-Scale Spiking Neural Networks",
    "authors": "Zhengdi Zhang, Cong Han, Wenjun Xia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14961v1",
    "source": "arXiv",
    "abstract": "This paper investigates the classification capability of small-scale spiking neural networks based on the Leaky Integrate-and-Fire (LIF) neuron model. We analyze the relationship between classification accuracy and three factors: the number of neurons, the number of stimulus nodes, and the number of classification categories. Notably, we employ a large language model (LLM) to assist in discovering the underlying functional relationships among these variables, and compare its performance against traditional methods such as linear and polynomial fitting. Experimental results show that classification accuracy follows a power-law scaling primarily with the number of categories, while the effects of neuron count and stimulus nodes are relatively minor. A key advantage of the LLM-based approach is its ability to propose plausible functional forms beyond pre-defined equation templates, often leading to more concise or accurate mathematical descriptions of the observed scaling laws. This finding has important implications for understanding efficient computation in biological neural systems and for pioneering new paradigms in AI-aided scientific discovery."
  },
  {
    "date": "2026-01-21",
    "title": "Towards Holistic Modeling for Video Frame Interpolation with Auto-regressive Diffusion Transformers",
    "authors": "Xinyu Peng, Han Li, Yuyang Huang, Ziyang Zheng, Yaoming Wang, Xin Chen, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14959v1",
    "source": "arXiv",
    "abstract": "Existing video frame interpolation (VFI) methods often adopt a frame-centric approach, processing videos as independent short segments (e.g., triplets), which leads to temporal inconsistencies and motion artifacts. To overcome this, we propose a holistic, video-centric paradigm named \\textbf{L}ocal \\textbf{D}iffusion \\textbf{F}orcing for \\textbf{V}ideo \\textbf{F}rame \\textbf{I}nterpolation (LDF-VFI). Our framework is built upon an auto-regressive diffusion transformer that models the entire video sequence to ensure long-range temporal coherence. To mitigate error accumulation inherent in auto-regressive generation, we introduce a novel skip-concatenate sampling strategy that effectively maintains temporal stability. Furthermore, LDF-VFI incorporates sparse, local attention and tiled VAE encoding, a combination that not only enables efficient processing of long sequences but also allows generalization to arbitrary spatial resolutions (e.g., 4K) at inference without retraining. An enhanced conditional VAE decoder, which leverages multi-scale features from the input video, further improves reconstruction fidelity. Empirically, LDF-VFI achieves state-of-the-art performance on challenging long-sequence benchmarks, demonstrating superior per-frame quality and temporal consistency, especially in scenes with large motion. The source code is available at https://github.com/xypeng9903/LDF-VFI."
  },
  {
    "date": "2026-01-21",
    "title": "TempViz: On the Evaluation of Temporal Knowledge in Text-to-Image Models",
    "authors": "Carolin Holtermann, Nina Krebs, Anne Lauscher",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14951v1",
    "source": "arXiv",
    "abstract": "Time alters the visual appearance of entities in our world, like objects, places, and animals. Thus, for accurately generating contextually-relevant images, knowledge and reasoning about time can be crucial (e.g., for generating a landscape in spring vs. in winter). Yet, although substantial work exists on understanding and improving temporal knowledge in natural language processing, research on how temporal phenomena appear and are handled in text-to-image (T2I) models remains scarce. We address this gap with TempViz, the first data set to holistically evaluate temporal knowledge in image generation, consisting of 7.9k prompts and more than 600 reference images. Using TempViz, we study the capabilities of five T2I models across five temporal knowledge categories. Human evaluation shows that temporal competence is generally weak, with no model exceeding 75% accuracy across categories. Towards larger-scale studies, we also examine automated evaluation methods, comparing several established approaches against human judgments. However, none of these approaches provides a reliable assessment of temporal cues - further indicating the pressing need for future research on temporal knowledge in T2I."
  },
  {
    "date": "2026-01-21",
    "title": "Spin Fluctuations in the Rare-Earth Doped Bilayer Nickelates",
    "authors": "Honglin Zhou, Xinman Ye, Gang Wang, Devashibhai Adroja, David Tam, Michael Marek Koza, Zhilun Lu, Jinguang Cheng, Dao-Xin Yao, Huiqian Luo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14946v1",
    "source": "arXiv",
    "abstract": "Spin fluctuations have been generally believed as the pairing glue of high-$T_c$ superconductivity. Recent inelastic neutron scattering (INS) studies have revealed a weak flat spin-fluctuation signal around 45 meV in the bilayer nickelate La$_3$Ni$_2$O$_{7-δ}$, suggesting strong interlayer and weak intralayer magnetic couplings ($SJ_{\\perp}\\approx$ 60 meV, $SJ_{\\parallel}\\leq$ 3.5 meV) in contrast to cuprate and pnictide superconductors. Here, we report further INS studies on the Pr and Nd doped La$_3$Ni$_2$O$_{7-δ}$ powder samples at ambient pressure. Besides the crystalline electric field excitations at low energies, we have found that the 45 meV flat mode splits into two modes in doped compounds, along with another weak mode at about 60 meV, where the spin fluctuations in La$_2$NdNi$_2$O$_{7-δ}$ are stronger than La$_3$Ni$_2$O$_{7-δ}$ and La$_2$PrNi$_2$O$_{7-δ}$. Based on an effective Heisenberg model by only considering the nearest-neighbor exchange couplings on the stripe-type antiferromagnetic orders, we conclude that the interlayer coupling $SJ_{\\perp}$ is enhanced to about 69 meV and 73 meV for Pr and Nd doped samples, respectively. Our results highlight the crucial role of interlayer coupling in the rare-earth doped bilayer nickelates, which towards to promote high $T_c$ via interlayer $s\\pm$ pairing."
  },
  {
    "date": "2026-01-21",
    "title": "Designing DNA nanostar hydrogels with programmable degradation and antibody release",
    "authors": "Giorgia Palombo, Christine A. Merrick, Jennifer Harnett, Susan Rosser, Davide Michieletto, Yair Augusto Gutiérrez Fosado",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14934v1",
    "source": "arXiv",
    "abstract": "DNA nanostar (DNAns) hydrogels are promising materials for in vivo applications, including tissue regeneration and drug and antibody delivery. However, a systematic and quantitative understanding of the design principles controlling their degradation is lacking. Here, we investigate hydrogels made of three-armed DNAns with varying flexible joints, arm lengths, and mesh sizes and use restriction enzymes to cut the DNAns structures while monitoring the gel's degradation. We discover that (i) removing flexible joints, (ii) increasing arm length, or (iii) relocating the RE site along a DNA linker markedly accelerates hydrogel degradation. In contrast, non-specific endonucleases, e.g. DNaseI, quicly degrade DNAns hydrogels regardless of design. Importantly, the release of antibodies from DNAns hydrogels can be modulated by the action of different enzymes, confirming that programmable degradation can be leveraged for responsive drug-delivery systems. These findings provide a better understanding of the design principles for DNAns-based scaffolds with tunable degradation, cargo release, and responsive rheology."
  },
  {
    "date": "2026-01-21",
    "title": "Barycenters in Disintegrated optimal transport",
    "authors": "Jun Kitagawa, Asuka Takatsu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14928v1",
    "source": "arXiv",
    "abstract": "We prove existence and duality on a wide class of metric spaces, and uniqueness results on any connected, complete Riemannian manifold, with or without boundary, for classical Monge--Kantorovich barycenters. In particular, this is the first and only uniqueness result with no restriction on the geometry of the manifold aside from connectedness and completeness. We obtain these via the corresponding results for barycenter problems associated to a new two-parameter family of metrics on probability measures on a general metric fiber bundle, called the $\\textit{disintegrated Monge--Kantorovich metrics}$ (previously introduced by the authors)."
  },
  {
    "date": "2026-01-21",
    "title": "Ring oscillator performance of the ATLAS inner tracker pixel readout chip",
    "authors": "Yahya Khwaira, Abdenour Lounis, Maurice Cohen-Solal, Mohsine Menouni, Pierre Barrillon, Denis Fougeron",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14924v1",
    "source": "arXiv",
    "abstract": "This paper presents experimental and simulation data to characterize the Ring Oscillators (RO) produced in 65-nm CMOS technology for the next promising generation of readout chips for the pixel detector in the Inner Tracker (ITk) at the ATLAS experiment at CERN. To enable a better understanding of the RO block embedded in ITkPixV1.1 single chip card (SCC), tests at various temperatures, voltages, accumulated total ionizing dose (TID) with X-ray irradiation, and high-temperature annealing will be presented. The objective of this study is to examine the RO output dependency based on different variable conditions and provide simulation data using Cadence, an electronic design automation (EDA) software to validate the experimental outcomes."
  },
  {
    "date": "2026-01-21",
    "title": "Energy-Selective Complete Spin Polarization in an Extended Su-Schrieffer-Heeger Ferromagnetic Chain",
    "authors": "Souvik Roy, Ranjini Bhattacharya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14919v1",
    "source": "arXiv",
    "abstract": "We study spin-dependent transport in an extended Su-Schrieffer-Heeger chain with cosine modulated nearest- and next-nearest-neighbor hopping using the nonequilibrium Green's function formalism. Suitable tuning of the hopping parameters yields a complete separation of spin channels and perfect spin polarization over broad energy windows. The inclusion of next-nearest-neighbor hopping enhances both tunability and robustness, while systematic phase-diagram analyses reveal quantized polarization across extended regions of parameter space rather than at isolated fine-tuned points. These characteristics persist for larger system sizes, establishing the extended SSH model as a versatile platform for controllable spin-polarized transport."
  },
  {
    "date": "2026-01-21",
    "title": "CodeDelegator: Mitigating Context Pollution via Role Separation in Code-as-Action Agents",
    "authors": "Tianxiang Fei, Cheng Chen, Yue Pan, Mao Zheng, Mingyang Song",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14914v1",
    "source": "arXiv",
    "abstract": "Recent advances in large language models (LLMs) allow agents to represent actions as executable code, offering greater expressivity than traditional tool-calling. However, real-world tasks often demand both strategic planning and detailed implementation. Using a single agent for both leads to context pollution from debugging traces and intermediate failures, impairing long-horizon performance. We propose CodeDelegator, a multi-agent framework that separates planning from implementation via role specialization. A persistent Delegator maintains strategic oversight by decomposing tasks, writing specifications, and monitoring progress without executing code. For each sub-task, a new Coder agent is instantiated with a clean context containing only its specification, shielding it from prior failures. To coordinate between agents, we introduce Ephemeral-Persistent State Separation (EPSS), which isolates each Coder's execution state while preserving global coherence, preventing debugging traces from polluting the Delegator's context. Experiments on various benchmarks demonstrate the effectiveness of CodeDelegator across diverse scenarios."
  },
  {
    "date": "2026-01-21",
    "title": "MIGHTEE: The evolving radio luminosity functions of star-forming galaxies to $z\\sim 4.5$ and the cosmic history of star formation",
    "authors": "Nijin J. Thykkathu, Matt J. Jarvis, Imogen H. Whittam, C. L. Hale, A. M. Matthews, I. Heywood, Eliab Malefahlo, R. G. Varadaraj, N. Stylianou, Chris Pearson, Nick Seymour, Mattia Vaccari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14913v1",
    "source": "arXiv",
    "abstract": "A key question in extragalactic astronomy is how the star-formation rate density (SFRD) evolves over cosmic time. A powerful way of addressing this question is using radio-continuum observations, where the radio waves are unaffected by dust and are able to reach sufficient resolution to resolve individual galaxies. We present an investigation of the 1.4 GHz radio luminosity functions (RLFs) of star-forming galaxies (SFGs) and Active Galactic Nuclei (AGN) using deep radio continuum observations in the COSMOS and XMM-LSS fields, covering a combined area of $\\sim 4\\,\\mathrm{deg}^2$. These data enable the most accurate measurement of the evolution in the SFRD from mid-frequency radio continuum observations. We model the total RLF as the sum of evolving SFG and AGN components, negating the need for individual source classification. We find that the SFGs have systematically higher space densities at fixed luminosity than found in previous radio studies, but consistent with more recent studies with MeerKAT. We attribute this to the excellent low-surface brightness sensitivity of MeerKAT. We then determine the evolution of the SFRD. Adopting the far-infrared - radio correlation results in a significantly higher the SFRD at $z > 1$, compared to combined UV and far-infrared measurements. However, using more recent relations for the correlation between star-formation rate and radio luminosity, based on full spectral energy distribution modelling, can resolve this apparent discrepancy. Thus radio observations provide a powerful method of determining the total SFRD, in the absence of dust-sensitive far-infrared data."
  },
  {
    "date": "2026-01-21",
    "title": "AlertGuardian: Intelligent Alert Life-Cycle Management for Large-scale Cloud Systems",
    "authors": "Guangba Yu, Genting Mai, Rui Wang, Ruipeng Li, Pengfei Chen, Long Pan, Ruijie Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14912v1",
    "source": "arXiv",
    "abstract": "Alerts are critical for detecting anomalies in large-scale cloud systems, ensuring reliability and user experience. However, current systems generate overwhelming volumes of alerts, degrading operational efficiency due to ineffective alert life-cycle management. This paper details the efforts of Company-X to optimize alert life-cycle management, addressing alert fatigue in cloud systems. We propose AlertGuardian, a framework collaborating large language models (LLMs) and lightweight graph models to optimize the alert life-cycle through three phases: Alert Denoise uses graph learning model with virtual noise to filter noise, Alert Summary employs Retrieval Augmented Generation (RAG) with LLMs to create actionable summary, and Alert Rule Refinement leverages multi-agent iterative feedbacks to improve alert rule quality. Evaluated on four real-world datasets from Company-X's services, AlertGuardian significantly mitigates alert fatigue (94.8\\% alert reduction ratios) and accelerates fault diagnosis (90.5\\% diagnosis accuracy). Moreover, AlertGuardian improves 1,174 alert rules, with 375 accepted by SREs (32% acceptance rate). Finally, we share success stories and lessons learned about alert life-cycle management after the deployment of AlertGuardian in Company-X."
  },
  {
    "date": "2026-01-21",
    "title": "Banach algebra crossed products by inverse semigroup actions",
    "authors": "K. Bardadyn, B. K. Kwaśniewski",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14907v1",
    "source": "arXiv",
    "abstract": "We give a self-contained and simplified presentation of the theory of covariant representations for inverse semigroup actions on Banach algebras, which was recently introduced in the authors and A. Mckee in the twisted case. The main result of this note is a general universal description of the associated Banach algebra crossed product, that allows disintegration of all representations of the crossed product. Such a disintegration was studied so far only for actions on spaces."
  },
  {
    "date": "2026-01-21",
    "title": "The eJWST active galactic nucleus observation catalogue",
    "authors": "Virginia Lenk, Alvaro Labiano, Chiara Circosta, Almudena Alonso-Herrero, Dominika Wylezalek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14905v1",
    "source": "arXiv",
    "abstract": "Context. The European Archive of the James Webb Space Telescope (eJWST) provides access to all data collected by the James Webb Space Telescope (JWST). JWST's capabilities span from studying early universe galaxy formation to probing exoplanet atmospheres. Specifically, for Active Galactic Nuclei (AGN), JWST offers unparalleled opportunities, enabling investigation into AGN phenomena with unprecedented detail through high-resolution imaging, spectroscopy, and photometric data. Aims. This study aims to compile and release a catalogue of all AGN observations conducted with JWST. Using eJWST, we systematically filter and organize these observations to facilitate access and retrieval of all of JWST's data products related to AGNs. Our goal is to provide the community with a valuable resource for their research. Methods. We compiled the AGN observations in eJWST using specific keywords set by the principal investigators in their proposals, manually reviewing the approved programs of JWST, as well as cross-matching all available observations with available AGN catalogues such as the Million Quasar catalogue, the SDSS MaNGA AGN catalogue, the CDFS catalogue, and others. Results. The resulting catalogue contains a total of 3,242 individual AGNs included in JWST observations. This is one of the first extensive collections of AGN observations from the JWST. It includes detailed information about the targets (name, coordinates, redshift), specifics of the JWST observations (instrument, aperture, filter, etc.), and provides links for data downloads."
  },
  {
    "date": "2026-01-21",
    "title": "On the maximum density of a matrix and a transcendental Turán-type density",
    "authors": "Raphael Yuster",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14904v1",
    "source": "arXiv",
    "abstract": "We prove that the inducibility of $P_4$ in ordered monotone balanced bipartite graphs is $2/e^2$, establishing the smallest known graph with transcendental Turán-type density. Moreover, the limit object is a binary graphon, so it generates a deterministic model. This is a special case of a more general framework addressed here -- the asymptotic maximum density of a constant matrix over an arbitrary symbol set, in a large, possibly monotone, matrix. We solve all $2 \\times 2$ monotone cases (one of which corresponds to the aforementioned $P_4$) and all but one of the $2 \\times 2$ unrestricted cases. While $(h!/h^h)^2$ is a lower bound for the asymptotic maximum density of an $h \\times h$ matrix, we explicitly construct, for all $h \\ge 1$, an $h \\times h$ minimizer, i.e., a matrix for which this bound is attained. We also sketch how known results on the inducibility of graphs can be modified to show that, as $h$ grows, almost all $h \\times h$ $0/1$ matrices are minimizers."
  },
  {
    "date": "2026-01-21",
    "title": "Precisely positioned generation of CsPbBr3 nano-light sources in a Cs4PbBr6 film by electron beam irradiation",
    "authors": "Tomoyasu Fujimaru, Kanta Hirai, Masato Inamata, Hiromu Tanaka, Midori Ikeuchi, Hidehiro Yamashita, Mitsutaka Haruta, Takehiko Tamaoka, Naohiko Kawasaki, Hikaru Saito",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14898v1",
    "source": "arXiv",
    "abstract": "Integration of high-quality photon emitters at specific locations within nanophotonic structures or optoelectronic devices is a key to innovating on-chip optical control and quantum technologies. Halide perovskite nanoparticles have great potential as single photon emitters with high quantum efficiency. To achieve their full potential, they must be embedded in a host material that ensures chemical stability and passivates surface defects. A previous experiment on a CsPbBr3-Cs4PbBr6 nanocomposite film suggested possibility that electron beam irradiation can be used to control positions of CsPbBr3 nano-light sources in the Cs4PbBr6 host although the effects of electron beam irradiation are not fully understood. Here, we fabricate a Cs4PbBr6-CsBr film, not containing the CsPbBr3 phase, and provide direct evidence that CsPbBr3 nanoparticles can be locally generated in the Cs4PbBr6 host by irradiation with a focused electron beam. We further demonstrate perovskite nano-light source arrays with submicron spacing using this method."
  },
  {
    "date": "2026-01-21",
    "title": "Some properties of a production function",
    "authors": "Constantin Chilarescu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14893v1",
    "source": "arXiv",
    "abstract": "We examine the new production function developed by Chilarescu, and prove that under certain restrictions, the values of the elasticity can also be less than one. We will also prove that under certain restrictions on the parameters, the production function satisfies the Inada conditions."
  },
  {
    "date": "2026-01-21",
    "title": "Helmholtz transmission problem and intrinsic impedance scattering problem on extension domains",
    "authors": "Gabriel Claret",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14866v1",
    "source": "arXiv",
    "abstract": "We consider a transmission problem for the Helmholtz equation across the boundary of an extension domain. A such boundary can be Lipschitz, fractal, or of varying Hausdorff dimension for instance. We generalise the notions of layer potential and Neumann-Poincar{é} operators, and of Calder{ó}n projectors in that context. Those boundary operators allow to connect the transmission problem (on the whole space) to one-sided problems -- notably, scattering problems -- with Dirichlet, Neumann and Robin boundary conditions. Since an extension domain needs no specific boundary measure, the Robin (impedance) condition is not understood in a boundary L^2-type space, rather by duality on the trace space itself. We discuss the well-posedness of the impedance scattering problem in that framework and compare to the classical L^2 setting. Our analysis allows to generalise optimisation results for acoustic scattering when the obstacle is an extension domain in any dimension."
  },
  {
    "date": "2026-01-21",
    "title": "Understanding Usefulness in Developer Explanations on Stack Overflow",
    "authors": "Martin Obaidi, Kushtrim Qengaj, Hannah Deters, Jakob Droste, Marc Herrmann, Kurt Schneider, Jil Klünder",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14865v1",
    "source": "arXiv",
    "abstract": "Explanations are essential in software engineering (SE) and requirements communication, helping stakeholders clarify ambiguities, justify design choices, and build shared understanding. Online Q&A forums such as Stack Overflow provide large-scale settings where such explanations are produced and evaluated, offering valuable insights into what makes them effective. While prior work has explored answer acceptance and voting behavior, little is known about which specific features make explanations genuinely useful. The relative influence of structural, contextual, and linguistic factors, such as content richness, timing, and sentiment, remains unclear. We analyzed 3,323 questions and 59,398 answers from Stack Overflow, combining text analysis and statistical modeling to examine how explanation attributes relate to perceived usefulness (normalized upvotes). Structural and contextual factors, especially explanation length, code inclusion, timing, and author reputation, show small to moderate positive effects. Sentiment polarity has negligible influence, suggesting that clarity and substance outweigh tone in technical communication. This study provides an empirical account of what drives perceived usefulness in developer explanations. It contributes methodological transparency through open data and replication materials, and conceptual insight by relating observed communication patterns to principles of requirements communication. The findings offer evidence-based implications for how developers and RE practitioners can craft clearer and more effective explanations, potentially supporting fairer communication in both open and organizational contexts. From an RE perspective, these determinants can be interpreted as practical signals for ambiguity reduction and rationale articulation in day-to-day requirements communication."
  },
  {
    "date": "2026-01-21",
    "title": "Modeling X-ray reflection spectra from returning radiation: application to 4U 1630$-$47",
    "authors": "Kostas Kourmpetis, Shafqat Riaz, Honghui Liu, Temurbek Mirzaev, Cosimo Bambi, Debtroy Das, Jiachen Jiang, Kostas D. Kokkotas, Andrea Santangelo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14860v1",
    "source": "arXiv",
    "abstract": "Returning radiation is thought to play a key role in disk illumination of black hole X-ray binaries in the high-soft state, yet it has not been fully incorporated into XSPEC reflection models. We present a new table model for reflection spectroscopy that, for the first time, self-consistently accounts for the returning radiation. To isolate this effect, we adopt the standard disk-corona configuration but disable the corona, allowing the reflection spectrum to be produced solely by self-irradiation of the disk. Applying our model to the black hole X-ray binary 4U 1630$-$47, we report a rapidly spinning black hole ($a_* \\sim 0.99$), a disk inclination of $i \\sim 53^\\circ$, a mass accretion rate of $\\dot{M}_{\\rm BH} \\sim 15\\% \\, {\\rm \\dot{M}_{Edd}}$, and an electron density of $n_{\\rm e} \\sim 10^{21} \\,\\mathrm{cm^{-3}}$ to reproduce the observed reflection features. The model also yields a source distance of $D\\sim 8.2 \\, {\\rm kpc}$, slightly below the commonly adopted value of $10 \\, {\\rm kpc}$ in the literature. Compared to the widely used relxillNS, our model naturally produces a harder high-energy reflection spectrum, fitting the data without invoking a Comptonized component."
  },
  {
    "date": "2026-01-21",
    "title": "Adaptive Exponential Integration for Stable Gaussian Mixture Black-Box Variational Inference",
    "authors": "Baojun Che, Yifan Chen, Daniel Zhengyu Huang, Xinying Mao, Weijie Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14855v1",
    "source": "arXiv",
    "abstract": "Black-box variational inference (BBVI) with Gaussian mixture families offers a flexible approach for approximating complex posterior distributions without requiring gradients of the target density. However, standard numerical optimization methods often suffer from instability and inefficiency. We develop a stable and efficient framework that combines three key components: (1) affine-invariant preconditioning via natural gradient formulations, (2) an exponential integrator that unconditionally preserves the positive definiteness of covariance matrices, and (3) adaptive time stepping to ensure stability and to accommodate distinct warm-up and convergence phases. The proposed approach has natural connections to manifold optimization and mirror descent. For Gaussian posteriors, we prove exponential convergence in the noise-free setting and almost-sure convergence under Monte Carlo estimation, rigorously justifying the necessity of adaptive time stepping. Numerical experiments on multimodal distributions, Neal's multiscale funnel, and a PDE-based Bayesian inverse problem for Darcy flow demonstrate the effectiveness of the proposed method."
  },
  {
    "date": "2026-01-21",
    "title": "Beyond Carr Madan: A Projection Approach to Risk-Neutral Moment Estimation",
    "authors": "Tjeerd De Vries",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14852v1",
    "source": "arXiv",
    "abstract": "We propose a projection method to estimate risk-neutral moments from option prices. We derive a finite-sample bound implying that the projection estimator attains (up to a constant) the smallest pricing error within the span of traded option payoffs. This finite-sample optimality is not available for the widely used Carr--Madan approximation. Simulations show sizable accuracy gains for key quantities such as VIX and SVIX. We then extend the framework to multiple underlyings, deriving necessary and sufficient conditions under which simple options complete the market in higher dimensions, and providing estimators for joint moments. In our empirical application, we recover risk-neutral correlations and joint tail risk from FX options alone, addressing a longstanding measurement problem raised by Ross (1976). Our joint tail-risk measure predicts future joint currency crashes and identifies periods in which currency portfolios are particularly useful for hedging."
  },
  {
    "date": "2026-01-21",
    "title": "Benchmarking neutrino-nucleus quasielastic scattering model predictions against a missing energy profile obtained using a monoenergetic neutrino beam",
    "authors": "Jake McKean, Laura Munteanu, Seisho Abe",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14831v1",
    "source": "arXiv",
    "abstract": "We examine three exclusive nuclear ground state shell models implemented in the NEUT neutrino event generator and benchmark them against the recent JSNS$^2$ measurement of missing energy using a monoenergetic neutrino source. The nature of the measurement allows a detailed investigation of nuclear ground-state modeling using a neutrino source, and gives access to a direct measurement of the neutron spectral function in a $^{12}$C nucleus. The NEUT intranuclear cascade and nuclear deexcitation \\textsc{NucDeEx} are used to simulate inelastic final-state interactions and nuclear deexcitations respectively. We find that the spectral function (SF) models perform better than relativistic mean field models in modeling both the ground state and the tail of the missing energy distribution when the NEUT cascade and nuclear excitation channels are turned on. We also find that taking into account the missing energy threshold for single nucleon knockout interactions results in all nuclear models being accepted based on the obtained $p$-values."
  },
  {
    "date": "2026-01-21",
    "title": "MIQCP and MISOCP-Based Solution Methods for the Multi-Layer Thin Films Problem",
    "authors": "Deniz Tuncer, Burak Kocuk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14828v1",
    "source": "arXiv",
    "abstract": "The Multi-Layer Thin Films Problem is a materials science problem that aims to enhance the reflectance of a metallic substrate by designing multi-layer coatings composed of different dielectric materials and thicknesses. While previous studies on the problem mostly rely on heuristic approaches and are designed for single wavelength applications, this work addresses the problem using global optimization techniques for multiple wavelengths. We develop an exact nonconvex mixed-integer quadratically constrained programming (MIQCP) model to solve this problem. We also develop a mixed-integer second-order cone programming relaxation that has computational advantage over the MIQCP model. Our numerical experiments yield solutions that have average reflectance of 99% over the visible spectrum (380-770 nm) and 95% over the broad spectrum (300-3000 nm)."
  },
  {
    "date": "2026-01-21",
    "title": "Measuring and Aligning Abstraction in Vision-Language Models with Medical Taxonomies",
    "authors": "Ben Schaper, Maxime Di Folco, Bernhard Kainz, Julia A. Schnabel, Cosmin I. Bercea",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14827v1",
    "source": "arXiv",
    "abstract": "Vision-Language Models show strong zero-shot performance for chest X-ray classification, but standard flat metrics fail to distinguish between clinically minor and severe errors. This work investigates how to quantify and mitigate abstraction errors by leveraging medical taxonomies. We benchmark several state-of-the-art VLMs using hierarchical metrics and introduce Catastrophic Abstraction Errors to capture cross-branch mistakes. Our results reveal substantial misalignment of VLMs with clinical taxonomies despite high flat performance. To address this, we propose risk-constrained thresholding and taxonomy-aware fine-tuning with radial embeddings, which reduce severe abstraction errors to below 2 per cent while maintaining competitive performance. These findings highlight the importance of hierarchical evaluation and representation-level alignment for safer and more clinically meaningful deployment of VLMs."
  },
  {
    "date": "2026-01-21",
    "title": "Ionization energy and electron affinity of fullerene C60 in the Hubbard model in the static fluctuation approximation",
    "authors": "Gennadiy Ivanovich Mironov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14817v1",
    "source": "arXiv",
    "abstract": "Within the Hubbard model, the ionization energy and electron affinity of the icosahedral C60 fullerene are calculated in the static fluctuation approximation. A graphical representation of the chemical potential equation is first obtained. The correlation function, which describes the transitions of π-electrons from one fullerene site to the nearest site, and the thermodynamic average, which characterizes the probability of detecting two π-electrons with oppositely oriented spin projections on a single fullerene site, are then calculated. The theoretically obtained values for the ionization energy of 7.57 eV and the electron affinity of 2.67 eV coincide with the experimentally observed values and demonstrate that, during photoionization or another process leading to either the acquisition or loss of a π-electron, the fullerene responds to external perturbations as a single system of strongly correlated π-electrons."
  },
  {
    "date": "2026-01-21",
    "title": "A Real-Space Formulation of the Zak Phase via Weyl m-Functions",
    "authors": "Habib Ammari, Clemens Thalhammer",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14816v1",
    "source": "arXiv",
    "abstract": "We establish a new, real-space formula for the Zak phase for one dimensional periodic Jacobi operators in terms of the Weyl $m_+$-function that does not rely on Floquet-Bloch theory. This novel representation highlights the dependence of the Zak phase on boundary terms. Moreover, we show how to recover the classical quantisation of the Zak phase for periodic Jacobi operators with inversion symmetric fundamental cells."
  },
  {
    "date": "2026-01-21",
    "title": "Precision measurement of the ground-state hyperfine constant for $^9Be^+$ in a linear Paul trap via magnetically insensitive hyperfine transitions",
    "authors": "Zhi-yuan Ao, Wen-li Bai, Qian-yu Zhang, Wen-cui Peng, Xin Tong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14811v1",
    "source": "arXiv",
    "abstract": "Direct measurements of the ground-state magnetically insensitive hyperfine transition |F=2,mF=0>->|F=1,mF=0> of $^9Be^+$ ions have been performed using microwave-driven state transfer. The $^9Be^+$ ions are confined and laser-cooled in a linear Paul trap, forming a Coulomb crystal. The transition frequencies have been measured over a magnetic field range of $ \\pm 0.5 mT $ centered at zero magnetic field, and the acquired data were fitted accounting for the high-order Zeeman effect. The hyperfine constant A is determined to be -625.008840(35) MHz, achieving a relative precision of $ 5.6 \\times 10^{-8}$."
  },
  {
    "date": "2026-01-21",
    "title": "Efficient Beamforming for Discrete SIM-Aided Multiuser Systems Under Statistical CSI",
    "authors": "Yuhui Jiao, Qian Zhang, Xuejun Cheng, Yunxiao Li, Yufei Zhao, Ju Liu, Yong Liang Guan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14803v1",
    "source": "arXiv",
    "abstract": "Stacked Intelligent Metasurfaces (SIM) have emerged as a revolutionary architecture for next-generation wireless communications, offering wave-domain signal processing capabilities with significantly reduced hardware complexity compared to conventional systems. However, most existing SIM research assumes continuous phase shifts and perfect instantaneous channel state information (CSI), which are impractical due to hardware discrete phase shift constraints and prohibitive pilot overhead. This paper presents a joint power allocation and discrete phase shift optimization framework for SIM-aided multiuser multiple-input single-output(MISO) downlink systems under statistical CSI. We formulate the achievable sum rate maximization problem considering practical discrete phase constraints and derive a closed-form expression for the average achievable rate under statistical CSI. To tackle the resulting non-convex optimization problem, we decouple the problem by using the weighted minimum mean square error (WMMSE) algorithm and alternating optimization (AO). Subsequently, we utilize the Lagrangian multiplier method and alternating direction method of multipliers (ADMM) to obtain closed-form iterative solutions. Our simulations demonstrate that the proposed algorithm reduces computational complexity by a factor of 50 compared to semi-definite relaxation (SDR) methods, , while maintaining over 85% of the continuous phase shift performance with only 1-bit quantization, highlighting its feasibility for low-cost hardware systems."
  },
  {
    "date": "2026-01-21",
    "title": "LocBAM: Advancing 3D Patch-Based Image Segmentation by Integrating Location Contex",
    "authors": "Donnate Hooft, Stefan M. Fischer, Cosmin Bercea, Jan C. Peeken, Julia A. Schnabel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14802v1",
    "source": "arXiv",
    "abstract": "Patch-based methods are widely used in 3D medical image segmentation to address memory constraints in processing high-resolution volumetric data. However, these approaches often neglect the patch's location within the global volume, which can limit segmentation performance when anatomical context is important. In this paper, we investigate the role of location context in patch-based 3D segmentation and propose a novel attention mechanism, LocBAM, that explicitly processes spatial information. Experiments on BTCV, AMOS22, and KiTS23 demonstrate that incorporating location context stabilizes training and improves segmentation performance, particularly under low patch-to-volume coverage where global context is missing. Furthermore, LocBAM consistently outperforms classical coordinate encoding via CoordConv. Code is publicly available at https://github.com/compai-lab/2026-ISBI-hooft"
  },
  {
    "date": "2026-01-21",
    "title": "UBATrack: Spatio-Temporal State Space Model for General Multi-Modal Tracking",
    "authors": "Qihua Liang, Liang Chen, Yaozong Zheng, Jian Nong, Zhiyi Mo, Bineng Zhong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14799v1",
    "source": "arXiv",
    "abstract": "Multi-modal object tracking has attracted considerable attention by integrating multiple complementary inputs (e.g., thermal, depth, and event data) to achieve outstanding performance. Although current general-purpose multi-modal trackers primarily unify various modal tracking tasks (i.e., RGB-Thermal infrared, RGB-Depth or RGB-Event tracking) through prompt learning, they still overlook the effective capture of spatio-temporal cues. In this work, we introduce a novel multi-modal tracking framework based on a mamba-style state space model, termed UBATrack. Our UBATrack comprises two simple yet effective modules: a Spatio-temporal Mamba Adapter (STMA) and a Dynamic Multi-modal Feature Mixer. The former leverages Mamba's long-sequence modeling capability to jointly model cross-modal dependencies and spatio-temporal visual cues in an adapter-tuning manner. The latter further enhances multi-modal representation capacity across multiple feature dimensions to improve tracking robustness. In this way, UBATrack eliminates the need for costly full-parameter fine-tuning, thereby improving the training efficiency of multi-modal tracking algorithms. Experiments show that UBATrack outperforms state-of-the-art methods on RGB-T, RGB-D, and RGB-E tracking benchmarks, achieving outstanding results on the LasHeR, RGBT234, RGBT210, DepthTrack, VOT-RGBD22, and VisEvent datasets."
  },
  {
    "date": "2026-01-21",
    "title": "RANDSMAPs: Random-Feature/multi-Scale Neural Decoders with Mass Preservation",
    "authors": "Dimitrios G. Patsatzis, Alessandro Della Pia, Lucia Russo, Constantinos Siettos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14794v1",
    "source": "arXiv",
    "abstract": "We introduce RANDSMAPs (Random-feature/multi-scale neural decoders with Mass Preservation), numerical analysis-informed, explainable neural decoders designed to explicitly respect conservation laws when solving the challenging ill-posed pre-image problem in manifold learning. We start by proving the equivalence of vanilla random Fourier feature neural networks to Radial Basis Function interpolation and the double Diffusion Maps (based on Geometric Harmonics) decoders in the deterministic limit. We then establish the theoretical foundations for RANDSMAP and introduce its multiscale variant to capture structures across multiple scales. We formulate and derive the closed-form solution of the corresponding constrained optimization problem and prove the mass preservation property. Numerically, we assess the performance of RANDSMAP on three benchmark problems/datasets with mass preservation obtained by the Lighthill-Whitham-Richards traffic flow PDE with shock waves, 2D rotated MRI brain images, and the Hughes crowd dynamics PDEs. We demonstrate that RANDSMAPs yield high reconstruction accuracy at low computational cost and maintain mass conservation at single-machine precision. In its vanilla formulation, the scheme remains applicable to the classical pre-image problem, i.e., when mass-preservation constraints are not imposed."
  },
  {
    "date": "2026-01-21",
    "title": "Robustness of Mixtures of Experts to Feature Noise",
    "authors": "Dong Sun, Rahul Nittala, Rebekka Burkholz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14792v1",
    "source": "arXiv",
    "abstract": "Despite their practical success, it remains unclear why Mixture of Experts (MoE) models can outperform dense networks beyond sheer parameter scaling. We study an iso-parameter regime where inputs exhibit latent modular structure but are corrupted by feature noise, a proxy for noisy internal activations. We show that sparse expert activation acts as a noise filter: compared to a dense estimator, MoEs achieve lower generalization error under feature noise, improved robustness to perturbations, and faster convergence speed. Empirical results on synthetic data and real-world language tasks corroborate the theoretical insights, demonstrating consistent robustness and efficiency gains from sparse modular computation."
  },
  {
    "date": "2026-01-21",
    "title": "CI4A: Semantic Component Interfaces for Agents Empowering Web Automation",
    "authors": "Zhi Qiu, Jiazheng Sun, Chenxiao Xia, Jun Zheng, Xin Peng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14790v1",
    "source": "arXiv",
    "abstract": "While Large Language Models demonstrate remarkable proficiency in high-level semantic planning, they remain limited in handling fine-grained, low-level web component manipulations. To address this limitation, extensive research has focused on enhancing model grounding capabilities through techniques such as Reinforcement Learning. However, rather than compelling agents to adapt to human-centric interfaces, we propose constructing interaction interfaces specifically optimized for agents. This paper introduces Component Interface for Agent (CI4A), a semantic encapsulation mechanism that abstracts the complex interaction logic of UI components into a set of unified tool primitives accessible to agents. We implemented CI4A within Ant Design, an industrial-grade front-end framework, covering 23 categories of commonly used UI components. Furthermore, we developed a hybrid agent featuring an action space that dynamically updates according to the page state, enabling flexible invocation of available CI4A tools. Leveraging the CI4A-integrated Ant Design, we refactored and upgraded the WebArena benchmark to evaluate existing SoTA methods. Experimental results demonstrate that the CI4A-based agent significantly outperforms existing approaches, achieving a new SoTA task success rate of 86.3%, alongside substantial improvements in execution efficiency."
  },
  {
    "date": "2026-01-21",
    "title": "The Intermediate-Mass Black Hole Reverberation Mapping Project: Stable Optical Continuum Lags of an IMBH in the Dwarf Galaxy NGC 4395 Over Years",
    "authors": "Yu Pan, Hengxiao Guo, Chenxu Liu, Xinlei Chen, Yuan Fang, Jinghua Zhang, Wenwen Zuo, Philip G. Edwards, Jamie Stevens, Manqi Fu, Mouyuan Sun, Zhen-yi Cai, Guowang Du, Xingzhu Zou, Tao Wang, Xufeng Zhu, Xiangkun Liu, Xiaowei Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14787v1",
    "source": "arXiv",
    "abstract": "NGC 4395 is a nearby dwarf spiral galaxy hosting an active galactic nucleus (AGN) powered by an intermediate-mass black hole (IMBH, $M_{\\rm BH} \\sim 10^{4-5}\\,M_\\odot$). Recent optical continuum reverberation mapping studies have suggested potential lag variations between different epochs, offering important clues to the physical mechanisms governing variability in the vicinity of the central black hole. We present continuous intranight multi-band photometric monitoring of NGC 4395 based on three nights of observations with the Faulkes Telescope North and two nights with the Mephisto telescope. This represents the first systematic investigation of optical continuum lag stability in a robustly confirmed IMBH. By applying difference-imaging techniques to both the new observations and archival data, we significantly detect the optical inter-band lags of $\\sim$5-15 minutes, which increase monotonically with wavelength. No obvious $u$-band lag excess is observed, implying a negligible fractional contribution from diffuse continuum (DC) emission to the optical continuum, in agreement with our spectral decomposition results. Remarkably, the inter-band lags remain stable over multi-year baselines. We attribute this long-term lag stability primarily to the minor DC contribution, a relatively steady disk-corona structure, and the unusually high X-ray-to-optical luminosity ratio characteristic of low-luminosity AGNs, which likely allows X-ray reprocessing to dominate over other potential variability mechanisms. Future facilities like Gemini/SCORPIO, with its simultaneous optical-to-near-infrared coverage, will be ideally suited to play an important role in advancing this field."
  },
  {
    "date": "2026-01-21",
    "title": "RECAP: Resistance Capture in Text-based Mental Health Counseling with Large Language Models",
    "authors": "Anqi Li, Yuqian Chen, Yu Lu, Zhaoming Chen, Yuan Xie, Zhenzhong Lan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14780v1",
    "source": "arXiv",
    "abstract": "Recognizing and navigating client resistance is critical for effective mental health counseling, yet detecting such behaviors is particularly challenging in text-based interactions. Existing NLP approaches oversimplify resistance categories, ignore the sequential dynamics of therapeutic interventions, and offer limited interpretability. To address these limitations, we propose PsyFIRE, a theoretically grounded framework capturing 13 fine-grained resistance behaviors alongside collaborative interactions. Based on PsyFIRE, we construct the ClientResistance corpus with 23,930 annotated utterances from real-world Chinese text-based counseling, each supported by context-specific rationales. Leveraging this dataset, we develop RECAP, a two-stage framework that detects resistance and fine-grained resistance types with explanations. RECAP achieves 91.25% F1 for distinguishing collaboration and resistance and 66.58% macro-F1 for fine-grained resistance categories classification, outperforming leading prompt-based LLM baselines by over 20 points. Applied to a separate counseling dataset and a pilot study with 62 counselors, RECAP reveals the prevalence of resistance, its negative impact on therapeutic relationships and demonstrates its potential to improve counselors' understanding and intervention strategies."
  },
  {
    "date": "2026-01-21",
    "title": "How high-resolution agent-based models can improve fundamental insights in tissue development and cell culturing methods",
    "authors": "Paul Van Liedekerke, Jiří Pešek, Kevin Alessandri, Dirk Drasdo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15273v1",
    "source": "arXiv",
    "abstract": "The fundamental understanding of how cells physically interact with each other and their environment is key to understanding their organisation in living tissues. Over the past decades several computational methods have been developed to decipher emergent multi-cellular behaviors. In particular agent-based (or cell-based) models that consider the individual cell as basic modeling unit tracked in space and time enjoy increasing interest across scientific communities. In this article we explore a particular class of cell-based models, so-called Deformable Cell Models (DCMs), that allow to simulate the biophysics of the cell with high realism. After situating this model among other model types, We give an overview of past and recent DCM developments and discuss new simulation results of several applications covering in-vitro and in-vivo systems. Our goal is to demonstrate how such models can generate quantitative added value in biological and biotechnological problems."
  },
  {
    "date": "2026-01-21",
    "title": "Lightweight LLMs for Network Attack Detection in IoT Networks",
    "authors": "Piyumi Bhagya Sudasinghe, Kushan Sudheera Kalupahana Liyanage, Harsha S. Gardiyawasam Pussewalage",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15269v1",
    "source": "arXiv",
    "abstract": "The rapid growth of Internet of Things (IoT) devices has increased the scale and diversity of cyberattacks, exposing limitations in traditional intrusion detection systems. Classical machine learning (ML) models such as Random Forest and Support Vector Machine perform well on known attacks but require retraining to detect unseen or zero-day threats. This study investigates lightweight decoder-only Large Language Models (LLMs) for IoT attack detection by integrating structured-to-text conversion, Quantized Low-Rank Adaptation (QLoRA) fine-tuning, and Retrieval-Augmented Generation (RAG). Network traffic features are transformed into compact natural-language prompts, enabling efficient adaptation under constrained hardware. Experiments on the CICIoT2023 dataset show that a QLoRA-tuned LLaMA-1B model achieves an F1-score of 0.7124, comparable to the Random Forest (RF) baseline (0.7159) for known attacks. With RAG, the system attains 42.63% accuracy on unseen attack types without additional training, demonstrating practical zero-shot capability. These results highlight the potential of retrieval-enhanced lightweight LLMs as adaptable and resource-efficient solutions for next-generation IoT intrusion detection."
  },
  {
    "date": "2026-01-21",
    "title": "Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions",
    "authors": "Yiran Hu, Huanghai Liu, Chong Wang, Kunran Li, Tien-Hsuan Wu, Haitao Li, Xinran Xu, Siqing Huo, Weihang Su, Ning Zheng, Siyuan Zheng, Qingyao Ai, Yun Liu, Renjun Bian, Yiqun Liu, Charles L. A. Clarke, Weixing Shen, Ben Kao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15267v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoning processes and trustworthy issues such as fairness and reliability. Systematic evaluation of LLM performance in legal tasks has therefore become essential for their responsible adoption. This survey identifies key challenges in evaluating LLMs for legal tasks grounded in real-world legal practice. We analyze the major difficulties involved in assessing LLM performance in the legal domain, including outcome correctness, reasoning reliability, and trustworthiness. Building on these challenges, we review and categorize existing evaluation methods and benchmarks according to their task design, datasets, and evaluation metrics. We further discuss the extent to which current approaches address these challenges, highlight their limitations, and outline future research directions toward more realistic, reliable, and legally grounded evaluation frameworks for LLMs in legal domains."
  },
  {
    "date": "2026-01-21",
    "title": "Bhabha scattering at future colliders with BHLUMI/BHWIDE",
    "authors": "Wiesław Płaczek, Maciej Skrzypek, Bennie F. L. Ward, Scott A. Yost",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15265v1",
    "source": "arXiv",
    "abstract": "In this paper, we briefly present the Monte Carlo event generators BHLUMI and BHWIDE for small and large angle Bhabha scattering, respectively, and discuss possible ways of their improvements in order to satisfy precision needs of future electron-positron colliders."
  },
  {
    "date": "2026-01-21",
    "title": "DrivIng: A Large-Scale Multimodal Driving Dataset with Full Digital Twin Integration",
    "authors": "Dominik Rößle, Xujun Xie, Adithya Mohan, Venkatesh Thirugnana Sambandham, Daniel Cremers, Torsten Schön",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15260v1",
    "source": "arXiv",
    "abstract": "Perception is a cornerstone of autonomous driving, enabling vehicles to understand their surroundings and make safe, reliable decisions. Developing robust perception algorithms requires large-scale, high-quality datasets that cover diverse driving conditions and support thorough evaluation. Existing datasets often lack a high-fidelity digital twin, limiting systematic testing, edge-case simulation, sensor modification, and sim-to-real evaluations. To address this gap, we present DrivIng, a large-scale multimodal dataset with a complete geo-referenced digital twin of a ~18 km route spanning urban, suburban, and highway segments. Our dataset provides continuous recordings from six RGB cameras, one LiDAR, and high-precision ADMA-based localization, captured across day, dusk, and night. All sequences are annotated at 10 Hz with 3D bounding boxes and track IDs across 12 classes, yielding ~1.2 million annotated instances. Alongside the benefits of a digital twin, DrivIng enables a 1-to-1 transfer of real traffic into simulation, preserving agent interactions while enabling realistic and flexible scenario testing. To support reproducible research and robust validation, we benchmark DrivIng with state-of-the-art perception models and publicly release the dataset, digital twin, HD map, and codebase."
  },
  {
    "date": "2026-01-21",
    "title": "The phase of de Sitter higher spin gravity",
    "authors": "Simone Giombi, Zimo Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15257v1",
    "source": "arXiv",
    "abstract": "The one-loop Euclidean partition function on the sphere is known to exhibit a nontrivial phase for massless fields of spin greater than one. Such a phase appears to be in tension with a state counting interpretation of the partition function and its relation to the de Sitter entropy. It has been recently argued that the phase associated with the gravitational path integral can be cancelled by including the contribution of an observer. In this note, we compute the total phase of Vasiliev higher spin gravity on the sphere by summing over the contributions of all spins. We evaluate the resulting infinite sum using two different regularization schemes, obtaining consistent results. We find that for the non-minimal Vasiliev theory, which includes massless fields of all integer spins, the total phase vanishes in all dimensions. This result suggests that the sphere partition function of these theories may be consistent with a counting interpretation, without explicitly including an observer."
  },
  {
    "date": "2026-01-21",
    "title": "Derived logarithmic deformation theory and moduli stacks of derived logarithmic structures",
    "authors": "Ruichuan Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15256v1",
    "source": "arXiv",
    "abstract": "This paper investigates the derived and spectral analogs of logarithmic geometry. We develop the deformation theory for animated log rings and $\\mathbb{E}_\\infty$-log rings and examine the corresponding theories of derived and spectral log stacks. Furthermore, we define moduli stacks for derived and spectral log structures and establish their representability. As an application, we will construct $\\infty$-root stacks in the derived and spectral settings and study the associated geometric properties."
  },
  {
    "date": "2026-01-21",
    "title": "Maximal spreading of impacting viscoelastic droplets",
    "authors": "Orr Avni, Dongyue Wang, Mithun Ravisankar, Roberto Zenit",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15246v1",
    "source": "arXiv",
    "abstract": "Droplet impact and spreading on solid substrates are well understood for Newtonian fluids, yet how viscoelasticity alone modifies the maximal spreading remains unclear. To discern the physical mechanisms governing the spreading dynamics, we present a simplified theoretical model, validated by impact experiments, to quantify how fluid elasticity modifies the maximal spreading of impacting droplets. Experiments were performed using fluids within a narrow range of viscosity and surface tension, but varying relaxation time. While following similar asymptotic scalings as Newtonian droplets, the maximum diameter for viscoelastic droplets exhibits a clear deviation from Newtonian behaviour only when the Deborah number is of order unity. The maximum spread diameter is reduced by as much as 40% from the expected value for Newtonian fluid. These results support the central prediction of our model: an extension of classical energy balance that incorporates viscoelastic effects through a single correction factor. The model captures the observed reduction in maximal spreading and predicts both the location and magnitude of the most substantial viscoelastic effects, providing a basis for extending impact models beyond purely Newtonian fluids."
  },
  {
    "date": "2026-01-21",
    "title": "Cosmic strings, domain walls and environment-dependent clustering",
    "authors": "Øyvind Christiansen, Julian Adamek, Martin Kunz",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15234v1",
    "source": "arXiv",
    "abstract": "Recent cosmological data favour phantom-crossing dark energy, motivating models with non-minimal couplings that induce a fifth force on structure formation. Reconciling these models with local tests often requires strong screening, leading to environment-dependent clustering. We investigate such effects via a late-time structure-induced phase transition driven by a non-minimally coupled scalar field. For this purpose, we introduce norns, a fully relativistic cosmological particle-mesh code that self-consistently evolves a complex scalar field - a generalisation of the symmetron producing global U(1) strings rather than domain walls. Using simulations, we compare string and wall-forming models, quantifying impacts on the matter power spectrum, halo mass function, and defect dynamics. Strong environment-dependent effects can generate significant departures from LCDM in underdense regions while keeping the overall power spectrum changes modest (~ 4-15% at k~0.3-0.5 h Mpc^-1, sub-percent for z > 0.2). We find that an attractive fifth force can locally suppress structure growth in voids while enhancing it in surrounding overdense regions by driving outflows from the voids. These effects leave distinctive signatures in the matter density probability density function and in marked halo power spectra, which are likely detectable in low-redshift data."
  },
  {
    "date": "2026-01-21",
    "title": "Direct Observation of Antimagnons with Inverted Dispersion",
    "authors": "Hanchen Wang, Junfeng Hu, Wenjie Song, Artim L. Bassant, Jinlong Wang, Haishen Peng, Emir Karadža, Paul Noël, William Legrand, Richard Schlitz, Jilei Chen, Song Liu, Dapeng Yu, Jean-Philippe Ansermet, Rembert A. Duine, Pietro Gambardella, Haiming Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15231v1",
    "source": "arXiv",
    "abstract": "We report direct spectroscopic evidence of antimagnons, i.e., negative-energy spin waves identified by their signature inverted dispersion with Brillouin light scattering (BLS) spectroscopy. We investigate an ultrathin BiYIG film with a perpendicular magnetized anisotropy that compensates the demagnetizing field. By injecting a spin-orbit torque, the magnetization is driven into auto-oscillation and eventually into a non-equilibrium reversed state above a secondary current threshold ($\\sim$1.2$\\times$10$^7$~A/cm$^2$). The dispersion is measured by wavevector-resolved BLS and exhibits a sharp change from an upward dispersion to a downward one, in agreement with theoretical predictions and micromagnetic simulations. Around the threshold current, we observe the coexistence of conventional magnons and antimagnons. Our work establishes antimagnons with inverted dispersion and is a first step towards exploring novel phenomena and applications due to magnon-antimagnon coupling, such as magnon amplification and magnon-antimagnon entanglement, which are part of the emerging field of antimagnonics."
  },
  {
    "date": "2026-01-21",
    "title": "A height-based metaconcept for rooted tree balance and its implications for the $B_1$ index",
    "authors": "Mareike Fischer, Tom Niklas Hamann, Kristina Wicke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15219v1",
    "source": "arXiv",
    "abstract": "Tree balance has received considerable attention in recent years, both in phylogenetics and in other areas. Numerous (im)balance indices have been proposed to quantify the (im)balance of rooted trees. A recent comprehensive survey summarized this literature and showed that many existing indices are based on similar underlying principles. To unify these approaches, three general metaconcepts were introduced, providing a framework to classify, analyze, and extend imbalance indices. In this context, a metaconcept is a function $Φ_f$ that depends on another function $f$ capturing some aspect of tree shape. In this manuscript, we extend this line of research by introducing a new metaconcept based on the heights of the pending subtrees of all inner vertices. We provide a thorough analysis of this metaconcept and use it to answer open questions concerning the well-known $B_1$ balance index. In particular, we characterize the tree shapes that maximize the $B_1$ index in two cases: (i) arbitrary rooted trees and (ii) binary rooted trees. For both cases, we also determine the corresponding maximum values of the index. Finally, while the $B_1$ index is induced by a so-called third-order metaconcept, we explicitly introduce three new (im)balance indices derived from the first- and second-order height metaconcepts, respectively, thereby demonstrating that pending subtree heights give rise to a variety of novel (im)balance indices."
  },
  {
    "date": "2026-01-21",
    "title": "Purcell enhanced electroluminescence of a unipolar light emitting quantum device at 10 micron",
    "authors": "Marta Mastrangelo, Djamal Gacemi, Axel Evirgen, Salvatore Pes, Alexandre Larrue, Pascal Filloux, Isabelle Sagnes, Abdelmounaim Harouri, Angela Vasanelli, Carlo Sirtori",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15193v1",
    "source": "arXiv",
    "abstract": "Efficient generation of radiation in the mid- and far- infrared relies primarily on lasers and coherent nonlinear optical phenomena driven by lasers. This wavelength range lacks of luminescent devices because the spontaneous emission rate becomes much longer than the nonradiative energy relaxation processes and therefore emitters have to count on stimulated emission produced by linear or non-linear optical gain. However, spontaneous emission is not a fundamental property of the emitter. By engineering metamaterials composed of arrays of nano-emitters into microcavities coupled to patch antennas, we have demonstrated mid-infrared electroluminescent devices emitting a collimated beam with excellent spatial properties and a factor 100 increase in the collected power, compared to standard devices. Our results illustrate that by reshaping the photonic environment around emitting dipoles, as in the Purcell effect, it is possible to enhance the spontaneous emission and conceive efficient optoelectronic light emitting devices that operate close to the thermodynamical equilibrium as LEDs in the visible range."
  },
  {
    "date": "2026-01-21",
    "title": "Ultrafast switching of antiferromagnetic order by field-derivative torque",
    "authors": "Pratyay Mukherjee, Ritwik Mondal",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15192v1",
    "source": "arXiv",
    "abstract": "Control of magnetic order in antiferromagnets is a central challenge in the development of next-generation spintronic devices. Here, we propose and analyze magnetization switching driven by the field-derivative torque, a torque that originates from the time-derivative of an applied THz pulse acting on the staggered order parameter. Using atomistic spin simulations, we show that the field-derivative torque couples efficiently to the Néel vector, enabling deterministic switching without net spin accumulation. Further, we show that using the circularly polarised THz pulse, the FDT-induced magnetization switching reduces the required THz magnetic field by two-fold. To this end, we compute the switching and non-switching areas as a function of THz pulse width, THz magnetic field, and damping of the antiferromagnetic material. We find that the switching and non-switching areas are completely deterministic in antiferromagnets. Moreover, the switching area increases by about 55% when the FDT is considered."
  },
  {
    "date": "2026-01-21",
    "title": "Parareal algorithm for coupled elliptic-parabolic problems",
    "authors": "Iñigo Jimenez-Ciga, Francisco Gaspar, Kundan Kumar, Florin A. Radu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15191v1",
    "source": "arXiv",
    "abstract": "We present a convergence analysis of the parallel-in-time integration method known as the Parareal algorithm for degenerate differential-algebraic systems arising from quasi-static Biot models, which govern coupled flow and deformation in porous media. The underlying system exhibits a saddle-point structure and degeneracy due to the quasi-static assumption. We extend the Parareal algorithm to this setting and propose three coarse propagators: monolithic, fixed-stress, and multirate fixed-stress schemes. For each, we derive sufficient conditions for convergence and establish explicit time step restrictions that guarantee contractivity of the iteration matrix. Numerical experiments show computational savings accrued by using a parareal solver in multiphysics simulations involving poroelasticity and other coupled systems."
  },
  {
    "date": "2026-01-21",
    "title": "Implications of the continuous radio-loudness distribution among AGNs in the local Universe",
    "authors": "A. Wójtowicz, N. Vale Asari, Ł. Stawarz, G. Stasinska, D. Kozieł-Wierzbowska",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15189v1",
    "source": "arXiv",
    "abstract": "Aims. We investigate the radio loudness ($\\mathcal{R}$) distribution in a large, homogeneous sample of radio galaxies. Methods. The sample is composed of galaxies from the ROGUE I/II catalogue belonging to the SDSS MGS and is divided into optically inactive radio galaxies (OPIRGs), optically active ones (OPARGs) and radio Seyferts. We use optical, mid-infrared and radio data to calculate the AGN bolometric luminosities, accretion rate ($λ$), black-hole mass ($M_{BH}$) and $\\mathcal{R}$. Results. Contrary to some previous studies based on restricted samples, using our complete sample of objects with redshifts $z < 0.4$, we find no evidence of bimodality in $\\mathcal{R}$. The highest $\\mathcal{R}$ values are associated with extended radio structures. $\\mathcal{R}$ is anti-correlated with $λ$, and spans about 2 dex at fixed $λ$. Radio Seyferts, OPARGs and OPIRGs form a sequence of increasing $M_{BH}$ with substantial overlap. Radio Seyferts show no $\\mathcal{R}$-$M_{BH}$ correlation, whereas OPARGs and OPIRGs show a weak positive trend. From theoretical considerations, the observed two-dex spread in radio luminosity and $\\mathcal{R}$ can be reproduced by a four-fold variation in the dimensionless magnetic flux $\\varphi$ assuming realistic black-hole spins. Conclusions. The smooth distribution of radio loudness supports a common evolutionary path for all radio sources, with black-hole spin and magnetic field varying continuously. The radio loudness depends on black-hole mass and accretion rate, while moderate variations in $\\varphi$ may account for the observed scatter in this relation."
  },
  {
    "date": "2026-01-21",
    "title": "Supporting Humans in Evaluating AI Summaries of Legal Depositions",
    "authors": "Naghmeh Farzi, Laura Dietz, Dave D. Lewis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15182v1",
    "source": "arXiv",
    "abstract": "While large language models (LLMs) are increasingly used to summarize long documents, this trend poses significant challenges in the legal domain, where the factual accuracy of deposition summaries is crucial. Nugget-based methods have been shown to be extremely helpful for the automated evaluation of summarization approaches. In this work, we translate these methods to the user side and explore how nuggets could directly assist end users. Although prior systems have demonstrated the promise of nugget-based evaluation, its potential to support end users remains underexplored. Focusing on the legal domain, we present a prototype that leverages a factual nugget-based approach to support legal professionals in two concrete scenarios: (1) determining which of two summaries is better, and (2) manually improving an automatically generated summary."
  },
  {
    "date": "2026-01-21",
    "title": "Contextual Metaprogramming for Session Types",
    "authors": "Pedro Ângelo, Atsushi Igarashi, Yuito Murase, Vasco T. Vasconcelos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15180v1",
    "source": "arXiv",
    "abstract": "We propose the integration of staged metaprogramming into a session-typed message passing functional language. We build on a model of contextual modal type theory with multi-level contexts, where contextual values, closing arbitrary terms over a series of variables, may be boxed and transmitted in messages. Once received, one such value may then be unboxed and locally applied before being run. To motivate this integration, we present examples of real-world use cases, for which our system would be suitable, such as servers preparing and shipping code on demand via session typed messages. We present a type system that distinguishes linear (used exactly once) from unrestricted (used an unbounded number of times) resources, and further define a type checker, suitable for a concrete implementation. We show type preservation, a progress result for sequential computations and absence of runtime errors for the concurrent runtime environment, as well as the correctness of the type checker."
  },
  {
    "date": "2026-01-21",
    "title": "Upper Bounds on Covering Minima of Convex Bodies",
    "authors": "Katarina Krivokuća",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15173v1",
    "source": "arXiv",
    "abstract": "We give two new upper bounds on the covering minima of convex bodies, depending on covering minima of certain projections and intersections with linear subspaces. We show one bound to be sharp for direct sums of two convex bodies, generalizing previous results on the covering radius and lattice width of direct sums. We apply our results to standard terminal simplices, reducing the gap between the upper and lower bounds in a conjecture of Gonzaléz Merino and Schymura (2017), which gives insight on a conjecture of Codenotti, Santos and Schymura (2021) on the maximal covering radius of a non-hollow lattice polytope."
  },
  {
    "date": "2026-01-21",
    "title": "Path-OED for infinite-dimensional Bayesian linear inverse problems governed by PDEs",
    "authors": "J. Nicholas Neuberger, Alen Alexanderian, Bart van Bloemen Waanders, Ahmed Attia",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15168v1",
    "source": "arXiv",
    "abstract": "We consider infinite-dimensional Bayesian linear inverse problems governed by time-dependent partial differential equations (PDEs) and develop a mathematical and computational framework for optimal design of mobile sensor paths in this setting. The proposed path optimal experimental design (path-OED) framework is established rigorously in a function space setting and elaborated for the case of Bayesian c-optimality, which quantifies the posterior variance in a linear functional of the inverse parameter. The latter is motivated by goal-oriented formulations, where we seek to minimize the uncertainty in a scalar prediction of interest. To facilitate computations, we complement the proposed infinite-dimensional framework with discretized formulations, in suitably weighted finite-dimensional inner product spaces, and derive efficient methods for finding optimal sensor paths. The resulting computational framework is flexible, scalable, and can be adapted to a broad range of linear inverse problems and design criteria. We also present extensive computational experiments, for a model inverse problem constrained by an advection-diffusion equation, to demonstrate the effectiveness of the proposed approach."
  },
  {
    "date": "2026-01-21",
    "title": "The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models",
    "authors": "Zanlin Ni, Shenzhi Wang, Yang Yue, Tianyu Yu, Weilin Zhao, Yeguo Hua, Tianyi Chen, Jun Song, Cheng Yu, Bo Zheng, Gao Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15165v1",
    "source": "arXiv",
    "abstract": "Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have leveraged reinforcement learning (RL) to elicit the reasoning capability of dLLMs. In this paper, we reveal a counter-intuitive reality: arbitrary order generation, in its current form, narrows rather than expands the reasoning boundary of dLLMs. We find that dLLMs tend to exploit this order flexibility to bypass high-uncertainty tokens that are crucial for exploration, leading to a premature collapse of the solution space. This observation challenges the premise of existing RL approaches for dLLMs, where considerable complexities, such as handling combinatorial trajectories and intractable likelihoods, are often devoted to preserving this flexibility. We demonstrate that effective reasoning is better elicited by intentionally forgoing arbitrary order and applying standard Group Relative Policy Optimization (GRPO) instead. Our approach, JustGRPO, is minimalist yet surprisingly effective (e.g., 89.1% accuracy on GSM8K) while fully retaining the parallel decoding ability of dLLMs. Project page: https://nzl-thu.github.io/the-flexibility-trap"
  },
  {
    "date": "2026-01-21",
    "title": "The Promises and Perils of using LLMs for Effective Public Services",
    "authors": "Erina Seh-Young Moon, Matthew Tamura, Angelina Zhai, Nuzaira Habib, Behnaz Shirazi, Altaf Kassam, Devansh Saxena, Shion Guha",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15163v1",
    "source": "arXiv",
    "abstract": "Governments are the primary providers of essential public services and are responsible for delivering them effectively. In high-stakes decision-making domains such as child welfare (CW), agencies must protect children without unnecessarily prolonging a family's engagement with the system. With growing optimism around AI, governments are pushing for its integration but concerns regarding feasibility and harms remain. Through collaborations with a large Canadian CW agency, we examined how LocalLLM and BERTopic models can track CW case progress. We demonstrate how the tools can potentially assist workers in opportunistically addressing gaps in their work by signaling case progress/deviations. And yet, we also show how they fail to detect case trajectories that require discretionary judgments grounded in social work training, areas where practitioners would actually want support to pre-emptively address substantive case concerns. We also provide a roadmap of future participatory directions to co-design language tools for/with the public sector."
  },
  {
    "date": "2026-01-21",
    "title": "Trimer Dynamics in Floquet-driven arrays of Rydberg Atoms",
    "authors": "Edoardo Tiburzi, Lorenzo Maffi, Luca Dell'Anna, Marco Di Liberto",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15162v1",
    "source": "arXiv",
    "abstract": "We analyze the WAHUHA Floquet protocol recently applied to arrays of Rydberg atoms and derive beyond-leading-order corrections in the high-frequency expansion of the effective spin theory. We find that an appropriate choice of the pulses times can enforce an approximate symmetry corresponding to the conservation of the total magnetization. The interaction channels emerging from higher-order Floquet terms affect three-body bound states (\\emph{trimers}), which gain a significant mobility. We estimate the corresponding enhancement in 1D spin chains and conclude that their dynamics is within experimental reach. Detrimental effects due to the proliferation of particles outside of the trimer magnetization sector are found to occur and spread on time-scales slower than the trimer propagation. Moreover, these can be suppressed in higher dimensional lattices, e.g. in 2D triangular lattices, as the lattice geometry brings these processes off resonance. Our results establish a concrete route to realizing mobile multiparticle bound states in Floquet-engineered Rydberg platforms."
  },
  {
    "date": "2026-01-21",
    "title": "Typical hyperbolic surfaces have an optimal spectral gap",
    "authors": "Laura Monk",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15157v1",
    "source": "arXiv",
    "abstract": "The first non-zero Laplace eigenvalue of a hyperbolic surface, or its spectral gap, measures how well-connected the surface is: surfaces with a large spectral gap are hard to cut in pieces, have a small diameter and fast mixing times. For large hyperbolic surfaces (of large area or large genus $g$, equivalently), we know that the spectral gap is asymptotically bounded above by $\\frac 14$. The aim of these talks is to present joint work with Nalini Anantharaman, where we prove that most hyperbolic surfaces have a near-optimal spectral gap. That is to say, we prove that, for any $ε> 0$, the Weil--Petersson probability for a hyperbolic surface of genus $g$ to have a spectral gap greater than $\\frac 14- ε$ goes to one as $g$ goes to infinity. This statement is analogous to Alon's 1986 conjecture for regular graphs, proven by Friedman in 2003. I will present our approach, which shares many similarities with Friedman's work, and introduce new tools and ideas that we have developed in order to tackle this problem."
  },
  {
    "date": "2026-01-21",
    "title": "Arguing conformance with data protection principles",
    "authors": "Chris Smith, Richard Hawkins",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15155v1",
    "source": "arXiv",
    "abstract": "We show how conformance arguments can be used by organisations to substantiate claims of conformance to data protection principles. Use of conformance arguments can improve the rigour and consistency with which these organisations, supervisory authorities, certification bodies and data subjects can assess the truth of these claims."
  },
  {
    "date": "2026-01-21",
    "title": "A Real-Time Error Prevention System for Gaze-Based Interaction in Virtual Reality Based on Anomaly Detection",
    "authors": "Björn R. Severitt, Yannick Sauer, Nora Castner, Siegfried Wahl",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15146v1",
    "source": "arXiv",
    "abstract": "Gaze-based interaction enables intuitive, hands-free control in immersive environments, but remains susceptible to unintended inputs. We present a real-time error prevention system (EPS) that uses a temporal convolutional network autoencoder (TCNAE) to detect anomalies in gaze dynamics during selection tasks. In a visual search task in VR, 41 participants used three gaze-based methods - dwell time, gaze and head direction alignment, and nod - with and without EPS. The system reduced erroneous selections by up to 95% for dwell time and gaze and head, and was positively received by most users. Performance varied for nodding and between individuals, suggesting the need for adaptive systems. Objective metrics and subjective evaluations show that anomaly-based error prevention can improve gaze interfaces without disrupting interaction. These findings demonstrate the potential of anomaly-based error prevention for gaze interfaces and suggest applications in VR, AR, and assistive technologies."
  },
  {
    "date": "2026-01-21",
    "title": "Quasi-isometry Invariance of discrete Higher Filling functions",
    "authors": "Jannis Weis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15140v1",
    "source": "arXiv",
    "abstract": "We prove that homological filling functions over a ring $R$ equipped with the discrete norm are quasi-isometry invariants for all groups of type $\\mathrm{FP}_n$. This confirms a conjecture of Bader-Kropholler-Vankov in the case of discrete norms. The proof uses a technique of equipping free chain complexes with a geometric structure, allowing for analogues of cellular constructions in the purely algebraic setting. As a further application we prove quasi-isometry invariance for a weighted version of integral and discrete filling functions originally introduced in the study of the rapid decay property."
  },
  {
    "date": "2026-01-21",
    "title": "Inequalities of Miyaoka-Yau type $\\&$ Uniformisation of varieties of intermediate Kodaira Dimension",
    "authors": "Niklas Müller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15138v1",
    "source": "arXiv",
    "abstract": "In this paper we present, for any integers $0\\leq ν\\leq n$, a set of inequalities satisfied by the Chern classes of any minimal complex projective variety of dimension $n$ and numerical dimension $ν$. In the cases where $ν$ is either very small or very large compared with $n$, this recovers many previously known results. We demonstrate that our inequalities are sharp by providing an explicit characterisation of those varieties achieving the equality; our proof, in particular, resolves the Abundance conjecture in this situation. Additionally, we provide some new examples of varieties with extremal Chern classes that demonstrate the optimality of our results."
  },
  {
    "date": "2026-01-21",
    "title": "A New Measure of Coarseness for Solutions to Cahn--Hilliard Equations",
    "authors": "Peter Howard, Adam Larios, Quyuan Lin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15134v1",
    "source": "arXiv",
    "abstract": "We introduce a new measure of coarseness for characterizing phase separation processes such as those described by Cahn--Hilliard equations. An advantage of our measure is that it remains consistent throughout the evolution, including for solutions with no periodic structure. We use our measure to compare two previous models of coarsening dynamics with numerically generated dynamics, providing the first direct check that we are aware of for the efficacy of these methods."
  },
  {
    "date": "2026-01-21",
    "title": "RSNA Large Language Model Benchmark Dataset for Chest Radiographs of Cardiothoracic Disease: Radiologist Evaluation and Validation Enhanced by AI Labels (REVEAL-CXR)",
    "authors": "Yishu Wei, Adam E. Flanders, Errol Colak, John Mongan, Luciano M Prevedello, Po-Hao Chen, Henrique Min Ho Lee, Gilberto Szarf, Hamilton Shoji, Jason Sho, Katherine Andriole, Tessa Cook, Lisa C. Adams, Linda C. Chu, Maggie Chung, Geraldine Brusca-Augello, Djeven P. Deva, Navneet Singh, Felipe Sanchez Tijmes, Jeffrey B. Alpert, Elsie T. Nguyen, Drew A. Torigian, Kate Hanneman, Lauren K Groner, Alexander Phan, Ali Islam, Matias F. Callejas, Gustavo Borges da Silva Teles, Faisal Jamal, Maryam Vazirabad, Ali Tejani, Hari Trivedi, Paulo Kuriki, Rajesh Bhayana, Elana T. Benishay, Yi Lin, Yifan Peng, George Shih",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15129v1",
    "source": "arXiv",
    "abstract": "Multimodal large language models have demonstrated comparable performance to that of radiology trainees on multiple-choice board-style exams. However, to develop clinically useful multimodal LLM tools, high-quality benchmarks curated by domain experts are essential. To curate released and holdout datasets of 100 chest radiographic studies each and propose an artificial intelligence (AI)-assisted expert labeling procedure to allow radiologists to label studies more efficiently. A total of 13,735 deidentified chest radiographs and their corresponding reports from the MIDRC were used. GPT-4o extracted abnormal findings from the reports, which were then mapped to 12 benchmark labels with a locally hosted LLM (Phi-4-Reasoning). From these studies, 1,000 were sampled on the basis of the AI-suggested benchmark labels for expert review; the sampling algorithm ensured that the selected studies were clinically relevant and captured a range of difficulty levels. Seventeen chest radiologists participated, and they marked \"Agree all\", \"Agree mostly\" or \"Disagree\" to indicate their assessment of the correctness of the LLM suggested labels. Each chest radiograph was evaluated by three experts. Of these, at least two radiologists selected \"Agree All\" for 381 radiographs. From this set, 200 were selected, prioritizing those with less common or multiple finding labels, and divided into 100 released radiographs and 100 reserved as the holdout dataset. The holdout dataset is used exclusively by RSNA to independently evaluate different models. A benchmark of 200 chest radiographic studies with 12 benchmark labels was created and made publicly available https://imaging.rsna.org, with each chest radiograph verified by three radiologists. In addition, an AI-assisted labeling procedure was developed to help radiologists label at scale, minimize unnecessary omissions, and support a semicollaborative environment."
  },
  {
    "date": "2026-01-21",
    "title": "Cooperative stabilization of persistent currents in superfluid ring networks",
    "authors": "Marzena Ciszak, Nicola Grani, Diego Hernandez-Rajkov, Giulia Del Pace, Giacomo Roati, Francesco Marino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15121v1",
    "source": "arXiv",
    "abstract": "Cooperative effects in oscillator networks are often associated with enhanced stability of phase-locked solutions, which increases with system size. We show that the stabilization of persistent currents in annular atomic superfluids with periodic barriers is a concrete manifestation of this phenomenon. Under the simplifying assumption of continuity of atomic flow across identical barriers, the system reduces to a ring of locally coupled Kuramoto-like oscillators. We analytically derive the stability diagram of phase-locked configurations and quantify their robustness to noise and small random initial imperfections, finding excellent agreement with experimental observations. These results are inherent to the ring topology and independent of the specific physical platform."
  },
  {
    "date": "2026-01-21",
    "title": "A Review of Hyperon Physics at BESIII Experiment",
    "authors": "Ruoyu Zhang, Xiongfei Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15116v1",
    "source": "arXiv",
    "abstract": "The BESIII Collaboration has collected large data samples from $e^+e^-$ collisions at center-of-mass energies ranging from 1.84 to 4.95 GeV, which include the world's largest charmonium sample, consisting of 10 billion $J/ψ$ and 3 billion $ψ(3686)$ events. These high-statistics datasets enable BESIII to carry out a wide range of studies in hyperon physics. In this article, we review the major achievements of the BESIII Collaboration in this field, which can be broadly categorized into four areas: hyperon polarization and $CP$ violation, rare hyperon decays, hyperon pair production, and hyperon-nucleon interactions."
  },
  {
    "date": "2026-01-21",
    "title": "Training-Free and Interpretable Hateful Video Detection via Multi-stage Adversarial Reasoning",
    "authors": "Shuonan Yang, Yuchen Zhang, Zeyu Fu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15115v1",
    "source": "arXiv",
    "abstract": "Hateful videos pose serious risks by amplifying discrimination, inciting violence, and undermining online safety. Existing training-based hateful video detection methods are constrained by limited training data and lack of interpretability, while directly prompting large vision-language models often struggle to deliver reliable hate detection. To address these challenges, this paper introduces MARS, a training-free Multi-stage Adversarial ReaSoning framework that enables reliable and interpretable hateful content detection. MARS begins with the objective description of video content, establishing a neutral foundation for subsequent analysis. Building on this, it develops evidence-based reasoning that supports potential hateful interpretations, while in parallel incorporating counter-evidence reasoning to capture plausible non-hateful perspectives. Finally, these perspectives are synthesized into a conclusive and explainable decision. Extensive evaluation on two real-world datasets shows that MARS achieves up to 10% improvement under certain backbones and settings compared to other training-free approaches and outperforms state-of-the-art training-based methods on one dataset. In addition, MARS produces human-understandable justifications, thereby supporting compliance oversight and enhancing the transparency of content moderation workflows. The code is available at https://github.com/Multimodal-Intelligence-Lab-MIL/MARS."
  },
  {
    "date": "2026-01-21",
    "title": "Pb4U-GNet: Resolution-Adaptive Garment Simulation via Propagation-before-Update Graph Network",
    "authors": "Aoran Liu, Kun Hu, Clinton Ansun Mo, Qiuxia Wu, Wenxiong Kang, Zhiyong Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15110v1",
    "source": "arXiv",
    "abstract": "Garment simulation is fundamental to various applications in computer vision and graphics, from virtual try-on to digital human modelling. However, conventional physics-based methods remain computationally expensive, hindering their application in time-sensitive scenarios. While graph neural networks (GNNs) offer promising acceleration, existing approaches exhibit poor cross-resolution generalisation, demonstrating significant performance degradation on higher-resolution meshes beyond the training distribution. This stems from two key factors: (1) existing GNNs employ fixed message-passing depth that fails to adapt information aggregation to mesh density variation, and (2) vertex-wise displacement magnitudes are inherently resolution-dependent in garment simulation. To address these issues, we introduce Propagation-before-Update Graph Network (Pb4U-GNet), a resolution-adaptive framework that decouples message propagation from feature updates. Pb4U-GNet incorporates two key mechanisms: (1) dynamic propagation depth control, adjusting message-passing iterations based on mesh resolution, and (2) geometry-aware update scaling, which scales predictions according to local mesh characteristics. Extensive experiments show that even trained solely on low-resolution meshes, Pb4U-GNet exhibits strong generalisability across diverse mesh resolutions, addressing a fundamental challenge in neural garment simulation."
  },
  {
    "date": "2026-01-21",
    "title": "A geometric approach to the uniform boundedness of $\\ell$-primary torsion points",
    "authors": "Zhuchao Ji, Jiarui Song, Junyi Xie",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15089v1",
    "source": "arXiv",
    "abstract": "We prove that for a non-isotrivial abelian scheme over a smooth curve, the genus of a generic sequence of multi-sections with small heights tends to infinity. As an application, we give a new proof of the uniform boundedness of $\\ell$-primary torsion points on fibers of an abelian scheme over a smooth curve, a result originally proved by Cadoret and Tamagawa. Furthermore, our approach allows us to resolve a conjecture of Cadoret and Tamagawa without additional assumptions. Our approach is based on the theory of Betti foliations and the arithmetic equidistribution theorem."
  },
  {
    "date": "2026-01-21",
    "title": "DeLog: An Efficient Log Compression Framework with Pattern Signature Synthesis",
    "authors": "Siyu Yu, Yifan Wu, Junjielong Xu, Ying Fu, Ning Wang, Maoyin Liu, Pancheng Jiang, Xiang Zhang, Tong Jia, Pinjia He, Ying Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15084v1",
    "source": "arXiv",
    "abstract": "Parser-based log compression, which separates static tem- plates from dynamic variables, is a promising approach to exploit the unique structure of log data. However, its perfor- mance on complex production logs is often unsatisfactory. This performance gap coincides with a known degradation in the accuracy of its core log parsing component on such data, motivating our investigation into a foundational yet unverified question: does higher parsing accuracy necessarily lead to better compression ratio? To answer this, we conduct the first empirical study quanti- fying this relationship and find that a higher parsing accuracy does not guarantee a better compression ratio. Instead, our findings reveal that compression ratio is dictated by achiev- ing effective pattern-based grouping and encoding, i.e., the partitioning of tokens into low entropy, highly compressible groups. Guided by this insight, we design DeLog, a novel log com- pressor that implements a Pattern Signature Synthesis mecha- nism to achieve efficient pattern-based grouping. On 16 public and 10 production datasets, DeLog achieves state-of-the-art compression ratio and speed."
  },
  {
    "date": "2026-01-21",
    "title": "Combined constraints on dark photons from high-energy collisions, cosmology, and astrophysics",
    "authors": "A. W. Romero Jorge, L. Sagunski, Guan-Wen Yuan, T. Song, E. Bratkovskaya",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15066v1",
    "source": "arXiv",
    "abstract": "We investigate a dark sector coupled to the Standard Model (SM) through a kinetically mixed dark photon $U$ associated with a new $U(1)'$ gauge symmetry. Kinetic mixing $\\varepsilon$ induces an effective coupling to the electromagnetic current, while $U$ interacts with stable dark matter (DM) $χ$ via a dark gauge coupling $g_χ$. Our analysis is based on the parton-hadron-string dynamics (PHSD) transport approach, extended to include dark photon production and decay into dileptons ($U\\!\\to e^+e^-$). In PHSD, dark photons are produced in high-energy collisions through Dalitz decays of light mesons ($π^0,η,η',ω$), Delta-resonances ($Δ\\!\\to N U$), direct vector meson decays ($ρ,ω,φ\\!\\to U$), kaon decays, and $q\\bar q\\!\\to U$ annihilation. Building on previous PHSD benchmarks against dilepton data, we extract upper limits on $\\varepsilon^2(m_U,m_χ,α_χ)$ in both the visible regime ($m_U<2m_χ$), where $U\\!\\to e^+e^-$ dominates, and the invisible regime ($m_U>2m_χ$), where $U\\!\\toχ\\barχ$ is kinematically open. Cosmological and astrophysical constraints are incorporated in two complementary ways. First, we compute the velocity-dependent self-interaction cross section $σ/m_χ$ for Yukawa-mediated SIDM and confront it with bounds from dwarf galaxies, galaxy groups, and clusters. Second, we determine thermal relic target curves by computing the relic abundance and requiring $Ω_{\\rm DM}h^2\\simeq 0.12$, consistent with \\textit{Planck} measurements of the cosmic microwave background. Combining PHSD limits on $\\varepsilon^2$ with relic density and self-interaction requirements, we exclude regions of the $(m_χ,m_U)$ plane for each DM realization (Dirac, Majorana, or complex scalar) and identify benchmark scenarios in which heavy-ion, cosmological, and astrophysical constraints are simultaneously satisfied."
  },
  {
    "date": "2026-01-21",
    "title": "Enhancing Few-Shot Out-of-Distribution Detection via the Refinement of Foreground and Background",
    "authors": "Tianyu Li, Songyue Cai, Zongqian Wu, Ping Hu, Xiaofeng Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15065v1",
    "source": "arXiv",
    "abstract": "CLIP-based foreground-background (FG-BG) decomposition methods have demonstrated remarkable effectiveness in improving few-shot out-of-distribution (OOD) detection performance. However, existing approaches still suffer from several limitations. For background regions obtained from decomposition, existing methods adopt a uniform suppression strategy for all patches, overlooking the varying contributions of different patches to the prediction. For foreground regions, existing methods fail to adequately consider that some local patches may exhibit appearance or semantic similarity to other classes, which may mislead the training process. To address these issues, we propose a new plug-and-play framework. This framework consists of three core components: (1) a Foreground-Background Decomposition module, which follows previous FG-BG methods to separate an image into foreground and background regions; (2) an Adaptive Background Suppression module, which adaptively weights patch classification entropy; and (3) a Confusable Foreground Rectification module, which identifies and rectifies confusable foreground patches. Extensive experimental results demonstrate that the proposed plug-and-play framework significantly improves the performance of existing FG-BG decomposition methods. Code is available at: https://github.com/lounwb/FoBoR."
  },
  {
    "date": "2026-01-21",
    "title": "Gauge transform for the Korteweg-de Vries equation and well-posedness below the $H^{-1}$-scale",
    "authors": "Andreia Chapouto, Simão Correia, João Pedro Ramos",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15060v1",
    "source": "arXiv",
    "abstract": "We propose a new formulation of the Korteweg-de Vries equation (KdV) on the real line, via a gauge transform. While KdV and the gauged equation are equivalent for smooth solutions, the latter is better behaved at low regularity in Fourier-Lebesgue spaces. In particular, the admissible regularities go beyond the $H^{-1}$-scale, which is a well-known threshold for KdV. As a byproduct, by reversing the gauge transform, we are able to improve on the known theory for KdV and derive sharp local well-posedness in Fourier-Lebesgue spaces with large integrability exponent. Our strategy is based on an infinite normal form reduction and Fourier restriction estimates, together with a thorough exploitation of algebraic cancellations. Additionally, our method is totally independent of the KdV completely integrable structure, and extends to other non-integrable models with quadratic nonlinearities."
  },
  {
    "date": "2026-01-21",
    "title": "SpooFL: Spoofing Federated Learning",
    "authors": "Isaac Baglin, Xiatian Zhu, Simon Hadfield",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15055v1",
    "source": "arXiv",
    "abstract": "Traditional defenses against Deep Leakage (DL) attacks in Federated Learning (FL) primarily focus on obfuscation, introducing noise, transformations or encryption to degrade an attacker's ability to reconstruct private data. While effective to some extent, these methods often still leak high-level information such as class distributions or feature representations, and are frequently broken by increasingly powerful denoising attacks. We propose a fundamentally different perspective on FL defense: framing it as a spoofing problem.We introduce SpooFL (Figure 1), a spoofing-based defense that deceives attackers into believing they have recovered the true training data, while actually providing convincing but entirely synthetic samples from an unrelated task. Unlike prior synthetic-data defenses that share classes or distributions with the private data and thus still leak semantic information, SpooFL uses a state-of-the-art generative model trained on an external dataset with no class overlap. As a result, attackers are misled into recovering plausible yet completely irrelevant samples, preventing meaningful data leakage while preserving FL training integrity. We implement the first example of such a spoofing defense, and evaluate our method against state-of-the-art DL defenses and demonstrate that it successfully misdirects attackers without compromising model performance significantly."
  },
  {
    "date": "2026-01-21",
    "title": "Theoretical relationship between the macro-texture and micro-structure in dairy processing revealed by the multi-scale simulation of coupled map lattice",
    "authors": "Erika Nozawa",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15051v1",
    "source": "arXiv",
    "abstract": "The theoretical relationship between the macroscopic textural quality and microscopic structural quality appearing in the phase inversion processes from fresh cream via whipped cream to butter is revealed by the multi-scale simulation of coupled map lattice (CML) based on the mesoscopic elementary processes of the emulsion interfaces. Using the Young-Laplace equation, we derive the microscopic particle quantities of the size and density of air bubbles and butter grains in an emulsion from the macroscopic rheological quantities of the overrun and viscosity of the emulsion. In doing so, we focus on the size determined by the \"tug-of-war\" between air bubbles and butter grains via their cohesion pressures, and on the density determined by the \"costume change\" of the emulsion molecular complexes (clad particles, e.g., butter grain-clad air bubbles) to their suitable size. Using the obtained microscopic particle quantities, we now propose a microscopic state diagram, the size-density plane, in addition to the previously proposed macroscopic state diagram, the viscosity-overrun plane. These state diagrams reveal that while the two well-known different phase inversion processes at high and low whipping temperatures appear as the two parallel processes of viscosity dominance and overrun dominance in the viscosity-overrun plane, they appear as the two orthogonal processes of isodensity/size dominance and isosize/density dominance in the size-density plane. This theoretical simulation result is significant for the quality design of butter because it demonstrates that differences in macroscopic textural quality can be easily controlled by differences in microscopic structural quality."
  },
  {
    "date": "2026-01-21",
    "title": "Towards Standardizing OTFS: A Candidate Waveform for Next-Generation Wireless Networks",
    "authors": "Mingcheng Nie, Ruoxi Chong, Shuangyang Li, Arman Farhang, Fabian Göttsch, Derrick Wing Kwan Ng, Michail Matthaiou, Yonghui Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15048v1",
    "source": "arXiv",
    "abstract": "The standardization of the sixth-generation (6G) has recently commenced to address the rapidly growing demands for enhanced wireless network services. Nevertheless, existing wireless systems, particularly at the physical layer waveform level, remain inadequate for achieving the ambitious key performance indicators (KPIs) envisioned for 6G. Specifically, orthogonal frequency division multiplexing (OFDM), the widely adopted waveform in fifth-generation new radio (5G-NR) networks, suffers from inherent limitations in satisfying these stringent requirements. In practice, OFDM can experience severe inter-carrier interference (ICI), resulting in a pronounced data rate error floor caused by high Doppler shifts. Additionally, the repetitive usage of cyclic prefixes (CPs), intended to combat multipath delays, results in significant spectral inefficiency. These fundamental drawbacks pose critical obstacles to fulfilling 6G performance objectives. Orthogonal time frequency space (OTFS) modulation has recently emerged as a promising waveform candidate, addressing the aforementioned challenges by exploiting the unique characteristics of the delay-Doppler (DD) domain channel. Unlike OFDM, OTFS is inherently resilient to channel distortions induced by delay and Doppler effects, while remaining sensitive to time and frequency shifts. Such intrinsic properties are instrumental in enabling OTFS, with joint communication and sensing capabilities, to embrace, rather than combat, dynamic channel conditions. Motivated by these compelling advantages, this article investigates the feasibility and practical implementation of OTFS modulation leveraging the current OFDM-based wireless systems."
  },
  {
    "date": "2026-01-21",
    "title": "HyperNet-Adaptation for Diffusion-Based Test Case Generation",
    "authors": "Oliver Weißl, Vincenzo Riccio, Severin Kacianka, Andrea Stocco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15041v1",
    "source": "arXiv",
    "abstract": "The increasing deployment of deep learning systems requires systematic evaluation of their reliability in real-world scenarios. Traditional gradient-based adversarial attacks introduce small perturbations that rarely correspond to realistic failures and mainly assess robustness rather than functional behavior. Generative test generation methods offer an alternative but are often limited to simple datasets or constrained input domains. Although diffusion models enable high-fidelity image synthesis, their computational cost and limited controllability restrict their applicability to large-scale testing. We present HyNeA, a generative testing method that enables direct and efficient control over diffusion-based generation. HyNeA provides dataset-free controllability through hypernetworks, allowing targeted manipulation of the generative process without relying on architecture-specific conditioning mechanisms or dataset-driven adaptations such as fine-tuning. HyNeA employs a distinct training strategy that supports instance-level tuning to identify failure-inducing test cases without requiring datasets that explicitly contain examples of similar failures. This approach enables the targeted generation of realistic failure cases at substantially lower computational cost than search-based methods. Experimental results show that HyNeA improves controllability and test diversity compared to existing generative test generators and generalizes to domains where failure-labeled training data is unavailable."
  },
  {
    "date": "2026-01-21",
    "title": "Quantitative weak mixing for typical Salem substitution suspension flows",
    "authors": "Juan Marshall-Maldonado, Boris Solomyak",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15035v1",
    "source": "arXiv",
    "abstract": "The paper investigates quantitative weak mixing of Salem substitutions flows. We prove that for a substitution whose substitution matrix is irreducible over the rationals and the dominant eigenvalue is a Salem number, for almost every suspension flow with a piecewise constant roof function, quantitative weak mixing holds with a rate that is slightly worse than a power of $\\log\\log$. We do not know if this is sharp, but we do show that for any suspension flow of this kind, quantitative weak mixing with a polynomial rate is impossible. Results for specific systems are often much weaker than for ``typical'' or ``generic'' ones. In the Appendix we explain how a minor modification of an argument from Bufetov and Solomyak (2014) yields very weak, but nevertheless quantitative weak mixing estimates of $\\log^*$ type for the {\\em self-similar} suspension flow over a Salem substitution. Simultaneously this provides first quantitative decay rates for the Fourier transform of Salem Bernoulli convolutions."
  },
  {
    "date": "2026-01-21",
    "title": "APPLE: Attribute-Preserving Pseudo-Labeling for Diffusion-Based Face Swapping",
    "authors": "Jiwon Kang, Yeji Choi, JoungBin Lee, Wooseok Jang, Jinhyeok Choi, Taekeun Kang, Yongjae Park, Myungin Kim, Seungryong Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15288v1",
    "source": "arXiv",
    "abstract": "Face swapping aims to transfer the identity of a source face onto a target face while preserving target-specific attributes such as pose, expression, lighting, skin tone, and makeup. However, since real ground truth for face swapping is unavailable, achieving both accurate identity transfer and high-quality attribute preservation remains challenging. In addition, recent diffusion-based approaches attempt to improve visual fidelity through conditional inpainting on masked target images, but the masked condition removes crucial appearance cues of target, resulting in plausible yet misaligned attributes. To address these limitations, we propose APPLE (Attribute-Preserving Pseudo-Labeling), a diffusion-based teacher-student framework that enhances attribute fidelity through attribute-aware pseudo-label supervision. We reformulate face swapping as a conditional deblurring task to more faithfully preserve target-specific attributes such as lighting, skin tone, and makeup. In addition, we introduce an attribute-aware inversion scheme to further improve detailed attribute preservation. Through an elaborate attribute-preserving design for teacher learning, APPLE produces high-quality pseudo triplets that explicitly provide the student with direct face-swapping supervision. Overall, APPLE achieves state-of-the-art performance in terms of attribute preservation and identity transfer, producing more photorealistic and target-faithful results."
  },
  {
    "date": "2026-01-21",
    "title": "Rethinking Video Generation Model for the Embodied World",
    "authors": "Yufan Deng, Zilin Pan, Hongyu Zhang, Xiaojie Li, Ruoqing Hu, Yufei Ding, Yiming Zou, Yan Zeng, Daquan Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15282v1",
    "source": "arXiv",
    "abstract": "Video generation models have significantly advanced embodied intelligence, unlocking new possibilities for generating diverse robot data that capture perception, reasoning, and action in the physical world. However, synthesizing high-quality videos that accurately reflect real-world robotic interactions remains challenging, and the lack of a standardized benchmark limits fair comparisons and progress. To address this gap, we introduce a comprehensive robotics benchmark, RBench, designed to evaluate robot-oriented video generation across five task domains and four distinct embodiments. It assesses both task-level correctness and visual fidelity through reproducible sub-metrics, including structural consistency, physical plausibility, and action completeness. Evaluation of 25 representative models highlights significant deficiencies in generating physically realistic robot behaviors. Furthermore, the benchmark achieves a Spearman correlation coefficient of 0.96 with human evaluations, validating its effectiveness. While RBench provides the necessary lens to identify these deficiencies, achieving physical realism requires moving beyond evaluation to address the critical shortage of high-quality training data. Driven by these insights, we introduce a refined four-stage data pipeline, resulting in RoVid-X, the largest open-source robotic dataset for video generation with 4 million annotated video clips, covering thousands of tasks and enriched with comprehensive physical property annotations. Collectively, this synergistic ecosystem of evaluation and data establishes a robust foundation for rigorous assessment and scalable training of video models, accelerating the evolution of embodied AI toward general intelligence."
  },
  {
    "date": "2026-01-21",
    "title": "MolecularIQ: Characterizing Chemical Reasoning Capabilities Through Symbolic Verification on Molecular Graphs",
    "authors": "Christoph Bartmann, Johannes Schimunek, Mykyta Ielanskyi, Philipp Seidl, Günter Klambauer, Sohvi Luukkonen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15279v1",
    "source": "arXiv",
    "abstract": "A molecule's properties are fundamentally determined by its composition and structure encoded in its molecular graph. Thus, reasoning about molecular properties requires the ability to parse and understand the molecular graph. Large Language Models (LLMs) are increasingly applied to chemistry, tackling tasks such as molecular name conversion, captioning, text-guided generation, and property or reaction prediction. Most existing benchmarks emphasize general chemical knowledge, rely on literature or surrogate labels that risk leakage or bias, or reduce evaluation to multiple-choice questions. We introduce MolecularIQ, a molecular structure reasoning benchmark focused exclusively on symbolically verifiable tasks. MolecularIQ enables fine-grained evaluation of reasoning over molecular graphs and reveals capability patterns that localize model failures to specific tasks and molecular structures. This provides actionable insights into the strengths and limitations of current chemistry LLMs and guides the development of models that reason faithfully over molecular structure."
  },
  {
    "date": "2026-01-21",
    "title": "Interpreting Multimodal Communication at Scale in Short-Form Video: Visual, Audio, and Textual Mental Health Discourse on TikTok",
    "authors": "Mingyue Zha, Ho-Chun Herbert Chang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15278v1",
    "source": "arXiv",
    "abstract": "Short-form video platforms integrate text, visuals, and audio into complex communicative acts, yet existing research analyzes these modalities in isolation, lacking scalable frameworks to interpret their joint contributions. This study introduces a pipeline combining automated multimodal feature extraction with Shapley value-based interpretability to analyze how text, visuals, and audio jointly influence engagement. Applying this framework to 162,965 TikTok videos and 814,825 images about social anxiety disorder (SAD), we find that facial expressions outperform textual sentiment in predicting viewership, informational content drives more attention than emotional support, and cross-modal synergies exhibit threshold-dependent effects. These findings demonstrate how multimodal analysis reveals interaction patterns invisible to single-modality approaches. Methodologically, we contribute a reproducible framework for interpretable multimodal research applicable across domains; substantively, we advance understanding of mental health communication in algorithmically mediated environments."
  },
  {
    "date": "2026-01-21",
    "title": "Online Linear Programming with Replenishment",
    "authors": "Yuze Chen, Yuan Zhou, Baichuan Mo, Jie Ying, Yufei Ruan, Zhou Ye",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14629v1",
    "source": "arXiv",
    "abstract": "We study an online linear programming (OLP) model in which inventory is not provided upfront but instead arrives gradually through an exogenous stochastic replenishment process. This replenishment-based formulation captures operational settings, such as e-commerce fulfillment, perishable supply chains, and renewable-powered systems, where resources are accumulated gradually and initial inventories are small or zero. The introduction of dispersed, uncertain replenishment fundamentally alters the structure of classical OLPs, creating persistent stockout risk and eliminating advance knowledge of the total budget. We develop new algorithms and regret analyses for three major distributional regimes studied in the OLP literature: bounded distributions, finite-support distributions, and continuous-support distributions with a non-degeneracy condition. For bounded distributions, we design an algorithm that achieves $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret. For finite-support distributions with a non-degenerate induced LP, we obtain $\\mathcal{O}(\\log T)$ regret, and we establish an $Ω(\\sqrt{T})$ lower bound for degenerate instances, demonstrating a sharp separation from the classical setting where $\\mathcal{O}(1)$ regret is achievable. For continuous-support, non-degenerate distributions, we develop a two-stage accumulate-then-convert algorithm that achieves $\\mathcal{O}(\\log^2 T)$ regret, comparable to the $\\mathcal{O}(\\log T)$ regret in classical OLPs. Together, these results provide a near-complete characterization of the optimal regret achievable in OLP with replenishment. Finally, we empirically evaluate our algorithms and demonstrate their advantages over natural adaptations of classical OLP methods in the replenishment setting."
  },
  {
    "date": "2026-01-21",
    "title": "Modification speed and radius of higher-order interactions alter the oscillatory dynamics in an agent-based model",
    "authors": "Thomas Van Giel, Hanna Jaspaert, Aisling J. Daly, Bernard De Baets, Jan M. Baetens",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15144v1",
    "source": "arXiv",
    "abstract": "Understanding the population dynamics of ecological systems is crucial for predicting shifts in biodiversity and ensuring the protection of these systems. Established models often focus on pairwise species interactions, yet recent studies have highlighted the importance of higher-order interactions (HOIs) in shaping community structure and function. In this study, we investigate the effects of HOIs in an agent-based model with three species engaged in intransitive competition. We introduce an HOI where one species modifies the competition between the other two. We explore the impact of the strength, radius of influence, and speed of this interaction modification on species abundances and oscillations thereof. Our results show that these abundances are not only greatly impacted by the strength, but also by the radius and speed of the interaction modification. A deeper investigation demonstrates that the changes in the oscillations are caused by the interaction modification itself, and not the change in pairwise interaction strength caused by the HOI. These results emphasize the importance of considering the spatio-temporal scales of higher-order interactions when assessing ecosystem stability, highlighting that such interactions can introduce complex dynamical behaviors that go beyond the predictions of traditional pairwise or simpler higher-order models"
  },
  {
    "date": "2026-01-21",
    "title": "A study of the high-inclination population in the Kuiper belt -- V. Mean motion resonances beyond 50 AU",
    "authors": "Jian Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15012v1",
    "source": "arXiv",
    "abstract": "In this paper, we present the most comprehensive study to date on Neptune's mean-motion resonances (MMRs) in the distant Kuiper belt from 50 to 100 AU. Over 200 resonant Kuiper belt objects (KBOs) have been identified in this region, spanning resonances from the 2nd-order 1:3 MMR to the 22nd-order 7:29 MMR, with inclinations $i<40^\\circ$. Building on these diverse distributions, we first analyse the dynamical features of numerous $m$:$n$ MMRs, providing an informative database that includes the possible eccentricity ($e$) range, resonance widths, resonance centres, and permissible $(e,i)$ distributions. We then conduct numerical simulations to explore the long-term stability of these MMRs. Our results show that: (1) resonators can occupy all 1:$n$ to 7:$n$ MMRs, with nearly any $n$ corresponding to the 50-100 AU region, including the farthest-out MMRs of 5:29 (24th-order), 6:35 (29th-order), and 7:40 (33rd-order). This suggests that KBOs could potentially exist in even higher-order MMRs than those currently observed. (2) For each set of $m$:$n$ resonances with the same $m$, resonators consistently exhibit inclinations up to $40^\\circ$, while eccentricities remain strictly restricted below 0.7. (3) For the 1:3 and 1:4 MMRs, the leading population is less stable than the trailing population. Most interestingly, we discover a novel phenomenon of number reversal, where the higher-order, weaker 3:8 MMR (at semimajor axis $a\\approx57.9$ AU) hosts more resonators, rather than fewer as expected, compared to the lower-order, stronger 3:7 MMR (at $a\\approx53.0$ AU). Future observations, whether confirming or challenging this phenomenon, will offer valuable insight into the eccentricity and inclination distributions of primordial KBOs."
  },
  {
    "date": "2026-01-21",
    "title": "Multi-Behavior Sequential Modeling with Transition-Aware Graph Attention Network for E-Commerce Recommendation",
    "authors": "Hanqi Jin, Gaoming Yang, Zhangming Chan, Yapeng Yuan, Longbin Li, Fei Sun, Yeqiu Yang, Jian Wu, Yuning Jiang, Bo Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14955v1",
    "source": "arXiv",
    "abstract": "User interactions on e-commerce platforms are inherently diverse, involving behaviors such as clicking, favoriting, adding to cart, and purchasing. The transitions between these behaviors offer valuable insights into user-item interactions, serving as a key signal for understanding evolving preferences. Consequently, there is growing interest in leveraging multi-behavior data to better capture user intent. Recent studies have explored sequential modeling of multi-behavior data, many relying on transformer-based architectures with polynomial time complexity. While effective, these approaches often incur high computational costs, limiting their applicability in large-scale industrial systems with long user sequences. To address this challenge, we propose the Transition-Aware Graph Attention Network (TGA), a linear-complexity approach for modeling multi-behavior transitions. Unlike traditional transformers that treat all behavior pairs equally, TGA constructs a structured sparse graph by identifying informative transitions from three perspectives: (a) item-level transitions, (b) category-level transitions, and (c) neighbor-level transitions. Built upon the structured graph, TGA employs a transition-aware graph Attention mechanism that jointly models user-item interactions and behavior transition types, enabling more accurate capture of sequential patterns while maintaining computational efficiency. Experiments show that TGA outperforms all state-of-the-art models while significantly reducing computational cost. Notably, TGA has been deployed in a large-scale industrial production environment, where it leads to impressive improvements in key business metrics."
  },
  {
    "date": "2026-01-21",
    "title": "ClaimDB: A Fact Verification Benchmark over Large Structured Data",
    "authors": "Michael Theologitis, Preetam Prabhu Srikar Dammu, Chirag Shah, Dan Suciu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14698v1",
    "source": "arXiv",
    "abstract": "Despite substantial progress in fact-verification benchmarks, claims grounded in large-scale structured data remain underexplored. In this work, we introduce ClaimDB, the first fact-verification benchmark where the evidence for claims is derived from compositions of millions of records and multiple tables. ClaimDB consists of 80 unique real-life databases covering a wide range of domains, from governance and healthcare to media, education and the natural sciences. At this scale, verification approaches that rely on \"reading\" the evidence break down, forcing a timely shift toward reasoning in executable programs. We conduct extensive experiments with 30 state-of-the-art proprietary and open-source (below 70B) LLMs and find that none exceed 83% accuracy, with more than half below 55%. Our analysis also reveals that both closed- and open-source models struggle with abstention -- the ability to admit that there is no evidence to decide -- raising doubts about their reliability in high-stakes data analysis. We release the benchmark, code, and the LLM leaderboard at https://claimdb.github.io ."
  },
  {
    "date": "2026-01-21",
    "title": "Entanglement summoning from entanglement sharing",
    "authors": "Lana Bozanic, Alex May, Stanley Miao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.15112v1",
    "source": "arXiv",
    "abstract": "In an entanglement summoning task, a set of distributed, co-operating parties attempt to fulfill requests to prepare entanglement between distant locations. The parties share limited communication resources: timing constraints may require the entangled state be prepared before some pairs of distant parties can communicate, and a restricted set of links in a quantum network may further constrain communication. Building on earlier work, we continue the characterization of entanglement summoning. We give an if and only if condition on entanglement summoning tasks with only bidirected causal connections, and provide a set of sufficient conditions addressing the most general case containing both oriented and bidirected causal connections. Our results rely on the recent development of entanglement sharing schemes."
  },
  {
    "date": "2026-01-21",
    "title": "Evidence of mutually exclusive outflow forms from a black hole X-ray binary",
    "authors": "Zuobin Zhang, Jiachen Jiang, Francesco Carotenuto, Honghui Liu, Cosimo Bambi, Rob P. Fender, Andrew J. Young, Jakob van den Eijnden, Christopher S. Reynolds, Andrew C. Fabian, Julien N. Girard, Joey Neilsen, James F. Steiner, John A. Tomsick, Stéphane Corbel, Andrew K. Hughes",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14762v1",
    "source": "arXiv",
    "abstract": "Accretion onto black holes often leads to the launch of outflows that significantly influence their surrounding environments. The two primary forms of these outflows are X-ray disk winds-hot, ionized gases ejected from the accretion disk-and relativistic jets, which are collimated streams of particles often expelled along the rotational axis of the black hole. While previous studies have revealed a general association between spectral states and different types of outflows, the physical mechanisms governing wind and jet formation remain debated. Here, using coordinated NICER and MeerKAT observations of the recurrent black hole X-ray binary 4U 1630-472, we identify a clear anti-correlation between X-ray disk winds and jets: during three recent outbursts, only one type of outflow is detected at a time. Notably, this apparent exclusivity occurs even as the overall accretion luminosity remains within the range expected for a standard thin disk, characteristic of the canonical soft state. These results suggest a competition between outflow channels that may depend on how the accretion energy is partitioned between the disk and the corona. Our findings provide new observational constraints on jet and wind formation in X-ray binaries and offer a fresh perspective on the interplay between different modes of accretion-driven feedback."
  },
  {
    "date": "2026-01-21",
    "title": "Gravitational form factors of the proton in the improved holographic QCD model",
    "authors": "Antti Hippeläinen, Niko Jokela, Matti Järvinen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.14939v1",
    "source": "arXiv",
    "abstract": "We compute the gluonic contribution to the gravitational form factors of the proton using the improved holographic QCD model, in which the proton is described in terms of bulk Dirac fermions. Model parameters are constrained using lattice and phenomenological input, allowing us to obtain estimates for the gravitational form factors and to compare them with results from other approaches. The resulting $\\mathcal{D}(t)$ form factor is found to exhibit an infrared pole in our framework. Using the extracted form factors, we analyze mechanical properties of the proton, including pressure and shear distributions. We obtain estimates of $ρ_\\text{mech} = 0.95$ fm and $ρ_\\text{mass} = 0.61$ fm for the mechanical and the mass radii of the proton, respectively, which are similar to values in other nonperturbative studies."
  },
  {
    "date": "2026-1-21",
    "title": "IEEE Transactions on Industry Applications Publication Information",
    "authors": "N/A",
    "publish": "IEEE Transactions on Industry Applications",
    "url": "https://doi.org/10.1109/tia.2025.3612859",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-1-21",
    "title": "Impact of Aspect Ratio on Propagation Delay and Parasitics in CMOS Inverters: A Cadence Simulation Study",
    "authors": "Nandana Kamath, Aditi Javeri, Samrat Sharma, Samana Nagendran, Arjun Sunil Rao, Basavaraj S Sannakashappanavar",
    "publish": "2025 Control Instrumentation System Conference (CISCON)",
    "url": "https://doi.org/10.1109/ciscon66933.2025.11337478",
    "source": "IEEE",
    "abstract": "This research focuses on the study of effect of aspect ratio on the propagation delay and parasitic resistance and capacitance of CMOS inverter circuit. Cadence simulation tool with technology file gpdk90 is used for the simulation of this research. Initially, using Virtuoso tool the schematic of CMOS inverter is designed with different <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\frac{W}{L}$</tex> ratios <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$1: 2.45,1: 1$</tex>, and 2.45:1 corresponding to aspect ratios <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$0.4081,1$</tex> and 2.45, respectively. It was found that the aspect ratio of 2.45 produced the lease propagation delay as compared to 1 and 0.4081 thereby, indicating that the aspect ratio of 2.45 performs much faster with minimal propagation delay. Furthermore, using Asura tool the layout of CMOS inverter with different aspect ratios are designed to determine the parasitic resistance and capacitance. These parasitics were determined at the input node and the output node for all three aspect ratios. It was found that the input parasitic resistance marginally changed. However, the output parasitic resistance was found to be <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$342.1 \\mathrm{m} \\Omega, 678.9 \\mathrm{m} \\Omega$</tex> and <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$808.8 \\mathrm{m} \\Omega$</tex> for aspect ratios <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$2.45,1$</tex> and 0.4081, respectively. In addition, the input parasitic capacitance was found to be <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$35.36 \\text{aF}, 3.19 \\text{aF}$</tex> and 54.15 aF for aspect ratios <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$0.4081,1$</tex> and 2.45, respectively. Furthermore, the output parasitic capacitance was found to be <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$42.89 \\text{aF}, 60.16 \\text{aF}$</tex> and 67.66 aF for aspect ratios <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$0.4081,1$</tex> and 2.45, respectively."
  },
  {
    "date": "2026-1-21",
    "title": "Mamba-Enhanced High-Resolution Network with Energy-Balanced and Region-Selective Feature Learning for Remote Sensing Semantic Segmentation",
    "authors": "Haoxue Zhang, Linjuan Li, Xinlin Xie, Gang Xie, Yan Qiao, Chenhao Chang",
    "publish": "2025 International Conference on Algorithms, Data Mining, and Information Technology (ADMIT)",
    "url": "https://doi.org/10.1109/admit67050.2025.11337041",
    "source": "IEEE",
    "abstract": "High-resolution remote sensing imagery (HRRSI) poses significant challenges for semantic segmentation due to complex landscapes and fine-grained details. Accurate segmentation remains difficult because existing models struggle to jointly preserve high-resolution details, capture long-range dependencies, and maintain regional coherence. We propose ERMHNet, an enhanced HRNet that integrates scale-cross Mamba (SCMamba) for long-range dependency modeling, the Residual Energy Balance Module (REBM) for feature balancing, and Selective Region-Aware Learning (SRAL) combined with a selective distillation loss for structural refinement. On the ISPRS Vaihingen dataset, ERMHNet achieves a <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{+ 1. 8 \\%}$</tex> mIoU improvement over leading CNN, Transformer, and hybrid baselines, demonstrating robustness, interpretability, and competitive complexity."
  },
  {
    "date": "2026-1-21",
    "title": "Quantum-Enhanced Emotion-Aware Pedestrian Trajectory Prediction for Autonomous Driving Systems",
    "authors": "M Sri Darshan, N NithinRaj, J Darsin David, T Sugirtha",
    "publish": "2025 IEEE North Karnataka Subsection Flagship International Conference (NKCon)",
    "url": "https://doi.org/10.1109/nkcon66957.2025.11345743",
    "source": "IEEE",
    "abstract": "As autonomous vehicles (AVs) transition from controlled experimentation to real-world use, their capacity to converse effectively with pedestrians is crucial.Existing research on pedestrian trajectory prediction has mostly ignored the nuances of human emotions on motion behavior in favor of motion cues. We introduce a novel emotion-aware vehicle interaction model that incorporates pedestrian emotion identification, vehicle trajectory prediction, and adaptive vehicle behavior. Utilizing a multimodal method that incorporates computer vision and affective computing, we can detect emotional states such as happiness, distraction, perplexity, and anger in real-time. In particular, each emotional manifestation will correspond to specific vehicular actions such as travelling at normal speed, decreasing speed, or coming to a complete stop based on the identified pedestrian’s behavior intent. The proposed system developed a pathway from emotional assessment of pedestrians to vehicle trajectory action that used a spatio-temporal model to predict pedestrian behavior and plan a vehicle trajectory in real-time that enabled a safe vehicle behavior while adhering to natural human-robot interaction. Evaluation of our model with urban datasets shows a much significant improvement in prediction accuracy, responsiveness, and collision avoidance compared to baseline methods. The findings demonstrate a need to build upon the findings from this study into the next generation AV system and know that emotionally aware AV systems can generate a more secure autonomous vehicle framework and setting for autonomous mobility that is more socially and human-centered."
  },
  {
    "date": "2026-1-21",
    "title": "Smart IoT-Enabled Cooling System for Real-Time EV Battery Temperature Management",
    "authors": "Sridhar B, Allirani S, Hassan Siddiq A, Dinesh TC, Harikaran K, Nishikant N",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336270",
    "source": "IEEE",
    "abstract": "The rapid proliferation of electric vehicles (EVs) has accentuated the need for robust safety systems, especially concerning lithium-ion battery management, which is a critical component in EV performance and safety. This project introduces a comprehensive battery burning detection and alert system designed to monitor the characteristics of lithium-ion batteries in electric vehicles. By employing a real-time battery fault detection framework, this system aims to mitigate risks associated with battery overheating and potential fire hazards, thereby enhancing the safety and reliability of electric vehicles. Specifically, a voltage and current sensor interfaced with a MCP3008 analog to digital converter (ADC) serves to collect accurate data on the electrical characteristics of the battery. The integration of a DHT11 temperature sensor further enriches the data set by monitoring ambient and battery temperatures, providing critical insights into thermal conditions that may indicate battery distress. Moreover, the system ensures seamless data transmission to a cloud-based platform using the Thing Speak API, which facilitates real time monitoring and forecasting of battery health over time. This data accumulation empowers users to visualize battery performance trends through a user-friendly web application, where they can access not only current parameters but also historical data this battery burning detection and alert system embodies an innovative approach to enhancing the safety of electric vehicles through diligent monitoring and real time data analysis. By leveraging modern sensor technology and cloud computing."
  },
  {
    "date": "2026-1-21",
    "title": "Deep Learning-Based Light Weight CAD System for Early and Accurate Detection of Multiple Lung Diseases from Chest X-Rays",
    "authors": "K. Kaaviyakanth, Pradeep S, Karthika A, S. Prema, Manna Moses C M, Midhuna S",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337068",
    "source": "IEEE",
    "abstract": "Lung diseases such as pneumonia, tuberculosis, and COVID-19 remain a major public health concern worldwide, contributing to millions of deaths annually. Early and accurate detection is crucial to improving survival rates and treatment effectiveness. Chest X-ray (CXR) imaging is one of the most accessible diagnostic tools, but interpretation is limited by human fatigue, subjectivity, and shortage of trained radiologists. This study proposes a lightweight deep learning-based computer-aided diagnosis (CAD) system for the classification of multiple lung diseases, including normal, pneumonia, tuberculosis, and COVID-19 cases. The proposed model employs a customized convolutional neural network (CNN) optimized for efficiency, accuracy, and deployment in low-resource environments. A combined dataset from multiple open-access repositories was used, consisting of six categories of CXR images. The model achieved high performance across multiple evaluation metrics, with accuracy exceeding 98%. Compared to state-of-the-art architectures such as EfficientNetB0, DenseNet169, and DenseNet201, the proposed framework provides competitive accuracy with significantly reduced computational cost. The results demonstrate the potential of lightweight CNN models to support radiologists in rapid and accurate lung disease detection, particularly in rural and resource-constrained clinical settings."
  },
  {
    "date": "2026-1-21",
    "title": "Multimodal Attention Evaluation in Child–Robot Storytelling: A Machine Learning Framework with NAO",
    "authors": "Laura Fiorini, Elena Adelucci, Lorenzo Pugi, Stefano Scatigna, Chiara Pecini, Filippo Cavallo",
    "publish": "2025 IEEE International Conference on Advanced Robotics (ICAR)",
    "url": "https://doi.org/10.1109/icar65334.2025.11338710",
    "source": "IEEE",
    "abstract": "Understanding and measuring children’s attention is a key challenge in educational human–robot interaction (HRI). This paper presents a novel evaluation framework for detecting attention in school-age children during a storytelling activity with the NAO social robot. Unlike traditional scenarios where the robot narrates, here the child actively tells a story while the robot listens and adapts, fostering engagement through constructivist and sociocultural learning principles. We integrate multimodal features—including gaze behaviour (automatically labelled using Gaze360 and K-means clustering), task performance, and physiological signals (heart rate)—to classify attention levels via machine learning methods (SVM, KNN, RF). Seventy-four children (aged 7–9) participated in the study, with attention labels validated by expert observers. Results show that combining gaze, task, and physiological features improves classification accuracy (>0.70) compared to unimodal approaches, with KNN achieving the best performance. These findings highlight the potential of multimodal attention detection for enabling adaptive, context-aware robot behaviours in education. Our framework advances the development of socially intelligent robots that can dynamically respond to children’s attentional states, ultimately supporting more engaging and effective learning experiences."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Powered Sustainable Smart Agriculture Using UAV and IoT Metadata",
    "authors": "Vijaya G, Saravanavel E, K. Ramesh, Tamilselvi S",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336861",
    "source": "IEEE",
    "abstract": "The growing demand for sustainable and data-driven farming practices has accelerated the use of intelligent systems that combine aerial and ground-based observations. This study presents an artificial intelligence framework that fuses multispectral imagery from unmanned aerial vehicles (UAVs) with Internet of Things (IoT) sensor data measuring soil nutrients and environmental factors such as nitrogen, phosphorus, potassium, moisture, pH, temperature, and humidity. A hybrid convolutional neural network-bidirectional long short-term memory (CNN-BiLSTM) architecture enhanced with an attention mechanism is employed to extract spatial features from UAV images and capture temporal trends from sequential IoT readings. The model is optimized using the Adam algorithm (learning rate = 0.001) over 50 epochs and evaluated on an 80:20 train-test split. Experimental results show stable convergence with a mean absolute error of approximately 0.53, indicating accurate prediction of nutrient stress and pest-related conditions. Based on the model outputs, the system provides probability-driven recommendations for fertilization, pest control, and field monitoring. Overall, the proposed framework demonstrates a scalable, energyefficient, and interpretable approach for advancing sustainable precision agriculture."
  },
  {
    "date": "2026-1-21",
    "title": "Analysis and Design of a Multi-Input Multi-Output Buck-Boost Converter for Enhanced Renewable Energy Integration",
    "authors": "Priya S, Anitha S",
    "publish": "2025 Control Instrumentation System Conference (CISCON)",
    "url": "https://doi.org/10.1109/ciscon66933.2025.11337770",
    "source": "IEEE",
    "abstract": "This paper presents a new architecture for a multi-input, multi-output (MIMO) buck-boost DC-DC converter, developed to support the integration of renewable energy sources. The converter is capable of interfacing multiple sources—such as photovoltaic panels, wind turbines, and energy storage units—with several output loads simultaneously. Utilizing a single inductor, the design enables both step-up and step-down voltage conversion along with bidirectional power flow, contributing to reduced component count and overall system cost. The converter is engineered to adapt to variable input and load conditions while maintaining stable output performance and high efficiency. A control strategy is implemented to manage power distribution, facilitate seamless mode transitions, and regulate voltage levels. Performance evaluation through MATLAB/Simulink simulations under various operational conditions demonstrates the converter's effectiveness in hybrid energy systems, showing high efficiency, minimal voltage ripple, and fast transient response."
  },
  {
    "date": "2026-1-21",
    "title": "SOMM: A Novel Context based N-gram Model for Opinion Mining in Odia Language",
    "authors": "Gayatri Dey, Hima Bindu Maringanti",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11337965",
    "source": "IEEE",
    "abstract": "Opinion Mining is the process to extract people’s opinions, feelings, experiences and emotions towards an object, that object may be a product, event, situation, person. An opinion is an expression that contains a word or a series of words. In this era of digitalization, people express their opinions through Natural Language on social media, review sites and blogs. Odia people also express their opinions in Odia language through these above web media. So, there is the need of opinion analysis to mine sentiment of people who express their opinions in this language. In this paper a model called \"SOMM: A Novel Context based N-gram Model for Opinion Mining in Odia Language\" is designed to extract people’s opinion written in Odia text. SOMM stands for Satyajit Opinion Mining Model. In this model the collected opinions are the simple written statements containing one to three words. This model is lexicon-based as well as context-based. It can be extended for the sentences containing more than three words and also for compound statements in future."
  },
  {
    "date": "2026-1-21",
    "title": "Post Quantum Zero Knowledge Consensus for Cooperative Malware Verdicts",
    "authors": "D. Sandhya Rani, Cheepu Balakrishna, SK. Yakoob, E. Padmalatha, G Bala Krishna, T. Veeranna",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337122",
    "source": "IEEE",
    "abstract": "The constant development of the malware and the fact that quantum-powered attackers are only a matter of time leave traditional collaborative threat intelligence solutions behind. This paper proposes PQ-ZK-CMV, a post-quantum, zero-knowledge consensus protocol that allows Internet service providers and enterprises to make in real-time a deliberation on malicious indicators that is verifiable but does not disclose sensitivity information in logs. The methodology uses a latticebased post-quantum signature combined with zero-knowledge attestation of evidence and stake-reputation weighted Byzantine consensus to mitigate Sybil and poisoning attacks. Experiments on synthetic CTI workloads demonstrate consistency of PQ-ZKCMV commit ratios <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$(\\sim 0.64)$</tex>, balance between the error rates <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$(F P=0.11, F N=0.09)$</tex>, and attack resistance (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\leqslant 0.32$</tex> due to attack without 40 % adversaries). A comparative evaluation with five published baselines affirms that PQ-ZK-CMV achieves a better balance of privacy preserving, quantum resistance and group defense capacity. These findings make PQ-ZK-CMV a feasible framework in cross-organizational malware protection in the post-quantum world."
  },
  {
    "date": "2026-1-21",
    "title": "Image-Based Big Data and Spatial Object Detection: A Bibliometric Review",
    "authors": "Juveriya Mujawar, Ravindra Rathod",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336789",
    "source": "IEEE",
    "abstract": "Big data has become an industry-changing phenomenon that supports intelligent systems of real-time analytics. Even with the promise, it is inefficient to be implemented on a large scale due to limitations in facets like scalability, real-time processing, data governance, and computational inefficiency. This paper comprises a significant bibliometric review of published papers from year 2020 to 2025. The dataset was cleaned to remove duplicates and non-relevant works, and analyzed using Excel-based bibliometric techniques including keyword frequency analysis, citation mapping, and publication trend visualization. The analysis, drawn tracks the keyword trends, citation rates, publication rates, and topic saturation to create the visualization of the changing research landscape of big data. The emerging growth in the areas of surveillance, autonomous navigation, healthcare, and multimedia analytics has contributed to taking image-based big data as a matter of high significance in contemporary computing. Given the exponential volume and complexity of visual information entering the data pipeline, classic big data paradigms are migrating to support spatial and localization of objects as well as semantic meaning in high-dimensional image sequences. A bibliometric analysis establishes the trends in the topic of object detection, spatial search, federated learning, and edge vision AI systems. Citation and keyword studies shows citation network analysis and keyword analysis particularly show how decentralized and privacy-friendly image analytics have become a major concern, as well as spatial conscious object detection as an important research challenge. This paper reveals important research gaps in adapting infrastructure studies to the applied computer vision problem, which provides the directions of future research on scalable, ethical, and intelligent big data platforms based on images appropriately."
  },
  {
    "date": "2026-1-21",
    "title": "Nuvon: An AI-Embedded Chatbot for Home Automation",
    "authors": "Seema U. Deoghare, Mrunalini Bhandarkar, Kshitij Ravikant Mathapati, Maitree Murti Dongre, Vedant Rajesh Mundada",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335749",
    "source": "IEEE",
    "abstract": "Voice assistants are increasingly integral to smart homes and IoT ecosystems, but widespread cloud dependence in commercial assistants like Amazon Alexa and Google Assistant leads to response latency, elevated power consumption, and privacy concerns. To address these issues, this study proposes Nuvon, an embedded AI voice assistant designed for home automation. Built on the ESP32 microcontroller, Nuvon employs Deepgram’s deep neural network for speech recognition and Gemini AI for dynamic response generation. Unlike conventional scripted assistants, Nuvon processes simple commands locally while leveraging cloud resources selectively for complex queries, balancing speed, accuracy, and privacy. Experimental evaluations demonstrate rapid response times under one second and recognition accuracy of approximately 85% in quiet and 72% in noisy environments. By minimizing raw audio transmission to the cloud, Nuvon enhances user data security and lowers power requirements to suit lightweight IoT devices. This hybrid embedded-cloud approach substantiates the practicality and effectiveness of AI-powered voice assistants for real-time, privacy-conscious home automation, advancing beyond the limitations of fully cloud-reliant systems."
  },
  {
    "date": "2026-1-21",
    "title": "QARV++: An Improved Hierarchical VAE for Learned Image Compression",
    "authors": "Yichi Zhang, Yuning Huang, Fengqing Zhu",
    "publish": "IEEE Transactions on Circuits and Systems for Video Technology",
    "url": "https://doi.org/10.1109/tcsvt.2026.3656831",
    "source": "IEEE",
    "abstract": "Hierarchical Variational Autoencoder (HVAE)-based Learned Image Compression (LIC) has shown great promise, but its performance still lags behind autoregressive models due to three key limitations identified: (1) shared latent mappings that lead to accumulated posterior collapse; (2) reliance on static convolutions, limiting adaptability; and (3) gradient imbalance during variable-rate optimization, causing unbalanced performance across different bit rates. To overcome these challenges, we propose QARV++, an improved HVAE-based LIC method. First, we introduce a disentangled latent mapping mechanism, assigning separate transformations to each latent variable to prevent posterior collapse propagation. Second, we integrate deformable convolutions into the network, introducing the DCNNeXt block, which enables dynamic feature adaptation while maintaining computational efficiency. Third, we reformulate variable-rate optimization to ensure balanced gradient updates across different λ values, stabilizing variable-rate training. Extensive experiments demonstrate that QARV++ achieves superior rate-distortion (R-D) performance among HVAE-based LIC models, exhibiting -12.20% -16.34% -15.23% BD-Rate against VVC Intra mode on the Kodak, Tecnick, and CLIC2020 test datasets, respectively. Our approach also generalizes effectively to existing LICs, delivering substantial improvements."
  },
  {
    "date": "2026-1-21",
    "title": "Typestate-based Fault Localization of API Usage Violations in a Deep Learning Program",
    "authors": "Fraol Batole, Ruchira Manke, Robert Dyer, Tien N. Nguyen, Hridesh Rajan",
    "publish": "IEEE Transactions on Software Engineering",
    "url": "https://doi.org/10.1109/tse.2026.3656464",
    "source": "IEEE",
    "abstract": "Deep Learning (DL) applications have become essential in numerous domains, yet they remain plagued by subtle bugs that cause 66% of crashes in production systems. These failures primarily stem from API usage violations in complex frameworks like TensorFlow, Keras, and PyTorch, where APIs lack formal specifications and interdependencies between operations remain undocumented. Traditional static analysis tools fail to address DL-specific constraints, such as data dependency between layers. To bridge this critical gap, we propose NEURALSTATE, an approach to detect performance and program crash bugs in a DL program. NEURALSTATE follows a four-step process: (i) gather specifications for Deep Learning operations from different sources; (ii) introduce abstract states to represent these Deep Learning operations; (iii) design formal rules for transitioning between states based on the specifications; (iv) utilize a combination of standard analysis techniques (i.e., typestate and value propagation) to identify bugs in a DL program. Our evaluation on real-world benchmarks demonstrates NEURALSTATE’s effectiveness, achieving a 25% improvement in precision and 63% improvement in recall compared to state-of-the-art tools. Most importantly, NEURALSTATE successfully detects 18 subtle bugs in 45 real-world programs that existing techniques miss entirely."
  },
  {
    "date": "2026-1-21",
    "title": "Assessing the Effects of Corrupted Parameters in a Large Language Model: A Case Study of LLAMA 3.2 1B",
    "authors": "Rathachai Chawuthai, Anon Thongsawaeng, John Paul Layug Perdio, Kaung Khant Zaw, Phalat Kraichoke, Hlaing Myat Nwe, Natthawut Kertkeidkachorn",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775040",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "VINS-Mah: A Robust Monocular Visual-Inertial State Estimator for Dynamic Environments",
    "authors": "Yuquan Hu, Alessandro Gardi",
    "publish": "IEEE Robotics and Automation Letters",
    "url": "https://doi.org/10.1109/lra.2026.3656724",
    "source": "IEEE",
    "abstract": "Conventional Visual-Inertial Navigation Systems (VINS) are developed under the assumption of static environments, leading to significant performance degradation in dynamic environments. In recent years, many dynamic-feature-aware VINS implementations have been proposed, but most of them rely on prior semantic information and lack generalizability. To address these limitations, we propose a robust monocular method called VINS-Mah, which is capable of identifying both dynamic and unreliable features without prior semantic information. First, the covariances related to the feature reprojection errors are computed via the proposed uncertainty estimator. Subsequently, a dynamic feature filter module combines the feature reprojection errors and the computed covariances to determine the Mahalanobis distance, and then applies a Chi-square test to filter out dynamic features. The proposed method is verified against several publicly available datasets, covering both simulated and real-world scenes. Experimental results demonstrate that VINS-Mah outperforms other state-of-the-art methods in dynamic scenarios, while not degrading in static environments. The implementation is publicly available at: <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/hyq123-cmd/VINS-Mah.git</uri>."
  },
  {
    "date": "2026-1-21",
    "title": "Smart Seat Occupancy and Energy Harvesting System",
    "authors": "K. Bagyalakshmi, S. Pavin Ashok, Kp. Kishore, K. Maniyarasan",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335655",
    "source": "IEEE",
    "abstract": "Smart seating systems that autonomously detect occupancy and generate power from user movements offer a promising avenue for intelligent buildings and transportation. By integrating polyvinylidene fluoride (PVDF) piezoelectric films onto seat cushions, this work tackles the problem of enabling self-powered seating by capturing mechanical energy from motions like standing, sitting, and changing posture. A rectifier-capacitor network is integrated into the proposed system to store collected energy and power lowpower wireless sensor nodes intermittently. At the same time, the generated voltage signals are analyzed to categorize occupancy states, such as occupied, unoccupied, and posture transitions. With gathered power ranging from 1 to 5 mW, experimental assessments show that the system can achieve real-time occupancy detection accuracy surpassing 95% under actual seated situations. These result demonstrate the dual advantages of PVDF-based films as energy harvesters and sensors, overcoming drawbacks associated with impedance mismatch and limited energy production. The results highlight the possibility of scalable, sustainable, and maintenance-free smart seating options for intelligent spaces of the future."
  },
  {
    "date": "2026-1-21",
    "title": "Simulation-based Analysis of Thermal and Timing Effects in VLSI",
    "authors": "Shraddha Makam, Sudipta Sunil, S Bindu, P Rekha, M K Prashanth",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335614",
    "source": "IEEE",
    "abstract": "This work provides a comprehensive simulationbased examination of thermal and timing effects in deepsubmicron VLSI circuits. A two-dimensional chip model, partitioned into functional blocks is employed to capture spatial and temporal power dissipation variation under dynamic workloads. Transient thermal analysis, facilitated using an explicit finite-difference solver, simulates temperature evolution with realistic silicon material properties and boundary convection. The synthesized thermal profiles are coupled with temperature-dependent delay equations to calculate critical-path delay, timing degradation, and delay spread between functional blocks. Simulation analysis demonstrates a quadratic correlation of temperature and delay that is strong, and up to a 13 ns hotspot-induced timing variation. The results indicate that average-temperature models cannot capture dynamic behavior, making it essential to use spatially and temporally resolved thermal-timing cosimulation. This method offers helpful advice for thermalaware floorplanning, power partitioning, and robust timing closure of modern VLSI designs under high power densities."
  },
  {
    "date": "2026-1-21",
    "title": "Matching Design of 650-V Cascode GaN Bidirectional Switch",
    "authors": "Sheng Li, Ziyu Chen, Mingfei Li, Weihao Lu, Yanfeng Ma, Leke Wu, Yiheng Li, Tinggang Zhu, Ran Ye, Jie Ma, Jiaxing Wei, Long Zhang, Siyang Liu, Weifeng Sun",
    "publish": "IEEE Transactions on Electron Devices",
    "url": "https://doi.org/10.1109/ted.2026.3653939",
    "source": "IEEE",
    "abstract": "This article discusses the matching design of a cascode-configured gallium nitride (GaN) bidirectional switch device (CG-BDS), based on the conventional depletion-mode (D-mode) GaN process platform. A CG-BDS consists of one bidirectional D-mode GaN (Bi-DGaN) device, two low-voltage silicon-based metal oxide semiconductor (LV-MOS) devices, which may face reliability problems without matching designs. With a large matching resistor connected in parallel across the drain–source terminals of the LV-MOS, the voltage drops on the LV-MOS are reduced under static high-voltage bias conditions, hence avoiding the avalanche of the LV-MOS. Simultaneously, with a matching capacitor connected in parallel across the drain–source terminals of the LV-MOS, the overvoltage caused by the dynamic responses of the inherently large parasitic capacitors within the inner Bi-DGaN is also reduced, ensuring that the LV-MOS always operates within the safe voltage range. However, a larger matching capacitor also affects the switching speed, thereby influencing the overall switching losses. Therefore, the analytical models that characterize turn-on and turn-off delay times, taking into account the effect of the matching capacitor, are proposed. These models help elucidate the relationship between cascode operation safety and switching loss, as experimentally demonstrated."
  },
  {
    "date": "2026-1-21",
    "title": "Label Free Detection of Positively Charged Biomolecules using SiC Schottky Barrier FET",
    "authors": "Sukasini S K, Papanasam E",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336916",
    "source": "IEEE",
    "abstract": "Label-free biosensors operate by detecting biomolecules based on their intrinsic biophysical properties, making the detection process faster and more accurate. This article introduces an innovative design for effective label-free biosensing applications. The suggested device features a Schottky Barrier FET made from <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{6 H}$</tex>-Silicon Carbide, incorporating a cavity for biomolecule detection. Through TCAD Sentaurus Sprocess, simulations were conducted for charged biomolecules with concentration of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$8 e^{12} \\mathrm{C} / \\text{cm}^{2}$</tex>, and across a temperature range of 200 K to 400 K. The device demonstrates a peak <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$O N$</tex> current sensitivity of 12.926, a transconductance sensitivity of 10.534, an Ion/Ioff sensitivity of 22.46 for positively charged biomolecules with a dielectric constant (K) of 18."
  },
  {
    "date": "2026-1-21",
    "title": "Real-Time Smart Solar Grid Integration Using Arduino and GSM Monitoring",
    "authors": "J Jency Joseph, Balaji K, Hari Krishna R, Kishore N",
    "publish": "2025 Control Instrumentation System Conference (CISCON)",
    "url": "https://doi.org/10.1109/ciscon66933.2025.11337877",
    "source": "IEEE",
    "abstract": "Electricity is generated by the system based on solar power, which is subsequently transformed and activated. Sunlight is captured by solar panels and transferred to direct DC (direct current) electricity. Thereafter, the electricity is transmitted to a SEPIC converter, which raises the voltage or reduces it to reach the desired level. Pulse width modulation (PWM) signals drive a driver circuit, ensuring output stability of the converter. A dSPIC30F2010 microcontroller drives the system but monitors voltage and present levels and providing control signals to prevent proper functioning. In the case of a difference between the reference and actual voltage, a comparator produces an error signal. An inverter that is suitable for grid integration then transforms the DC electricity to alternating current (AC). Depending on the power condition, a relay module is used to turn on or isolate the system from the grid. The system also possesses a communication module that can send notifications with regard to defects or voltages, ensuring efficient operation and timely settlement of any issues."
  },
  {
    "date": "2026-1-21",
    "title": "Parametrized Dynamic Model for Off-the-Shelf Quadrotors: Incorporating Flapping-Induced Drag and Autopilot Constraints",
    "authors": "Daniel K. D. Villa, Vinícius Pacheco Bacheti, Mário Sarcinelli-Filho",
    "publish": "2025 IEEE International Conference on Advanced Robotics (ICAR)",
    "url": "https://doi.org/10.1109/icar65334.2025.11338652",
    "source": "IEEE",
    "abstract": "This study reviews the simplified model proposed in previous articles by the same research group to represent the dynamic behavior of an unmanned aerial vehicle (UAV), specifically a quadrotor equipped with an onboard autopilot. The autopilot tracks high-level control inputs, which consist of attitude commands for roll and pitch, as well as vertical speed and yaw rate commands. These high-level inputs are normalized by the maximum allowable value for each control channel, a constraint that is imposed by the embedded autopilot. In the new model provided, it is shown that the control input matrix is directly related to the maximum values thus configured, while the remaining dynamic terms are associated with aerodynamic drag in the ${\\dot x^b}$ and ${\\dot y^b}$ directions and with the internal gains of the embedded low-level controllers in the ${\\dot z^b}$ and $\\dot \\psi $. The revised model is identified and experimentally validated using a feedback linearization controller designed based on this model."
  },
  {
    "date": "2026-1-21",
    "title": "A Brief Study of Cybersecurity Penetration Testing Methods and Their Applications",
    "authors": "Ashkan Hosseini, Hossein Salehfar",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337852",
    "source": "IEEE",
    "abstract": "One way to secure the system is through offensive security. Offensive security is a cybersecurity method in which experts perform cyberattacks on any system to identify weaknesses. Then, they report the identified weak points to the company or party requesting penetration testing. The information collected can be used to improve system security, ensuring that identified flaws are fixed or improved to prevent hacker break-ins. Penetration testing involves a team of security professionals who actively attempt to break into a company's network by exploiting weaknesses and vulnerabilities in the systems. Penetration testing can be performed externally or internally to simulate different attack scenarios. This study focuses on performing three types of penetration testing: network penetration testing, web application penetration testing, and wireless penetration testing. The author aims to discuss what should be done to improve the flaws and weaknesses discovered by these tests and how to improve the testing methods as a whole. The study also provides a brief comparison of the advantages and disadvantages of each type in the end. To achieve these goals, previous related studies on the subject of penetration testing were analyzed, and scenario-based examples were examined for each type of test. In the end, the results obtained from the scenarios were discussed, and the best possible tools for each testing method were identified. These data verify that penetration tests must be performed according to the needs of each network or organization. This is due to the vast amount of tools and software available for various needs."
  },
  {
    "date": "2026-1-21",
    "title": "AFT-Net: Adaptive Spatiotemporal Feature Learning for Disaster-Aware Change Detection",
    "authors": "Chaoyun Mai, Zhiyuan Su, Panrong Chen, Lu Cao, Yikui Zhai, Yigui Huang, Hao Xie, Xiao Li",
    "publish": "2025 5th International Conference on Electronic Information Engineering and Computer Technology (EIECT)",
    "url": "https://doi.org/10.1109/eiect68017.2025.11331665",
    "source": "IEEE",
    "abstract": "Remote sensing change detection (RSCD) plays an important role in land use monitoring, disaster assessment, and emergency response. However, in disaster scenarios, bi-temporal images often suffer from spatial misalignment and a lack of modeling for gradual processes, leading to inaccurate and unstable detection results. To address these issues, this paper proposes the Adaptive Feature Alignment and Temporal Consistency Network (AFT-Net). The network is designed with two key modules: the Adaptive Feature Alignment and Enhancement (AFAE) module, which integrates deformable convolution, SE attention mechanism, and multi-scale atrous convolution to align mismatched regions and enhance change features; and the Temporal Consistency Constraint (TCC) module, which introduces feature memory and temporal attention mechanisms to model cross-temporal dependencies and ensure continuity in change detection. Experimental results on three representative datasets, LEVIR-CD, SYSU-CD, and S1GFloods, demonstrate that our model outperforms several state-of-the-art methods, particularly showing stronger robustness and temporal consistency in gradual disaster scenarios."
  },
  {
    "date": "2026-1-21",
    "title": "Direct position determination of wideband sources via distributed arrays: a dimensionality reduction and sub-band energy weighting method",
    "authors": "Yue Liu, Yingxian Zhang, Xuan Li, Lili Yang, Xilong Lian, Wen Wang",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338312",
    "source": "IEEE",
    "abstract": "To improve the positioning precision of wideband emitters via distributed sensor arrays, this paper proposes a direct position determination (DPD) algorithm based on sub-band energy weighting and dimension reduction. By employing distributed array data fusion, the proposed method significantly improves positioning precision. Furthermore, the introduced dimension reduction strategy eliminates the need for grid searches over unknown attenuation coefficient fields, thereby achieving lower computational complexity compared to conventional approaches. Crucially, the algorithm incorporates energy-based sub-band weighting, which discards low-energy sub-bands while amplifying the contribution of high-energy sub-bands to localization. Numerical simulations demonstrate the superior performance of the proposed algorithm over existing methods."
  },
  {
    "date": "2026-1-21",
    "title": "MapExRL: Human-Inspired Indoor Exploration with Predicted Environment Context and Reinforcement Learning",
    "authors": "Narek Harutyunyan, Brady Moon, Seungchan Kim, Cherie Ho, Adam Hung, Sebastian Scherer",
    "publish": "2025 IEEE International Conference on Advanced Robotics (ICAR)",
    "url": "https://doi.org/10.1109/icar65334.2025.11338661",
    "source": "IEEE",
    "abstract": "Path planning for robotic exploration is challenging, requiring reasoning over unknown spaces and anticipating future observations. Efficient exploration requires selecting budget-constrained paths that maximize information gain. Despite advances in autonomous exploration, existing algorithms still fall short of human performance, particularly in structured environments where predictive cues exist but are underutilized. Guided by insights from our user study, we introduce MapExRL, which improves robot exploration efficiency in structured indoor environments by enabling longer-horizon planning through a learned policy and global map predictions. Unlike many learning-based exploration methods that use motion primitives as the action space, our approach leverages frontiers for more efficient model learning and longer horizon reasoning. Our framework generates global map predictions from the observed map, which our policy utilizes, along with the prediction uncertainty, estimated sensor coverage, frontier distance, and remaining distance budget, to assess the strategic long-term value of frontiers. By leveraging multiple frontier scoring methods and additional context, our policy makes more informed decisions at each stage of the exploration. We evaluate our framework on a real-world indoor map dataset, achieving up to an 18.8% improvement over the strongest state-of-the-art baseline, with even greater gains compared to conventional frontier-based algorithms. Website: mapexrl.github.io"
  },
  {
    "date": "2026-1-21",
    "title": "Real-time Analysis of DDoS Attack Detection and Mitigation Measures Using XGBoost Machine Learning Algorithm",
    "authors": "Seth Yao Alornyo, Derrick Agyapong, Joel Koima Kibiwott, Eunjin Kim",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337836",
    "source": "IEEE",
    "abstract": "Distributed Denial of Service (DDoS) attacks pose an ongoing threat to networked systems, often disrupting services and compromising data integrity. This study presents a real-time approach to DDoS detection and mitigation using the Extreme Gradient Boosting (XGBoost) machine learning algorithm. A comprehensive evaluation was conducted using the SDN-DDoS dataset, with detailed feature engineering focused on temporal and volumetric traffic attributes. The model demonstrated strong performance across key metrics. Results from confusion matrix analysis and feature importance visualization reveal the model's capacity to accurately classify traffic and identify critical features such as packet flow, jitter, and traffic rate. This work validates XGBoost's effectiveness in high-dimensional network environments and highlights its adaptability, transparency, and computational efficiency for real world cybersecurity applications."
  },
  {
    "date": "2026-1-21",
    "title": "Wireless Energy Theft Detection and Live Tracking using Power Line Harmonic Signature &amp; AI",
    "authors": "P Hemalatha, G B Mohankumar, R Balakrishnan, R Dhanushmathi, K Kaviyashree, M Mukundhan",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335863",
    "source": "IEEE",
    "abstract": "Electricity theft is one of the major challenges in energy distribution systems, especially in developing regions. Traditional detection methods often rely on smart meters (or) GSM based alerts, which are limited by cost, infrastructure and accuracy. This paper proposes a novel wireless electricity theft detection system that combines dual end sensing with harmonic signature analysis and AI based classification. By monitoring current at both the distribution pole, consumer end and analyzing distortion in power line harmonics using FFT, the system can detect theft patterns such as hooking, meter bypassing and unauthorized loads. A machine learning model is trained on harmonic features to improve detection accuracy. Real time alerts are communicated using LoRa (or) ZigBee (or) GSM modules. This system offers cost effective, low power and scalable deployment with improved accuracy, making it suitable for rural and semi urban electrical grids. In the future, this system can be integrated with cloud platforms and mobile apps for centralized monitoring. Edge AI can be used for faster on site detection. The design can also be extended to support industrial and three phase power systems."
  },
  {
    "date": "2026-1-21",
    "title": "Serverless Computing: The Future of Cloud Infrastructure and Development",
    "authors": "Gayatri Gurupad Hegde, Vishwanath V Murthy, Misba Abdul Khayum Sab",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11336042",
    "source": "IEEE",
    "abstract": "Serverless computing has emerged as a revolutionary paradigm in modern cloud computing, enabling developers to concentrate on application logic rather than infrastructure management [14]. Built upon Function-as-a-Service (FaaS) and Backend-as-a-Service (BaaS) models, serverless platforms offer automatic scaling, event-driven execution, and a pay-per-use pricing model, significantly reducing operational overhead [13]. Motivated by the need to evaluate operational benefits and limitations of serverless architectures, this paper uses a structured literature-review methodology to analyze frameworks, platforms, and optimization techniques. Findings indicate that serverless adoption accelerates development cycles, simplifies deployment, and improves resource efficiency, while persistent challenges include cold start latency, security vulnerabilities, monitoring gaps, and vendor lock-in [1]. Recent solutions surveyed involve intelligent scheduling, lightweight isolation mechanisms, and integration with edge computing to reduce latency and enhance locality. The paper concludes by highlighting future research trends, including AI-driven performance optimization, standardized observability, and hybrid deployment strategies that balance scalability with predictable performance, emphasizing the growing role of serverless computing in shaping next-generation cloud-native applications [10]."
  },
  {
    "date": "2026-1-21",
    "title": "Comparative Analysis of Trajectory Generation Strategies for Multiple Mobile Robots in Simulated Logistics Environments",
    "authors": "Bruno C. Hermes, Carlos R. Moratelli, Ebrahim S. El Youssef, Leonardo M. Rincon",
    "publish": "2025 IEEE International Conference on Advanced Robotics (ICAR)",
    "url": "https://doi.org/10.1109/icar65334.2025.11338662",
    "source": "IEEE",
    "abstract": "This paper presents a comparative analysis of three classical trajectory planning algorithms, Dijkstra, A* with visibility graph representation, and Wavefront, for differential-drive mobile robots in simulated logistics environments. Implemented in CoppeliaSim with a centralized conflict management policy based on task priority, the algorithms were evaluated in five scenarios with varying complexity. Metrics such as path length, execution time, and conflict resolution were assessed. The A* algorithm achieved the shortest paths (up to 25% shorter than Dijkstra) and lowest execution times, while Dijkstra was the only algorithm to complete all scenarios without failure. These results offer practical trade-offs for algorithm selection in autonomous mobile robot (AMR) logistics systems."
  },
  {
    "date": "2026-1-21",
    "title": "Energy and Security Trade-Offs in Cloud Data Center Scheduling: A Comprehensive Review",
    "authors": "Sowbarnika V, R Dhanapal",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337164",
    "source": "IEEE",
    "abstract": "Cloud data centres (CDCs) are at the core of contemporary computing services, but they struggle significantly with reconciling energy efficiency and security. A significant increase in workloads has led to a corresponding surge in power usage, carbon emissions, and operational costs. On the other hand, increased virtualization and multi-tenancy pose a variety of security threats, including, but not limited to, co-residency attacks, sidechannel attacks, and insecure VM migration. The double challenge of resource convergence is the allocation, consolidation, and optimization of computational resources in resource scheduling. Traditional scheduling algorithms mainly concentrate on energyaware scheduling strategies (i.e., energy-efficient works), which include heuristic, meta-heuristic, machine learning, and statistical methodologies that help to minimise energy usage to maintain service level agreements (SLA). Lately, security-inspired scheduling frameworks have emerged, focusing on VM separation, trust in the blockchain, intrusion detection, and access control. However, little effort has been made to integrate these two considerations into hybrid frameworks that aim to achieve optimal energy and security simultaneously. This paper provides an in-depth comparison of state-of-the-art practices, classifies them into specific categories, and discusses trade-offs between them. The comparative analysis exposes limitations in achieving multi-objective optimisation. The work outlines future research directions for sustainable, secure, and resilient CDC scheduling frameworks."
  },
  {
    "date": "2026-1-21",
    "title": "IC-CGU 2025 Content Announcement Page",
    "authors": "N/A",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338083",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-1-21",
    "title": "Structured Quantum Neural Networks Inspired by Multi-Head Attention Mechanisms",
    "authors": "Chufan Lyu",
    "publish": "2025 5th International Conference on Electronic Information Engineering and Computer Technology (EIECT)",
    "url": "https://doi.org/10.1109/eiect68017.2025.11331713",
    "source": "IEEE",
    "abstract": "We propose a quantum-classical hybrid neural network architecture inspired by the query-key-value attention mechanism widely used in classical deep learning. In this framework, feature extraction, weighting, and prediction are each implemented by parameterized quantum circuits (PQCs), while a lightweight classical module performs dot-product similarity and softmax normalization to realize attention-like interactions among quantum representations. The model operates entirely on amplitude-encoded data, using 12-qubit registers to process raw RGB images from a five-class subset of the CIFAR-10 dataset without any compression. By combining multi-basis quantum measurements with attention-style feature weighting, the proposed network captures relational dependencies across quantum features and achieves a test accuracy of approximately 74%. These results demonstrate that attention-inspired structures can enhance the expressivity and stability of variational quantum models, providing a scalable route toward structured learning in quantum neural networks and highlighting the potential of attention mechanisms as a design principle for future quantum deep learning architectures."
  },
  {
    "date": "2026-1-21",
    "title": "A TF-IDF-LDA Approach for Training Recommender System Based on Faculty Interests",
    "authors": "Jayson James Manglicmot Mayor",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775036",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Optimal Allocation and Scheduling of Battery Swapping and Charging Stations for Urban City",
    "authors": "Sachin Shivaji Kumbhar, Vaiju N. Kalkhambkar, Atul Jaysing Patil",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336785",
    "source": "IEEE",
    "abstract": "Electric mobility is rapidly growing in urban cities, reflecting a growing need due to rising fuel prices and decreasing air pollution. This paper presents the optimal siting, sizing, and day-ahead scheduling of Battery Swapping and Charging Stations (BSCS) for urban city contexts. The model minimizes the total annualized cost, comprising BSCS investment cost, operations and maintenance cost, charging cost, cycle-based battery degradation, and quality-of-service constraints. Novel elements of the proposed work include a road-graph network coverage constraint to ensure urban accessibility; joint land-area sizing for chargers and swappers; inventory dynamics for ready packs; and class-specific charging, i.e., slow/fast charging with PV-grid netting and linear cycle-degradation costs. The formulation ensures positive installation of both slow and fast chargers at selected site locations. Using realistic hourly demand, rates, and PV profiles, the model provides optimal site selection, number of devices, and storage capacity, as well as their cost and usage diagnostics. Results highlight PV-first and slow-first charging, strategic use of fast charging at peaks to protect service availability, and quantified trade-offs among capital, energy, and degradation. The framework is generic, data-driven, and directly implementable in real-life scenarios. The optimized deployment selects 4 of 14 candidate sites, installing 22 slow-charging bays, 4 fast-charging bays, and 4 swap bays."
  },
  {
    "date": "2026-1-21",
    "title": "HF Propagation Over Curved Sea-Land-Sea Mixed Paths: Coherent Attenuation Function",
    "authors": "Christophe Bourlier",
    "publish": "2025 IEEE Conference on Antenna Measurements and Applications (CAMA)",
    "url": "https://doi.org/10.1109/cama65664.2025.11335188",
    "source": "IEEE",
    "abstract": "In this communication, the coherent field propagating over a curved rough sea surface in presence of an island is computed from two approaches. First, an analytical closedform model (residues series), based on Bremmer’s and Feinberg’s works, in which the sea surface roughness is included from an heuristic way, based on Ishimaru’s work. Second, this model is validated from the full-wave method of moments hybridized to numerical accelerations."
  },
  {
    "date": "2026-1-21",
    "title": "Table of Contents",
    "authors": "N/A",
    "publish": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "url": "https://doi.org/10.1109/tcad.2025.3650324",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-1-21",
    "title": "A Hybrid Deep Learning and Quantum Feature Selection Framework for Multi-Class Intrusion Detection",
    "authors": "Ilhan Uysal, Utku Kose",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337944",
    "source": "IEEE",
    "abstract": "Intrusion Detection Systems (IDS) have become indispensable in modern cybersecurity due to the increasing sophistication of attack vectors and the limitations of traditional signature-based approaches. To address these challenges, this study proposes a hybrid deep learning and quantum feature selection (QFS) framework for multi-class intrusion detection. The methodology integrates classical ensemble learners (XGBoost, LightGBM), deep neural architectures (ANN, CNN+BiLSTM, Transformer, TabNet), and a stacking ensemble meta-learner to capture complementary strengths across models. Class imbalance was mitigated through SMOTE-based resampling, while QFS was employed to enhance dimensionality reduction and kernel alignment by selecting discriminative subsets of principal components. Experimental evaluation on a Windows host telemetry dataset encompassing seven attack classes demonstrated the effectiveness of the proposed framework. Classical ensemble models (XGBoost, LightGBM) achieved near-ceiling accuracy, whereas CNN+BiLSTM emerged as the most robust deep learning baseline with over 99% macro-F1 performance. In contrast, ANN and Transformer underperformed due to difficulties in modeling mixed-type tabular features. The stacking ensemble consistently delivered consistently high classification metrics across 10-fold cross-validation and the independent test set. QFS further contributed by reducing redundancy and improving computational efficiency while retaining predictive accuracy. These findings highlight the potential of integrating quantum-inspired optimization with deep learning and ensemble methods to advance next-generation IDS. The proposed framework not only addresses challenges of high-dimensional and imbalanced data but also provides a scalable and adaptable solution for real-world cybersecurity applications."
  },
  {
    "date": "2026-1-21",
    "title": "An Improved Yolov11 Model for Small Object Detection in Unmanned Aerial Vehicle Aerial Images",
    "authors": "Wenchen Wu, Hanyu Xian, Tao Yan",
    "publish": "2025 International Conference on Algorithms, Data Mining, and Information Technology (ADMIT)",
    "url": "https://doi.org/10.1109/admit67050.2025.11337086",
    "source": "IEEE",
    "abstract": "Accurate small object detection in Unmanned Aerial Vehicle imagery is essential for automated monitoring and intelligent management. To improve the accuracy of small object detection in Unmanned Aerial Vehicle Aerial Images, this paper proposes an improved detection framework based on the 11th version of the “You Only Look Once” algorithm. Three modifications are designed on the original YOLOv11 architecture:a dynamic sampling module for preserving finegrained features, a dynamic detection head combining attention and adaptive receptive fields, and a shape-based loss function emphasizing geometric consistency. Experiments on an aerial imagery dataset show improvements of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{4. 2 \\%}, \\mathbf{1. 7 \\%}, \\mathbf{2. 6 \\%}$</tex>, and <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{2. 1 \\%}$</tex> in precision, recall, detection accuracy at 0.5 threshold, and average precision, respectively, over the baseline. These results confirm the effectiveness of the framework in improving the accuracy of dense small object detection and its potential in UAVbased applications such as intelligent inspection and urban security."
  },
  {
    "date": "2026-1-21",
    "title": "Low-Profile Broadband Planar Log-Periodic Dipole Array Antenna for IEMI Detection Application",
    "authors": "M. H. Gharavi, Edalatipour Masoud, Hui Deng",
    "publish": "IEEE Transactions on Electromagnetic Compatibility",
    "url": "https://doi.org/10.1109/temc.2026.3652628",
    "source": "IEEE",
    "abstract": "A low-profile planar log-periodic dipole array (PLPDA) antenna is presented for broadband intentional electromagnetic interference (IEMI) sensing over 2–6 GHz. The design employs only six printed dipoles in a modified LPDA, combined with a conformal-loaded reflector and a planar horn-shaped director as a Yagi section. The synergistic combination of the LPDA and Yagi configurations preserves the broadband, frequency-independent behavior of the LPDA while achieving a compact profile. In contrast, conventional LPDAs typically require more than 13 dipoles to cover the same band with poorer gain flatness. The proposed antenna exhibits a fractional bandwidth of 100% with VSWR < 2 and a stable gain of 6.9 ± 0.8 dBi. RE102 testing confirms the proposed PLPDA performance and measurement reliability, demonstrating its effectiveness for wideband IEMI detection and system-level EMC applications."
  },
  {
    "date": "2026-1-21",
    "title": "Design of an ESP32-Based Smart Home Environment Monitoring System",
    "authors": "Yvheng Lv, Jinghui Zhang, Zhaojun Han, Desheng Li",
    "publish": "2025 5th International Conference on Electronic Information Engineering and Computer Technology (EIECT)",
    "url": "https://doi.org/10.1109/eiect68017.2025.11331632",
    "source": "IEEE",
    "abstract": "With the development of science and technology and the improvement of people's living standards, people's pursuit of the quality of life is constantly increasing. Issues such as the safety, health and comfort of indoor living environments have received increasing attention. To promptly understand the indoor living environment conditions, this study designed a smart home environment monitoring system based on the ESP32 microcontroller <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">[1]</sup>. This system integrates three types of sensors: color sensors, temperature and humidity sensors, and air quality sensors. It can conduct comprehensive monitoring of the indoor environment and upload the measurement data to the Alibaba Cloud platform in real time via the MQTT communication protocol. Meanwhile, by leveraging the cloud product circulation function of Alibaba Cloud platform, the data uploaded to the cloud is sent to the mobile APP so that users can view the indoor living environment conditions in real time. It has been verified that the system operates stably, monitors accurately and has high sensitivity. It has significant practical significance for enhancing the safety and comfort of living."
  },
  {
    "date": "2026-1-21",
    "title": "Experimental Performance Assessment and Comparison of IMU-Equipped Wearable Devices for Gait Analysis",
    "authors": "Veronica Mattioli, Marco Sanfelici, Marta Bettini, Luca Davoli, Laura Belli, Riccardo Raheli, Gianluigi Ferrari",
    "publish": "2025 International Workshop on Biomedical Applications, Technologies and Sensors (BATS)",
    "url": "https://doi.org/10.1109/bats67559.2025.11336176",
    "source": "IEEE",
    "abstract": ""
  },
  {
    "date": "2026-1-21",
    "title": "Copyright Page",
    "authors": "N/A",
    "publish": "2025 International Workshop on Biomedical Applications, Technologies and Sensors (BATS)",
    "url": "https://doi.org/10.1109/bats67559.2025.11336196",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-1-21",
    "title": "Seismic and Geospatial Feature Integration for Earthquake Magnitude Prediction Using Machine Learning",
    "authors": "Padmashree G, Aman S Dsouza, P Adarsh",
    "publish": "2025 Control Instrumentation System Conference (CISCON)",
    "url": "https://doi.org/10.1109/ciscon66933.2025.11337796",
    "source": "IEEE",
    "abstract": "Predicting earthquake magnitudes remains a critical difficulty in disaster preparedness and mitigation efforts. This research investigates the use of various machine learning models to forecast earthquake magnitudes based on seismic characteristics retrieved from the USGS database from 2001 to 2023. Along with features like location, depth, tsunami indicators, signal significance, and alert levels, the collection consists of 782 recordings. In-depth preprocessing methods were used to get the data ready for training, such as feature scaling and onehot encoding. We evaluated the model's performance using MAE, MSE, RMSE, <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{R}^{2}$</tex>, and MAPE metrics. The outcomes show that automated and ensemble approaches greatly improve prediction accuracy, underscoring their potential for early warning systems and real-time seismic risk assessment."
  },
  {
    "date": "2026-1-21",
    "title": "DeepWave: A Hybrid CNN-Wavelet Approach for Brain Tumor MRI Classification",
    "authors": "Nihar Ranjan Panda, Debendra Muduli, Sourav Parija, Santosh Kumar Sharma, Rakesh Ranjan Kumar",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338053",
    "source": "IEEE",
    "abstract": "Brain tumor classification is a critical task in medical imaging and diagnostics. This paper suggests a new hybrid method called DeepWave that uses both deep learning and wavelet-based feature extraction to accurately classify brain tumours. We use a custom Convolutional Neural Network (CNN) to get high-level features from MRI images and a Haar wavelet transform to get texture and frequency information that goes well with the other data. The feature sets are combined, and a selection based on mutual information is used to find the features that give the most information. Then, an XGBoost classifier is trained on the chosen features to guess what kind of tumour it is. We test the model on a public MRI dataset of brain tumours that has four classes: glioma, meningioma, pituitary tumour, and no tumour. The suggested method gets very high accuracy of 90.31% on the test set) and good results on a number of evaluation metrics. The results show that using CNN features and wavelet features together, along with feature selection, greatly improves classification performance. This is a promising way to accurately and automatically diagnose brain tumours."
  },
  {
    "date": "2026-1-21",
    "title": "Predictive Maintenance AI for Irrigation Systems Integrating Sensor Networks and Historical Performance Data",
    "authors": "K. Vidhya, Usikela Naresh, D Deepa, Kalluri Praveen, T. Saranya, G. Akshitha",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337156",
    "source": "IEEE",
    "abstract": "This paper suggests a predictive maintenance system of irrigation systems with the help of artificial intelligence (AI) with sensor networks built in the framework of the IoT technology and historical data on performance. The main objective is to reduce operational disruptions, optimize operation of maintenance work and improve efficiency in using water in agricultural setting. The given system gathers real-time measurements of soil moisture, water pressure, and flow rate, which is examined alongside previous data with the help of a complex of supervised learning (Random Forest, SVM), anomaly detection (Isolation Forest, GMM), and timeseries forecasting (LSTM, TCN) models. The resulting predictive models are used to determine the remaining useful life (RUL) of components and anomalies that reveal possible degradation of systems. The experimental validation shows that there is 10% greater water-use efficiency and downtime is reduced by 75% in comparison with the traditional maintenance techniques. The proposed structure will facilitate the development of sustainable irrigation methods, as it will allow to organize proactive maintenance and more productive use of water resources based on data."
  },
  {
    "date": "2026-1-21",
    "title": "Phishing Email Detection with Data Augmentation Using LLMs",
    "authors": "Johnna Nance, R. E. Davis, Jinsheng Xu, Xiaohong Yuan, Kaushik Roy",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337886",
    "source": "IEEE",
    "abstract": "Phishing attacks frequently occur in institutions such as schools and workplaces, leading to numerous breaches and harm to individuals globally. Therefore, accurate phishing email detection algorithms are critical in reducing the harmful impact of Phishing attacks. Traditional phishing detection methods include known phishing domain list based detection including white lists and black lists, machine learning based detection with extracted text features from the emails, and more recently, transformer model (e.g. BERT) based detection. Large Language Models (LLMs) are getting increasingly more accurate in detecting phishing emails. LLMs also provide explanations why some emails are phishing email while others are not. In this paper, we introduce a novel approach that combines LLMs and traditional machine learning methods to further enhance the accuracy of Phishing detection. The role of LLMs is to generate augmented data with new features to be added to existing text based features. These new features are typical Phishing email indicators such as sense of urgency and writing as an authority. Our experimental result shows that this approach outperforms both traditional machine learning models without augmented data and LLMs based Phishing detection."
  },
  {
    "date": "2026-1-21",
    "title": "WAIBO: A Prototype of Water-Pipeline Inspection Robot in Murky Water, Fast Flow, and Small Obstacles_supp1-3644932.mp4",
    "authors": "Mitsuhiro Kamezaki",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tmech.2025.3644932/mm1",
    "source": "IEEE",
    "abstract": "It remains a challenge for a pipeline inspection robot to traverse pipelines with water flow and obstacles and keep a smooth traversal in murky water. In this article, we developed a water-pipeline inspection robot (WAIBO) capable of resisting water flow and overcoming obstacles in murky water. WAIBO consists of two driving modules and one sensing module. The driving module has three leg wheels and a mechanism to adjust the pressure against the walls. This telescopic-pressing mechanism allows WAIBO to traverse stably by providing adequate normal force, i.e., to resist water flow and overcome obstacles. The sensing module can physically detect curved pipes using two encoders. This curve-detection mechanism allows WAIBO to control the speed of each wheel according to the turning direction and curvature, even in murky water. WAIBO is designed to resist 1 m/s of water flow and to traverse obstacles up to 10 mm in height. We performed experiments using a 15-m-long pipeline environment, including 1 m/s of water flow, six curved pipes, and three obstacles. The experimental results showed that WAIBO could smoothly overcome the obstacles using the telescopic-pressing mechanism and traverse the curved pipes using the curve-detection mechanism, without getting stuck."
  },
  {
    "date": "2026-1-21",
    "title": "A Review of Shared Aperture Antenna Designs for Dual-Band Satellite Communication: Techniques, Trends and Challenges",
    "authors": "Anant Ajitkumar Vadgave, S.D. Ruikar",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336688",
    "source": "IEEE",
    "abstract": "The growing demand for compact, efficient, and multiband antennas in satellite communication has led to rapid advancements in shared-aperture and dual-band antenna tech-nologies. These systems allow simultaneous operation across multiple frequency bands-such as C, X, Ku, and Ka-while minimizing the physical footprint, cost, and complexity of satellite payloads. This review provides a comprehensive analysis of recent developments in shared-aperture antenna arrays, particularly those offering dual-polarized and wideband performance suitable for low Earth orbit (LEO) and geostationary satellite termi-nals. Key contributions include hybrid configurations combining magnetoelectric (ME) dipoles and Vivaldi antennas, stacked and interleaved patch arrays, and novel filtering mechanisms that enhance out-of-band rejection and reduce mutual coupling. Emerging approaches such as inkjet-printed dipoles, metasurface loading, and flexible beamforming algorithms are also discussed for their potential in next-generation platforms. Despite these ad-vancements, challenges remain in terms of miniaturization, beam-scanning integration, fabrication tolerance, and environmental resilience. This review identifies current limitations and outlines future research directions, including reconfigurable architectures, AI -assisted beamforming, and multilayer 3D integration, aiming to support the development of high-performance, multifunctional, and scalable antenna systems for advanced satellite communication applications."
  },
  {
    "date": "2026-1-21",
    "title": "Blockchain-Optimized Quantum GANs for Secure Localization in IoT-WSNs",
    "authors": "Hamer Shield J M, Suresh K",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336953",
    "source": "IEEE",
    "abstract": "The Internet of Things (IoT) relies heavily on Wireless Sensor Networks (WSNs) for critical applications in healthcare, defense, and smart infrastructure, but these networks are vulnerable to malicious nodes that compromise data integrity and service availability. Existing detection methods often face limitations in scalability, accuracy, and energy efficiency. This paper proposes a novel Blockchain-Optimized Hamiltonian Quantum Generative Adversarial Network (HQGAN-WO) for secure localization and malicious node detection in IoT-enabled WSNs. A Blockchain-enabled Efficient Verifiable Outsourced Attribute-Based Encryption (B-EVOAE) ensures tamper-proof data authentication, while HQGAN detects adversarial behavior using quantum-inspired adversarial learning. The Walrus Optimizer (WO) dynamically fine-tunes model hyperparameters to accelerate convergence, reduce prediction error, and enhance generalization. Experimental evaluation on the UNSW-NB15 dataset and ns-3 simulated IoT-WSNs shows that HQGAN-WO achieves 99.17% accuracy, 99.05% precision, and 1.82% localization error, outperforming recent methods such as DHN-SCA, KMC-IG, Hybrid ML, and TLBO-IDS. Furthermore, the proposed framework significantly reduces transaction latency and energy consumption, ensuring scalability in large IoT deployments. This research demonstrates a robust, decentralized, and energy-efficient security solution for IoTdriven WSNs."
  },
  {
    "date": "2026-1-21",
    "title": "Evaluating Simulated Augmented Reality Interfaces in a VR Role-Playing Simulator for Police De-Escalation Training",
    "authors": "Jeronimo Grandi, Dalton B. Costa, Regis Kopper",
    "publish": "2025 27th Symposium on Virtual and Augmented Reality (SVR)",
    "url": "https://doi.org/10.1109/svr67689.2025.00019",
    "source": "IEEE",
    "abstract": "This study evaluates future Augmented Reality (AR) interfaces for police de-escalation training by simulating them within a Virtual Reality (VR) role-playing platform, RESPOND. The platform uses live actors to embody avatars, creating realistic and unscripted traffic stop scenarios. We conducted a between-subjects study with 18 police officers to compare simulated AR interfaces against current procedures, measuring performance, workload, and user acceptance. Our results show that the simulated AR-enhanced procedures performed on par with traditional methods, with no significant differences in task time, interaction outcomes, or cognitive load. Despite maintaining operational performance, officers strongly preferred traditional methods (NPS = -77.78), though individual AR safety features received high ratings, revealing a critical performance-acceptance paradox. This finding of non-inferiority with resistance is critical, as it demonstrates how VR-based evaluation can uncover adoption barriers before hardware investment. These results validate the feasibility of using VR simulation to preview AR concepts for complex police work and provide a foundation for designing future systems that can enhance officer safety and effectiveness."
  },
  {
    "date": "2026-1-21",
    "title": "Enhancing the Neighborhood Median Pixel Method Accuracy with Weighted Landsat-8 OLI Image and Spectral Indices",
    "authors": "Abraham T. Magpantay, Proceso L. Fernandez",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775034",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Edge-based Bidirectional EV Converter with Integrated Renewable Forecasting",
    "authors": "S Naveen, B Preethaa, S Libernaa",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335995",
    "source": "IEEE",
    "abstract": "The sudden upsurge in Electric Vehicle (EV) adoption and the integration of renewable energy requires smart energy management to ensure grid stability and sustainability. This paper introduces an adaptive bidirectional converter with Vehicle-to-Grid (V2G) and Grid-to-Vehicle (G2V) capabilities utilizing edge computing and artificial intelligence (AI) for real-time control. The system under proposal regulates power flow between solar photovoltaic (PV) sources, battery storage, and the grid independently, using Maximum Power Point Tracking (MPPT) and State of Charge (SOC)-based logic for maximum efficiency. An artificial intelligence-based forecasting algorithm foretells renewable availability to allow advance scheduling of power and smooth mode switching. Hardware realization with an ESP32 microcontroller exhibits efficient conversion (as high as $93 \\%$) and lowering grid dependence by $26 \\%$, while also ensuring stable DC-bus voltage. Simulation results in MATLAB/Simulink validate enhanced renewable usage and a quicker dynamic response relative to traditional systems. The system developed offers a scalable, predictive, and affordable next-generation solution for smart-grid EV infrastructures, with the potential to have more renewable penetration and sustainable electric mobility."
  },
  {
    "date": "2026-1-21",
    "title": "Training-Free White Blood Cell Detection: Achieving State-of-the-Art Performance with Traditional Computer Vision",
    "authors": "SeungBin Baek, ManJae Shin, SungMin Kim",
    "publish": "2025 7th International Conference on Robotics and Computer Vision (ICRCV)",
    "url": "https://doi.org/10.1109/icrcv67407.2025.11349220",
    "source": "IEEE",
    "abstract": "This study presents a training-free approach for white blood cell (WBC) detection using traditional computer vision on the BCCD dataset. While deep learning methods dominate blood cell analysis, they require extensive training data and computational resources, limiting clinical adoption. Our methodology combines HSV color space preprocessing, watershed segmentation, and morphological operations to achieve 99.7% mAP@0.5 with sub-6ms processing times. The approach eliminates training requirements while providing interpretable results suitable for clinical environments. Results demonstrate competitive performance compared to AI-based methods with significant advantages in deployment simplicity and computational efficiency."
  },
  {
    "date": "2026-1-21",
    "title": "A Multi-scale Structural Feature Fusion Vehicle Detection Method for Complex Lighting Conditions",
    "authors": "Mingming Kong, Yannan Hu, Xi Wang, Zhanbo Sun, Ang Ji, Chao Zhang",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775033",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Fast Polarimetric Modeling and Calibration of a Multi-Node Antenna Pattern Measurement Setup",
    "authors": "Máté L. Iványi, Changxu Zhao, Yanki Aslan, Alexander Yarovoy, Marco Spirito",
    "publish": "2025 IEEE Conference on Antenna Measurements and Applications (CAMA)",
    "url": "https://doi.org/10.1109/cama65664.2025.11335357",
    "source": "IEEE",
    "abstract": "To perform the polarimetric calibration of the Antenna Dome – a fixed multi-node over-the-air measurement setup for antenna pattern characterization – a fast simulation model is developed. The model enables characterization and compensation of angle-dependent polarimetric distortions in the transmitted field of an antenna under test (AUT). An open ended waveguide and a horn antenna at 26.5 GHz are used for referencing and validation, respectively. The total power simulated at broadside with the proposed model showed an average power difference of 0.5 dB compared with the measurement results for the reference antenna. The proposed calibration method reduces the power deviation between the full-wave simulation model and the practical Dome measurement system of about 67% in the antenna used for validation. The calibration procedure compensating for systematic power imbalances across the sensing nodes and correcting angle-dependent polarization basis distortions."
  },
  {
    "date": "2026-1-21",
    "title": "Trust-Aware Federated Learning for Secure Loan Approval in Peer-to-Peer Lending Platforms",
    "authors": "Layla Safwat Jamil, Amjed Sahib Noori Alshami, Azhaar A. Shalal, Amjed Abbas Ahmed, Dena Kadhim Muhsen, Karrar Abbas Yousif",
    "publish": "2025 International Conference on Electrical Engineering and Informatics (ICEEI)",
    "url": "https://doi.org/10.1109/iceei68459.2025.11331084",
    "source": "IEEE",
    "abstract": "Peer-to-peer (P2P) lending platforms have revolutionized financial services by enabling direct transactions between borrowers and lenders, bypassing traditional banking systems. The integration of machine learning for automated loan approval has further enhanced efficiency and accessibility in these decentralized environments. However, existing centralized and federated learning approaches face critical challenges, including data privacy risks, susceptibility to adversarial inputs, and unreliable decision-making due to untrustworthy or biased data sources. These issues compromise both the security and fairness of loan approval systems. To address these limitations, we propose T-FedLoan: a Trust-Aware Federated Learning Framework for Secure Loan Approval in Peer-to-Peer Lending Platforms. This framework incorporates a dynamic trust evaluation mechanism to assess the reliability of participating peers based on historical behavior, data quality, and consistency. The trust scores are then integrated into an enhanced federated averaging algorithm (TA-FedAvg), where each participant's model update is weighted according to its trust level. Additionally, secure aggregation techniques are employed to ensure data privacy and robustness against adversarial attacks. The proposed T-FedLoan method enables decentralized model training while filtering out low-trust or malicious contributors, leading to more accurate and fair loan approval decisions without exposing sensitive financial data. Experimental results on simulated P2P lending datasets demonstrate that T-FedLoan significantly improves model accuracy, fairness, and resilience compared to conventional federated learning methods. The findings validate T-FedLoan as a secure and trustworthy framework suitable for next-generation decentralized financial services."
  },
  {
    "date": "2026-1-21",
    "title": "A&amp;B-LO: Continuous-time LiDAR Odometry with Adaptive Non-uniform B-spline Trajectory Representation",
    "authors": "Yuchu Lu, Chenpeng Yao, Jiayuan Du, Chengju Liu, Qijun Chen",
    "publish": "IEEE Robotics and Automation Letters",
    "url": "https://doi.org/10.1109/lra.2026.3656754",
    "source": "IEEE",
    "abstract": "LiDAR odometry, fused by inertial measurement units (IMU), is an essential task in robotics navigation. Unlike the mainstream methods compensate the motion distortion of LiDAR data by high frequency inertial sensors, this paper deals with the distortion with continuous-time trajectory representation, and achieved competitive performance against state-of-the-art. We propose a compact framework of LiDAR odometry with adaptive non-uniform B-spline trajectory representation to formulate it as continuous-time estimation problem. We deploy point-toplane registration and pseudo-velocity smoothing constraints to fully utilize geometric and kinematic information of odometry. For faster convergence of optimization, analytical Jacobian of constraints is derived to solve the non-linear least squares minimization. For more efficient B-spline representation, an adaptive knot spacing technique is proposed to adjust the time interval of control poses of spline. Extensive experiments on public and realistic datasets demonstrate validation and efficiency of our system compared with other LiDAR or LiDAR-inertial methods."
  },
  {
    "date": "2026-1-21",
    "title": "Transformer-Based Bispectral Fusion: Enhancing UCA DOA Estimation in Low SNR",
    "authors": "Guiyu Zhang, Wen Li, Yanjun Zhang, Fenghua Li",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338459",
    "source": "IEEE",
    "abstract": "Direction of Arrival (DOA) estimation using deep learning (DL) for uniform circular arrays (UCAs) demonstrates significant potential in complex environments. However, DL-based methods inherently sacrifice resolution for robustness due to heightened sensitivity, which exacerbates spurious peaks in low-SNR scenarios and leads to inaccurate estimates. To address this limitation, we propose a Transformer-based dual-spectrum fusion model (SFD-Net). Specifically, multiple-snapshot data are processed in parallel by the Transformer encoder backbone, and the extracted features are fed into subsequent branches. Subsequently, one branch integrates the MUSIC algorithm by substituting its key high-complexity operations with neural networks, achieving computational efficiency while preserving high resolution. Meanwhile, the other branch employs attention mechanisms combined with residual networks to enhance feature extraction, enabling comprehensive target verification across all angles. Simulations demonstrate SFD-Net’s superior performance in low-SNR, reducing angular estimation error by 77% at SNR = −18dB. The model also generalizes to scenarios with varying numbers of targets while significantly suppressing spurious peaks."
  },
  {
    "date": "2026-1-21",
    "title": "ICICSP 2025 Content Announcement Page",
    "authors": "N/A",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338289",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-1-21",
    "title": "An Advanced Deep Learning Approach for Monkeypox and Other Skin Lesion Classification",
    "authors": "Kazi Shaharair Sharif, Mohammad Navid Nayyem, Jahirul Islam, Dill Mahzabina Tabila, Touhid Imam, Md Azad Hossain Raju",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337787",
    "source": "IEEE",
    "abstract": "Monkeypox is a viral disease, originates from animals and can spread to humans. It causes skin lesions that often resemble those seen in conditions like chickenpox and cowpox, making accurate and timely diagnosis challenging. Accurately identifying monkeypox is essential because its distinctive skin lesions often resemble those of other diseases, which can make diagnosis difficult and delay treatment. Often lack the precision needed to tackle the specific challenges of diagnosing monkeypox and similar skin diseases, especially in resource-limited settings. This study introduces to develop and validate an optimized AI-driven framework for accurately classifying monkeypox and related skin lesions, addressing the limitations of existing diagnostic systems by delivering high accuracy, scalability, and applicability in real-world healthcare settings, especially in resourceconstrained environments. Using Mpox Skin Lesion Dataset Version 2.0 enriched with extensive augmentation, and eight advanced deep learning models such as EfficientNetB5, ResNet50, ResNet101, MobileNet, Xception, DenseNet121, NasNetMobile, and InceptionV3 were systematically evaluated through a rigorous 5-fold cross-validation, ensuring robust generalization. The novelty lies in integrating adaptive augmentation, optimized preprocessing, and lightweight architectures like EfficientNetB5 and MobileNet, designed for efficiency without compromising accuracy. Both models outperformed others, achieving over (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\pm 90 \\%$</tex>) accuracy and F1 scores, demonstrating exceptional efficiency and robustness for practical use. This framework addresses key limitations in automated dermatological diagnostics by providing a scalable, precise, and resource-efficient solution, enabling healthcare professionals to improve workflows, make informed decisions, and enhance patient outcomes, especially in resource-limited and high-demand environments."
  },
  {
    "date": "2026-1-21",
    "title": "Deep Learning MobileNetV2 Based Recognition of Indoor Medicinal Plants",
    "authors": "Pradeep Surasura, Gurusiddappa Hugar, Vishwanath Kamatar, Rajeshwari V Patil, Gp Vanitha, E Shilpa",
    "publish": "2025 IEEE North Karnataka Subsection Flagship International Conference (NKCon)",
    "url": "https://doi.org/10.1109/nkcon66957.2025.11345752",
    "source": "IEEE",
    "abstract": "The sustainable practice of organic farming and the growing interest in natural products have increased medicinal plant cultivation at home. Plant recognition remains a challenge, especially for novice gardeners. This research presents a novel, computational implementation employing deep learning techniques for the recognition of twelve commonly produced medicinal plants. An image-based plant recognition system was developed using MobileNetV2 and transfer learning, enabling users to accurately identify plants. A new set of images was used to test the model, demonstrating its effectiveness in various situations. The model’s overall test accuracy exceeds $99.17 \\%$, highlighting its potential to assist individuals in cultivating medicinal plants with confidence."
  },
  {
    "date": "2026-1-21",
    "title": "Interpretable ANN-Based Computer Vision System for Mangosteen Ripeness Detection for Export Markets",
    "authors": "Ravipat Lapcharoensuk, Naphon Tosribunjerd, Pasu Poonpakdee",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775032",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Automated Detection of Image Morphing using Convolutional Neural Networks and Autoencoders for Enhancing Digital Forensics",
    "authors": "Saravanan C, Keerti S R, Kalki S, Jeevan Prasanth V, Akileswaran J",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338066",
    "source": "IEEE",
    "abstract": "Image manipulation through morphing has become a serious concern in today's digital world, especially in highly sensitive domains like biometric authentication, passport issuance, and forensic analysis. Image morphing blends the facial features of two or more individuals to form a new synthetic image that looks real to human eyes and machine-based verification systems. Conventional approaches towards morphing detection have mainly employed handcrafted features, frequency domain analyses, and inconsistencies in the biometric features to be the primary discriminant factors between original and morphed images. Such methods provide only very preliminary solutions, since most of them are not robust against newer morphing techniques and lack generalization across a wide variety of datasets and real-world scenarios. Deep learning-based methods using basic CNN architectures have enhanced performance by automatically learning the important features. They, however, might suffer from overfitting, are unable to focus on minute and localized inconsistencies in the images, and usually fail to perform well when unseen types of morphing attacks are encountered. Therein lies the requirement for a much more adaptive and resilient solution. Diffusion autoencoders are employed to further enhance feature reconstruction and acquire minute differences between morphed and authentic images. The incorporation of CNNs with a diffusion model enhances robustness, generalizes better, and offers higher accuracy. Created with Streamlit, this solution represents a user-friendly, interactive interface that accepts an uploaded image for real-time processing, detection, and result visualization, thus turning into a practical deployment for digital forensic investigations and secure identity verification system."
  },
  {
    "date": "2026-1-21",
    "title": "Research on Equipment Fault Diagnosis and Predictive Maintenance Model for Intelligent Manufacturing",
    "authors": "Shufen Li, Hongtao Mou, Liting Hu",
    "publish": "2025 5th International Conference on Electronic Information Engineering and Computer Technology (EIECT)",
    "url": "https://doi.org/10.1109/eiect68017.2025.11332175",
    "source": "IEEE",
    "abstract": "The valuation of unprofitable tech enterprises has been a significant challenge in the financial field, as traditional valuation methods struggle to accurately assess their intangible asset value and financial risks. This study proposes an integrated valuation model based on artificial intelligence that combines deep learning, random forest, and gradient boosting algorithms to achieve precise valuation of unprofitable tech enterprises by integrating financial risk indicators, intangible asset evaluation indicators, and market sentiment data. The research collected multi-dimensional data from 85 unprofitable tech enterprises during 2020–2023, constructing a dataset containing 12 core feature variables. Experimental results demonstrate that the proposed AI-driven valuation model significantly outperforms traditional valuation methods in prediction accuracy, with the Mean Absolute Percentage Error (MAPE) reduced to 8.734%, and the coefficient of determination <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$(R^{2})$</tex> reaching 0.892, representing improvements of 47.3% and 53.6% compared to traditional DCF models and comparable company methods, respectively. Ablation experiments validated the important contributions of intangible asset features and financial risk indicators to model performance, while sensitivity analysis revealed that R&D intensity, patent quantity, and cash flow risk are key factors affecting valuation. This study provides scientific evidence and practical tools for investment decision-making, risk management, and financing pricing of unprofitable tech enterprises."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Enabled Infrastructure Management: A Comprehensive Framework and Empirical Analysis from Platform Engineering Perspective",
    "authors": "Goutam Tadi, Akshay Mittal",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337561",
    "source": "IEEE",
    "abstract": "Modern infrastructure management faces unprecedented complexity as organizations scale their digital operations across hybrid and multi-cloud environments. This paper presents a comprehensive analysis of artificial intelligence enablement in infrastructure management from a platform engineering perspective. We propose a four-pillar framework encompassing Intelligent Automation, Predictive Analytics, Unified Observability, and Continuous Learning. Through systematic analysis of real-world implementations at Netflix, Google, and Meta, we demonstrate that AI-enabled infrastructure management can reduce operational overhead by 50–93 % while improving system reliability and performance. Our empirical analysis reveals critical success factors including data quality, model interpretability, and organizational readiness that determine AI adoption effectiveness. The study contributes a practical implementation framework, comparative analysis of enterprise approaches, and identification of common pitfalls that can guide platform engineering teams in their AI transformation journeys."
  },
  {
    "date": "2026-1-21",
    "title": "Wide-Area Frequency Based Power Sharing Scheme for Hybrid Multiple Subgrids",
    "authors": "N. V. N. Jagadish",
    "publish": "2025 International Conference on Future Energy Solutions (FES)",
    "url": "https://doi.org/10.1109/fes65767.2025.11341851",
    "source": "IEEE",
    "abstract": "Modernizing distribution grids to enhance grid resiliency has led to the development of AC/DC hybrid multiple subgrids (HMS). This new operational paradigm integrates existing AC main grids with advanced distributed energy resources (DERs). HMS addresses critical operational challenges like power sharing complexities, voltage stability during contingencies, and power transfer management, ultimately improving system efficiency, performance, and reliability. HMS comprises interconnected AC and DC subgrid clusters linked by interlinking converters (ICs), which minimize conversion stages and offer cost benefits. To manage power sharing within HMS, especially during autonomous operation, a wide-area frequency-based power sharing (WAFPS) scheme is proposed. This decentralized method uses AC and DC droop gain values to regulate AC frequency and DC voltage at the ICs. The reliability of this power sharing approach is validated across various operating scenarios, including proportional and disproportional loading and generation. Furthermore, a real-time hardware experimental prototype, aggregating a communication-based system using the IEC61131 standard, is proposed on Real-Time Digital Simulator (RTDS™) and implemented via MATLAB/Simulink. This setup evaluates the power sharing method under different AC/DC HMS operating conditions. Extensive simulations demonstrate the scheme's effectiveness across various power flow conditions. Performance under steady-state and dynamic conditions is also evaluated using phasor measurement units (PMUs) based on the IEEE C37.118 standard. A novel bi-directional AC/DC power-flow strategy with droop control for ICs is established to manage power variations, regulate voltage and frequency, and maintain stability."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Augmented Leadership Framework for Enhancing Employee Engagement and Well-Being in Knowledge-Driven Industries",
    "authors": "R. Anitha, Sudarshana V, Thirukumaran D, Vignesh A, Yadav KN, Saru Shine S",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336691",
    "source": "IEEE",
    "abstract": "There is a requirement for a fresh leadership style approach to enhance long-term worker involvement and welfare against the background of intensified digital transformation in high-knowledge-intensive industries. In an attempt to enhance organizational efficiency, this research suggests an AI-Augmented Leadership Model. This model infuses sentiment analysis, customized feedback mechanisms, and sophisticated analytics into management decision-making. In contrast to conventional leadership approaches, the suggested model leverages AI to provide managers with instant feedback on the morale of employees, workload trends, and inter-personal relationships so that forward-looking interventions can achieve a balanced integration of mental well-being and efficiency. AI-based predictive analytics leadership approaches can help companies mitigate burnout risks, trust building, and diverse workplace cultures. In addition to motivation, the system also maintains long-term durability by linking employee well-being and company performance goals. The initial outcomes demonstrate that this approach has the ability to transform leadership into a data-informed, humane practice capable of addressing the two critical concerns of people-focused care and digital competitiveness in the dynamic information economy. The model achieved 22% employee engagement gain."
  },
  {
    "date": "2026-1-21",
    "title": "Sampling-aware Multi-rate Combined Control for an Orbital Manipulator",
    "authors": "Ria Vijayan, Marco De Stefano, Christian Ott",
    "publish": "IEEE Robotics and Automation Letters",
    "url": "https://doi.org/10.1109/lra.2026.3656723",
    "source": "IEEE",
    "abstract": "In on-orbit servicing missions using robotic manipulators, certain challenging scenarios require the use of combined control i.e. actuation of spacecraft and the manipulator, to meet mission requirements. The low frequency of the controller of the spacecraft compared to the manipulator can compromise the stability margin of the combined control. In this paper, we first design a combined control strategy to carefully decouple the high-rate manipulator control from the spacecraft's low-rate control. Second, we design a novel discrete controller accounting for the first-order effects of the servicer's low sampling rate. This is realized by augmenting a classical proportional-derivative (PD) control scheme. The operational bounds of the discrete controller are first benchmarked on a one-DoF system and further investigated for performance using a multi-DoF orbital manipulator. The results shed light on the regions of enhanced performance in terms of stability and impulse utilization as a measure of efficiency. Simulation results and hardware-in-theloop experiments are performed to validate the proposed method."
  },
  {
    "date": "2026-1-21",
    "title": "Remote Work Revolution: Building Infrastructure for Seamless Remote Operations",
    "authors": "William P. Rey, Jabes P. Pauya",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775039",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Artificial Intelligence Powered IoT for Real-Time Inventory Control and Hyper-Personalized Retail Experiences",
    "authors": "P Ashok, S Lakshmi Sridevi, V Kanagaraj, K Murali Krishna, Sarala Patchala, Suryansh Jaiswal",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336711",
    "source": "IEEE",
    "abstract": "The contemporary retail sector is undergoing a profound metamorphosis, driven by the symbiotic convergence of Artificial Intelligence (AI) and the Internet of Things (IoT). This research work presents a critical and technical survey of this paradigm shift, focusing on its dual impact on operational efficiency through real-time inventory control and customer-centricity through hyper-personalized experiences. The integration of IoT sensor networks-comprising RFID tags, BLE beacons, computer vision systems, and smart shelving-has created an unprecedented data deluge from the physical retail environment. This forms the afferent pathway, sensing stock levels, customer footfall, and item interaction with granular precision. The work critically synthesizes the architectural evolution from centralized cloud-based models to hybrid edge-fog-cloud architectures, a necessary transition to meet the low-latency demands of real-time applications. Such a distributed framework is analogous to modern clinical decision support systems, where point-of-care diagnostics (the edge) provide immediate results while large-scale epidemiological analysis (the cloud) informs broader strategy. Furthermore, the synthesis of these technologies to curate hyper-personalized shopping journeys is examined, including context-aware promotions, dynamic pricing, and frictionless checkout systems. However, this technological synthesis is not without its challenges. A nuanced discussion is provided on the significant hurdles of data privacy and security, particularly in the context of regulations like GDPR, the complexities of system interoperability, the high capital expenditure for SMEs, and the critical shortage of skilled human capital. Finally, the work charts a forward-looking trajectory, exploring nascent research directions such as the use of digital twins for retail operations simulation, federated learning for privacy-preserving AI, and the establishment of robust ethical frameworks to govern the use of pervasive in-store surveillance technologies."
  },
  {
    "date": "2026-1-21",
    "title": "Impact of Semiconductor Layer Thickness on the Electrical Performance of Double-Gate OTFTs for Biosensor Applications",
    "authors": "Meena Naga Raju, Piduguralla Kranthi, Patta Supraja, M. Durga Prakash",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335915",
    "source": "IEEE",
    "abstract": "This work presents a two-dimensional numerical simulation study of pentacene organic thin-film transistors (OTFTs). Analyzing the influence of pentacene thickness on key device characteristics. Simulations were performed using Silvaco ATLAS to systematically evaluate the effect of decreasing the organic semiconductor (OSC) thickness from 50 $\\mathbf{n m}$ to $\\mathbf{1 0 ~ n m}$. Critical electrical parameters such as threshold voltage ($\\mathrm{V}_{\\text {th }}$), ON-current (Ion), OFF-current (Ioff), Ion/off ratio, transconductance (gm), and subthreshold slope (SS) were extracted and analyzed. The results reveal that these parameters are significantly influenced by changes in the active layer thickness. The Ion/Ioff ratio shows strong dependence on the semiconductor thickness, with the highest Ion/Ioff ratio observed at $\\mathbf{1 0 ~ n m}$ to $\\mathbf{5 0 ~ n m}$, making it particularly suitable for high-speed switching applications in digital circuits. This study emphasizes the importance of thickness optimization for enhancing OTFT performance, paving the way for their integration into practical low-power electronic applications such as Organic Transistors Using Flexibility for Biosensing, flexible displays, sensors, and RFID systems."
  },
  {
    "date": "2026-1-21",
    "title": "Edge-Based Collaborative Log Anomaly Detection Using Retrieval-Augmented Language Models",
    "authors": "Daniel Perez Fiadzeawu, Puhao Li, Enoch Hwang, Jielun Zhang",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337648",
    "source": "IEEE",
    "abstract": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to perform context-aware reasoning by incorporating relevant examples during inference. In the context of system log anomaly detection, the quality and avail-ability of retrieved examples play a critical role in classification accuracy. While prior RAG-based approaches have been studied primarily in cloud or server environments, their deployment in resource-constrained edge settings remains underexplored. In this work, we propose an edge-based collaborative log anomaly detection framework implemented on the NVIDIA Jetson Nano Orin Super platform. In our framework, each neighbor node maintains a local cluster of text-embedded logs and responds to query requests from a target node by retrieving its top-k most similar examples. The responses from all neighbors are aggregated, and the target node selects a final top-k set for prompt construction, which is then processed by the LLM for anomaly detection. We evaluate the framework on OpenStack and BGL logs from the LogHub benchmark repository, using quantized Granite3.2:8B, Granite3.3:8B, and Mistral:7B models hosted locally via OLLAMA. Experimental results show that our approach achieves over 96 % classification accuracy, highlighting the effectiveness of collaborative retrieval in edge environments."
  },
  {
    "date": "2026-1-21",
    "title": "Leveraging Lexical Knowledge in a BERT Classifier for Emotion Analysis",
    "authors": "Manjog Padhy, Rasmita Rautray, Premananda Sahu",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338084",
    "source": "IEEE",
    "abstract": "Emotion recognition from textual data is crucial to understanding user sentiment in various domains such as social media, healthcare, and customer feedback systems. By integrating lexical semantics with the deep contextual knowledge offered by BERT, this framework is able to utilize both syntactic and semantic cues to bring out the subtle emotional tones of the text. Several preprocessing techniques like tokenization, stop words removal, stemming, and TF-IDF vectorization were applied to Twitter-based emotion datasets for potentially enhancing the quality of features and their representation. The additional lexical knowledge to BERT was achieved by means of expanding the input space with emotion-carrying words and domain specific lexicons. The lexical BERT model is experimentally evaluated on the GoEmotions dataset, a collection of 58,009 selectively sampled Reddit comments with 27 different fine-grained emotion class labels, where the accuracy is 98.67 and the precision 98.52 as well as the recall 98.39 and F1-score 98.45. To enhance clarity and further use of the emotion categories in the future in context of sentiment analysis, the emotion categories were re-mapped to higher level polarities: positive and negative. The results testify that integrating deep contextual embedding with lexical resources provide a powerful solution to fine-grained emotion recognition."
  },
  {
    "date": "2026-1-21",
    "title": "Real-Time Forest Fire and Wildlife Poacher Detection and Alerting System Using YOLOV11",
    "authors": "Rithanya G, Revathi R, Shanthini S",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337168",
    "source": "IEEE",
    "abstract": "Forest ecosystems are increasingly being threatened by wildfires, poaching, and human-wildlife conflicts. Traditional monitoring systems with manual patrolling and static CCTV cameras fail to bear fruit because their coverage is restricted, visibility is low, and response is slower. WILDGUARD: A Real-Time Forest Fire and Poacher Detection System Using YOLOv11 is an AI-based monitoring system proposed to overcome such hurdles. It integrates CCTV cameras with high definition using YOLOv11 to enable real-time detection of fires, poachers, illegal vehicles, and wildlife activity in sensitive areas. Automated messages with details such as object class, location coordinates, date and time, as well as captured images, are sent via a secure wireless medium to forest monitoring centers as well as ground officers. It is intended to safeguard wildlife better and respond to disasters faster by enabling instantaneous detection with rapid response. What is distinctive about such a system is that YOLOv11 is coupled with multi-class object detection, IoT-based alarm transmission, and deployability to ensure integrated and proactive forest monitoring."
  },
  {
    "date": "2026-1-21",
    "title": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1145/3775030",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Reinforcement-Guided Navigation for Optimizing Drone Delivery Routes Through Dense Urban Environments",
    "authors": "Gopal K, Jeevakarunya C, A.Daniel Das, Shivapanchakshari T G, M. Nageswaran, M. Murali",
    "publish": "2025 International Conference on Electrical Engineering and Informatics (ICEEI)",
    "url": "https://doi.org/10.1109/iceei68459.2025.11331057",
    "source": "IEEE",
    "abstract": "The growing requirement for drone-based delivery creates unique challenges in densely populated urban environments, where the optimal route can involve static and dynamic obstacles. Given that standard path planning methods do not adequately capture real-world urban layouts, we implement reinforcement-guided learning algorithms using real-world datasets. The proposed reinforcement-guided navigation system will identify the optimal drone delivery route with the least energy consumption and crash probability. The main goal of the study is to educate reinforcement learning agents on more realistic flying behaviors using the understanding of urban scenes from the labeled images in the Semantic Drone Dataset. This will include converting the labeled images in the Semantic Drone Dataset into structured graphs consisting of roads, buildings, and obstacles. In this approach, we refer to this method as Graph-Constrained Reinforcement Navigation (GCRN). Publishing reinforcement learning in the context of graphs will enable us to teach the agent the balance of speed vs. safety while delivering cargo, with the goal of finding the quickest route. The results of the study will show that the policies trained based on the Semantic Drone Dataset maps provide more efficient routes than A* and DQN baselines, all with fewer collisions and roads traveled. Also, we demonstrate this approach can generalize to real-world urban domain environments, and still perform well in complex architectural designs."
  },
  {
    "date": "2026-1-21",
    "title": "Enhanced Advanced Text Summarization Using GraphRAG Algorithm",
    "authors": "Sanjukta Mohanty, Namita Panda, Ashis Kumat Naik, Arup Abhinna Acharya, Biswajit Pagal",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11337986",
    "source": "IEEE",
    "abstract": "The growth in digital text has expanded the demand for devices to efficiently activities and summarize detail. Text summarization in NLP (Natural Language Processing) addresses this by creating concise summaries that maintain the main message. However, traditional processes often conflict with coherence and accuracy especially when dealing with complex or specialized texts. Hence, to addresses these issues the GraphRAG algorithm has been explored in this research work, which suggests an innovative blend of graph theory and retrieval augmented generation techniques to generate concise and coherent summaries. By using graph based structures, the method effectively captures contextual relationships among sentences and concepts, guarantee relevance and logical flow. Additionally, it combines a retrieval component to utilize external information, enhancing its capacity to summarize context rich content. The algorithm proves adaptable across various datasets, including news reports, academic papers, and long-form texts. Experimental findings indicate that GraphRAG achieves superior performance in metrics such as precision, recall, and readability, representing a meaningful contribution to NLP. This research provides an in depth discussion of the algorithm’s design, implementation, and evaluation."
  },
  {
    "date": "2026-1-21",
    "title": "Enabling Cost-Effective Vulnerability Scanning with OpenVAS: A Nested Virtualization Approach for Understaffed Security Teams",
    "authors": "Prime Wongsaard, Phithak Thaenkaew, Kalika Suksomboon",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775037",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Adaptive Resource Management in Cloud-Native Databases: A Study of Autonomous Scaling and Query Optimization",
    "authors": "Prasad Sundaramoorthy, Milan Parikh, Srikanth Reddy Keshireddy, Aparna Krishna Penumatcha, Kathiresan Jayabalan",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336962",
    "source": "IEEE",
    "abstract": "Cloud native databases continue to gain credibility to manage dynamic and large-scale workloads in the new enterprise and cloud computing environment. However, conventional static resource allocation and query optimization functions perform poorly in terms of performance, latency and operating cost, under variable loads. This paper presents an adaptive resource management framework with predictive workload modeling, autonomous scale and adaptive query optimization to improve the performance, resource utilization and the cost effectiveness. The methodology is evaluated with the help of datasets of cloud workloads are available for the public domain is evaluated with quantitative results showing 30 % reduction in CPU utilization, 25 % reduction in memory usage, 120 ms average query latency and significant improved throughput, load balancing efficiency, and energy consumption with respect to four state-of-the-art methods. The results reveal the possibility of proactive and datadriven resource management to ensure maintenance of the service-level objectives, optimal utilization of cloud resources, and cost savings for operating them."
  },
  {
    "date": "2026-1-21",
    "title": "Enhancing IoT-Edge Security with Deep Learning a Real-Time Intrusion Detection Framework Using UMAP and LightBGM",
    "authors": "S. Hariprasad, B. Vamsy Krishna, Subhashini Tata, Ramkumar Natarajan, R. S. Venkatesan",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338078",
    "source": "IEEE",
    "abstract": "The combination of IoT with emerging technologies by connecting various devices and sensors directly at the network edge. This minimizes latency, increases efficiency, and propels progress in fields of smart applications. However, the fast expansion of these technologies has created substantial security issues, needing cutting-edge solutions to secure devices and sensitive data from cyberattacks. This work introduces a secure periphery computing platform that employs deep learning to facilitate the efficient detection and isolation of intrusions. The Intrusion Detection System (IDS) reduces dimensionality using Uniform Manifold Approximation and Projection (UMAP) and detects intrusions quickly and accurately using LightGBM. The suggested technique outperforms existing algorithms like DBN, CNN, LSTM, and RNN. It significantly decreases false alerts, saves computing resources, and maintains excellent security efficiency. Experimental findings show that the model is scalable and capable of delivering accurate, real-time intrusion detection in IoT and edge computing contexts, offering a viable answer to today's security concerns."
  },
  {
    "date": "2026-1-21",
    "title": "Design and Analysis of Fuzzy Logic Control-based Half-Bridge Resonant LLC Converter",
    "authors": "R Akshay Kumar, G.V Jayaramaiah",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335973",
    "source": "IEEE",
    "abstract": "This paper presents the design and implementation of a Fuzzy Logic Controller (FLC) integrated with a half-bridge LLC resonant DC-DC converter to achieve high-efficiency and stable voltage regulation. The proposed system dynamically adjusts the switching frequency based on the voltage error and its rate of change, ensuring adaptive control under varying load and input conditions. The LLC resonant topology enables soft switching through Zero-Voltage Switching (ZVS) and Zero-Current Switching (ZCS), minimizing conduction and switching losses. Simulation results in MATLAB/Simulink demonstrate a peak efficiency of $94.6 \\%$ with negligible output ripple at a resonant frequency of $\\mathbf{6 5 ~ k H z}$. A hardware prototype implemented using an Arduino microcontroller and TLP250 gate driver further validates the design, achieving $93.75 \\%$ efficiency while converting a 12 V input to a regulated 15 V output. The proposed FLC-based converter exhibits superior transient response, robust regulation, and reduced electromagnetic interference, making it a promising and cost-effective solution for power conversion in renewable energy systems, electric vehicles, and other high-performance DC applications."
  },
  {
    "date": "2026-1-21",
    "title": "Enhancing Operational Efficiency: A Study on Supply Chain Module Deployment in ERP",
    "authors": "Sapna Yadav, Shilpa Wadhwa, Tanushree Sanwal, Meenakshi Tyagi, Sandhya Avasthi, Shenki Tyagi",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338106",
    "source": "IEEE",
    "abstract": "The paper is aimed at identifying the significant differences between pre- and post-implementation of ERP in SCM. It has helped in identifying inefficiencies and improving supply chain practices to boost the development of the company. Too many organizations endure information silos that keep data closed off to other parts of the business. Supplanting this multitude of systems with a single integrated ERP technology implies more productive processes and fewer workaround costs. This research fills the gap in developing ERP systems to support the company by integrating different functions in an ERP system and providing them online to its users, for the timely dissemination of information to make better decisions. Tailored to fit the specific needs of the Company, this research will help in handling \"enquiry to delivery\" and dispatch of materials to the customers. All functions predominantly used in business operations have been kept in various modules, which essentially reduces the lead time to zero for software development. The proposed ERP system can handle many users with better bandwidth and built-in security protocols. The ERP module has simplified the operation of Logic Eastern. Customer demand is conveyed to the installed ERP network. The network then informs all the relevant departments. The perceptible benefit from such an operation is manifold. The clerical work, like paper processing, involved in the previous system is now completely removed, and time is saved from such unproductive work. Also, the accuracy of information and its timeliness are greatly enhanced."
  },
  {
    "date": "2026-1-21",
    "title": "Effect of Arm Support as a Compensatory Mechanism on Knee Joint Kinetics During Sit-to-Stand in Patients with Osteoarthritis",
    "authors": "Letizia Mancini, Giovanni Spallone, Arianna Carnevale, Carla Antonacci, Stefano Campi, Alessandro De Sire, Pieter D'Hoghe, Carlo Massaroni, Rocco Papalia, Emiliano Schena, Umile Giuseppe Longo",
    "publish": "2025 International Workshop on Biomedical Applications, Technologies and Sensors (BATS)",
    "url": "https://doi.org/10.1109/bats67559.2025.11336180",
    "source": "IEEE",
    "abstract": "Sit-to-stand and stand-to-sit transitions are biomechanically demanding tasks commonly impaired in individuals with knee osteoarthritis (QOA). While upper limb support is frequently used to facilitate task execution, its impact on three-dimensional knee joint loading patterns remains underexplored. This study aimed to examine the influence of arm-assisted (aSTS) versus unassisted (uSTS) executions on knee joint kinetics in individuals with end-stage KOA. Eighteen patients performed three repetitions of both aSTS and uSTS tasks. Kinematic and kinetic data were collected using a 3D optoelectronic motion capture system and force platforms. Knee flexion/extension (KFM), abduction/adduction (KAM), and internal/external rotation (KRM) moments were calculated through inverse dynamics. Differences between tasks were assessed using Statistical Parametric Mapping (SPM), and the Total Joint Moment (TJM) and its components were analyzed across three movement phases: ascending, standing, and descending. SPM revealed significant reductions in KFM during the ascending and descending phases in uSTS compared to aSTS. Although KFM remained the primary contributor to the TJM across all phases and conditions, the uSTS execution was associated with a slight increase in the relative contributions of KAM and KRM, suggesting a compensatory redistribution of joint loading. These findings highlight the role of upper limb support in modulating interplanar knee joint kinetics during STS transitions and underscore the importance of evaluating multi-planar compensatory strategies in individuals with KOA."
  },
  {
    "date": "2026-1-21",
    "title": "Blockchain Applications for Enhancing Security and Transparency in Intellectual Property Management",
    "authors": "Divyanshi Rajvanshi, Kalyandurg Rafeeq Ahmed, A. Pravin, Abhilash Pati, Adarsha Harinaiha, J. Jesupriya",
    "publish": "2025 International Conference on Electrical Engineering and Informatics (ICEEI)",
    "url": "https://doi.org/10.1109/iceei68459.2025.11330693",
    "source": "IEEE",
    "abstract": ""
  },
  {
    "date": "2026-1-21",
    "title": "Weather-Aware CubeSat Link Simulation with Dynamic Power Control",
    "authors": "Sakshi N Sunil, D R Harshapradha, S Bindu, B L Sujaya, P Rekha",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335689",
    "source": "IEEE",
    "abstract": "CubeSat-based satellite communication systems operate under strict power and size constraints, making them vulnerable to signal degradation caused by atmospheric conditions, especially in high-frequency bands like S, Ku, and Ka. Traditional systems rely on fixed transmit power, which can result in either wasted energy or unreliable links during adverse weather. This study presents a Python-based simulation framework that models a dynamic power control scheme for CubeSats using ITU-R propagation models (P.618, P.676, P.840) to estimate rain, gas, and cloud attenuation. The system dynamically adjusts transmit power based on real-time attenuation estimates to maintain link reliability while conserving energy. Simulations across varying rain rates and elevation angles show that the adaptive system improves link availability up to 99.99% and reduces average power consumption by up to 30% compared to static transmission. The framework supports integration with regional weather datasets and is scalable for future mission planning. This work bridges the gap between theoretical attenuation models and real-time adaptive control, offering a practical, energy-efficient solution for CubeSat communication in dynamic weather environments."
  },
  {
    "date": "2026-1-21",
    "title": "Rail Corrugation Feature Extraction Method Based on Acoustic-Vibration Cross-Spectral Fusion",
    "authors": "Yun Liao, ZhiXin Cai, DaWei Zhang, Min Li",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338464",
    "source": "IEEE",
    "abstract": "To address the limitations of single-channel methods in rail corrugation detection—such as insufficient sensitivity, poor robustness, and vulnerability to interference—a feature extraction method based on acoustic-vibration cross-spectral fusion is proposed. First, corrugation-induced frequency components jointly present in both acoustic and vibration channels are extracted using the cross-power spectrum. These common components serve as a physically consistent basis for fusion. Then, guided by the dominant frequencies identified in the cross-spectrum, the corresponding fundamental and harmonic amplitude components are retrieved from the individual spectra of each channel. Finally, a correlation-driven weighting mechanism is introduced to construct a fused indicator, termed AVCFI, enabling robust characterization of rail corrugation features. Onboard experiments were conducted under various track conditions using an operational metro train. Experimental results demonstrate that the proposed method significantly improves the stability and robustness of the extracted features, provides strong physical interpretability, and exhibits resilience to single-channel signal degradation, making it well suited for practical engineering applications."
  },
  {
    "date": "2026-1-21",
    "title": "DM-JCR: Diffusion Model-Based Approaches for Joint Allocation of Communication and Computing Resources",
    "authors": "Xiaoming Yuan, Songyu Wang, Jiaxin Zhou, Hongyang Du, Hongwei Ding, Qingxu Deng, Changle Li",
    "publish": "IEEE Transactions on Vehicular Technology",
    "url": "https://doi.org/10.1109/tvt.2026.3656593",
    "source": "IEEE",
    "abstract": "Edge computing significantly enhances the data processing efficiency and response speed of Connected and Autonomous vehicles (CAVs) by offloading computing tasks to network edge nodes. However, critical challenges arise, including limited edge resources, the complexity of resource allocation strategies and signal obstruction caused by buildings. Existing approaches often address communication and computing resources allocation separately, which hinders their ability to fulfill the stringent latency and reliability demands of CAVs. To tackle these challenges, this paper first employs Unmanned Aerial Vehicles (UAVs) as both communication relay nodes and mobile edge computing nodes, establishing a unique CAVs communication architecture. Based on the architecture, this paper proposes the DM-JCR algorithm grounded in the diffusion model, which is designed to optimize the joint allocation of communication and computing resources in edge computing nodes. Specifically, the algorithm uses environmental information category as a prompt to guide the diffusion model to generate an optimized joint allocation strategy for communication and computing resources. The denoising process of the diffusion model is improved based on the practical requirements of the joint communication and computing resources allocation problem. Finally, the DM-JCR algorithm is deployed in the proposed architecture to validate its effectiveness. Experimental results show that the proposed algorithm achieves superior performance compared to baseline methods in both latency and energy consumption."
  },
  {
    "date": "2026-1-21",
    "title": "Portable multi-channel functional NIR spectrometer system for human brain oxygen monitoring in motion states",
    "authors": "Yunfei Li, Lebin Sun, Fuzhou Shen, Jing Jie, Zhenhua Song, Yanfang Sui, Fuhong Cai",
    "publish": "IEEE Transactions on Instrumentation and Measurement",
    "url": "https://doi.org/10.1109/tim.2026.3655911",
    "source": "IEEE",
    "abstract": "Investigating brain function in naturalistic settings is crucial for neuroscience but is hampered by the current technological landscape of high-density functional near-infrared spectroscopy (fNIRS). Traditional fNIRS systems face inherent limitations in miniaturization, power efficiency, and scalable high-density deployment due to reliance on discrete photodetector arrays and complex light source modulation. Here, we overcome these fundamental barriers through a radically different fNIRS architecture. We introduce a compact (<2 kg, 2 W power consumption) system wherein an imaging spectrometer serves as a massively parallel, spectrally-resolved detector for signals from numerous optical fibers (≥ 32) captured by a single CMOS sensor. This pivotal design choice has profound implications: it inherently performs spectral demultiplexing, thereby eliminating the need for LED intensity modulation and drastically simplifying the overall system. We demonstrate robust, multi-channel monitoring of changes in cerebral oxygenation during motion (nine-channel). This elegant, scalable, and high-throughput spectral acquisition platform is poised to significantly advance brain function research by enabling widespread, multi-channel fNIRS in ecologically valid environments."
  },
  {
    "date": "2026-1-21",
    "title": "A Hybrid Deep Learning and Elliptic Curve Cryptography Scheme for Real-Time Financial Transaction Security",
    "authors": "Azhaar A. Shalal, Aamer Fadhil, Layla safwat Jamil, Saif Aamer Fadhil, Ahmed Mazin Jalal, Karrar Abbas Yousif",
    "publish": "2025 International Conference on Electrical Engineering and Informatics (ICEEI)",
    "url": "https://doi.org/10.1109/iceei68459.2025.11331095",
    "source": "IEEE",
    "abstract": "Real-time financial transactions demand high levels of security and intelligence to prevent unauthorized access and fraudulent activities. To address this, integrating deep learning with cryptographic techniques provides a promising approach to enhancing transaction safety without compromising speed. Existing methods often suffer from two major issues: limited real-time fraud detection accuracy and significant computational overhead due to traditional encryption algorithms. These shortcomings result in either delayed responses or vulnerable transaction channels, particularly in mobile or lightweight financial systems. This paper proposes HDELTS (Hybrid Deep Learning and Elliptic Curve Cryptography Scheme for Live Transaction Security). This novel framework combines LSTM-based Autoencoder models for anomaly detection with Elliptic Curve Cryptography (ECC) for secure data transmission. The LSTM Autoencoder is trained to learn normal transaction behaviors and detect anomalies with high precision based on reconstruction errors. Meanwhile, ECC ensures the lightweight, strong encryption of transaction data, making it suitable for real-time applications with limited processing capacity. Experimental results demonstrate that HDELTS significantly improves the accuracy of real-time fraud detection while reducing encryption latency compared to traditional systems. The framework achieves a balanced trade-off between security, speed, and resource efficiency, making it highly suitable for modern digital financial infrastructures."
  },
  {
    "date": "2026-1-21",
    "title": "α-Rank-Collections: Analyzing Expected Strategic Behavior with Uncertain Utilities",
    "authors": "Fabian Raoul Pieroth, Martin Bichler",
    "publish": "ACM Transactions on Economics and Computation",
    "url": "https://doi.org/10.1145/3787971",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Synaptic Sampling Networks with True Random Number Generation",
    "authors": "J. Darby Smith, William Severa, James B. Aimone",
    "publish": "2025 International Conference on Neuromorphic Systems (ICONS)",
    "url": "https://doi.org/10.1109/icons69015.2025.00035",
    "source": "IEEE",
    "abstract": "Emerging devices for probabilistic neuromorphic computing stand to provide extreme energy benefits while opening the door for advanced stochastic computation. However, it is not clear how existing methods can take advantage of such devices given the uncertainty surrounding performance when faced with potential non-idealities in device behavior. In this work, we confront synaptic sampling networks-a network where weights are replaced with probabilistic synapses and single predictions become distributions-with data from stochastic tunnel diode devices, examining the network’s behavior when operating using the data as a stochastic source. The tunnel diode data collected exhibits non-idealities in the form of bit-to-bit dependence. Leveraging recent developments in true random number generation, we interpret our tunnel diode data as output from a multi-state device, reducing the effects of dependence. Using this multi-state data as a source of stochasticity, we again evaluate our synaptic sampling network. Ultimately we find that our network is mostly robust to non-idealities in stochastic input, but data with less internal dependence can improve the contrast between correct and incorrect prediction distributions. Using synthetic data, we explore additional effects of bias and dependence from binary and multi-state data."
  },
  {
    "date": "2026-1-21",
    "title": "Enhancing Functional Coverage Closure in Network-On-Chip Systems with Reinforcement Learning",
    "authors": "N. Vamshi Krishna, Rachana Chintalapati, Paresh Saxena, J. Soumya",
    "publish": "IEEE Embedded Systems Letters",
    "url": "https://doi.org/10.1109/les.2026.3656758",
    "source": "IEEE",
    "abstract": "As the demand for designing and validating complex technologies increases, the need for computationally efficient methodologies becomes crucial. Network-On-Chip (NoC) verification, with its vast architecture of numerous routers and links, presents significant challenges when performed using traditional methods, delaying the entry of products into the market. This paper presents a streamlined and lightweight solution that uses Reinforcement Learning to automate test vector generation. By optimizing the verification process, this approach significantly speeds up coverage closure, ensuring thorough validation and improving overall efficiency."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Driven Facial Biometrics for Early Disease Detection: A Deep Learning Approach using ESRGAN, ResNet-50, and AlexNet in Clinical Diagnostics",
    "authors": "P Lakshman, R Lakshmi Narayan, S Rajeshkannan",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11336113",
    "source": "IEEE",
    "abstract": "Use of artificial intelligence (AI) in facial analysis is transforming early detection of disease (Anemia, Skin Diseases) by uncovering subtle facial expressions related to many health disorders. Employing deep learning models like ESRGAN for image enhancement, ResNet-50 for feature extraction, and AlexNet for classification, this data-driven study examines the application of facial images for supporting clinical diagnosis. These AI models support accurate analysis of highresolution facial data, thus informing early treatment and enabling long-term health monitoring. However, to enable broad clinical use of this technology, there are a number of challenging barriers to be overcome, including data privacy, algorithmic fairness, model interpretability, and digital health regulatory compliance. This study identifies the transformative potential of AI-based facial analysis for enabling improved patient care and public health outcomes. With ethics and regulatory compliance, this modality has the potential to be an effective, non-invasive device for delivering accessible and early medical insight in diverse populations."
  },
  {
    "date": "2026-1-21",
    "title": "Determining implementation and redundancy configurations of applications based on multi-start hill climbing algorithms",
    "authors": "Wataru Honda, Go Hasegawa, Yoshihiro Nakahira, Masayuki Kashima",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775035",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Scalable IoT Architectures and Energy-Efficient Protocols for Secure and Adaptive Device Connectivity",
    "authors": "Shanker Chandre, Modugu Krishnaiah, Srikanth Chintakindi",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337109",
    "source": "IEEE",
    "abstract": "The Internet of Things (IoT) has helped develop exciting opportunities for monitoring systems in real-time, as well as making smart autonomous decisions. Nonetheless, challenges such as scalability, power consumption, and secure connectivity may arise based on the number of devices and the connectivity designs that operate. This study focused on developing a unified framework, referred to as the Adaptive Secure IoT Framework (ASIF). ASIF integrated scalable designs, low-power communications systems, and adaptive security to ensure reliable IoT functioning and sustainability with multiple devices. The approach consisted of developing datasets and preparing them, designing and developing energy-efficient, scalable designs, energy-efficient communication systems, lightweight cryptography, and a viable and effective training and evaluation framework. Experimental results indicate that ASIF produced a packet delivery ratio of 91 % with an energy efficiency of 88 % and a latency of 77 %, and with security strength of 89 %, compared to traditional systems, routing systems, and cryptography systems. These results corroborate the fusion of the architecture, energy optimization, and adaptive security, as a significant increase in reliability, sustainability, and protection with large-scale IoT deployments. In conclusion, the work provided a pathway for adaptive, secure, and energy-efficient IoT connectivity in substantial deployments, but provided insight into future design developments in modular and context-based protocol designs for upcoming IoT environments."
  },
  {
    "date": "2026-1-21",
    "title": "Securing AI Systems Through Transparency: A CIA Triad-Based Analysis",
    "authors": "Esther Y. Chung, Ian Hamilton, Laura Morgan, Katherine Grillaert, Joshua Scarpino",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337813",
    "source": "IEEE",
    "abstract": "Transparency in artificial intelligence (AI) systems is widely recognized as a foundational requirement for trustworthy development and deployment. This paper establishes a foundational link between AI transparency and cybersecurity by mapping its three core dimensions—explainability, interpretability, and auditability—directly to the established CIA (confidentiality, integrity, and availability) triad. We demonstrate that the inherent opacity of General Purpose AI (GPAI) systems makes them fundamentally insecure within this framework. Finally, we recom-mend practical measures that leverage transparency principles to improve AI security, including hybrid architectural designs, new tooling, and a risk-based approach to standards and policy."
  },
  {
    "date": "2026-1-21",
    "title": "Towards Long-Wavelength Ionospheric Correction of InSAR Time Series Using GNSS-Based TEC",
    "authors": "Yidi Wang, Zhang Yunjun, Ningbo Wang, Runqing Liu, Cunren Liang, Yosuke Aoki, Robert Wang",
    "publish": "IEEE Transactions on Geoscience and Remote Sensing",
    "url": "https://doi.org/10.1109/tgrs.2026.3656511",
    "source": "IEEE",
    "abstract": "Ionospheric delays dominate the long-wavelength deformation measurement errors in InSAR time series. Most existing correction techniques are SAR data-based and rely on interferometric coherence, which restricts their applicability in vegetated areas and operational systems. Here we investigate a rapid ionospheric correction approach that uses external total electron content (TEC) products derived from global navigation satellite system (GNSS) observations with a focus on the long-wavelength deformation mapping. We tested five products, including global ionospheric maps (GIMs), Madrigal TEC products, and local ionospheric maps. The method is fully automatic and reduces processing time from days to minutes, desirable for operational data system as well as existing InSAR databases. We validate the method using C-band Sentinel-1 and L-band ALOS-2 data in the western United States, northern Chile, and southwestern Japan. Using independent GNSS displacements as reference, our method reduces the RMSE from 1.7–3.8 mm/yr to 0.9–2.9 mm/yr for Sentinel-1 ascending tracks in mid-latitude regions and all descending tracks, achieving accuracy comparable to the split-spectrum method (1.0–2.8 mm/yr). However, for Sentinel-1 ascending track in low-latitude regions and ALOS-2 descending tracks, the split-spectrum method still remains much more precise. We demonstrate the effectiveness of the GNSS-based TEC approach using OPERA displacement products over western USA. The global analysis of ionospheric delays using multi-year GIM products could serve as a useful reference for potential ionospheric impact on InSAR velocities for most common InSAR missions."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Powered Inhaler Assistant with Real-Time Alerts for Asthma Management",
    "authors": "Loganayagi P, Ilakkiya Jothi V P, Sathiyarupa T",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11337173",
    "source": "IEEE",
    "abstract": "The AI-Powered Inhaler Assistant is an intelligent health-monitoring system developed to enhance asthma management through real-time detection, prediction, and alert mechanisms. This research explores the integration of Internet of Things (IoT) sensors with artificial intelligence techniques to monitor inhaler usage, record vital signs, and track environmental conditions that may trigger asthma attacks. The system employs a pressure sensor embedded in the inhaler casing to detect actuation events, wearable or smartphone-based sensors to capture physiological parameters such as heart rate and SpO2, and APIs or physical sensors to assess humidity and air quality. Collected data are processed using a lightweight machine learning model that predicts the likelihood of an asthma attack and sends instant notifications to users via a mobile application. Comprehensive health reports are also generated for review by healthcare professionals, enabling continuous remote monitoring. Challenges such as sensor reliability, data synchronization, and false alarms are addressed through modular design principles, and adaptive model optimization. Experimental validation demonstrates reliable asthma risk prediction and effective reduction of false alerts. By combining AI-based forecasting with seamless IoT connectivity, the proposed system provides an affordable, and patient-centric framework for chronic respiratory disease management."
  },
  {
    "date": "2026-1-21",
    "title": "F-RRT: an Efficient Algorithm for Semi-Constrained Path Planning Problems",
    "authors": "Guillaume de Mathelin de Papigny, Franco Gassibe, Vincent Padois",
    "publish": "IEEE Robotics and Automation Letters",
    "url": "https://doi.org/10.1109/lra.2026.3656722",
    "source": "IEEE",
    "abstract": "This paper addresses the challenging problem of Semi-Constrained End-Effector Path Planning for robotic manipulators. This problem arises when complex specifications restrict the end-effector's motion during the execution of industrial tasks. Traditional path planning algorithms often struggle with such problems due to the difficulty of exploring the robot's valid configuration space, or constrained manifold, under these conditions. In this work, we propose a novel sampling-based approach that efficiently navigates the constrained manifold by exploring an alternative space representing the end-effector's degrees of freedom, such as process-related tolerances, throughout the task. This method retains the simplicity of sampling-based techniques. Building on this approach, we introduce the F-RRT algorithm, an adaptation of the renowned RRT planner [1]. F-RRT demonstrates enhanced speed and robustness compared to existing solutions, particularly in complex and cluttered environments."
  },
  {
    "date": "2026-1-21",
    "title": "Signaling for a Fluid Antenna System With Uniform Correlation",
    "authors": "Ranjan K. Mallik, Ross Murch",
    "publish": "IEEE Transactions on Wireless Communications",
    "url": "https://doi.org/10.1109/twc.2026.3653914",
    "source": "IEEE",
    "abstract": "For a single-antenna fluid antenna system (FAS) with <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">N</i> fixed antenna locations or ports, analytical expressions for the error performance of four types of signaling schemes for digitally modulated data transmission and reception are found. The signaling schemes are: (1) <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">M</i>-ary phase-shift keying with coherent reception, (2) two-sided <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">M</i>-ary amplitude-shift keying (<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">M</i>-ASK) with coherent reception, (3) one-sided <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">M</i>-ASK with noncoherent reception, and (4) one-sided <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">M</i>-ASK with partially noncoherent reception. The <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">N</i> ports are evenly distributed on a line. The FAS error performance is analyzed when the ports are subject to identically distributed Rayleigh fading with uniform correlation between the channels at the ports. A series expression for the characteristic function (c.f.) of the random complex channel coefficient magnitude squared of the chosen FAS port, in terms of a series of elementary c.f.s, where each elementary c.f. is the c.f. of a sum of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">N</i> independent gamma random variables, is obtained. Series expressions for the symbol error probabilities as weighted sums of functions in closed form are presented. Closed form asymptotic high signal-to-noise ratio results for error performance are also derived. Numerical are presented to show the variation of the error performance with respect to the spacing between the first and<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> N</i>th ports and <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">N</i>."
  },
  {
    "date": "2026-1-21",
    "title": "LACL: Overcoming Semantic Sparsity in Mashup Development via LLM-Enhanced Service Bundle Recommendation",
    "authors": "Kaipu Sun, Wen Tang, Yechen Jin, Meng Xi, Jiacheng Pan, Ying Li, Jianwei Yin",
    "publish": "IEEE Transactions on Services Computing",
    "url": "https://doi.org/10.1109/tsc.2026.3656398",
    "source": "IEEE",
    "abstract": "The rapid proliferation of web services has brought substantial challenges to mashup development, where developers integrate multiple APIs to create new applications. As the number and complexity of services continue to grow, effective recommendation methods have become increasingly important. Service bundles, which group complementary services, provide a promising way to improve the efficiency and quality of mashup construction. Thus, recent approaches aim to better capture mashup preferences by jointly modeling interactions from both mashup and service bundle perspectives. However, those studies still face challenges such as scarcity of semantic data, discrepancy of multilevel descriptions and sparsity of historical interactions. In this work, we propose an LLM-enhanced Alignment Contrastive Learning model for service bundle recommendation model (LACL) to tackle the issues. Specifically, we design LLM-enhanced Semantic Imputation Block and Multi-Projection Autoencoder Block to generate enriched semantic representations. We further establish information propagation among mashups, services, and bundles based on their historical interaction relationships, and incorporate the proposed Dual-Attention Block to alleviate data sparsity by effectively capturing both global and local collaborative signals. Finally, we propose a contrastive learning strategy that aligns and integrates textual and structural features, thereby improving the model's ability to represent complex semantics. Extensive experiments on real-world dataset demonstrate that LACL notably outperforms state-of-the-art methods on all metrics, with average improvements of 10.31% in NDCG and 16.67% in Recall on real-world ProgrammableWeb dataset."
  },
  {
    "date": "2026-1-21",
    "title": "Machine Learning Applications in Composite Material Synthesis and Property Prediction",
    "authors": "Dodla S. Rao, Mudra Narasimharao, Bashir N. Jamadar, Anil A. Powar, Balasaheb. B. Vhankhande, Anantkumar J. Umbarkar",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336698",
    "source": "IEEE",
    "abstract": "Composite materials are increasingly essential in various engineering applications due to their unique properties. However, accurately predicting their mechanical behaviour remains a challenge, often requiring substantial time and resources. In this study, we propose a novel approach leveraging machine learning techniques to accelerate the discovery and characterization of composite materials. By harnessing the power of machine learning, we aim to reduce computational costs, shorten development cycles, and enhance the accuracy of mechanical property predictions for composite materials. Drawing on recent advancements in machine learning applications across diverse research fields, such as superconductivity, thermoelectric, and catalysis, we explore the potential of machine learning in the context of composite material science. Specifically, we review the basic principles of machine learning, introduce commonly used algorithms, and discuss their applications in predicting mechanical properties and guiding composite material synthesis. Through this study, we provide valuable insights into the intersection of machine learning and composite material science, paving the way for future advancements in this critical field. The limitations of traditional methods, including their material synthesis, have been elaborated."
  },
  {
    "date": "2026-1-21",
    "title": "No-Reference Light Field Image Quality Assessment Based On Spatial-Angular Attention Fusion and Adaptive Pooling",
    "authors": "Yu Sun, Rui Zhou, Bin Wang, Yeyao Chen, Gangyi Jiang",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338375",
    "source": "IEEE",
    "abstract": "Light field images (LFIs), which provide richer scene information, have attracted increasing attention in the development of multimedia. However, LFIs are prone to distortion during acquisition, processing, compression and reconstruction, leading to a decline in perceptual quality. Therefore, monitoring quality degradation is of critical importance. To address this issue, this paper proposes a no-reference quality assessment metric for LFIs based on spatial-angular attention fusion and adaptive pooling. Specifically, a multi-dilation angular decomposition module and a stair network are designed to extract LFI features. On this basis, a spatial-angular attention feature fusion module is introduced to allocate corresponding weights based on spatial and angular information. Furthermore, an adaptive pooling network is designed to predict spatial and angular distortions separately and dynamically adjust their impact on the evaluation results through learnable parameters. Experimental results demonstrate that the proposed metric outperforms existing metrics."
  },
  {
    "date": "2026-1-21",
    "title": "Aegis-5: A Hybrid Ensemble Framework for Intrusion Detection in Industry 5.0 Driven Smart Manufacturing Environment",
    "authors": "Vijay Govindarajan, Faraz Ahmed, Zaid Bin Faheem, Muhammad Bilal, Manel Ayadi, Jehad Ali",
    "publish": "ACM Transactions on Autonomous and Adaptive Systems",
    "url": "https://doi.org/10.1145/3787224",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Design and Implementation of a Multi-Protocol Converter Supporting SPI, I2C, and UART Interfaces",
    "authors": "Sneha Sai Raju, Shuo Wu, Nan Wang",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338395",
    "source": "IEEE",
    "abstract": "This paper presents the design and ASIC implementation of a Multi-Protocol Conversion Unit (MPCU) enabling seamless data transfer across SPI, I2C, and UART communication ports. These protocols have incompatible signaling mechanisms, data formats, and timing models, making real-time conversion challenging in embedded systems. The proposed MPCU, implemented using Verilog HDL and synthesized using industry-standard tools, supports N-byte transfers, dynamic protocol selection using a Conversion Select (COSE) signal, and handles both single- and multi-byte transmission. The design achieves 99.3% ATPG test coverage and is optimized for low power, timing slack, and compact area. This real-time hardware-based protocol bridge eliminates the need for software conversion, making it suitable for SoC, IoT, and FPGA-based embedded applications."
  },
  {
    "date": "2026-1-21",
    "title": "Enhancing Network Security: Hybrid XGMB Model for Intrusion Detection with Intelligent Feature Engineering",
    "authors": "Shayla Islam, S Phani Praveen, Naga Deepti Ponnaganti, Sreenath Kocharla, Nurhizam Safie",
    "publish": "2025 International Conference on Electrical Engineering and Informatics (ICEEI)",
    "url": "https://doi.org/10.1109/iceei68459.2025.11330761",
    "source": "IEEE",
    "abstract": "Network intrusion detection is a very important component of cybersecurity that demands sophisticated methods to distinguish between malicious and normal network traffic correctly. The current study proposes a new hybrid model, XGMB, that combines XGBoost and GBM to optimize intrusion detection performance and reduce false positives. The applied method implements comprehensive data preprocessing, including data cleaning, SMOTE to balance the data, and outlier removal using the IQR method. The Boruta feature selection algorithm was implemented to select the most relevant features and improve model performance. The model was developed and evaluated using the XGMB model and based on the results from the UNSW-NB15 dataset, it achieved an accuracy of 98.92%, which outperformed traditional machine Learning models (K-NN, Logistic regression, SVM, Neural Networks). To demonstrate effective model comparison, the findings highlight the advantages of ensemble learning, which is shown to be superior for network security, thereby enhancing the robustness of boosting-based hybrid models. These findings indicate that, to detect dynamic cyberthreats in real time, efficient feature engineering and model optimization are required. This study adds to intelligence-based intrusion detection system research by creating a high accurate, scalable solution to be utilized in real-time environments. Future work will focus on optimizing for real-time implementation, developing multi-class classification methods, and leveraging deep learning to enhance effective detection in dynamic environments."
  },
  {
    "date": "2026-1-21",
    "title": "Energy Efficient Short-Packet Covert Communications for Full-Duplex Wireless Systems with AoI Constraint",
    "authors": "Yangfan Xu, Bin Yang, Lei Shao, Xiuwen Sun, Shikai Shen, Haibao Chen, Bao Gui, Tarik Taleb",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2026.3656653",
    "source": "IEEE",
    "abstract": "This paper investigates the energy efficient short-packet covert communications in a full-duplex wireless system with the constraint of age of information (AoI), where a transmitter covertly transmits information to a receiver operating on full-duplex communication mode, while a warden tries to detect the existence of this covert transmission. For supporting various security and time-sensitive applications in Internet of Things (IoT) with energy-limited devices, we focus on critical performances of short-packet communications in terms of energy efficiency, covertness and timeliness. To this end, we first analyze the covert constraint condition, AoI and covert energy efficiency (CEE) under the finite block length codewords. We then formulate CEE maximization as an optimization problem with the constraints of some parameters, i.e., the covert constraint condition, freshness of information, block length, the prior transmission probability and transmit powers of transmitter and receiver.We obtain maximum CEE by jointly optimizing the block-length, prior transmission probability and transmit powers using the interior point method. Finally, numerical results are presented to illustrate the impact of the parameters on CEE."
  },
  {
    "date": "2026-1-21",
    "title": "Real-Time User Frustration Detection Through Sub-Second Behavioural Pattern Analysis: A Machine Learning Approach to Digital User Experience Optimization",
    "authors": "Roshaan Js, Srisanajana K, Sharmila Parveen M, Shivanandham R. S, R. Subha, S. Ananthi",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336865",
    "source": "IEEE",
    "abstract": "This research proposes a real-time user frustration detection framework that overcomes the limitation of traditional post hoc usability testing through the utilization of sub-second behavioral micro-patterns extracted directly from raw interaction data. The primary objective is to identify and quantify user frustration in real time while interactive in digital media in order to enable adaptive and empathetic user interfaces. A domain-specific feature engineering pipeline outputs high-fidelity indicators, such as inter-event delay distributions, clicking bursts scroll jitter, tap frequency, and dwell time, from mouse and touch events to build a high-fidelity behavioral model. The new system integrates two complementary models: an XGBoost classifier for explainable feature-based decision making and a Bidirectional Long Short-Term Memory (BiLSTM) network with an attention mechanism for sequence-sensitive frustration inference. Experimental testing demonstrates state-of- the-art performance with 92% prediction accuracy and less than 100 ms response latency, verifying the model's capability to successfully track subtle emotional changes in real time."
  },
  {
    "date": "2026-1-21",
    "title": "An End-to-End Target Monocular Positioning Method for 3-D Measurement of Large-Scale Components",
    "authors": "Yang Liu, Wenqi Ma, Fan Qin, Xiucai Zhang, Guanyu Zhang, Huanyu Zhao",
    "publish": "IEEE Transactions on Industrial Informatics",
    "url": "https://doi.org/10.1109/tii.2025.3647064",
    "source": "IEEE",
    "abstract": "High-accuracy and high-efficiency target positioning method is crucial for the 3-D measurement performance of large-scale components. However, most existing methods typically involve the time-consuming process of identification and matching of target markers, which can lead to the measurement system failing to meet the real-time demands of the manufacturing industry. To solve this problem, we propose an end-to-end target monocular positioning method. Specifically, we first design a speckle texture spherical target to eliminate the necessity of identifying and matching target markers. Next, we propose a fast target positioning regression network to model the mapping relationship between the speckle texture information of the spherical target and its spatial position parameters, thereby ensuring the accuracy and efficiency of the target positioning. Experimental results demonstrate that our proposed method achieves a translation error of less than 0.15 mm and a rotation error of less than 0.17<inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><tex-math notation=\"LaTeX\">$^{\\circ }$</tex-math></inline-formula>, with a visual positioning time of 0.02 s. In addition, our proposed method can achieve precise target positioning within a measurement range of 2 m. Furthermore, extensive experiments demonstrate the robustness and reliability of our proposed method under various conditions."
  },
  {
    "date": "2026-1-21",
    "title": "Cloud-Based Random Forest Models for Early Prediction of Septic Shock in ICUs",
    "authors": "Mohammed Ashik Saleem, Visumathi J, S P Vimal, M. Moorthy, G. Surya, S Murugan",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336894",
    "source": "IEEE",
    "abstract": "Septic shock is a severe condition with increased death rates, necessitating early prediction in Intensive Care Units (ICUs) to enhance patient outcomes. This research aims to establish a cloud-based prediction system using Random Forest (RF) algorithms for the detection of septic shock onset. The technique incorporates real-time patient data from IoT-enabled monitoring devices, including vital signs (heart rate, blood pressure, oxygen saturation), laboratory findings, and demographic information, into an RF model. Random Forest is selected for its resilience in managing high-dimensional data and its capacity to provide interpretable feature significance metrics. Cloud architecture facilitates safe storage, fast computing, ongoing model upgrades, and remote accessibility for healthcare professionals. The model underwent training and validation using a publicly accessible ICU dataset, attaining a sensitivity of 97% and a specificity of 98%. These findings suggest prompt notifications and preemptive clinical measures. The proposed approach is scalable, adaptable to various healthcare settings, and signifies a substantial improvement in predictive analytics for critical care."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Integrated Sensor Networks for Industrial Automation",
    "authors": "Vidhi Chamat, Prekshita Motghare, Steven Titus, Tejal Irkhede",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335596",
    "source": "IEEE",
    "abstract": "Agriculture is a key driver of food security and rural livelihoods, especially in developing nations, but it’s exposed to issues like soil loss, climatic uncertainty, and insect infestation. This paper introduces an AI-integrated sensor network for smart farming with the aim of producing accurate, data-driven, real-time advice to the farmer. The system utilizes Random Forest and Decision Tree classifiers to decide on best crop and fertilizer decisions based on the parameters of the soil, such as $\\mathbf{p H}$, NPK levels, and water content. Convolutional Neural Networks (CNNs) are used for the early detection of crop diseases and pest infestation using images. IoT sensors constantly track soil moisture, temperature, and nutrient content and data thus gathered is processed on a cloud platform to provide optimized irrigation schedules and bio-fertilizer recommendations. A web-based user-friendly interface, built with Flask and Firebase, makes it easy for farmers without much technical know-how to use. Through its integration of AI and IoT, the system maximizes resource use, decreases the cost of inputs, increases quality of crop yield, and facilitates sustainable agriculture. The system is scalable, economical, and combines conventional farming with smart, green, and high-yielding production, with high potential for future precision agriculture and rural development."
  },
  {
    "date": "2026-1-21",
    "title": "Joint ICI-ISI Equalization and Estimation for Multi-carrier Communication over Doubly-Dispersive High-Spread Channels",
    "authors": "Jorge A. Pires, Benjamin J. Belzer, Krishnamoorthy Sivakumar, Thomas R. Fischer, Mohammad Torabi",
    "publish": "IEEE Transactions on Wireless Communications",
    "url": "https://doi.org/10.1109/twc.2026.3653808",
    "source": "IEEE",
    "abstract": "We introduce a guard-time-free approach for simultaneous channel estimation and equalization, addressing both inter-carrier interference (ICI) and inter-symbol interference (ISI) in multi-carrier communication systems. The proposed method utilizes two maximum <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">a-posteriori</i> (MAP) equalizers based on the Bahl-Cocke-Jelinek-Raviv (BCJR) algorithm, operating in the time-frequency domain. These equalizers share soft-bit data among themselves and with a channel decoder. We derive the <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">a-posteriori</i> probabilities (APPs) and show that the equalizers exploit Doppler-time diversity. We also derive maximum-likelihood (ML) bounds on the system’s performance, which also exhibit diversity gains. We initially simulate on Rayleigh fading doubly-dispersive (DD) channels with the Jakes autocorrelation function, a channel model often employed in radio frequency (RF) communications, under the assumption of perfect receiver channel state information (CSI). We compare with an existing iterative maximum likelihood equalizer (IMLE) from the literature and show that the proposed system outperforms it. Next, we focus on an underwater acoustic channel (UAC), and develop a joint channel estimation and equalization architecture. To estimate this sparse channel, we take a compressed sensing (CS) approach using the orthogonal matching pursuit (OMP) algorithm together with an over-complete dictionary set. Compared to one-dimensional (1D) equalization with full guard-time, the guard-time-free estimation-equalization system achieves bit error rate (BER) reductions between 24% and 78% for high-spread channels that can surpass the orthogonal time-frequency space (OTFS) crystallization condition."
  },
  {
    "date": "2026-1-21",
    "title": "AI-Enabled Fertilizer Analysis and Dispensing Rover",
    "authors": "P. Leninpugalhanthi, K. Nathish, S. Naveen Kumar, A. U. Sudharsan",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11336025",
    "source": "IEEE",
    "abstract": "Proper fertilizer management and crop selection are critical to increasing agricultural production without increasing costs and impacts to the environment. However, traditional soil testing can be lengthy, expensive, and requires multiple steps, which has been a driving force for the demand for a more efficient, data-driven methodology to improve farmer yield. We present an AI agronomic simulation tool that provides fertilizer recommendations and crop selection guidance without, a physical sensor or soil chemistry dataset. Soil nutrient levels are predicted using a Convolutional Neural Network (CNN) on soil image datasets - nitrogen (N), phosphorus (P), and potassium (K). Soil nutrients are directly correlated to soil fertility, therefore we then account for the crop selected by the farmer, and predicted nutrient gaps using a crop-nutrient database. The proposed system uses TensorFlow and Keras for deep learning, Pandas and NumPy for data processing, and Pre-process soil images in OpenCV-Python. Prediction data was validated and the results were accurate and robust. The proposed system offers opportunity for precision agriculture, real-time, low-cost, sustainable opportunity to utilizing nutrients more sustainably, increase yield, and provides a environmentally friendly agricultural practice."
  },
  {
    "date": "2026-1-21",
    "title": "Battery Solutions and Aging Process Simulation for Maritime Electric Propulsion",
    "authors": "Cristi Irimia, Robert-Matei Szabo, Mihail Grovu, Calin Husar, Roberta Luca, Tiberio Brinzea",
    "publish": "2025 International Conference on Future Energy Solutions (FES)",
    "url": "https://doi.org/10.1109/fes65767.2025.11341844",
    "source": "IEEE",
    "abstract": "Climate change poses a significant challenge to human life and ecosystems. Today, the maritime industry faces increasing pressure to reduce its carbon footprint, with all stakeholders required to comply with the International Maritime Organization (IMO) regulations. To support the design of innovative ships, the Siemens Simcenter portfolio provides solutions that meet IMO specifications. Electrical propulsion systems are particularly important for vessels operating in Emission Control Areas (ECAs), where carbon emissions can be significantly reduced. The main objective of this article is to simulate a fully hybrid electric ship propulsion architecture and evaluate the aging process of its battery system. Battery capacity loss over the system's lifespan is determined using aging test data to calibrate an empirical aging law."
  },
  {
    "date": "2026-1-21",
    "title": "Smart Stock: Automating Inventory Management for Small Warehouses with Real-Time Intelligence",
    "authors": "Kathyani Avuduri, Muthu Lakshmi V, Sowmiya L",
    "publish": "2025 10th International Conference on Communication and Electronics Systems (ICCES)",
    "url": "https://doi.org/10.1109/icces67310.2025.11336945",
    "source": "IEEE",
    "abstract": "Small and medium-sized enterprises (SMEs) frequently rely on manual, disconnected processes for inventory classification and stock tracking, which leads to human error, operational delays, and inaccurate demand forecasting. This research aims to develop an AI-powered Smart Inventory Management System that automates stock monitoring, improves prediction accuracy, and enhances decision-making for replenishment. The proposed methodology integrates QR-based product identification with a Raspberry Pi-based edge device equipped with a camera and scanning modules for real-time data collection. Machine learning model, XGBoost are incorporated to classify stock levels and forecast demand trends based on historical and live inventory data. To ensure secure operation, the system employs role-based access control (RBAC), QR code-based authentication, and AES-256 encryption for sensitive information. The framework further categorizes inventory by product type, brand, and packaging variants, enabling structured reporting and streamlined tracking. Experimental evaluation using a custom dataset demonstrates superior performance of the proposed predictive model, achieving a coefficient of determination (R<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup>) greater than 0.95, accuracy achieved 96% outperforming traditional approaches. The system is designed to be scalable, costeffective, and suitable for SMEs compared to commercial platforms like Oracle and SAP. Future enhancements include IoT-based warehouse automation, cloud integration, and API connectivity for e-commerce synchronization and advanced analytics."
  },
  {
    "date": "2026-1-21",
    "title": "A novel method to accelerate the phagocytosis of\n                    <i>Saccharomyces cerevisiae</i>\n                    by macrophages based on optically-induced dielectrophoresis",
    "authors": "Mingao Du, Lixiang Zheng, Fei Liu, Na Liu, Gongxin Li",
    "publish": "IEEE Transactions on NanoBioscience",
    "url": "https://doi.org/10.1109/tnb.2026.3656608",
    "source": "IEEE",
    "abstract": "<italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">Saccharomyces cerevisiae (S. cerevisiae)</i> can be used to treat diarrhea and the diseases associated with malaria, but it may cause invasive infections in individuals with weakened immune systems. While antibiotics are available for treating these infections, they can also produce side effects in the body. Additionally, macrophages in the human immune system can engulf infected <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i>, but they have some limitations, including a relatively weak active chemotactic response and a prolonged engulfing process. To address this, this paper proposes a novel method to enhance the phagocytosis of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i> by macrophages using optically induced dielectrophoresis (ODEP). ODEP is a cellular micromanipulation technique that directs phagocytes towards <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i> cells, significantly improving phagocytosis efficiency. Furthermore, the optical electrodes created by ODEP expedite the phagocytosis process. To validate this approach, the optimal operating parameters for ODEP were determined through a combination of numerical simulations and experiments, enabling the swift and precise capture of phagocytes targeting <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i>. A comparative experiment was conducted to assess macrophage phagocytosis of <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i> with and without the aid of optical electrodes. Results showed that the time required for macrophages to engulf <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i> was reduced by 50%, highlighting a promising method for the early prevention or accelerated treatment of invasive <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">S. cerevisiae</i> fungal infections."
  },
  {
    "date": "2026-1-21",
    "title": "Persona Vectors in Controlling Hallucination of Small Large Language Models: A Safety-Oriented Analysis",
    "authors": "Utku Kose, Ilhan Uysal",
    "publish": "2025 Cyber Awareness and Research Symposium (CARS)",
    "url": "https://doi.org/10.1109/cars67163.2025.11337402",
    "source": "IEEE",
    "abstract": "Large Language Models (LLMs) ensured a paradigm change in artificial intelligence research and the way of human-computer interaction. However, they are not perfect yet and can easily demonstrate failures in generating senseful answers. Hallucinations are among the failures, and they are known as fabricated, false but convincing content. Reasons for hallucinations vary but the US company Anthropic showed that a latent space called as persona vectors can be one reason triggering them. So, it is seen that monitoring and controlling such vectors can help in reducing hallucinations. In this sense, this study presents an analysis of persona vectors in hallucination behaviors, by considering four different small models: TinyLlama, Qwen2, Phi-2, and Phi-3-mini. The study included use of two data sets TruthfulQA, and SQuAD v2 to test the models with four different metrics (in terms of accuracy, hallucinations, and abstention) and analyze them in a basic RAG experiment. According to the findings, the persona switches had the highest effect on abstention behaviors of the models."
  },
  {
    "date": "2026-1-21",
    "title": "MHA-YOLO: A Lightweight Model for River Waste Detection",
    "authors": "Min Li, Tao Xu, Yinping Jiang, Ruiqiang Guo",
    "publish": "2025 5th International Conference on Electronic Information Engineering and Computer Technology (EIECT)",
    "url": "https://doi.org/10.1109/eiect68017.2025.11331838",
    "source": "IEEE",
    "abstract": "Current deep learning models for river waste detection face challenges such as high computational resource consumption and large model parameter sizes. To address these issues, this paper proposes a lightweight river waste detection model, Multiscale Hybrid Attention YOLO (MHA-YOLO). Built upon the YOLOv11n framework, the model incorporates several key innovations to significantly reduce computational complexity and model size while improving the detection capability for river waste targets. Experiments were conducted using the publicly available FLOW-IMG dataset, and the MHA-YOLO model was compared with the YOLOv11n model in terms of mAP, Precision <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$(\\mathrm{P})$</tex>, Recall (R), and mAP@0.5:0.95. The results show that MHA-YOLO improves by <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$3.0 \\%, 2.1 \\%, 2.3 {\\%}$</tex>, and 1.5%, respectively, while GFLOPs and the number of parameters are reduced by 24.9% and 27.7%, respectively. These findings demonstrate that MHA-YOLO achieves lower resource consumption compared to other state-of-the-art models, making it well-suited for deployment in resource-constrained environments for river waste detection."
  },
  {
    "date": "2026-1-21",
    "title": "A Real-Time Computer Vision System for Liquid Monitoring in Transparent Containers",
    "authors": "Nicolás Torres",
    "publish": "Proceedings of the 2025 6th Asia Service Sciences and Software Engineering Conference",
    "url": "https://doi.org/10.1145/3775030.3775041",
    "source": "ACM",
    "abstract": "None"
  },
  {
    "date": "2026-1-21",
    "title": "Spatiotemporal Ocean Data Reconstruction Based on Deep Unfolding Networks",
    "authors": "Yuhan Wang, Wei Qiu",
    "publish": "2025 8th International Conference on Information Communication and Signal Processing (ICICSP)",
    "url": "https://doi.org/10.1109/icicsp66564.2025.11338339",
    "source": "IEEE",
    "abstract": "Ocean observation data (e.g., SST, SSH, SSS) serve as crucial indicators for characterizing marine physical states, yet missing data frequently occur due to sensor node failures. Accurate reconstruction of these parameters is essential for applications such as marine environmental monitoring, climate prediction, and disaster early warning. By exploiting the spatiotemporal continuity and gradual variation characteristics of ocean data, this paper proposes a deep unfolding (DU) network-based reconstruction method. Firstly, the ocean data is modeled by time-varying graph signals. Then the data reconstruction is formulated as a low-rankness and joint smoothness (LRJS) constrained optimization problem and solved via the ADMM algorithm. Subsequently, the variable updates during the optimization are implemented through deep unfolding networks to overcome the low reconstruction accuracy of traditional methods, which is termed as the DU-LRJS algorithm. Finally, simulation experiments on both synthetic and real-world ocean datasets demonstrate that, compared to existing methods, DU-LRJS significantly improves convergence speed and reconstruction accuracy."
  },
  {
    "date": "2026-1-21",
    "title": "Cooperative Control of Virtually Coupled Train Sets Considering Interaction Forces Between Carriages",
    "authors": "Lei Zhu, Xuefang Li, Jing Xiao, Chunquan Gan",
    "publish": "2025 IEEE 5th International Conference on Control Theory and Applications (ICoCTA)",
    "url": "https://doi.org/10.1109/icocta66834.2025.11337246",
    "source": "IEEE",
    "abstract": "This work develops a distributed control method for the cooperative operation of virtually coupled train sets (VCTS), which consists of a train collaboration layer and a carriage collaboration layer. The proposed distributed control method is characterized by the consideration of the interaction forces between carriages and the constraints of coupler forces. For the train collaboration layer, a distributed nonlinear model predictive control scheme is designed based on the nominal single-particle dynamics model of the train to address the cooperative control of VCTS with distinct initial states. For the carriage collaboration layer, the coupler force constraints between carriages are first transformed into the operational state constraints of each carriage based on the spring-damping model of the coupler. Subsequently, the multiple-particle dynamics (MPD) model with state constraints is converted into a new MPD model without state constraints using the unified barrier function. Based on the unconstrained MPD model, an adaptive sliding mode control approach is proposed to address the cooperative control of carriages. Finally, the effectiveness of the proposed control method is validated through simulations."
  },
  {
    "date": "2026-1-21",
    "title": "A Study on Propagation Delay and Dynamic Power Dissipation of Inverter Architectures Using Cadence Gpdk90",
    "authors": "Aditi Javeri, Nandana Kamath, Samana Nagendran, Samrat Sharma, Arjun Sunil Rao, Basavaraj S Sannakashappanavar",
    "publish": "2025 Control Instrumentation System Conference (CISCON)",
    "url": "https://doi.org/10.1109/ciscon66933.2025.11337805",
    "source": "IEEE",
    "abstract": "This research focuses on the study of propagation delay and dynamic power dissipation for various inverter circuits. The inverter circuits used in this research are static CMOS inverter, clocked CMOS (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$C^{2}$</tex> MOS) inverter circuit, nMOS logic inverter circuit and dynamic CMOS inverter circuit. Cadence Virtuoso simulation tool is used to design the schematic and symbol of above-mentioned circuits. gpdk90 is the technology file that is used in this research. Our results show that the propagation delay followed the trend as follows: nMOS logic inverter, dynamic CMOS inverter, static CMOS inverter and <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{C}^{\\mathbf{2}}$</tex> MOS inverter, nMOS logic inverter circuit produced a least propagation delay of 0.0475 ns followed by dynamic CMOS inverter circuit with propagation delay of 0.575 ns followed by static CMOS inverter circuit with propagation delay of 0.7212 ns. C²MOS inverter circuit produced the highest propagation delay of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1 0. 2 5 6 ~ n s}$</tex>, thereby indicating nMOS logic inverter is faster in processing the signal as compared to the other types. The dynamic power dissipation of dynamic CMOS inverter, <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$C^{2}$</tex> MOS inverter circuit, nMOS logic inverter and static CMOS inverter circuits are found to be <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1. 0 2 1 ~ m W}, \\mathbf{0. 6 6 8 6 ~ m W}, \\mathbf{0. 2 2 0 1}$</tex> mW and 0.1849 mW, respectively. This indicates the potential application of these circuits in low power VLSI circuits."
  },
  {
    "date": "2026-1-21",
    "title": "Survival Outcome Prediction for Hematopoietic Cell Transplantation by using ML Ensemble Model",
    "authors": "Srinivas Kanakala, Bala Abhishek Udagandla",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335942",
    "source": "IEEE",
    "abstract": "Hematopoietic Cell Transplantation (HCT) is a treatment which is used to cure the diseases related to blood and blood cancers like leukemia, Lymphoma, anemia. After the transplant, predicting survival outcomes of patient is very challenging because of complex interactions between various patient and donor data. Accurately predicting Event Free Survival (EFS) is very important in medical industry to support the clinicians or doctors for decision making regarding treatments. This research is performed by using ensemble machine learning model which combines Random Forest, Logistic Regression and XG Boost with the help of soft-voting approach in order to predict the Event Free Survival using pre-clinical data of patient. By balancing the precision and recall, this model has achieved $91.35 \\%$ accuracy. In addition to this, Shapley Additive Explanations (SHAP) was integrated with this model in order to enhance the model interpretability and to enable the clinicians to understand which factors are influencing prediction result. This work shows that combining ensemble model with explainability feature can make clinical support for HCT patients more effective."
  },
  {
    "date": "2026-1-21",
    "title": "Get Published in the\n                    <i>IEEE Open Journal of Power Electronics</i>",
    "authors": "N/A",
    "publish": "IEEE Transactions on Power Electronics",
    "url": "https://doi.org/10.1109/tpel.2026.3654294",
    "source": "IEEE",
    "abstract": null
  },
  {
    "date": "2026-1-21",
    "title": "A Comparative Analysis of XGBoost, Ridge Regression, and LSTM for Stock Price Prediction",
    "authors": "Santoshinee Mohapatra, Priyanka Sen, Yogendra Kumar, Nisha",
    "publish": "2025 International Conference on Cognitive, Green and Ubiquitous Computing (IC-CGU)",
    "url": "https://doi.org/10.1109/ic-cgu67042.2025.11338062",
    "source": "IEEE",
    "abstract": "Algorithmic trading depends on core models that help in comprehending the decision structures to obtain profits in the desired stock. This paper analyzes three different models, including stock index prices with ever-increasing machine learning (M-L) and deep learning(D-LM) models using stock data (from past years) and technical attributes. The models are made from Yahoo Finance that is augmented with Simple Moving Averages (S-MA), Relative Strength Index (R-SI), Moving Average Convergence Divergence (M-ACD) and Bollinger Bands. XGBoost captures strong predictive power in comparison to the classical model with an almost even split in bias and variance, Ridge Regression takes on a robust linear predictive approach that has regularization on it, and Bidirectional Long short term memory (B-LSTM)takes advantage of temporal dependencies for better sequential forecasting. Performance is evaluated using the Root Mean Square Error (R-MSE), R<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">2</sup>-score, and Mean Absolute Percentage Error (M-APE) to examine the final result. From the analysis, it is confirmed that deep learning methods outperform the classical models in the stock price range predictions. The deep learning methods have emerged as a great contribution in financial forecasting that has the attention of many traders and quantitative analysts for the versatile insights offered in a predicted future stock."
  },
  {
    "date": "2026-1-21",
    "title": "Propeller-Based Drone Tracking with a Moving Neuromorphic Camera",
    "authors": "Kevin Murray, Cameron Nowzari",
    "publish": "2025 International Conference on Neuromorphic Systems (ICONS)",
    "url": "https://doi.org/10.1109/icons69015.2025.00030",
    "source": "IEEE",
    "abstract": "Neuromorphic event cameras offer unique advantages for counter-Uncrewed Air Systems (c-UAS) applications due to their high temporal resolution and sparse data output, enabling capabilities like the detection of high-frequency propeller signatures. However, a critical challenge arises when deploying these sensors on moving platforms, such as pan-tilt units (PTUs), used for surveillance and tracking. The rapid egomotion generated during PTU sweeps can overwhelm the sensor, distort characteristic spatio-temporal event patterns, and cause traditional propeller-frequency analysis methods to fail. This paper addresses the challenge of robust drone detection and tracking amidst significant ego-motion. We propose processing the event stream as sparse ($t, x, y$) voxel grids and employing a compact sparse 3D Convolutional Neural Network (CNN), chosen for its ability to efficiently integrate spatio-temporal propeller streak evidence over time, enhancing robustness against motioninduced distortions. Our learning-based approach effectively extracts the motion-distorted propeller patterns while remaining robust to background clutter induced by ego-motion. We demonstrate robust drone localization during aggressive PTU maneuvers up to $40 \\% \\mathrm{~s}$, significantly improving the practicality of event-based c-UAS on dynamic platforms. The complete pipeline, evaluation data, and a re-implementation of a prior frequencybased tracking method for baseline comparison are available at: https://github.com/overlab-kevin/event-cam-prop-tracker."
  },
  {
    "date": "2026-1-21",
    "title": "Design of 3D Unit Cells for Reconfigurable Intelligent Surfaces Based on Slot Rings",
    "authors": "Mats Kohler Dijkstra, Ángel Palomares-Caballero, Raphaël Gillard, Carlos Molero, María García-Vigueras, Pablo Padilla",
    "publish": "2025 IEEE Conference on Antenna Measurements and Applications (CAMA)",
    "url": "https://doi.org/10.1109/cama65664.2025.11335207",
    "source": "IEEE",
    "abstract": "This paper presents reconfigurable intelligent surface unit cells based on a loaded slot ring topology. The use of rings enables an increased bandwidth for PIN diode-based reconfigurable unit cells. Measurement results demonstrate that the unit cell provides two phase states separated by 180°±20° over a 21.4% relative bandwidth centered at 40 GHz. The concept is then applied to a mechanically reconfigurable structure capable of achieving two configuration states with a phase difference of 180°±20° across a 20.3% relative bandwidth centered at 16 GHz. Full-wave simulations confirm the unit cell’s ability to steer beams up to a 60° angle when integrated into a surface configuration. These results demonstrate the viability of the proposed architecture for broadband reconfigurable intelligent surface applications."
  },
  {
    "date": "2026-1-21",
    "title": "Few-Shot Generative Deep Learning for Cross-Regional Identification of Rare Banana Sigatoka Infections",
    "authors": "P. Jagadeesan, D. Senthil Kumar, P. Sathish, S. Deepa, B. Mythili, B. Swapna",
    "publish": "2025 Third International Conference on Emerging Applications of Material Science and Technology (ICEAMST)",
    "url": "https://doi.org/10.1109/iceamst67459.2025.11335605",
    "source": "IEEE",
    "abstract": "Plant diseases represent a major challenge to global food security, with banana crops particularly vulnerable to fungal and viral infections. Early and reliable detection of these conditions is essential for timely intervention and yield preservation. Traditional approaches often depend on handcrafted features or shallow learning techniques, which are limited in their ability to generalize under data scarcity and class imbalance. Deep learning models have improved performance but still face challenges when dealing with rare infections and cross-regional variability. This study introduces a generative few-shot learning framework that integrates diffusion-based data augmentation with a prototypical network for robust banana disease recognition. The PlantVillage dataset, containing approximately 3,700 banana leaf images across four categories, was employed to evaluate the model. Experimental results demonstrated a Top-1 accuracy of 97.3%, F1-score of 96.8%, and AUC of 98.5%, outperforming ResNet50, EfficientNet-B3, and Vision Transformer baselines. Crossregional evaluation further confirmed the adaptability of the proposed method with a Top-1 accuracy of 91.5%. These findings indicate that the framework is effective for addressing data imbalance and regional diversity, offering a practical direction for intelligent plant disease monitoring and precision agriculture."
  },
  {
    "date": "2026-1-21",
    "title": "Fire Recognition Method for Electric Bicycle Parking Areas Based on Multimodal Feature Fusion",
    "authors": "Zhipeng Qi, Qiangqiang Xie, Yaojin Liao, Yukun Lain",
    "publish": "2025 International Conference on Meta-Networking (MEET)",
    "url": "https://doi.org/10.1109/meet67398.2025.11335763",
    "source": "IEEE",
    "abstract": "Electric bicycle fire accidents, often occurring in crowded parking areas, present significant detection challenges due to numerous visual interferences, specific fire characteristics, and the need for early recognition. Traditional fire detection methods, including generic deep learning models and sensor-based systems, fall short in this specific case. They are susceptible to false alarms from vehicle components and fail to leverage the unique static and dynamic features of electric bicycle fires. This paper proposes a novel, fire-specific multimodal feature fusion method for fire recognition in electric bicycle parking areas. Our approach integrates a lightweight tracking-analysis framework with a specialized visual feature set, including static color bias and dynamic trajectory features of flames and smoke. The paper quantifies the importance of these features using a feature importance evaluation mechanism to optimize a final authenticity score. Experimental results demonstrate that our method significantly improves detection accuracy and reduces the false alarm rate compared to generic fire detection models. The proposed framework, running efficiently on a low-power edge device, meets real-time monitoring requirements, making it a robust and cost-effective solution for early fire warning."
  },
  {
    "date": "2026-1-21",
    "title": "Bridging Financial NLP and Decision-Making: An AI-Powered SEC 10-K Report Analysis System",
    "authors": "Khushi Arora, Kashika Singh, Khushin Vyas, Aniket K. Shahade, Mayur Gaikwad, Shruti Patil",
    "publish": "2025 International Conference on Future Technologies (ICFT)",
    "url": "https://doi.org/10.1109/icft66708.2025.11336620",
    "source": "IEEE",
    "abstract": "This research presents an intelligent question-answering system designed to streamline the analysis of SEC 10-K reports. These lengthy documents are crucial for investors but are often difficult to navigate due to their complexity and volume. Our system integrates retrieval-augmented generation (RAG) with fine-tuned transformer models, specifically Meta-Llama-3-8B, to provide precise summarization and contextual question-answering. Evaluation on a financial QA dataset demonstrated strong performance, with ROUGE-1 and ROUGE-2 scores of 0.987 and 0.919, and a BERTScore of 0.903, indicating high semantic fidelity. The architecture significantly reduces the cognitive load and time required for financial analysis, enabling a wider range of users to extract critical insights efficiently. By bridging raw financial data and human understanding, this system contributes to the field of Financial NLP and supports more informed, timely decision-making."
  },
  {
    "date": "2026-1-21",
    "title": "Robust and Lightweight User Authentication Scheme Using Deep Learning-Based Cancelable Biometrics in Smart Home Environments",
    "authors": "Taehun Kim, Deokkyu Kwon, Ashok Kumar Das, Youngho Park",
    "publish": "IEEE Internet of Things Journal",
    "url": "https://doi.org/10.1109/jiot.2026.3656524",
    "source": "IEEE",
    "abstract": "In smart home environments, users are provided with various convenient services using smart devices. However, without adequate security measures, sensitive information can be exposed to adversaries because messages are transmitted through public channels. The biometric information of users can be employed for security, but leakage of biometric templates can cause permanent damage to users. In 2025, Hu et al. proposed a user authentication scheme using revocable biometrics for smart home environments. However, we found that their scheme is insecure to eavesdropping and stolen verifier attacks and does not ensure user untraceability. To overcome these security problems, we propose a robust and lightweight user authentication scheme for smart home environments. Moreover, we propose new cancelable biometric protection scheme using DeepPrint and indexing-min-max (IMM) hashing to protect biometric templates of users. To demonstrate the performance and security of these schemes, this work conducts performance and security analyses on the cancelable biometric template generation scheme and the user authentication scheme. The results demonstrate that the proposed scheme offers lower equal error rates, lower computational and communication costs, and more security features than existing schemes."
  },
  {
    "date": "2026-1-21",
    "title": "Ultra-Wideband Circular Polarized Linear Antenna Array with Electronic Steering",
    "authors": "Plamen Tsonev, Stoyan Iliev, Hristomir Yordanov",
    "publish": "2025 IEEE Conference on Antenna Measurements and Applications (CAMA)",
    "url": "https://doi.org/10.1109/cama65664.2025.11335348",
    "source": "IEEE",
    "abstract": "In this work we present an ultra-wideband (UWB) circular polarized four-element phased linear antenna array operating in the UWB channel 5 – a frequency bandwidth of 500 MHz in the range of 6.25 to 6.75 GHz. The antenna can find application as a scanning array for short-range communications in the Internet of Things (IoT), such as real-time location and automation. The antenna is based on right-hand circular polarized rectangular or circular patch elements implemented on a FR-4 substrate with thickness of 2.4 mm. It is fed by a $2 \\times 2$ Butler matrix that provides progressive 90° phase shifts, which enables beam steering up to ±30°. Side-lobe levels are reduced using a simple taper through 6 dB $\\mathbf{\\Pi}$-attenuators applied to the outer radiators. We present electromagnetic simulations results, alongside measurements to demonstrate antenna gain up to 10 dB (simulated), bandwidth exceeding 500 MHz, and axial ratio bandwidth of 250–350 MHz."
  }
]