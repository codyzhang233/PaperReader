[
  {
    "date": "2026-01-13",
    "title": "Agent Contracts: A Formal Framework for Resource-Bounded Autonomous AI Systems",
    "authors": "Qing Ye, Jing Tan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08815v1",
    "source": "arXiv",
    "abstract": "The Contract Net Protocol (1980) introduced coordination through contracts in multi-agent systems. Modern agent protocols standardize connectivity and interoperability; yet, none provide formal, resource governance-normative mechanisms to bound how much agents may consume or how long they may operate. We introduce Agent Contracts, a formal framework that extends the contract metaphor from task allocation to resource-bounded execution. An Agent Contract unifies input/output specifications, multi-dimensional resource constraints, temporal boundaries, and success criteria into a coherent governance mechanism with explicit lifecycle semantics. For multi-agent coordination, we establish conservation laws ensuring delegated budgets respect parent constraints, enabling hierarchical coordination through contract delegation. Empirical validation across four experiments demonstrates 90% token reduction with 525x lower variance in iterative workflows, zero conservation violations in multi-agent delegation, and measurable quality-resource tradeoffs through contract modes. Agent Contracts provide formal foundations for predictable, auditable, and resource-bounded autonomous AI deployment.",
    "title_zh": "代理合约：面向资源受限的自主人工智能系统的正式框架",
    "abstract_zh": "合同网协议（1980年）首次在多智能体系统中引入了通过合同进行协调的机制。现代智能体协议虽已标准化了连接性和互操作性，但尚未提供正式的、具有资源治理规范性的机制，以界定智能体可消耗的资源量或其运行时长。我们提出了“智能体合同”（Agent Contracts），这是一个形式化框架，将合同隐喻从任务分配扩展至资源约束下的执行过程。智能体合同将输入/输出规范、多维资源约束、时间边界以及成功标准统一为一个连贯的治理机制，并具备明确的生命周期语义。在多智能体协调中，我们建立了守恒定律，确保委派的预算始终遵守上级约束，从而实现通过合同委托实现的层级化协调。四项实验的实证验证表明：在迭代工作流中，token消耗减少90%，方差降低525倍；多智能体委托过程中零守恒违规；并通过合同模式实现了可度量的质量-资源权衡。智能体合同为可预测、可审计且资源受限的自主人工智能部署提供了形式化基础。"
  },
  {
    "date": "2026-01-13",
    "title": "APEX-SWE",
    "authors": "Abhi Kottamasu, Akul Datta, Aakash Barthwal, Chirag Mahapatra, Ajay Arun, Adarsh Hiremath, Brendan Foody, Bertie Vidgen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08806v1",
    "source": "arXiv",
    "abstract": "We introduce the AI Productivity Index for Software Engineering (APEX-SWE), a benchmark for assessing whether frontier AI models can execute economically valuable software engineering work. Unlike existing evaluations that focus on narrow, well-defined tasks, APEX-SWE assesses two novel task types that reflect real-world software engineering work: (1) Integration tasks (n=100), which require constructing end-to-end systems across heterogeneous cloud primitives, business applications, and infrastructure-as-code services, and (2) Observability tasks (n=100), which require debugging production failures using telemetry signals such as logs and dashboards, as well as unstructured context. We evaluated eight frontier models on APEX-SWE. Gemini 3 Pro (Thinking = High) performs best, with a Pass@1 score of 25\\%. Our analysis shows that strong performance is primarily driven by epistemic reasoning, defined as the ability to distinguish between assumptions and verified facts, combined with agency to resolve uncertainty prior to acting. We open-source the APEX-SWE evaluation harness and a dev set (n=50).",
    "title_zh": "APEX-SWE",
    "abstract_zh": "我们推出了软件工程领域的人工智能生产力指数（APEX-SWE），这是一个用于评估前沿人工智能模型是否能够执行具有经济价值的软件工程任务的基准测试。与现有评估侧重于狭窄且定义明确的任务不同，APEX-SWE引入了两种新型任务类型，更真实地反映了实际的软件工程工作：（1）集成任务（n=100），要求在异构云原生组件、业务应用及基础设施即代码服务之间构建端到端系统；（2）可观测性任务（n=100），要求利用日志、仪表盘等遥测信号以及非结构化上下文信息来排查生产环境中的故障。我们在APEX-SWE上对八种前沿模型进行了评估，其中Gemini 3 Pro（思维模式 = 高）表现最佳，其Pass@1得分为25%。我们的分析表明，优异的表现主要源于“认识论推理”能力，即区分假设与已验证事实的能力，以及在行动前主动消除不确定性的自主性。我们已开源APEX-SWE评估工具包及一个开发数据集（n=50）。"
  },
  {
    "date": "2026-01-13",
    "title": "Reliable Graph-RAG for Codebases: AST-Derived Graphs vs LLM-Extracted Knowledge Graphs",
    "authors": "Manideep Reddy Chinthareddy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08773v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation for software engineering often relies on vector similarity search, which captures topical similarity but can fail on multi-hop architectural reasoning such as controller to service to repository chains, interface-driven wiring, and inheritance. This paper benchmarks three retrieval pipelines on Java codebases (Shopizer, with additional runs on ThingsBoard and OpenMRS Core): (A) vector-only No-Graph RAG, (B) an LLM-generated knowledge graph RAG (LLM-KB), and (C) a deterministic AST-derived knowledge graph RAG (DKB) built with Tree-sitter and bidirectional traversal. Using 15 architecture and code-tracing queries per repository, we measure indexing time, query latency, corpus coverage, cost, and answer correctness. DKB builds its graph in seconds, while LLM-KB requires much longer graph generation. LLM-KB also shows indexing incompleteness: on Shopizer, 377 files are skipped or missed, reducing embedded chunk coverage and graph size compared to DKB. End-to-end cost is modest for DKB relative to the vector-only baseline but much higher for LLM-KB, especially as repository scale increases. Query latency is similar for No-Graph and DKB, while LLM-KB is slower and more variable. On the Shopizer question suite, DKB achieves the highest correctness, LLM-KB is close behind, and the vector-only baseline performs worst on upstream architectural queries and has the highest hallucination risk. Overall, deterministic AST-derived graphs provide more reliable coverage and multi-hop grounding than LLM-extracted graphs at substantially lower indexing cost.",
    "title_zh": "面向代码库的可靠图RAG：基于AST的图与大模型提取的知识图谱",
    "abstract_zh": "在软件工程中，基于检索增强生成（Retrieval-Augmented Generation, RAG）的方法通常依赖于向量相似性搜索，这种方法虽然能够捕捉主题上的相似性，但在处理多跳架构推理任务时表现不佳，例如控制器到服务再到仓库的调用链、接口驱动的连接关系以及继承结构等。本文针对Java代码库（以Shopizer为主，并额外在ThingsBoard和OpenMRS Core上进行了测试）对三种检索管道进行了基准测试：(A) 仅使用向量的无图RAG（No-Graph RAG），(B) 由大语言模型（LLM）生成的知识图谱RAG（LLM-KB），以及(C) 基于树状抽象语法树（AST）并利用Tree-sitter与双向遍历构建的确定性知识图谱RAG（DKB）。我们每种代码库设置了15个架构相关及代码追踪类查询，评估了索引时间、查询延迟、语料覆盖率、成本以及答案正确性。\n\n结果显示，DKB可在数秒内完成图谱构建，而LLM-KB则需要更长的图生成时间。此外，LLM-KB表现出明显的索引不完整性：在Shopizer项目中，有377个文件被跳过或遗漏，导致其嵌入块覆盖率和图谱规模均低于DKB。从端到端的成本来看，DKB相对于仅向量的基线方案成本适中，而LLM-KB的成本显著更高，且随着代码库规模增大，差距愈发明显。查询延迟方面，No-Graph与DKB表现相近，而LLM-KB则更慢且波动更大。在Shopizer的测试问题集上，DKB取得了最高的答案正确率，LLM-KB紧随其后，而仅向量的基线在上游架构类查询中表现最差，并具有最高的幻觉风险。\n\n总体而言，基于确定性AST推导出的知识图谱在覆盖范围和多跳推理的准确性方面优于由LLM提取的图谱，同时在索引成本上也具有显著优势。"
  },
  {
    "date": "2026-01-13",
    "title": "Discovery and Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees",
    "authors": "Kun Li, Zenan Xu, Junan Li, Zengrui Jin, Jinghao Deng, Zexuan Qiu, Bo Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08274v1",
    "source": "arXiv",
    "abstract": "Tool-Integrated Reasoning has emerged as a key paradigm to augment Large Language Models (LLMs) with computational capabilities, yet integrating tool-use into long Chain-of-Thought (long CoT) remains underexplored, largely due to the scarcity of training data and the challenge of integrating tool-use without compromising the model's intrinsic long-chain reasoning. In this paper, we introduce DART (Discovery And Reinforcement of Tool-Integrated Reasoning Chains via Rollout Trees), a reinforcement learning framework that enables spontaneous tool-use during long CoT reasoning without human annotation. DART operates by constructing dynamic rollout trees during training to discover valid tool-use opportunities, branching out at promising positions to explore diverse tool-integrated trajectories. Subsequently, a tree-based process advantage estimation identifies and credits specific sub-trajectories where tool invocation positively contributes to the solution, effectively reinforcing these beneficial behaviors. Extensive experiments on challenging benchmarks like AIME and GPQA-Diamond demonstrate that DART significantly outperforms existing methods, successfully harmonizing tool execution with long CoT reasoning.",
    "title_zh": "通过回溯树实现工具集成推理链的发现与强化",
    "abstract_zh": "工具集成推理（Tool-Integrated Reasoning）已成为增强大型语言模型（LLMs）计算能力的关键范式，然而如何在长链思维（long CoT）中有效整合工具使用仍鲜有研究，主要原因在于训练数据稀缺，以及在不损害模型内在长链推理能力的前提下实现工具集成的挑战。本文提出 DART（通过滚动树发现与强化工具集成推理链），一种基于强化学习的框架，能够在无需人工标注的情况下，在长链思维推理过程中自发地使用工具。DART 在训练过程中构建动态的滚动树，以发现有效的工具使用机会，并在有潜力的位置进行分支，探索多样化的工具融合推理路径。随后，基于树结构的策略优势估计方法能够识别并奖励那些工具调用对最终解题产生积极贡献的具体子路径，从而有效强化这些有益行为。在 AIME 和 GPQA-Diamond 等具有挑战性的基准测试上的大量实验表明，DART 显著优于现有方法，成功实现了工具执行与长链思维推理的有机融合。"
  },
  {
    "date": "2026-01-13",
    "title": "Unleashing Tool Engineering and Intelligence for Agentic AI in Next-Generation Communication Networks",
    "authors": "Yinqiu Liu, Ruichen Zhang, Dusit Niyato, Abbas Jamalipour, Trung Q. Duong, Dong In Kim",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08259v1",
    "source": "arXiv",
    "abstract": "Nowadays, agentic AI is emerging as a transformative paradigm for next-generation communication networks, promising to evolve large language models (LLMs) from passive chatbots into autonomous operators. However, unleashing this potential requires bridging the critical gap between abstract reasoning and physical actuation, a capability we term tool intelligence. In this article, we explore the landscape of tool engineering to empower agentic AI in communications. We first analyze the functionalities of tool intelligence and its effects on communications. We then propose a systematic review for tool engineering, covering the entire lifecycle from tool creation and discovery to selection, learning, and benchmarking. Furthermore, we present a case study on tool-assisted uncrewed aerial vehicles (UAV) trajectory planning to demonstrate the realization of tool intelligence in communications. By introducing a teacher-guided reinforcement learning approach with a feasibility shield, we enable agents to intelligently operate tools. They utilize external tools to eliminate navigational uncertainty while mastering cost-aware scheduling under strict energy constraints. This article aims to provide a roadmap for building the tool-augmented intelligent agents of the 6G era.",
    "title_zh": "释放工具工程与智能，赋能下一代通信网络中的代理型人工智能",
    "abstract_zh": "如今，代理型人工智能（agentic AI）正作为一种变革性范式，推动下一代通信网络的发展，有望将大型语言模型（LLMs）从被动的聊天机器人演变为自主运行的智能体。然而，要释放这一潜力，必须弥合抽象推理与物理执行之间的关键鸿沟，我们称之为“工具智能”。本文探讨了工具工程的现状，以赋能通信领域的代理型人工智能。我们首先分析了工具智能的功能及其对通信系统的影响；随后提出了一套系统性的工具工程综述框架，涵盖从工具创建、发现，到选择、学习和基准测试的全生命周期。此外，我们通过一个基于工具辅助的无人飞行器（UAV）航迹规划案例研究，展示了工具智能在通信中的实际应用。通过引入一种带有可行性保护机制的教师引导强化学习方法，使智能体能够智能地操作外部工具，在消除导航不确定性的同时，实现严格能源约束下的成本敏感调度。本文旨在为构建6G时代具备工具增强能力的智能体提供一条清晰的发展路线图。"
  },
  {
    "date": "2026-01-13",
    "title": "Generation-Augmented Generation: A Plug-and-Play Framework for Private Knowledge Injection in Large Language Models",
    "authors": "Rongji Li, Jian Xu, Xueqing Chen, Yisheng Yang, Jiayi Wang, Xingyu Chen, Chunyu Xie, Dawei Leng, Xu-Yao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08209v1",
    "source": "arXiv",
    "abstract": "In domains such as biomedicine, materials, and finance, high-stakes deployment of large language models (LLMs) requires injecting private, domain-specific knowledge that is proprietary, fast-evolving, and under-represented in public pretraining. However, the two dominant paradigms for private knowledge injection each have pronounced drawbacks: fine-tuning is expensive to iterate, and continual updates risk catastrophic forgetting and general-capability regression; retrieval-augmented generation (RAG) keeps the base model intact but is brittle in specialized private corpora due to chunk-induced evidence fragmentation, retrieval drift, and long-context pressure that yields query-dependent prompt inflation. Inspired by how multimodal LLMs align heterogeneous modalities into a shared semantic space, we propose Generation-Augmented Generation (GAG), which treats private expertise as an additional expert modality and injects it via a compact, representation-level interface aligned to the frozen base model, avoiding prompt-time evidence serialization while enabling plug-and-play specialization and scalable multi-domain composition with reliable selective activation. Across two private scientific QA benchmarks (immunology adjuvant and catalytic materials) and mixed-domain evaluations, GAG improves specialist performance over strong RAG baselines by 15.34% and 14.86% on the two benchmarks, respectively, while maintaining performance on six open general benchmarks and enabling near-oracle selective activation for scalable multi-domain deployment.",
    "title_zh": "生成增强型生成：一种用于大型语言模型私有知识注入的即插即用框架",
    "abstract_zh": "在生物医学、材料科学和金融等领域能够实现大语言模型（LLMs）的高风险部署，关键在于注入私有的、领域特定的知识——这些知识具有专有性、更新迅速且在公开预训练数据中代表性不足。然而，当前主流的私有知识注入方法存在明显缺陷：微调（fine-tuning）迭代成本高昂，而持续更新又容易引发灾难性遗忘和通用能力退化；检索增强生成（RAG）虽能保持基础模型不变，但在专业私有语料库中表现脆弱，主要由于分块导致的证据碎片化、检索漂移以及长上下文压力带来的查询依赖型提示膨胀问题。\n\n受多模态大语言模型将异构模态对齐至共享语义空间机制的启发，我们提出“生成增强生成”（Generation-Augmented Generation, GAG）方法。该方法将私有专业知识视为一种额外的专家模态，通过一个紧凑的、与冻结的基础模型对齐的表示层接口进行注入，避免了在提示阶段对证据进行序列化处理，同时实现了即插即用的领域专业化，支持可扩展的多领域组合，并具备可靠的定向激活能力。\n\n在两个私有科学问答基准测试（免疫学佐剂与催化材料）及跨领域综合评估中，GAG 相较于强大的 RAG 基线，在两个基准上分别提升了 15.34% 和 14.86% 的专家性能，同时在六个开放通用基准上保持了原有性能水平，并实现了接近“理想选择性激活”的效果，为大规模多领域部署提供了可靠支持。"
  },
  {
    "date": "2026-01-13",
    "title": "Hybrid Distillation with CoT Guidance for Edge-Drone Control Code Generation",
    "authors": "Yizhan Feng, Hichem Snoussi, Yuhang Wang, Jing Teng, Abel Cherouat, Tian Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08412v1",
    "source": "arXiv",
    "abstract": "With large language models demonstrating significant potential in code generation tasks, their application to onboard control of resource-constrained Unmanned Aerial Vehicles has emerged as an important research direction. However, a notable contradiction exists between the high resource consumption of large models and the real-time, lightweight requirements of UAV platforms. This paper proposes an integrated approach that combines knowledge distillation, chain-of-thought guidance, and supervised fine-tuning for UAV multi-SDK control tasks, aiming to efficiently transfer complex reasoning and code generation capabilities to smaller models. Firstly, a high-quality dataset covering various mainstream UAV SDKs is constructed, featuring instruction-code-reasoning chains, and incorporates counterfactual negative samples for data augmentation, guiding the model to learn the end-to-end logic from instruction parsing to code generation. Secondly, leveraging DeepSeek-Coder-V2-Lite quantized via QLoRA as the teacher model, and based on a hybrid black-box and white-box distillation strategy, high-quality chain-of-thought soft labels are generated. These are combined with a weighted cross-entropy loss using hard labels to transfer complex reasoning capabilities to the smaller student model. Finally, through prompt tuning engineering optimized for the UAV control scenario, the model performance on core tasks such as SDK type recognition and function call matching is enhanced. Experimental results indicate that the distilled lightweight model maintains high code generation accuracy while achieving significant improvements in deployment and inference efficiency, effectively demonstrating the feasibility and superiority of our approach in achieving precise and lightweight intelligent control for UAVs",
    "title_zh": "基于思维链引导的混合蒸馏方法用于边缘无人机控制代码生成",
    "abstract_zh": "随着大型语言模型在代码生成任务中展现出巨大潜力，其在资源受限的无人飞行器（UAV）机载控制中的应用已成为重要的研究方向。然而，大型模型的高资源消耗与UAV平台对实时性、轻量化的严格要求之间存在显著矛盾。本文提出一种融合知识蒸馏、思维链引导和监督微调的综合方法，用于实现UAV多SDK控制任务，旨在高效地将复杂的推理与代码生成能力迁移至小型化模型。首先，构建了一个覆盖多种主流UAV SDK的高质量数据集，包含指令-代码-推理链结构，并引入反事实负样本进行数据增强，引导模型学习从指令解析到代码生成的端到端逻辑。其次，以通过QLoRA量化后的DeepSeek-Coder-V2-Lite作为教师模型，采用混合黑盒与白盒蒸馏策略，生成高质量的思维链软标签；结合硬标签的加权交叉熵损失函数，将复杂推理能力有效传递给小型学生模型。最后，通过针对UAV控制场景优化的提示调优工程，显著提升了模型在SDK类型识别、函数调用匹配等核心任务上的性能。实验结果表明，经过蒸馏的轻量级模型在保持高代码生成准确率的同时，大幅提升了部署与推理效率，充分验证了本方法在实现精准且轻量化的UAV智能控制方面的可行性与优越性。"
  },
  {
    "date": "2026-01-13",
    "title": "Ministral 3",
    "authors": "Alexander H. Liu, Kartik Khandelwal, Sandeep Subramanian, Victor Jouault, Abhinav Rastogi, Adrien Sadé, Alan Jeffares, Albert Jiang, Alexandre Cahill, Alexandre Gavaudan, Alexandre Sablayrolles, Amélie Héliou, Amos You, Andy Ehrenberg, Andy Lo, Anton Eliseev, Antonia Calvi, Avinash Sooriyarachchi, Baptiste Bout, Baptiste Rozière, Baudouin De Monicault, Clémence Lanfranchi, Corentin Barreau, Cyprien Courtot, Daniele Grattarola, Darius Dabert, Diego de las Casas, Elliot Chane-Sane, Faruk Ahmed, Gabrielle Berrada, Gaëtan Ecrepont, Gauthier Guinet, Georgii Novikov, Guillaume Kunsch, Guillaume Lample, Guillaume Martin, Gunshi Gupta, Jan Ludziejewski, Jason Rute, Joachim Studnia, Jonas Amar, Joséphine Delas, Josselin Somerville Roberts, Karmesh Yadav, Khyathi Chandu, Kush Jain, Laurence Aitchison, Laurent Fainsin, Léonard Blier, Lingxiao Zhao, Louis Martin, Lucile Saulnier, Luyu Gao, Maarten Buyl, Margaret Jennings, Marie Pellat, Mark Prins, Mathieu Poirée, Mathilde Guillaumin, Matthieu Dinot, Matthieu Futeral, Maxime Darrin, Maximilian Augustin, Mia Chiquier, Michel Schimpf, Nathan Grinsztajn, Neha Gupta, Nikhil Raghuraman, Olivier Bousquet, Olivier Duchenne, Patricia Wang, Patrick von Platen, Paul Jacob, Paul Wambergue, Paula Kurylowicz, Pavankumar Reddy Muddireddy, Philomène Chagniot, Pierre Stock, Pravesh Agrawal, Quentin Torroba, Romain Sauvestre, Roman Soletskyi, Rupert Menneer, Sagar Vaze, Samuel Barry, Sanchit Gandhi, Siddhant Waghjale, Siddharth Gandhi, Soham Ghosh, Srijan Mishra, Sumukh Aithal, Szymon Antoniak, Teven Le Scao, Théo Cachet, Theo Simon Sorg, Thibaut Lavril, Thiziri Nait Saada, Thomas Chabal, Thomas Foubert, Thomas Robert, Thomas Wang, Tim Lawson, Tom Bewley, Tom Bewley, Tom Edwards, Umar Jamil, Umberto Tomasini, Valeriia Nemychnikova, Van Phung, Vincent Maladière, Virgile Richard, Wassim Bouaziz, Wen-Ding Li, William Marshall, Xinghui Li, Xinyu Yang, Yassine El Ouahidi, Yihan Wang, Yunhao Tang, Zaccharie Ramzi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08584v1",
    "source": "arXiv",
    "abstract": "We introduce the Ministral 3 series, a family of parameter-efficient dense language models designed for compute and memory constrained applications, available in three model sizes: 3B, 8B, and 14B parameters. For each model size, we release three variants: a pretrained base model for general-purpose use, an instruction finetuned, and a reasoning model for complex problem-solving. In addition, we present our recipe to derive the Ministral 3 models through Cascade Distillation, an iterative pruning and continued training with distillation technique. Each model comes with image understanding capabilities, all under the Apache 2.0 license.",
    "title_zh": "Ministral 3",
    "abstract_zh": "我们推出Ministral 3系列，这是一组专为计算和内存受限应用场景设计的参数高效密集型语言模型，提供三种模型规模：30亿、80亿和140亿参数。针对每种模型规模，我们发布了三个变体：适用于通用场景的预训练基础模型、经过指令微调的版本，以及用于复杂问题求解的推理模型。此外，我们还介绍了通过“级联蒸馏”（Cascade Distillation）技术构建Ministral 3系列模型的方法，该技术结合了迭代剪枝与持续蒸馏训练。所有模型均具备图像理解能力，且全部采用Apache 2.0许可证开源。"
  },
  {
    "date": "2026-01-13",
    "title": "On Deciding Constant Runtime of Linear Loops",
    "authors": "Florian Frohn, Jürgen Giesl, Peter Giesl, Nils Lommen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08492v1",
    "source": "arXiv",
    "abstract": "We consider linear single-path loops of the form \\[ \\textbf{while} \\quad \\varphi \\quad \\textbf{do} \\quad \\vec{x} \\gets A \\vec{x} + \\vec{b} \\quad \\textbf{end} \\] where $\\vec{x}$ is a vector of variables, the loop guard $\\varphi$ is a conjunction of linear inequations over the variables $\\vec{x}$, and the update of the loop is represented by the matrix $A$ and the vector $\\vec{b}$. It is already known that termination of such loops is decidable. In this work, we consider loops where $A$ has real eigenvalues, and prove that it is decidable whether the loop's runtime (for all inputs) is bounded by a constant if the variables range over $\\mathbb R$ or $\\mathbb Q$. This is an important problem in automatic program verification, since safety of linear while-programs is decidable if all loops have constant runtime, and it is closely connected to the existence of multiphase-linear ranking functions, which are often used for termination and complexity analysis. To evaluate its practical applicability, we also present an implementation of our decision procedure.",
    "title_zh": "决定线性循环的常数运行时间",
    "abstract_zh": "我们考虑如下形式的线性单路径循环：\n\n$$\n\\textbf{while} \\quad \\varphi \\quad \\textbf{do} \\quad \\vec{x} \\gets A \\vec{x} + \\vec{b} \\quad \\textbf{end}\n$$\n\n其中，$\\vec{x}$ 是变量向量，循环条件 $\\varphi$ 是关于变量 $\\vec{x}$ 的线性不等式组的合取，循环的更新由矩阵 $A$ 和向量 $\\vec{b}$ 表示。已知此类循环的终止性是可判定的。在本文中，我们研究 $A$ 具有实特征值的情形，并证明：当变量取值于 $\\mathbb{R}$ 或 $\\mathbb{Q}$ 时，该循环对所有输入的运行时间是否被某个常数所限制，这一问题是可判定的。这一问题在自动程序验证中具有重要意义，因为若所有循环的运行时间均为常数，则线性 while 程序的安全性是可判定的；此外，该问题与多阶段线性排序函数的存在性密切相关，而这类排序函数常用于终止性及复杂度分析。为了评估其实际应用价值，我们还实现了一个基于该判定过程的算法。"
  },
  {
    "date": "2026-01-13",
    "title": "Closed-Loop LLM Discovery of Non-Standard Channel Priors in Vision Models",
    "authors": "Tolgay Atinc Uzun, Dmitry Ignatov, Radu Timofte",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08517v1",
    "source": "arXiv",
    "abstract": "Channel configuration search the optimization of layer specifications such as layer widths in deep neural networks presents a complex combinatorial challenge constrained by tensor shape compatibility and computational budgets. We posit that Large Language Models (LLMs) offer a transformative approach to Neural Architecture Search (NAS), capable of reasoning about architectural code structure in ways that traditional heuristics cannot. In this paper, we investigate the application of an LLM-driven NAS framework to the problem of channel configuration. We formulate the search as a sequence of conditional code generation tasks, where an LLM refines architectural specifications based on performance telemetry. Crucially, we address the data scarcity problem by generating a vast corpus of valid, shape-consistent architectures via Abstract Syntax Tree (AST) mutations. While these mutated networks are not necessarily high-performing, they provide the critical volume of structural data required for the LLM to learn the latent relationship between channel configurations and model performance. This allows the LLM to internalize complex design patterns and apply them to optimize feature extraction strategies. Experimental results on CIFAR-100 validate the efficacy of this approach, demonstrating that the model yields statistically significant improvements in accuracy. Our analysis confirms that the LLM successfully acquires domain-specific architectural priors, distinguishing this method from random search and highlighting the immense potential of language-driven design in deep learning.",
    "title_zh": "闭环大模型在视觉模型中发现非标准信道先验的研究",
    "abstract_zh": "通道配置的优化，如深度神经网络中各层宽度的调整，是一个复杂的组合优化问题，受到张量形状兼容性以及计算资源预算的双重约束。我们提出，大型语言模型（LLM）为神经网络架构搜索（NAS）提供了一种变革性的方法，能够以传统启发式规则无法实现的方式推理架构代码的结构。本文研究了基于LLM的NAS框架在通道配置优化中的应用。我们将搜索过程建模为一系列条件化的代码生成任务，其中LLM根据性能遥测数据逐步优化架构规范。关键在于，我们通过抽象语法树（AST）变异的方法生成了大量有效且形状一致的网络架构，以解决数据稀缺的问题。尽管这些变异后的网络未必具有高性能，但它们提供了LLM学习通道配置与模型性能之间潜在关系所必需的大量结构化数据。这使得LLM能够内化复杂的设设计模式，并将其应用于优化特征提取策略。在CIFAR-100上的实验结果验证了该方法的有效性，表明模型在准确率方面实现了统计上显著的提升。我们的分析证实，LLM成功习得了特定领域的架构先验知识，从而区别于随机搜索，凸显了语言驱动设计在深度学习中的巨大潜力。"
  },
  {
    "date": "2026-01-13",
    "title": "Surgical Refusal Ablation: Disentangling Safety from Intelligence via Concept-Guided Spectral Cleaning",
    "authors": "Tony Cristofano",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08489v1",
    "source": "arXiv",
    "abstract": "Safety-aligned language models systematically refuse harmful requests. While activation steering can modulate refusal, ablating the raw \"refusal vector\" calculated from contrastive harmful and harmless prompts often causes collateral damage and distribution drift. We argue this degradation occurs because the raw vector is polysemantic, entangling the refusal signal with core capability circuits and linguistic style. We introduce Surgical Refusal Ablation (SRA) to distill these steering directions. SRA constructs a registry of independent Concept Atoms representing protected capabilities and stylistic confounds, then uses ridge-regularized spectral residualization to orthogonalize the refusal vector against these directions. This yields a clean refusal direction that targets refusal-relevant structure while minimizing disruption to the model's semantic geometry. Across five models (Qwen3-VL and Ministral series), SRA achieves deep refusal reduction (0-2%) with negligible perplexity impact on Wikitext-2 (mean delta PPL approx. 0.02) and minimal distribution drift. Notably, standard ablation on Qwen3-VL-4B induces severe drift (first-token KL = 2.088), whereas SRA maintains the original distribution (KL = 0.044) while achieving the same 0% refusal rate. Using teacher-forced perplexity on GSM8K and MBPP as a high-resolution capability proxy, we show SRA preserves math and code distributions. These results suggest that common \"model damage\" is often \"Ghost Noise,\" defined as the spectral bleeding of the dirty refusal direction into capability subspaces.",
    "title_zh": "外科拒绝消融：通过概念引导的谱清洗，将安全性与智能性分离",
    "abstract_zh": "安全对齐的语言模型会系统性地拒绝有害请求。尽管激活控制（activation steering）可以调节拒绝行为，但若直接剔除从对比有害与无害提示中计算出的原始“拒绝向量”，往往会导致附带损伤和分布漂移。我们认为这种性能退化的原因在于：原始向量具有多义性，将拒绝信号与核心能力电路及语言风格混杂在一起。为此，我们提出**外科式拒绝剔除**（Surgical Refusal Ablation, SRA），以提炼出更纯净的调控方向。SRA 构建了一个独立的“概念原子”注册表，用以表示受保护的能力特征和风格干扰因素，随后采用岭回归正则化的谱残差方法，将拒绝向量在这些方向上进行正交化处理。由此得到的拒绝方向更加清晰，仅针对与拒绝相关的结构，同时最大限度减少对模型语义几何结构的破坏。\n\n在五个模型（Qwen3-VL 和 Ministral 系列）上的实验表明，SRA 实现了深度的拒绝率降低（0–2%），对 Wikitext-2 的困惑度影响极小（平均困惑度变化约 0.02），且分布漂移微乎其微。值得注意的是，在 Qwen3-VL-4B 上进行标准剔除操作时，导致严重的分布漂移（首词 KL = 2.088），而 SRA 在实现相同 0% 拒绝率的同时，保持了原始分布（KL = 0.044）。通过使用教师强制下的困惑度（teacher-forced perplexity）在 GSM8K 和 MBPP 数据集上作为高分辨率能力代理，我们进一步验证了 SRA 能有效保留数学与代码生成的分布特性。\n\n这些结果表明，常见的“模型损伤”往往并非真实能力损失，而是由“幽灵噪声”（Ghost Noise）所致——即不干净的拒绝方向在频谱上渗入能力子空间所引发的虚假退化。"
  },
  {
    "date": "2026-01-13",
    "title": "Large Language Models to Enhance Multi-task Drone Operations in Simulated Environments",
    "authors": "Yizhan Feng, Hichem Snoussi, Jing Teng, Abel Cherouat, Tian Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08405v1",
    "source": "arXiv",
    "abstract": "Benefiting from the rapid advancements in large language models (LLMs), human-drone interaction has reached unprecedented opportunities. In this paper, we propose a method that integrates a fine-tuned CodeT5 model with the Unreal Engine-based AirSim drone simulator to efficiently execute multi-task operations using natural language commands. This approach enables users to interact with simulated drones through prompts or command descriptions, allowing them to easily access and control the drone's status, significantly lowering the operational threshold. In the AirSim simulator, we can flexibly construct visually realistic dynamic environments to simulate drone applications in complex scenarios. By combining a large dataset of (natural language, program code) command-execution pairs generated by ChatGPT with developer-written drone code as training data, we fine-tune the CodeT5 to achieve automated translation from natural language to executable code for drone tasks. Experimental results demonstrate that the proposed method exhibits superior task execution efficiency and command understanding capabilities in simulated environments. In the future, we plan to extend the model functionality in a modular manner, enhancing its adaptability to complex scenarios and driving the application of drone technologies in real-world environments.",
    "title_zh": "大型语言模型在模拟环境中增强多任务无人机操作的应用",
    "abstract_zh": "得益于大型语言模型（LLMs）的快速发展，人机无人机交互迎来了前所未有的机遇。本文提出了一种将微调后的CodeT5模型与基于Unreal Engine的AirSim无人机模拟器相结合的方法，能够通过自然语言指令高效执行多任务操作。该方法使用户可通过提示词或命令描述与模拟无人机进行交互，轻松获取并控制无人机状态，显著降低了操作门槛。在AirSim模拟器中，我们可灵活构建视觉逼真的动态环境，以模拟无人机在复杂场景中的应用。通过结合由ChatGPT生成的大规模（自然语言，程序代码）命令-执行配对数据集以及开发者编写的无人机代码作为训练数据，我们对CodeT5模型进行微调，实现了从自然语言到可执行无人机任务代码的自动化转换。实验结果表明，所提方法在模拟环境中展现出优异的任务执行效率和命令理解能力。未来，我们计划以模块化方式扩展模型功能，提升其在复杂场景下的适应性，推动无人机技术在真实环境中的应用。"
  },
  {
    "date": "2026-01-13",
    "title": "Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge",
    "authors": "Yao Tang, Li Dong, Yaru Hao, Qingxiu Dong, Furu Wei, Jiatao Gu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08808v1",
    "source": "arXiv",
    "abstract": "Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.",
    "title_zh": "多路思维：通过逐标记分支与合并进行推理",
    "abstract_zh": "大型语言模型在解决复杂推理任务时，通常通过思维链（Chain-of-Thought, CoT）方法表现更优，但代价是生成冗长且带宽低的标记序列。相比之下，人类往往采用“软性”推理方式，即在每一步保持对可能后续动作的概率分布。受此启发，我们提出了**多路思考（Multiplex Thinking）**——一种随机化的软推理机制。该机制在每个思考步骤中，从候选词中采样 K 个 token，并将其嵌入向量聚合为一个连续的“多路混合 token”。这一方法既保留了标准离散生成中的词汇嵌入先验和采样动态，又在多路推进路径上诱导出一个可处理的概率分布。因此，多路轨迹可直接通过基于策略的强化学习（RL）进行优化。重要的是，Multiplex Thinking 具有自适应特性：当模型信心充足时，多路 token 几乎表现为离散形式，行为类似传统 CoT；当模型不确定时，则紧凑地表示多个可能的下一步，而无需增加序列长度。在多个具有挑战性的数学推理基准测试中，Multiplex Thinking 在 Pass@1 到 Pass@1024 的各项指标上均持续优于强大的离散 CoT 和 RL 基线方法，同时生成的序列更短。代码与模型检查点已公开于 https://github.com/GMLR-Penn/Multiplex-Thinking。"
  },
  {
    "date": "2026-01-13",
    "title": "Rewarding the Rare: Uniqueness-Aware RL for Creative Problem Solving in LLMs",
    "authors": "Zhiyuan Hu, Yucheng Wang, Yufei He, Jiaying Wu, Yilun Zhao, See-Kiong Ng, Cynthia Breazeal, Anh Tuan Luu, Hae Won Park, Bryan Hooi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08763v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) has become a central paradigm for post-training large language models (LLMs), particularly for complex reasoning tasks, yet it often suffers from exploration collapse: policies prematurely concentrate on a small set of dominant reasoning patterns, improving pass@1 while limiting rollout-level diversity and gains in pass@k. We argue that this failure stems from regularizing local token behavior rather than diversity over sets of solutions. To address this, we propose Uniqueness-Aware Reinforcement Learning, a rollout-level objective that explicitly rewards correct solutions that exhibit rare high-level strategies. Our method uses an LLM-based judge to cluster rollouts for the same problem according to their high-level solution strategies, ignoring superficial variations, and reweights policy advantages inversely with cluster size. As a result, correct but novel strategies receive higher rewards than redundant ones. Across mathematics, physics, and medical reasoning benchmarks, our approach consistently improves pass@$k$ across large sampling budgets and increases the area under the pass@$k$ curve (AUC@$K$) without sacrificing pass@1, while sustaining exploration and uncovering more diverse solution strategies at scale.",
    "title_zh": "奖励稀有：面向大语言模型创造性问题解决的独创性感知强化学习",
    "abstract_zh": "强化学习（RL）已成为大语言模型（LLMs）后训练阶段的核心范式，尤其在处理复杂推理任务时表现突出。然而，该方法常面临“探索坍缩”问题：策略过早集中于少数占主导地位的推理模式，虽然提升了 pass@1 的表现，却限制了生成结果的多样性，也阻碍了 pass@k 的进一步提升。我们认为，这一缺陷的根本原因在于对局部 token 行为进行正则化，而非对解集的整体多样性进行建模。为此，我们提出一种新颖的**独特性感知强化学习**（Uniqueness-Aware Reinforcement Learning），其核心是基于 rollout 层面的目标，明确奖励那些展现出稀有高层策略的正确解法。该方法利用基于大语言模型的评判器，根据高阶解题策略对同一问题的不同生成路径进行聚类，忽略表面形式的细微差异，并将策略优势重新加权，使其与聚类规模成反比。因此，那些正确但新颖的解题策略将获得更高的奖励，而重复冗余的策略则被抑制。在数学、物理和医学推理等多个基准测试中，我们的方法在大规模采样预算下持续提升了 pass@$k$，同时显著提高了 pass@$k$ 曲线下的面积（AUC@$K$），且未牺牲 pass@1 的性能。更重要的是，该方法有效维持了探索能力，在大规模场景下揭示出更多样化的解题策略。"
  },
  {
    "date": "2026-01-13",
    "title": "From Rows to Reasoning: A Retrieval-Augmented Multimodal Framework for Spreadsheet Understanding",
    "authors": "Anmol Gulati, Sahil Sen, Waqar Sarguroh, Kevin Paul",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08741v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) struggle to reason over large-scale enterprise spreadsheets containing thousands of numeric rows, multiple linked sheets, and embedded visual content such as charts and receipts. Prior state-of-the-art spreadsheet reasoning approaches typically rely on single-sheet compression or full-context encoding, which limits scalability and fails to reflect how real users interact with complex, multimodal workbooks. We introduce FRTR-Bench, the first large-scale benchmark for multimodal spreadsheet reasoning, comprising 30 enterprise-grade Excel workbooks spanning nearly four million cells and more than 50 embedded images. To address these challenges, we present From Rows to Reasoning (FRTR), an advanced, multimodal retrieval-augmented generation framework that decomposes Excel workbooks into granular row, column, and block embeddings, employs hybrid lexical-dense retrieval with Reciprocal Rank Fusion (RRF), and integrates multimodal embeddings to reason over both numerical and visual information. We tested FRTR on six LLMs, achieving 74% answer accuracy on FRTR-Bench with Claude Sonnet 4.5, a substantial improvement over prior state-of-the-art approaches that reached only 24%. On the SpreadsheetLLM benchmark, FRTR achieved 87% accuracy with GPT-5 while reducing token usage by roughly 50% compared to context-compression methods.",
    "title_zh": "从行到推理：一种用于电子表格理解的检索增强型多模态框架",
    "abstract_zh": "大型语言模型（LLMs）在处理包含数千行数值数据、多张相互关联的表格以及嵌入式视觉内容（如图表和收据）的企业级电子表格时面临巨大挑战。以往最先进的电子表格推理方法通常依赖于单表压缩或全上下文编码，这限制了可扩展性，并未能反映真实用户与复杂、多模态工作簿交互的方式。为此，我们提出了FRTR-Bench，这是首个面向多模态电子表格推理的大规模基准测试集，包含30个企业级Excel工作簿，覆盖近四百万个单元格及超过50张嵌入图像。\n\n为应对这些挑战，我们提出了“从行到推理”（From Rows to Reasoning, FRTR）框架——一种先进的多模态检索增强生成系统。该框架将Excel工作簿分解为细粒度的行、列和区块嵌入表示，采用混合词法-密集型检索策略并结合倒数排名融合（Reciprocal Rank Fusion, RRF），同时整合多模态嵌入，以实现对数值信息与视觉内容的联合推理。\n\n我们在六个大型语言模型上测试了FRTR，在FRTR-Bench基准上取得了74%的答对率（使用Claude Sonnet 4.5），相比此前最先进方法仅24%的准确率实现了显著提升。在SpreadsheetLLM基准测试中，FRTR使用GPT-5达到了87%的准确率，同时相比传统上下文压缩方法，token消耗减少了约50%。"
  },
  {
    "date": "2026-01-13",
    "title": "Relational Knowledge Distillation Using Fine-tuned Function Vectors",
    "authors": "Andrea Kang, Yingnian Wu, Hongjing Lu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08169v1",
    "source": "arXiv",
    "abstract": "Representing relations between concepts is a core prerequisite for intelligent systems to make sense of the world. Recent work using causal mediation analysis has shown that a small set of attention heads encodes task representation in in-context learning, captured in a compact representation known as the function vector. We show that fine-tuning function vectors with only a small set of examples (about 20 word pairs) yields better performance on relation-based word-completion tasks than using the original vectors derived from causal mediation analysis. These improvements hold for both small and large language models. Moreover, the fine-tuned function vectors yield improved decoding performance for relation words and show stronger alignment with human similarity judgments of semantic relations. Next, we introduce the composite function vector - a weighted combination of fine-tuned function vectors - to extract relational knowledge and support analogical reasoning. At inference time, inserting this composite vector into LLM activations markedly enhances performance on challenging analogy problems drawn from cognitive science and SAT benchmarks. Our results highlight the potential of activation patching as a controllable mechanism for encoding and manipulating relational knowledge, advancing both the interpretability and reasoning capabilities of large language models.",
    "title_zh": "使用微调函数向量的关系知识蒸馏",
    "abstract_zh": "表示概念之间的关系是智能系统理解世界的核心前提。近期研究利用因果中介分析发现，少量注意力头在上下文学习中编码了任务表征，这些信息被浓缩为一种称为“函数向量”的紧凑表示。我们发现，仅用少量示例（约20对词语）对函数向量进行微调，即可在基于关系的词语补全任务上取得优于原始因果中介分析所得向量的性能表现，这一优势在小型和大型语言模型中均成立。此外，经过微调的函数向量在关系词解码方面表现更优，并与人类对语义关系的相似性判断具有更强的一致性。随后，我们提出了“复合函数向量”——即经过微调的函数向量的加权组合——用于提取关系知识并支持类比推理。在推理阶段，将该复合向量插入大语言模型的激活值中，显著提升了模型在认知科学和SAT测试基准中具有挑战性的类比问题上的表现。我们的研究结果凸显了激活值修补作为一种可控机制，在编码与操控关系知识方面的潜力，从而推动了大语言模型在可解释性与推理能力方面的进步。"
  },
  {
    "date": "2026-01-13",
    "title": "Embedded AI Companion System on Edge Devices",
    "authors": "Rahul Gupta, Stephen D. H. Hsu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08128v1",
    "source": "arXiv",
    "abstract": "Computational resource constraints on edge devices make it difficult to develop a fully embedded AI companion system with a satisfactory user experience. AI companion and memory systems detailed in existing literature cannot be directly used in such an environment due to lack of compute resources and latency concerns. In this paper, we propose a memory paradigm that alternates between active and inactive phases: during phases of user activity, the system performs low-latency, real-time dialog using lightweight retrieval over existing memories and context; whereas during phases of user inactivity, it conducts more computationally intensive extraction, consolidation, and maintenance of memories across full conversation sessions. This design minimizes latency while maintaining long-term personalization under the tight constraints of embedded hardware. We also introduce an AI Companion benchmark designed to holistically evaluate the AI Companion across both its conversational quality and memory capabilities. In our experiments, we found that our system (using a very weak model: Qwen2.5-7B-Instruct quantized int4) outperforms the equivalent raw LLM without memory across most metrics, and performs comparably to GPT-3.5 with 16k context window.",
    "title_zh": "边缘设备上的嵌入式人工智能伴侣系统",
    "abstract_zh": "边缘设备上的计算资源限制使得开发一个具备良好用户体验的完全嵌入式AI助手系统变得困难。现有文献中详述的AI助手与记忆系统由于缺乏计算资源以及延迟问题，无法直接应用于此类环境。本文提出了一种在活跃与非活跃状态之间交替的记忆范式：在用户活跃阶段，系统通过轻量级检索现有记忆和上下文信息，实现低延迟、实时对话；而在用户不活跃阶段，则执行更耗计算资源的记忆提取、整合与维护任务，覆盖完整的对话会话。该设计在嵌入式硬件严苛的资源约束下，有效降低了延迟，同时保持了长期个性化能力。此外，我们还引入了一个AI助手评估基准，用于全面评估AI助手在对话质量与记忆能力方面的综合表现。实验结果表明，我们的系统（采用极为轻量的模型：Qwen2.5-7B-Instruct 量化为int4）在大多数指标上均优于无记忆的原始大语言模型，并且在性能上可与具有16k上下文窗口的GPT-3.5相媲美。"
  },
  {
    "date": "2026-01-13",
    "title": "Modeling LLM Agent Reviewer Dynamics in Elo-Ranked Review System",
    "authors": "Hsiang-Wei Huang, Junbin Lu, Kuang-Ming Chen, Jenq-Neng Hwang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08829v1",
    "source": "arXiv",
    "abstract": "In this work, we explore the Large Language Model (LLM) agent reviewer dynamics in an Elo-ranked review system using real-world conference paper submissions. Multiple LLM agent reviewers with different personas are engage in multi round review interactions moderated by an Area Chair. We compare a baseline setting with conditions that incorporate Elo ratings and reviewer memory. Our simulation results showcase several interesting findings, including how incorporating Elo improves Area Chair decision accuracy, as well as reviewers' adaptive review strategy that exploits our Elo system without improving review effort. Our code is available at https://github.com/hsiangwei0903/EloReview.",
    "title_zh": "基于Elo评分系统的大型语言模型代理评审员动态建模",
    "abstract_zh": "在本研究中，我们通过真实世界会议论文投稿数据，探讨了在Elo评分体系下的大型语言模型（LLM）代理评审员之间的互动动态。多个具有不同人格特征的LLM代理评审员在领域主席（Area Chair）的协调下进行多轮评审交互。我们对比了基线设置与引入Elo评分和评审员记忆机制的条件。模拟结果揭示了若干有趣发现：例如，引入Elo评分能够提升领域主席决策的准确性；同时，评审员会采取适应性评审策略，利用Elo系统的优势，却并未真正提高评审投入程度。相关代码已公开，地址为 https://github.com/hsiangwei0903/EloReview。"
  },
  {
    "date": "2026-01-13",
    "title": "Learner-Tailored Program Repair: A Solution Generator with Iterative Edit-Driven Retrieval Enhancement",
    "authors": "Zhenlong Dai, Zhuoluo Zhao, Hengning Wang, Xiu Tang, Sai Wu, Chang Yao, Zhipeng Gao, Jingyuan Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08545v1",
    "source": "arXiv",
    "abstract": "With the development of large language models (LLMs) in the field of programming, intelligent programming coaching systems have gained widespread attention. However, most research focuses on repairing the buggy code of programming learners without providing the underlying causes of the bugs. To address this gap, we introduce a novel task, namely \\textbf{LPR} (\\textbf{L}earner-Tailored \\textbf{P}rogram \\textbf{R}epair). We then propose a novel and effective framework, \\textbf{\\textsc{\\MethodName{}}} (\\textbf{L}earner-Tailored \\textbf{S}olution \\textbf{G}enerator), to enhance program repair while offering the bug descriptions for the buggy code. In the first stage, we utilize a repair solution retrieval framework to construct a solution retrieval database and then employ an edit-driven code retrieval approach to retrieve valuable solutions, guiding LLMs in identifying and fixing the bugs in buggy code. In the second stage, we propose a solution-guided program repair method, which fixes the code and provides explanations under the guidance of retrieval solutions. Moreover, we propose an Iterative Retrieval Enhancement method that utilizes evaluation results of the generated code to iteratively optimize the retrieval direction and explore more suitable repair strategies, improving performance in practical programming coaching scenarios. The experimental results show that our approach outperforms a set of baselines by a large margin, validating the effectiveness of our framework for the newly proposed LPR task.",
    "title_zh": "学习者定制的程序修复：一种通过迭代编辑驱动检索增强的解决方案生成器",
    "abstract_zh": "随着大型语言模型（LLMs）在编程领域的不断发展，智能编程辅导系统受到了广泛关注。然而，现有研究大多聚焦于修复编程学习者代码中的错误，却未能提供错误的根本原因。为弥补这一不足，我们提出了一项新任务——**LPR**（**L**earner-Tailored **P**rogram **R**epair）。随后，我们设计了一个新颖且高效的框架——**\\textsc{\\MethodName{}}**（**L**earner-Tailored **S**olution **G**enerator），旨在提升程序修复能力的同时，为存在缺陷的代码提供详细的错误说明。\n\n在第一阶段，我们采用一种修复方案检索框架，构建解决方案检索数据库，并通过基于编辑距离的代码检索方法，精准获取有价值的修复方案，从而引导大语言模型识别并修复有缺陷的代码。在第二阶段，我们提出一种基于方案引导的程序修复方法，在检索到的解决方案指导下，不仅完成代码修复，还生成相应的解释说明。此外，我们引入一种**迭代式检索增强机制**，利用生成代码的评估结果，不断优化检索方向，探索更合适的修复策略，从而显著提升在实际编程辅导场景中的表现。\n\n实验结果表明，我们的方法在多个基准测试中均大幅优于现有基线模型，充分验证了所提出的LPR任务及相应框架的有效性。"
  },
  {
    "date": "2026-01-13",
    "title": "LLMs in Code Vulnerability Analysis: A Proof of Concept",
    "authors": "Shaznin Sultana, Sadia Afreen, Nasir U. Eisty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08691v1",
    "source": "arXiv",
    "abstract": "Context: Traditional software security analysis methods struggle to keep pace with the scale and complexity of modern codebases, requiring intelligent automation to detect, assess, and remediate vulnerabilities more efficiently and accurately. Objective: This paper explores the incorporation of code-specific and general-purpose Large Language Models (LLMs) to automate critical software security tasks, such as identifying vulnerabilities, predicting severity and access complexity, and generating fixes as a proof of concept. Method: We evaluate five pairs of recent LLMs, including both code-based and general-purpose open-source models, on two recognized C/C++ vulnerability datasets, namely Big-Vul and Vul-Repair. Additionally, we compare fine-tuning and prompt-based approaches. Results: The results show that fine-tuning uniformly outperforms both zero-shot and few-shot approaches across all tasks and models. Notably, code-specialized models excel in zero-shot and few-shot settings on complex tasks, while general-purpose models remain nearly as effective. Discrepancies among CodeBLEU, CodeBERTScore, BLEU, and ChrF highlight the inadequacy of current metrics for measuring repair quality. Conclusions: This study contributes to the software security community by investigating the potential of advanced LLMs to improve vulnerability analysis and remediation.",
    "title_zh": "大型语言模型在代码漏洞分析中的应用：一个概念验证",
    "abstract_zh": "背景：传统的软件安全分析方法难以跟上现代代码库的规模与复杂性，亟需智能自动化技术以更高效、更准确地检测、评估和修复漏洞。  \n目标：本文探讨将代码专用型及通用型大型语言模型（LLMs）融入软件安全任务自动化中的可行性，作为概念验证，涵盖漏洞识别、严重性预测、访问复杂度评估以及补丁生成等关键环节。  \n方法：我们在两个公认的C/C++漏洞数据集——Big-Vul和Vul-Repair上，评估了五组近期的LLM模型，包括基于代码的模型与通用开源模型，并对比了微调（fine-tuning）与提示工程（prompt-based）两种方法的表现。  \n结果：实验表明，在所有任务和模型中，微调方法均显著优于零样本（zero-shot）和少样本（few-shot）方法。值得注意的是，代码专用模型在复杂任务的零样本和少样本场景下表现尤为突出，而通用模型也保持了接近的性能。CodeBLEU、CodeBERTScore、BLEU和ChrF等指标之间的差异揭示了现有修复质量评估指标的不足。  \n结论：本研究为软件安全领域提供了重要贡献，深入探索了先进LLMs在提升漏洞分析与修复效率方面的潜力。"
  },
  {
    "date": "2026-01-13",
    "title": "Silence the Judge: Reinforcement Learning with Self-Verifier via Latent Geometric Clustering",
    "authors": "Nonghai Zhang, Weitao Ma, Zhanyu Ma, Jun Xu, Jiuchong Gao, Jinghua Hao, Renqing He, Jingwen Xu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08427v1",
    "source": "arXiv",
    "abstract": "Group Relative Policy Optimization (GRPO) significantly enhances the reasoning performance of Large Language Models (LLMs). However, this success heavily relies on expensive external verifiers or human rules. Such dependency not only leads to significant computational costs and training latency, but also yields sparse rewards that hinder optimization efficiency. To address these challenges, we propose Latent-GRPO, a framework that derives intrinsic rewards directly from latent space geometry. Crucially, our empirical analysis reveals a compelling geometric property: terminal token representations of correct reasoning trajectories form dense clusters with high intra-class similarity, whereas incorrect trajectories remain scattered as outliers. In light of this discovery, we introduce the Iterative Robust Centroid Estimation (IRCE) algorithm, which generates dense, continuous rewards by mitigating magnitude fluctuations via spherical projection and estimating a robust ``truth centroid'' through iterative aggregation. Experimental results on multiple datasets show that our method maintains model performance while achieving a training speedup of over 2x compared to baselines. Furthermore, extensive results demonstrate strong generalization ability and robustness. The code will be released soon.",
    "title_zh": "沉默的法官：通过潜在几何聚类实现自验证的强化学习",
    "abstract_zh": "组相对策略优化（GRPO）显著提升了大型语言模型（LLM）的推理能力。然而，这一成功高度依赖于昂贵的外部验证器或人工规则，这种依赖不仅带来巨大的计算成本和训练延迟，还导致奖励稀疏，从而制约了优化效率。为解决上述挑战，我们提出了一种名为**潜空间GRPO（Latent-GRPO）**的新框架，该框架直接从潜在空间的几何结构中提取内在奖励。关键发现在于：经实证分析，正确推理路径的终态标记表示在潜空间中形成密集聚类，具有高度的类内相似性；而错误推理路径则表现为分散的异常点。基于此现象，我们设计了**迭代鲁棒中心估计（IRCE）算法**，通过球面投影抑制幅度波动，并通过迭代聚合估计一个稳健的“真理中心”，从而生成密集且连续的奖励信号。在多个数据集上的实验结果表明，我们的方法在保持模型性能的同时，相较基线实现了超过2倍的训练加速。此外，大量实验进一步验证了该方法出色的泛化能力和鲁棒性。代码即将开源。"
  },
  {
    "date": "2026-01-13",
    "title": "TerraFormer: Automated Infrastructure-as-Code with LLMs Fine-Tuned via Policy-Guided Verifier Feedback",
    "authors": "Prithwish Jana, Sam Davidson, Bhavana Bhasker, Andrey Kan, Anoop Deoras, Laurent Callot",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08734v1",
    "source": "arXiv",
    "abstract": "Automating Infrastructure-as-Code (IaC) is challenging, and large language models (LLMs) often produce incorrect configurations from natural language (NL). We present TerraFormer, a neuro-symbolic framework for IaC generation and mutation that combines supervised fine-tuning with verifier-guided reinforcement learning, using formal verification tools to provide feedback on syntax, deployability, and policy compliance. We curate two large, high-quality NL-to-IaC datasets, TF-Gen (152k instances) and TF-Mutn (52k instances), via multi-stage verification and iterative LLM self-correction. Evaluations against 17 state-of-the-art LLMs, including ~50x larger models like Sonnet 3.7, DeepSeek-R1, and GPT-4.1, show that TerraFormer improves correctness over its base LLM by 15.94% on IaC-Eval, 11.65% on TF-Gen (Test), and 19.60% on TF-Mutn (Test). It outperforms larger models on both TF-Gen (Test) and TF-Mutn (Test), ranks third on IaC-Eval, and achieves top best-practices and security compliance.",
    "title_zh": "TerraFormer：通过策略引导的验证器反馈微调大模型实现基础设施即代码的自动化",
    "abstract_zh": "自动化基础设施即代码（IaC）极具挑战性，而大型语言模型（LLMs）往往从自然语言（NL）生成不正确的配置。我们提出了TerraFormer，一种用于IaC生成与变异的神经符号框架，该框架结合了监督微调与验证器引导的强化学习，并利用形式化验证工具对语法、可部署性及策略合规性提供反馈。我们通过多阶段验证和迭代式LLM自我修正，构建了两个大规模、高质量的NL-to-IaC数据集：TF-Gen（15.2万条实例）和TF-Mutn（5.2万条实例）。在与17个最先进的LLM（包括规模大约50倍的模型如Sonnet 3.7、DeepSeek-R1和GPT-4.1）的对比评估中，TerraFormer在IaC-Eval上比其基础LLM提升了15.94%的正确率，在TF-Gen（测试集）上提升11.65%，在TF-Mutn（测试集）上提升19.60%。它在TF-Gen（测试集）和TF-Mutn（测试集）上均优于更大规模的模型，在IaC-Eval上排名第三，并实现了最佳实践和安全合规性的顶尖水平。"
  },
  {
    "date": "2026-01-13",
    "title": "RAGShaper: Eliciting Sophisticated Agentic RAG Skills via Automated Data Synthesis",
    "authors": "Zhengwei Tao, Bo Li, Jialong Wu, Guochen Yan, Huanyao Zhang, Jiahao Xu, Haitao Mi, Wentao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08699v1",
    "source": "arXiv",
    "abstract": "Agentic Retrieval-Augmented Generation (RAG) empowers large language models to autonomously plan and retrieve information for complex problem-solving. However, the development of robust agents is hindered by the scarcity of high-quality training data that reflects the noise and complexity of real-world retrieval environments. Conventional manual annotation is unscalable and often fails to capture the dynamic reasoning strategies required to handle retrieval failures. To bridge this gap, we introduce RAGShaper, a novel data synthesis framework designed to automate the construction of RAG tasks and robust agent trajectories. RAGShaper incorporates an InfoCurator to build dense information trees enriched with adversarial distractors spanning Perception and Cognition levels. Furthermore, we propose a constrained navigation strategy that forces a teacher agent to confront these distractors, thereby eliciting trajectories that explicitly demonstrate error correction and noise rejection. Comprehensive experiments confirm that models trained on our synthesized corpus significantly outperform existing baselines, exhibiting superior robustness in noise-intensive and complex retrieval tasks.",
    "title_zh": "RAGShaper：通过自动化数据合成激发高级代理型RAG技能",
    "abstract_zh": "代理型检索增强生成（RAG）使大型语言模型能够自主规划并检索信息，以解决复杂问题。然而，由于缺乏能够反映真实检索环境噪声与复杂性的高质量训练数据，构建稳健的智能体仍面临挑战。传统的手动标注方法难以扩展，且往往无法捕捉处理检索失败所需的动态推理策略。为弥合这一差距，我们提出了RAGShaper——一种新颖的数据合成框架，旨在自动化构建RAG任务及鲁棒智能体的行动轨迹。RAGShaper引入了一个信息整理器（InfoCurator），用于构建富含对抗性干扰项的密集信息树，这些干扰项覆盖感知与认知两个层面。此外，我们提出了一种受约束的导航策略，迫使教师智能体直面这些干扰项，从而激发显式体现错误修正与噪声剔除行为的智能体轨迹。全面的实验结果表明，基于我们合成语料库训练的模型显著优于现有基线，在高噪声和复杂检索任务中展现出更优越的鲁棒性。"
  },
  {
    "date": "2026-01-13",
    "title": "Parallel Context-of-Experts Decoding for Retrieval Augmented Generation",
    "authors": "Giulio Corallo, Paolo Papotti",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08670v1",
    "source": "arXiv",
    "abstract": "Retrieval Augmented Generation faces a trade-off: concatenating documents in a long prompt enables multi-document reasoning but creates prefill bottlenecks, while encoding document KV caches separately offers speed but breaks cross-document interaction. We propose Parallel Context-of-Experts Decoding (Pced), a training-free framework that shifts evidence aggregation from the attention mechanism to the decoding. Pced treats retrieved documents as isolated \"experts\", synchronizing their predictions via a novel retrieval-aware contrastive decoding rule that weighs expert logits against the model prior. This approach recovers cross-document reasoning capabilities without constructing a shared attention across documents.",
    "title_zh": "并行专家上下文解码在检索增强生成中的应用",
    "abstract_zh": "检索增强生成面临一个权衡：将多个文档拼接为长提示虽能实现多文档推理，但会引发预填充瓶颈；而分别编码文档的键值缓存虽可提升速度，却破坏了跨文档交互。我们提出一种无需训练的框架——并行专家上下文解码（Pced），将证据聚合从注意力机制转移到解码阶段。Pced 将检索到的文档视为相互独立的“专家”，通过一种新颖的、基于检索感知的对比解码规则，同步各专家的预测结果，该规则根据模型先验对专家的输出 logits 进行加权。这一方法在不构建跨文档共享注意力机制的前提下，恢复了跨文档推理能力。"
  },
  {
    "date": "2026-01-13",
    "title": "Quantum State Discrimination Enhanced by FPGA-Based AI Engine Technology",
    "authors": "Anastasiia Butko, Artem Marisov, David I. Santiago, Irfan Siddiqi",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08213v1",
    "source": "arXiv",
    "abstract": "Identifying the state of a quantum bit (qubit), known as quantum state discrimination, is a crucial operation in quantum computing. However, it has been the most error-prone and time-consuming operation on superconducting quantum processors. Due to stringent timing constraints and algorithmic complexity, most qubit state discrimination methods are executed offline. In this work, we present an enhanced real-time quantum state discrimination system leveraging FPGA-based AI Engine technology. A multi-layer neural network has been developed and implemented on the AMD Xilinx VCK190 FPGA platform, enabling accurate in-situ state discrimination and supporting mid-circuit measurement experiments for multiple qubits. Our approach leverages recent advancements in architecture research and design, utilizing specialized AI/ML accelerators to optimize quantum experiments and reduce the use of FPGA resources.",
    "title_zh": "基于FPGA的人工智能引擎技术增强的量子态鉴别",
    "abstract_zh": "量子比特（qubit）状态的识别，即量子态鉴别，是量子计算中一项至关重要的操作。然而，这一操作在超导量子处理器上一直是最容易出错且耗时最长的操作之一。由于严格的时序限制和算法复杂性，大多数量子比特状态鉴别方法都是离线执行的。在本研究中，我们提出了一种基于FPGA的AI引擎技术的增强型实时量子态鉴别系统。我们在AMD Xilinx VCK190 FPGA平台上开发并实现了多层神经网络，实现了高精度的原位状态鉴别，并支持对多个量子比特进行电路中间测量实验。我们的方法充分利用了近期架构研究与设计的进展，通过专用的AI/ML加速器优化量子实验，同时有效降低了FPGA资源的占用。"
  },
  {
    "date": "2026-01-13",
    "title": "JudgeRLVR: Judge First, Generate Second for Efficient Reasoning",
    "authors": "Jiangshan Duo, Hanyu Li, Hailin Zhang, Yudong Wang, Sujian Li, Liang Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08468v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has become a standard paradigm for reasoning in Large Language Models. However, optimizing solely for final-answer correctness often drives models into aimless, verbose exploration, where they rely on exhaustive trial-and-error tactics rather than structured planning to reach solutions. While heuristic constraints like length penalties can reduce verbosity, they often truncate essential reasoning steps, creating a difficult trade-off between efficiency and verification. In this paper, we argue that discriminative capability is a prerequisite for efficient generation: by learning to distinguish valid solutions, a model can internalize a guidance signal that prunes the search space. We propose JudgeRLVR, a two-stage judge-then-generate paradigm. In the first stage, we train the model to judge solution responses with verifiable answers. In the second stage, we fine-tune the same model with vanilla generating RLVR initialized from the judge. Compared to Vanilla RLVR using the same math-domain training data, JudgeRLVR achieves a better quality--efficiency trade-off for Qwen3-30B-A3B: on in-domain math, it delivers about +3.7 points average accuracy gain with -42\\% average generation length; on out-of-domain benchmarks, it delivers about +4.5 points average accuracy improvement, demonstrating enhanced generalization.",
    "title_zh": "JudgeRLVR：先判断，后生成，实现高效推理",
    "abstract_zh": "基于可验证奖励的强化学习（Reinforcement Learning with Verifiable Rewards, RLVR）已成为大语言模型进行推理的标准范式。然而，仅以最终答案正确性为目标进行优化，常常导致模型陷入无目的、冗长的探索过程，依赖于耗时的试错策略而非结构化规划来寻找解法。尽管可通过长度惩罚等启发式约束减少冗余输出，但这类方法往往过度压缩必要的推理步骤，造成效率与验证质量之间的艰难权衡。\n\n本文认为，判别能力是高效生成的前提：通过学习区分有效解与无效解，模型能够内化一种指导信号，从而有效剪枝搜索空间。为此，我们提出 JudgeRLVR——一种“先判断，后生成”的两阶段范式。第一阶段，我们训练模型对具有可验证答案的解题响应进行判别；第二阶段，我们使用从判别模型初始化的普通生成式 RLVR 对同一模型进行微调。\n\n与使用相同数学领域训练数据的 Vanilla RLVR 相比，JudgeRLVR 在 Qwen3-30B-A3B 模型上实现了更优的质量—效率平衡：在域内数学任务中，平均准确率提升约 3.7 个百分点，同时生成长度减少约 42%；在域外基准测试中，平均准确率提升约 4.5 个百分点，展现出更强的泛化能力。"
  },
  {
    "date": "2026-01-13",
    "title": "Controlled LLM Training on Spectral Sphere",
    "authors": "Tian Xie, Haoming Luo, Haoyu Tang, Yiwen Hu, Jason Klein Liu, Qingnan Ren, Yang Wang, Wayne Xin Zhao, Rui Yan, Bing Su, Chong Luo, Baining Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08393v1",
    "source": "arXiv",
    "abstract": "Scaling large models requires optimization strategies that ensure rapid convergence grounded in stability. Maximal Update Parametrization ($\\boldsymbolμ$P) provides a theoretical safeguard for width-invariant $Θ(1)$ activation control, whereas emerging optimizers like Muon are only ``half-aligned'' with these constraints: they control updates but allow weights to drift. To address this limitation, we introduce the \\textbf{Spectral Sphere Optimizer (SSO)}, which enforces strict module-wise spectral constraints on both weights and their updates. By deriving the steepest descent direction on the spectral sphere, SSO realizes a fully $\\boldsymbolμ$P-aligned optimization process. To enable large-scale training, we implement SSO as an efficient parallel algorithm within Megatron. Through extensive pretraining on diverse architectures, including Dense 1.7B, MoE 8B-A1B, and 200-layer DeepNet models, SSO consistently outperforms AdamW and Muon. Furthermore, we observe significant practical stability benefits, including improved MoE router load balancing, suppressed outliers, and strictly bounded activations.",
    "title_zh": "在谱球上的受控大语言模型训练",
    "abstract_zh": "大规模模型的训练需要优化策略来确保在稳定基础上实现快速收敛。最大更新参数化（$\\boldsymbolμ$P）从理论上保障了宽度无关的 $Θ(1)$ 激活控制，而新兴优化器如 Muon 仅“半对齐”于这些约束：它们虽能控制参数更新，却允许权重发生漂移。为克服这一局限，我们提出**谱球优化器（Spectral Sphere Optimizer, SSO）**，该方法在模块层面严格施加对权重及其更新的谱约束。通过推导谱球上的最速下降方向，SSO 实现了完全与 $\\boldsymbolμ$P 对齐的优化过程。为支持大规模训练，我们在 Megatron 中高效实现了 SSO 的并行算法。在多种架构上进行的大规模预训练实验（包括 Dense 1.7B、MoE 8B-A1B 和 200 层 DeepNet 模型）表明，SSO 始终优于 AdamW 和 Muon。此外，我们还观察到显著的实际稳定性优势，包括改善 MoE 路由器负载均衡、抑制异常值，以及严格限制激活值的范围。"
  },
  {
    "date": "2026-01-13",
    "title": "Evaluating Implicit Regulatory Compliance in LLM Tool Invocation via Logic-Guided Synthesis",
    "authors": "Da Song, Yuheng Huang, Boqi Chen, Tianshuo Cong, Randy Goebel, Lei Ma, Foutse Khomh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08196v1",
    "source": "arXiv",
    "abstract": "The integration of large language models (LLMs) into autonomous agents has enabled complex tool use, yet in high-stakes domains, these systems must strictly adhere to regulatory standards beyond simple functional correctness. However, existing benchmarks often overlook implicit regulatory compliance, thus failing to evaluate whether LLMs can autonomously enforce mandatory safety constraints. To fill this gap, we introduce LogiSafetyGen, a framework that converts unstructured regulations into Linear Temporal Logic oracles and employs logic-guided fuzzing to synthesize valid, safety-critical traces. Building on this framework, we construct LogiSafetyBench, a benchmark comprising 240 human-verified tasks that require LLMs to generate Python programs that satisfy both functional objectives and latent compliance rules. Evaluations of 13 state-of-the-art (SOTA) LLMs reveal that larger models, despite achieving better functional correctness, frequently prioritize task completion over safety, which results in non-compliant behavior.",
    "title_zh": "通过逻辑引导合成评估大语言模型工具调用中的隐含监管合规性",
    "abstract_zh": "将大型语言模型（LLMs）集成到自主代理中，已使其能够执行复杂的工具操作。然而，在高风险领域，这些系统不仅需满足基本的功能正确性，还必须严格遵守监管标准。但现有的评估基准往往忽视了隐含的合规性要求，无法有效检验LLMs是否能自主执行强制性的安全约束。为填补这一空白，我们提出了LogiSafetyGen框架，该框架可将非结构化的法规转化为线性时序逻辑（Linear Temporal Logic）的断言，并利用逻辑引导的模糊测试技术，生成符合安全关键要求的有效执行轨迹。基于此框架，我们构建了LogiSafetyBench基准，包含240个经人工验证的任务，要求LLMs生成满足功能目标和潜在合规规则的Python程序。对13个当前最先进的（SOTA）LLM的评估结果显示，尽管更大规模的模型在功能正确性方面表现更优，但它们常常更倾向于完成任务而非保障安全，从而导致不合规行为。"
  },
  {
    "date": "2026-01-13",
    "title": "Improving LLM Reasoning with Homophily-aware Structural and Semantic Text-Attributed Graph Compression",
    "authors": "Zijun Di, Bin Lu, Huquan Kang, Luoyi Fu, Jiaxin Ding, Xiaoying Gan, Lei Zhou, Xinbing Wang, Chenghu Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08187v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have demonstrated promising capabilities in Text-Attributed Graph (TAG) understanding. Recent studies typically focus on verbalizing the graph structures via handcrafted prompts, feeding the target node and its neighborhood context into LLMs. However, constrained by the context window, existing methods mainly resort to random sampling, often implemented via dropping node/edge randomly, which inevitably introduces noise and cause reasoning instability. We argue that graphs inherently contain rich structural and semantic information, and that their effective exploitation can unlock potential gains in LLMs reasoning performance. To this end, we propose Homophily-aware Structural and Semantic Compression for LLMs (HS2C), a framework centered on exploiting graph homophily. Structurally, guided by the principle of Structural Entropy minimization, we perform a global hierarchical partition that decodes the graph's essential topology. This partition identifies naturally cohesive, homophilic communities, while discarding stochastic connectivity noise. Semantically, we deliver the detected structural homophily to the LLM, empowering it to perform differentiated semantic aggregation based on predefined community type. This process compresses redundant background contexts into concise community-level consensus, selectively preserving semantically homophilic information aligned with the target nodes. Extensive experiments on 10 node-level benchmarks across LLMs of varying sizes and families demonstrate that, by feeding LLMs with structurally and semantically compressed inputs, HS2C simultaneously enhances the compression rate and downstream inference accuracy, validating its superiority and scalability. Extensions to 7 diverse graph-level benchmarks further consolidate HS2C's task generalizability.",
    "title_zh": "通过同性相吸感知的结构与语义文本属性图压缩提升大语言模型的推理能力",
    "abstract_zh": "大型语言模型（LLMs）在文本属性图（Text-Attributed Graph, TAG）理解方面展现了令人瞩目的能力。近期研究通常通过手工设计的提示词来描述图结构，将目标节点及其邻域上下文输入到LLM中进行处理。然而，受限于上下文窗口长度，现有方法主要依赖随机采样策略，常通过随机丢弃节点或边来实现，这不可避免地引入噪声，导致推理过程不稳定。我们认为，图结构本身蕴含丰富的结构性与语义信息，若能有效挖掘这些信息，有望显著提升LLM的推理性能。为此，我们提出一种面向LLM的同质性感知结构与语义压缩框架——HS2C（Homophily-aware Structural and Semantic Compression）。该框架的核心思想是利用图的同质性特性。\n\n在结构层面，基于结构熵最小化原则，HS2C执行全局分层划分，以解码图的本质拓扑结构。该划分能够识别出自然凝聚、具有同质性的社区，同时剔除随机连接带来的噪声。在语义层面，HS2C将检测到的结构同质性信息传递给LLM，使其能够根据预定义的社区类型对语义信息进行差异化聚合。这一过程将冗余的背景上下文压缩为简洁的社区级共识，有选择性地保留与目标节点语义上一致的同质信息。\n\n在10个不同规模和家族的LLM上进行的大量节点级基准测试表明，通过向LLM提供经过结构与语义双重压缩的输入，HS2C不仅显著提升了压缩率，还同步提高了下游推理的准确性，充分验证了其优越性与可扩展性。进一步在7个多样化的图级别基准上的扩展实验，进一步证明了HS2C在多种任务中的泛化能力。"
  },
  {
    "date": "2026-01-13",
    "title": "ZeroDVFS: Zero-Shot LLM-Guided Core and Frequency Allocation for Embedded Platforms",
    "authors": "Mohammad Pivezhandi, Mahdi Banisharif, Abusayeed Saifullah, Ali Jannesari",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08166v1",
    "source": "arXiv",
    "abstract": "Dynamic voltage and frequency scaling (DVFS) and task-to-core allocation are critical for thermal management and balancing energy and performance in embedded systems. Existing approaches either rely on utilization-based heuristics that overlook stall times, or require extensive offline profiling for table generation, preventing runtime adaptation. We propose a model-based hierarchical multi-agent reinforcement learning (MARL) framework for thermal- and energy-aware scheduling on multi-core platforms. Two collaborative agents decompose the exponential action space, achieving 358ms latency for subsequent decisions. First decisions require 3.5 to 8.0s including one-time LLM feature extraction. An accurate environment model leverages regression techniques to predict thermal dynamics and performance states. When combined with LLM-extracted semantic features, the environment model enables zero-shot deployment for new workloads on trained platforms by generating synthetic training data without requiring workload-specific profiling samples. We introduce LLM-based semantic feature extraction that characterizes OpenMP programs through 13 code-level features without execution. The Dyna-Q-inspired framework integrates direct reinforcement learning with model-based planning, achieving 20x faster convergence than model-free methods. Experiments on BOTS and PolybenchC benchmarks across NVIDIA Jetson TX2, Jetson Orin NX, RubikPi, and Intel Core i7 demonstrate 7.09x better energy efficiency and 4.0x better makespan than Linux ondemand governor. First-decision latency is 8,300x faster than table-based profiling, enabling practical deployment in dynamic embedded systems.",
    "title_zh": "ZeroDVFS：面向嵌入式平台的零样本LLM引导的核心与频率分配",
    "abstract_zh": "动态电压频率调节（DVFS）与任务到核心的分配对于嵌入式系统中的热管理以及能量与性能的平衡至关重要。现有方法要么依赖于基于利用率的启发式策略，忽略了停顿时间的影响；要么需要大量离线分析来生成查找表，难以实现运行时自适应。本文提出一种基于模型的分层多智能体强化学习（MARL）框架，用于多核平台上的热感知与能耗感知调度。两个协同工作的智能体将指数级的动作空间进行分解，使后续决策的延迟降低至358毫秒。首次决策耗时3.5至8.0秒，其中包括一次性的大语言模型（LLM）特征提取。一个精确的环境模型利用回归技术预测热动态和性能状态。当结合LLM提取的语义特征后，该环境模型能够在训练过的平台上实现对新工作负载的零样本部署，通过生成合成训练数据而无需特定工作负载的采样分析。我们引入基于LLM的语义特征提取方法，仅通过代码层面的13个特征即可刻画OpenMP程序，无需实际执行。受Dyna-Q启发的框架将直接强化学习与基于模型的规划相结合，相比无模型方法实现了20倍更快的收敛速度。在NVIDIA Jetson TX2、Jetson Orin NX、RubikPi和Intel Core i7平台上的BOTS与PolybenchC基准测试实验表明，本方法在能效方面比Linux ondemand调度器提升7.09倍，在完成时间（makespan）上提升4.0倍。首次决策延迟比基于查表的分析方法快8300倍，使得该方案在动态嵌入式系统中具备实际部署可行性。"
  },
  {
    "date": "2026-01-13",
    "title": "To Retrieve or To Think? An Agentic Approach for Context Evolution",
    "authors": "Rubing Chen, Jian Wang, Wenjie Li, Xiao-Yong Wei, Qing Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08747v1",
    "source": "arXiv",
    "abstract": "Current context augmentation methods, such as retrieval-augmented generation, are essential for solving knowledge-intensive reasoning tasks.However, they typically adhere to a rigid, brute-force strategy that executes retrieval at every step. This indiscriminate approach not only incurs unnecessary computational costs but also degrades performance by saturating the context with irrelevant noise. To address these limitations, we introduce Agentic Context Evolution (ACE), a framework inspired by human metacognition that dynamically determines whether to seek new evidence or reason with existing knowledge. ACE employs a central orchestrator agent to make decisions strategically via majority voting.It aims to alternate between activating a retriever agent for external retrieval and a reasoner agent for internal analysis and refinement. By eliminating redundant retrieval steps, ACE maintains a concise and evolved context. Extensive experiments on challenging multi-hop QA benchmarks demonstrate that ACE significantly outperforms competitive baselines in accuracy while achieving efficient token consumption.Our work provides valuable insights into advancing context-evolved generation for complex, knowledge-intensive tasks.",
    "title_zh": "检索还是思考？一种面向上下文演化的自主性方法",
    "abstract_zh": "当前的上下文增强方法，如检索增强生成（Retrieval-Augmented Generation），在解决知识密集型推理任务中至关重要。然而，这些方法通常采用僵化且粗暴的策略，在每一步都执行检索操作。这种不加区分的做法不仅带来不必要的计算开销，还会因引入无关噪声而降低模型性能。为解决上述局限性，我们提出了受人类元认知启发的**代理式上下文演化框架（Agentic Context Evolution, ACE）**，该框架能够动态判断是否需要获取新证据，或仅基于已有知识进行推理。ACE 通过一个核心协调代理，利用多数投票机制进行策略性决策，旨在在调用检索代理获取外部信息与激活推理代理进行内部分析和优化之间交替切换。通过消除冗余的检索步骤，ACE 有效保持了上下文的简洁性与演进性。在多个具有挑战性的多跳问答基准测试上的大量实验表明，ACE 在准确率方面显著优于现有先进基线方法，同时实现了高效的 token 消耗。本研究为推进复杂、知识密集型任务中的上下文演化生成提供了重要洞见。"
  },
  {
    "date": "2026-01-13",
    "title": "RULERS: Locked Rubrics and Evidence-Anchored Scoring for Robust LLM Evaluation",
    "authors": "Yihan Hong, Huaiyuan Yao, Bolin Shen, Wanpeng Xu, Hua Wei, Yushun Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.08654v1",
    "source": "arXiv",
    "abstract": "The LLM-as-a-Judge paradigm promises scalable rubric-based evaluation, yet aligning frozen black-box models with human standards remains a challenge due to inherent generation stochasticity. We reframe judge alignment as a criteria transfer problem and isolate three recurrent failure modes: rubric instability caused by prompt sensitivity, unverifiable reasoning that lacks auditable evidence, and scale misalignment with human grading boundaries. To address these issues, we introduce RULERS (Rubric Unification, Locking, and Evidence-anchored Robust Scoring), a compiler-executor framework that transforms natural language rubrics into executable specifications. RULERS operates by compiling criteria into versioned immutable bundles, enforcing structured decoding with deterministic evidence verification, and applying lightweight Wasserstein-based post-hoc calibration, all without updating model parameters. Extensive experiments on essay and summarization benchmarks demonstrate that RULERS significantly outperforms representative baselines in human agreement, maintains strong stability against adversarial rubric perturbations, and enables smaller models to rival larger proprietary judges. Overall, our results suggest that reliable LLM judging requires executable rubrics, verifiable evidence, and calibrated scales rather than prompt phrasing alone. Code is available at https://github.com/LabRAI/Rulers.git.",
    "title_zh": "评估大语言模型的稳健性：锁定评分标准与证据锚定评分方法",
    "abstract_zh": "大语言模型作为评判者（LLM-as-a-Judge）范式承诺实现可扩展的基于评分标准的评估，然而由于生成过程固有的随机性，将冻结的黑箱模型与人类标准对齐仍面临挑战。我们重新将评判对齐问题视为标准迁移问题，并识别出三种反复出现的失效模式：由提示敏感性引发的评分标准不稳定性、缺乏可审计证据的不可验证推理，以及与人类评分边界存在尺度错配。为解决这些问题，我们提出了RULERS（评分标准统一、锁定与证据锚定鲁棒评分）框架——一种编译器-执行器架构，能够将自然语言评分标准转化为可执行规范。RULERS通过将评价标准编译为版本化且不可变的封装包，强制采用结构化解码并实现确定性证据验证，并应用轻量级基于Wasserstein距离的后处理校准，整个过程无需更新模型参数。在作文和摘要任务基准上的大量实验表明，RULERS在与人类判断的一致性方面显著优于代表性基线方法，对对抗性评分标准扰动表现出强稳定性，并使小型模型达到与大型专有评判模型相当的性能。总体而言，我们的研究结果表明，可靠的LLM评判依赖于可执行的评分标准、可验证的证据以及经过校准的评分尺度，而不仅仅是提示语的设计。代码已公开于 https://github.com/LabRAI/Rulers.git。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: Leveraging LLMs for Enforcing Design Principles in Student Code: Analysis of Prompting Strategies and RAG",
    "authors": "Dhruv Kolhatkar, Soubhagya Akkena, Edward F. Gehringer",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328445",
    "source": "IEEE",
    "abstract": "This work-in-progress research-to-practice paper explores the integration of Large Language Models (LLMs) into the code-review process for open-source software projects developed in computer science and software engineering courses. The focus is on developing an automated feedback tool that evaluates student code for adherence to key object-oriented design principles, addressing the need for more effective and scalable methods to teach software design best practices. The innovative practice involves leveraging LLMs and Retrieval-Augmented Generation (RAG) to create an automated feedback system that assesses student code for principles like SOLID, DRY, and design patterns. It analyzes the effectiveness of various prompting strategies and the RAG integration. Preliminary findings show promising improvements in code quality. Future work will aim to improve model accuracy and expand support for additional design principles.",
    "title_zh": "正在进行中：利用大语言模型强化学生代码中的设计原则——提示策略与RAG的分析",
    "abstract_zh": "本篇正在进行中的研究实践论文探讨了将大型语言模型（LLMs）融入计算机科学与软件工程课程中开源软件项目代码审查过程的可行性。研究重点在于开发一种自动化反馈工具，用于评估学生代码是否符合关键的面向对象设计原则，以应对当前教学中对更高效、可扩展的教学方法以传授软件设计最佳实践的需求。该创新实践通过利用大型语言模型和检索增强生成（RAG）技术，构建了一个自动化反馈系统，能够评估学生代码在SOLID原则、DRY原则以及设计模式等方面的符合程度。研究还分析了不同提示策略及RAG集成的有效性。初步结果表明，代码质量得到了显著提升。未来工作将致力于提高模型的准确性，并拓展对更多设计原则的支持。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: Tutoring System Using a Large Language Model",
    "authors": "Balaji R Rao, Naveen Mathews Renji, Carlo Lipizzi",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328211",
    "source": "IEEE",
    "abstract": "This innovative practice Work-in-Progress (WIP) paper describes early design, implementation, and pilot evaluation of SSE-EduBot, a course-specific tutoring assistant that integrates semantic search with a LoRA-fine-tuned Llama-213B model. AI in education is a promising domain for the utilization of LLMs to make personalized learning materials using elements of generative AI. This can help educators “riff” on traditional teaching by leveraging Gen AI as tutoring systems. We design a system targeted for a <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1 0 0} \\boldsymbol{+}$</tex> student graduate data science course. The three-stage pipeline (1) retrieves answers from prior instructor-student emails, (2) invokes the fine-tuned model when no archival match is found, and (3) reformats the output into conversational prose for a web interface. A curated corpus of lecture transcripts, slides, and textbook excerpts, augmented with <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\approx 4,300$</tex> automatically generated question-answer pairs, serves as the domain knowledge base. Preliminary comparisons against ChatGPT-3.5 on representative queries show that SSE-EduBot delivers more context-aligned explanations and reduced domainspecific hallucinations/verbose explanations. Deployment on the university server for the upcoming semester will help collect real-world interaction data to refine retrieval precision, response latency, and ethical guardrails. We share the reproducible workflow and outline next steps toward scaling the approach across additional courses and disciplines.",
    "title_zh": "正在开发中：基于大语言模型的辅导系统",
    "abstract_zh": "本文是一篇创新性的进展报告（Work-in-Progress）论文，介绍了SSE-EduBot的早期设计、实现及试点评估。SSE-EduBot是一款面向特定课程的教学辅导助手，它将语义搜索与经过LoRA微调的Llama-2 13B模型相结合。人工智能在教育领域的应用前景广阔，利用大语言模型（LLMs）结合生成式AI技术，可实现个性化学习材料的生成，从而帮助教育工作者借助生成式AI作为辅导系统，对传统教学方式进行“即兴发挥”式的创新。\n\n本研究针对一门拥有100名以上学生的研究生数据科学课程，设计并实现了一个三阶段流程：（1）从以往教师与学生之间的邮件中检索答案；（2）当档案中无匹配结果时，调用微调后的模型进行响应；（3）将输出结果重新格式化为适合网页界面的对话式表达。系统所依赖的领域知识库由精心整理的课程讲义、幻灯片和教科书节选构成，并额外增加了约4,300个自动生成的问题-答案对。\n\n初步测试表明，在代表性查询任务上，与ChatGPT-3.5相比，SSE-EduBot能够提供更符合上下文的解释，同时显著减少领域特定的幻觉现象和冗长的解释内容。计划在下一学期于大学服务器上部署该系统，以收集真实世界中的交互数据，进一步优化检索精度、响应延迟以及伦理安全机制。本文还分享了可复现的工作流程，并展望了未来将该方法推广至更多课程与学科领域的下一步工作。"
  },
  {
    "date": "2026-1-13",
    "title": "The Future of AI-Powered Auditing: Enhancing Accuracy and Reducing Errors",
    "authors": "Siddharth S Karale, Sudip Debkumar Chatterji, Jaya Krishna Modadugu, Avinash Hanmant Ghadage, Hasan Ali Alsailawi, Mustafa Mudhafar",
    "publish": "2025 IEEE 5th International Conference on ICT in Business Industry &amp;amp; Government (ICTBIG)",
    "url": "https://doi.org/10.1109/ictbig68706.2025.11323708",
    "source": "IEEE",
    "abstract": "The adoption of artificial intelligence (AI) technologies is significantly improving monitoring functions while also transforming audit functions by providing increased precision, audit scalability, and real-time monitoring capabilities. In this paper, we propose an audit methodology based on artificial intelligence (AI) that incorporates the processes of data gathering, data cleansing, machine learning application, and anomaly detection to streamline error-prone audit processes and increase audit accuracy. A multi-stage model was built and tested in five industry sectors, and the model demonstrated better performance in anomaly detection and audit efficiency in all the sectors tested. The AI technologies have proven, using a novel-designed Audit Enhancement Index (AEI), to have substantially more efficiency in comparison to the traditional methods of auditing in a data-rich industry. An additional detailed workflow diagram and summary chart have been provided to visually demonstrate the advantages of the system over the traditional methods. AI can redefine the auditing processes from a post hoc examination of information to an ongoing, intelligent reevaluation of real-time data streams. This research has the potential to significantly advance automation in auditing and change perceptions of auditors to vision strategists empowered by instantaneous AI data analysis.",
    "title_zh": "人工智能驱动审计的未来：提升准确性并减少错误",
    "abstract_zh": "人工智能（AI）技术的采用显著提升了监控功能，同时通过提高审计的精确度、可扩展性以及实时监控能力，正在深刻变革审计工作。本文提出了一种基于人工智能的审计方法，该方法整合了数据收集、数据清洗、机器学习应用及异常检测等流程，旨在简化易出错的审计环节，提升审计准确性。我们构建并测试了一个多阶段模型，覆盖五个行业领域，结果显示该模型在所有测试行业中均表现出更优的异常检测能力和更高的审计效率。通过一种创新设计的“审计增强指数”（AEI），AI技术在数据密集型行业中的表现相较于传统审计方法展现出显著更高的效率。此外，本文还提供了详细的流程图和总结图表，直观展示了该系统相较于传统方法的优势。人工智能有望将审计过程从对历史信息的事后审查，转变为对实时数据流的持续智能评估。本研究具有显著推动审计自动化发展的潜力，并将重塑审计人员的角色，使其从传统的执行者转变为依托即时AI数据分析的战略规划者。"
  },
  {
    "date": "2026-1-13",
    "title": "Teaching Programming in the Age of AI: Transforming Pedagogy Amidst Code-Generating Technologies",
    "authors": "Asad Azemi",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328573",
    "source": "IEEE",
    "abstract": "This innovative to practice full-paper examines how the rapid evolution of artificial intelligence (AI) tools capable of generating code—exemplified by systems such as ChatGPT and GitHub Copilot—has instigated a pedagogical shift in how programming is taught and learned. As these AI tools become more deeply embedded in professional and academic practices, educators are compelled to reassess traditional pedagogical approaches and realign them with the demands of an AIaugmented future. This paper explores the profound implications of these developments for computer programming education, focusing on the challenges that instructors face and the promising opportunities for curricular innovation. While AI tools provide valuable learning assistance, they risk encouraging superficial understanding if students rely on them excessively. We begin by reviewing major challenges associated with the use of AI tools by students, such as the ease with which students can generate complete code solutions without engaging in the problem-solving process. The birth of code-generating AI also poses significant challenges in maintaining academic rigor and assessment fairness. We also cover a short review of strategies and processes that instructors are employing to combat this issue. Finally, we will present our proposed innovative approach, which includes the integration of AI into programming education by shifting the focus from merely producing code to designing and architecting software systems. This approach encourages students to use AI as a collaborative tool, fostering creativity, strategic thinking, and ethical reasoning. This approach requires greater emphasis on systems thinking and design, which can foster an entrepreneurial mindset.",
    "title_zh": "人工智能时代编程教学：在代码生成技术浪潮中重塑教育理念",
    "abstract_zh": "本文是一项具有创新性的实践研究，探讨了人工智能（AI）工具在代码生成方面的快速发展——以ChatGPT和GitHub Copilot等系统为代表——如何引发编程教学与学习方式的根本性变革。随着这些AI工具日益深入地融入专业与学术实践，教育工作者不得不重新审视传统的教学方法，并将其调整以适应一个由AI赋能的未来。本文深入分析了这一发展趋势对计算机编程教育带来的深远影响，重点关注教师面临的挑战以及课程改革所蕴含的广阔机遇。\n\n尽管AI工具为学习提供了宝贵支持，但如果学生过度依赖，也可能导致理解流于表面。本文首先回顾了学生使用AI工具所带来的一系列主要问题，例如学生可轻易生成完整的代码解决方案，却未真正参与问题求解过程。与此同时，代码生成型AI的兴起也对学术严谨性与评估公平性构成了严峻挑战。随后，文章简要梳理了教师们正在采取的应对策略与实践路径。最后，我们提出一种创新性教学方案：将AI深度融入编程教育，但将教学重点从单纯编写代码转向软件系统的整体设计与架构。该方案鼓励学生将AI视为协作伙伴，从而激发创造力、培养战略思维与伦理判断能力。这一新范式要求更加强调系统化思维与工程设计，有助于培育学生的创业精神与综合素养。"
  },
  {
    "date": "2026-1-13",
    "title": "A Retrospective Study to Understand Student Coding Style Quality via Static Analysis",
    "authors": "Francisco T. S. S. Pereira, Roberto A. Bittencourt, Elaine H. T. Oliveira, David B. F. De Oliveira",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328179",
    "source": "IEEE",
    "abstract": "This research full paper carries out an investigation of student code quality regarding coding style conventions with the support of static analyzers (SA). In programming courses, students need to learn both about code correctness and quality. Autograders have been used to support checking correctness of student code, but quality has mostly been ignored. SAs may be used to provide reports on code quality, such as checking whether students abide by coding standards and adequate coding style. Related work on student code quality in programming courses is scarce, especially in CS2 courses. The study analyzes a code dataset from 496 students from 10 different CS2 classes, and describes coding style issues both qualitatively and quantitatively. From prevalent style issues, we derived four metrics to summarize coding style problems related to formatting and naming identifiers. Then, we characterized student coding style to understand its relation with autograder student performance. Results provide more thorough understanding of student code quality regarding style, which may be useful to both researchers and instructors.",
    "title_zh": "通过静态分析理解学生编程风格质量的回顾性研究",
    "abstract_zh": "本研究论文深入探讨了在静态分析工具（SA）支持下，学生代码质量中的编码风格规范问题。在编程课程中，学生不仅需要掌握代码的正确性，还需关注代码质量。虽然自动评分系统已被广泛用于检测学生代码的正确性，但代码质量方面却长期被忽视。静态分析工具可用来生成代码质量报告，例如检查学生是否遵守编码标准以及是否具备良好的编码风格。目前关于编程课程中学生代码质量的研究相对较少，尤其是在CS2课程中更为稀缺。本研究分析了来自10个不同CS2班级共496名学生的代码数据集，从定性和定量两个角度描述了常见的编码风格问题。基于普遍存在的风格问题，我们提炼出四项指标，用以总结与格式化和标识符命名相关的编码风格缺陷。随后，我们对学生的编码风格进行了特征刻画，以探究其与自动评分系统中学生表现之间的关系。研究结果深化了人们对学生代码风格质量的理解，对研究人员和授课教师均具有重要参考价值。"
  },
  {
    "date": "2026-1-13",
    "title": "Can LLMs Classify CVEs? Investigating LLMs Capabilities in Computing CVSS Vectors",
    "authors": "Francesco Marchiori, Denis Donadel, Mauro Conti",
    "publish": "2025 IEEE Symposium on Computers and Communications (ISCC)",
    "url": "https://doi.org/10.1109/iscc65549.2025.11326354",
    "source": "IEEE",
    "abstract": "Common Vulnerability and Exposure (CVE) records are fundamental to cybersecurity, offering unique identifiers for publicly known software and system vulnerabilities. Each CVE is typically assigned a Common Vulnerability Scoring System (CVSS) score to support risk prioritization and remediation. However, score inconsistencies often arise due to subjective interpretations of certain metrics. As the number of new CVEs continues to grow rapidly, automation is increasingly necessary to ensure timely and consistent scoring. While prior studies have explored automated methods, the application of Large Language Models (LLMs), despite their recent popularity, remains relatively underexplored.In this work, we evaluate the effectiveness of LLMs in generating CVSS scores for newly reported vulnerabilities. We investigate various prompt engineering strategies to enhance their accuracy and compare LLM-generated scores against those from embedding-based models, which use vector representations classified via supervised learning. Our results show that while LLMs demonstrate potential in automating CVSS evaluation, embedding-based methods outperform them in scoring more subjective components, particularly confidentiality, integrity, and availability impacts. These findings underscore the complexity of CVSS scoring and suggest that combining LLMs with embedding-based methods could yield more reliable results across all scoring components.",
    "title_zh": "LLMs 能否分类 CVE？探究 LLM 在计算 CVSS 向量中的能力",
    "abstract_zh": "通用漏洞与暴露（CVE）记录是网络安全领域的基础，为已公开的软件和系统漏洞提供唯一的标识符。每个CVE通常会分配一个通用漏洞评分系统（CVSS）分数，以支持风险优先级排序和修复工作。然而，由于对某些指标的主观理解差异，评分不一致的情况时常发生。随着新CVE数量的迅速增长，自动化已成为确保评分及时性和一致性的必要手段。尽管以往研究已探索过多种自动化方法，但大型语言模型（LLM）尽管近年来广受关注，其在该领域的应用仍相对较少。本文评估了大型语言模型在生成新报告漏洞CVSS分数方面的有效性，探讨了多种提示工程策略以提升其准确性，并将LLM生成的分数与基于嵌入（embedding-based）的模型结果进行比较。后者采用向量表示并通过监督学习进行分类。研究结果表明，虽然LLM在自动化CVSS评估方面展现出潜力，但在处理更具主观性的评分维度——尤其是机密性、完整性和可用性影响方面，基于嵌入的方法表现更优。这些发现凸显了CVSS评分的复杂性，也表明将LLM与基于嵌入的方法相结合，可能在所有评分维度上实现更可靠的评估结果。"
  },
  {
    "date": "2026-1-13",
    "title": "Large Language Model-based defect detection in context of industry 5.0",
    "authors": "Kai Quan Foong, Saaveethya Sivakumar, King Hann Lim, Chye Ing Lim, Ing Ming Chew, Siew Eng Fui",
    "publish": "2025 International Conference on Green Energy, Computing and Sustainable Technology (GECOST)",
    "url": "https://doi.org/10.1109/gecost66002.2025.11324536",
    "source": "IEEE",
    "abstract": "The transition from manual labor to automation, driven by Industry 4.0 and the emerging Industry 5.0, has significantly transformed manufacturing. However, defects are still unavoidable in manufacturing, especially in the metal domain. To avoid substantial economic and reputational losses, defect detection is a must to guarantee long-term quality and durability of metal products. Despite high accuracy in defect detection, advanced Artificial Intelligence (AI) models like Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) can optimize production processes, improve efficiency, and lower operational costs. This drives the emergence of AI agents, which are autonomous systems powered by advanced AI models to efficiently perform complex tasks. Thus, this paper is aimed to address the question of how LLMs and MLLMs can enhance defect detection efficiency and interpretability in Industry 5.0 manufacturing systems. To achieve this, a comparative and conceptual analysis is conducted among the studies applying LLMs and MLLMs in a workflow, in terms of data collection, models, and evaluation metrics. In addition, this paper also further studies the practical applications and limitations encountered among the studies.",
    "title_zh": "基于大语言模型的工业5.0背景下的缺陷检测",
    "abstract_zh": "从手工劳动向自动化转型，由工业4.0及新兴的工业5.0所推动，已深刻改变了制造业格局。然而，在制造过程中，缺陷依然不可避免，尤其是在金属领域。为避免造成重大的经济损失和声誉损害，缺陷检测已成为确保金属产品长期质量与耐久性的必要环节。尽管现有的缺陷检测技术已具备高精度，但以大型语言模型（LLMs）和多模态大型语言模型（MLLMs）为代表的先进人工智能（AI）模型，仍能进一步优化生产流程、提升效率并降低运营成本。这一趋势催生了AI代理的出现——即基于先进AI模型的自主系统，能够高效完成复杂任务。因此，本文旨在探讨在工业5.0制造系统中，LLMs与MLLMs如何提升缺陷检测的效率与可解释性。为此，本文对应用于工作流中的LLMs与MLLMs相关研究进行了比较性与概念性分析，重点考察数据收集、模型架构以及评估指标等方面。此外，本文还深入研究了这些技术在实际应用中所面临的实践案例与局限性问题。"
  },
  {
    "date": "2026-1-13",
    "title": "Towards Personalized Programming Instruction Using Generative Language Models",
    "authors": "Julieto E. Perez, Jennifer Joyce M. Montemayor",
    "publish": "2025 IEEE Conference on Pervasive and Intelligent Computing (PICom)",
    "url": "https://doi.org/10.1109/picom68402.2025.00033",
    "source": "IEEE",
    "abstract": "As demand grows for flexible and personalized learning tools, especially for novice programmers, this work-in-progress investigates the use of generative language models to produce tailored explanations of programming concepts. In this study, GPT-3 was prompted to generate various explanation styles—direct, example-based, comparative, and analogical—to better align with diverse learner preferences. Human annotators evaluated and ranked the generated explanations, and their feedback was used to create a refined dataset. The generated dataset was then used to fine-tune a GPT-2 model, enabling it to produce context-aware and pedagogically relevant explanations. Preliminary results suggest that generative models can support the development of adaptive tutoring systems by generating educational content that responds to individual learning needs. Future work will focus on deeper evaluation, integration into interactive platforms, and assessing learner outcomes.",
    "title_zh": "使用生成式语言模型实现个性化编程教学",
    "abstract_zh": "随着对灵活且个性化的学习工具需求的增长，尤其是针对编程初学者，本项正在进行的研究探讨了利用生成式语言模型来提供量身定制的编程概念解释。在本研究中，通过向GPT-3提出不同类型的解释提示——直接型、基于示例型、对比型和类比型——以更好地契合多样化的学习者偏好。人类标注者对生成的解释进行了评估与排序，其反馈被用于构建一个优化后的数据集。该数据集随后被用于微调GPT-2模型，使其能够生成具有上下文感知能力且符合教学逻辑的解释内容。初步结果表明，生成式模型能够支持自适应辅导系统的开发，生成可响应个体学习需求的教育内容。未来的工作将聚焦于更深入的评估、将其集成到交互式平台中，并评估学习者的实际学习成效。"
  },
  {
    "date": "2026-1-13",
    "title": "TransMap: Transformer-Enhanced Divide-and-Conquer Reinforcement Learning Framework for Efficient CGRA Compilation",
    "authors": "Jingyuan Li, Wenbo Yin, Lingli Wang",
    "publish": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
    "url": "https://doi.org/10.1109/tcad.2026.3653869",
    "source": "IEEE",
    "abstract": "Coarse-grained reconfigurable architectures (CGRAs) combine flexibility with high performance, making them a promising solution for data-intensive computing. CGRA compilers are essential for determining how data flow graphs (DFGs) are executed on hardware. Recently, machine learning-based compilers have garnered significant attention for CGRA compilation. However, few deep learning compilers leverage the rich attentional information between DFGs and the CGRA abstractions effectively. Meanwhile, traditional compilers continue to struggle with inadequate compilation quality and long compilation time. In this paper, we propose a novel deep learning-based compiler that integrates transformer encoders with reinforcement learning (RL) to address these issues. The transformer encoder captures task dependencies by embedding feature maps from both the DFG and CGRA abstraction. Additionally, we design a tree-structured RL agent that employs spectral clustering to explore the extensive mapping solution space, optimizing task-to-resource allocation. Experimental results demonstrate that our method outperforms state-of-the-art (SOTA) compilers, achieving an average 1.22× improvement in compilation quality, a 33.39% increase in throughput, and a 12.83× speedup in compilation time, underscoring its potential to enhance CGRA performance.",
    "title_zh": "TransMap：一种基于Transformer增强的分治强化学习框架，用于高效CGRA编译",
    "abstract_zh": "粗粒度可重构架构（CGRAs）结合了灵活性与高性能，使其成为数据密集型计算的有前景解决方案。CGRA编译器对于确定数据流图（DFGs）在硬件上的执行方式至关重要。近年来，基于机器学习的编译器在CGRA编译领域受到广泛关注。然而，现有的深度学习编译器很少能有效利用DFG与CGRA抽象之间的丰富注意力信息。与此同时，传统编译器仍面临编译质量不足和编译时间过长的问题。本文提出了一种新型基于深度学习的编译器，将Transformer编码器与强化学习（RL）相结合，以解决上述问题。Transformer编码器通过嵌入来自DFG和CGRA抽象的特征图，捕捉任务间的依赖关系。此外，我们设计了一种树状结构的强化学习代理，采用谱聚类方法探索庞大的映射解空间，优化任务到资源的分配。实验结果表明，我们的方法优于当前最先进的（SOTA）编译器，在编译质量上平均提升1.22倍，吞吐量提高33.39%，编译时间加快12.83倍，充分展示了其在提升CGRA性能方面的巨大潜力。"
  },
  {
    "date": "2026-1-13",
    "title": "Decoding AI Impact: Longitudinal Analysis of Code Submissions in Programming MOOCs",
    "authors": "Leo Leppänen, Juho Leinonen, Arto Hellas, Erkki Kaila, Linda Mannila",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328633",
    "source": "IEEE",
    "abstract": "This full research paper investigates how the emergence of large language model (LLM)-based tools has influenced student code submissions in Massive Open Online Courses (MOOCs) on programming. The rise of LLMs has introduced new opportunities and challenges in programming education, particularly regarding how students approach programming tasks. As code submissions can be used as artifacts representing the learning process, analyzing submissions before and after the wide-spread adoption of LLMs can provide insight into changes in how and whether students' approaches to solving programming tasks have changed and more broadly whether the way how programming is practiced has evolved. Using programming assignment submission data from two University-level programming MOOCs, we explore whether and to what extent code submissions have changed after the emergence of LLMs. Our analyses focus on quantitative metrics from the MOOCs, including number of submissions, code lengths, stylistic aspects, and code complexity and originality. Our results highlight that there are some differences in the high-level metrics extracted from submissions between the pre- and post-LLM era, although the differences are largely subtle. We discuss possible reasons for the subtle differences.",
    "title_zh": "解码人工智能的影响：编程类MOOCs中代码提交的纵向分析",
    "abstract_zh": "本篇完整研究论文探讨了大型语言模型（LLM）相关工具的兴起对学生在编程类大规模开放在线课程（MOOCs）中提交代码行为的影响。随着LLM的出现，编程教育迎来了新的机遇与挑战，尤其是在学生应对编程任务的方式方面。由于代码提交可作为学习过程的实物证据，分析LLM广泛普及前后学生的代码提交情况，有助于深入了解学生解决编程问题的方法是否发生了变化，以及编程实践方式是否整体演进。本文基于两门大学级别编程MOOC的编程作业提交数据，探究LLM出现后代码提交行为是否以及在多大程度上发生了改变。我们的分析聚焦于MOOC中的量化指标，包括提交次数、代码长度、风格特征，以及代码的复杂度和原创性。研究结果表明，在LLM出现前后的提交数据中，高阶指标存在一些差异，但这些差异总体上较为细微。我们进一步讨论了导致这些细微差异的可能原因。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: Structured AI Tutoring in Engineering Education",
    "authors": "Alberto C. Cruz, Anjana Yatawara, Maruti Misha, Jianjun Wang",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328293",
    "source": "IEEE",
    "abstract": "This innovative practice Work-in-Progress paper presents a structured approach to integrating AI tutors into undergraduate engineering education at a Hispanic-Serving Institution. The study focuses on two upper-division computer architecture courses and explores how large language models (LLMs), such as ChatGPT-4o, can be scaffolded to support student learning. Our approach emphasizes guided AI interaction rather than direct answer generation. It is grounded in Vygotsky's Zone of Proximal Development and implemented through the ADDIE instructional design model. Two scaffolding protocols—AI Think-Aloud and AI-Driven Pair Programming—are proposed, that foster metacognitive engagement and collaborative problem-solving. The paper highlights the need for differentiated instruction aligned with Universal Design for Learning (UDL) to assist individuals who lack skills necessary to take advantage of LLMs. Preliminary findings suggest that structured AI integration can enhance learning outcomes and engagement, while minimizing risks associated with unregulated AI use. Evaluation methods include SOLO taxonomy analysis of student-AI interactions and short-term longitudinal survey data on student attitudes. The work contributes to emerging frameworks for ethical, inclusive, and pedagogically grounded AI adoption in engineering classrooms.",
    "title_zh": "正在进行中：工程教育中的结构化人工智能辅导",
    "abstract_zh": "本文是一篇创新性的工作进展论文，提出了一种将人工智能辅导工具融入本科工程教育的系统化方法，研究对象为一所服务于拉丁裔学生的高校中的两门高年级计算机体系结构课程。研究探讨了大型语言模型（LLMs），如ChatGPT-4o，在支持学生学习方面的应用潜力，并强调通过引导式AI互动而非直接生成答案来促进学习。该方法以维果茨基的“最近发展区”理论为基础，采用ADDIE教学设计模型进行实施。论文提出了两种支架式教学策略——“AI思维外显”与“AI驱动的结对编程”，旨在促进学生的元认知参与和协作问题解决能力。研究还强调，必须依据通用学习设计（UDL）理念实施差异化教学，以帮助那些缺乏有效利用LLM技能的学生。初步研究结果表明，经过结构化设计的AI整合能够提升学习成效与学生参与度，同时降低未经规范使用的AI所带来的风险。评估方法包括对学生与AI互动过程的SOLO分类法分析，以及关于学生态度的短期纵向调查数据。本研究为工程课堂中伦理、包容且具有教学根基的人工智能应用提供了新兴框架支持。"
  },
  {
    "date": "2026-1-13",
    "title": "Improving User Privacy Through Deep Learning: JavaScript Tracking Detection",
    "authors": "Aminah Alqahtani, Mounir Frikha, Ahmad Aljughaiman",
    "publish": "2025 IEEE Twelfth International Conference on Communications and Networking (ComNet)",
    "url": "https://doi.org/10.1109/comnet68251.2025.11325482",
    "source": "IEEE",
    "abstract": "The web environment has evolved from being dominated by individual or organizational content creation to a complex web of interrelated webpages featuring content from various third-party websites involved in activities like advertising and analytics. This shift, while contributing to free content and innovation, has raised significant privacy concerns. Many researchers have increasingly focused on the privacy implications of third-party tracking of users’ browsing activities. This paper provides an overview of existing tools designed to defend against various tracking methods. It proposes a framework that utilizes deep learning to counteract tracking practices by classifying JavaScript asking or functional snippet and compares it with existing privacy tools. The aim is to empower users to gain control over their online privacy. This innovative solution leverages deep learning techniques to identify JavaScript programs and enhance privacy defenses, ultimately striving to strengthen privacy in the web tracking domain by preventing detection evasion through code.",
    "title_zh": "通过深度学习提升用户隐私保护：JavaScript跟踪检测",
    "abstract_zh": "网络环境已从以个人或组织内容创作为主导，演变为一个由众多相互关联的网页构成的复杂体系，其中包含来自多个第三方网站的内容，这些内容涉及广告投放、数据分析等活动。这一转变虽然促进了免费内容和创新的发展，但也引发了严重的隐私问题。越来越多的研究者开始关注第三方对用户浏览行为进行追踪所带来的隐私风险。本文综述了现有用于抵御各类追踪手段的工具，并提出了一种利用深度学习技术来应对追踪行为的框架：通过分类JavaScript代码片段或功能代码，识别潜在的追踪行为，并与现有的隐私保护工具进行对比。该研究旨在帮助用户更好地掌控自身的在线隐私。这一创新方案借助深度学习技术，能够有效识别JavaScript程序，提升隐私防护能力，最终通过防止代码层面的检测规避，增强网络追踪领域的隐私保护效果。"
  },
  {
    "date": "2026-1-13",
    "title": "AI-assisted Intent-Mapping and translation for Digital Twins Network applications",
    "authors": "Pasquale Pace, Gianluca Aloi, Antonio Iera, Angelo Mendicelli, Paola Guarasci, Domenico Laurito",
    "publish": "2025 IEEE Conference on Pervasive and Intelligent Computing (PICom)",
    "url": "https://doi.org/10.1109/picom68402.2025.00017",
    "source": "IEEE",
    "abstract": "The aim of this work is to delve into an issue that is becoming strategic in the perspective of an effective management of future networks, namely the automatic mapping of user and network “intents” into a set of Key Value Indicators (KVI) and Key Performance Indicators (KPI) that measure the achievement of a specific goal. In particular, an effective method is proposed for an automatic translation of intents supported by artificial intelligence techniques based on large language models (LLM). Through a specific software platform, users are enabled to specify their intents in a natural or formal language, resulting in set of best-fit KVI, KPI and functional attributes to be satisfied by the QoS manager of a Digital Twin Networks (DTN). The followed approach ensures that intent-based network management can rapidly scale from simple and standardized deployments to highly customized expert-level configurations, while maintaining consistency and reliability.",
    "title_zh": "人工智能辅助的意图映射与翻译在数字孪生网络应用中的研究",
    "abstract_zh": "本研究旨在深入探讨一个在有效管理未来网络视角下日益重要的战略性问题，即如何将用户与网络的“意图”自动映射为一组关键值指标（KVI）和关键性能指标（KPI），以衡量特定目标的达成情况。具体而言，本文提出了一种基于大语言模型（LLM）的人工智能技术，实现意图的自动转换。通过一个专门的软件平台，用户可使用自然语言或形式化语言明确表达其意图，系统则自动生成最匹配的KVI、KPI及功能属性，供数字孪生网络（DTN）的服务质量（QoS）管理器参考执行。该方法确保了基于意图的网络管理能够从简单的标准化部署快速扩展至高度定制化的专家级配置，同时保持一致性和可靠性。"
  },
  {
    "date": "2026-1-13",
    "title": "An Agentic Reasoning-Based Feedback System for Programming Assignments",
    "authors": "Nor Anis Asma Sulaiman, Hazlina Haron, Nurshazwani Muhamad Mahfuz, Nurul Azlia Mat Saat, Siti Norbaya Daud, Syazwina Alias",
    "publish": "2025 IEEE 11th International Conference on Computing, Engineering and Design (ICCED)",
    "url": "https://doi.org/10.1109/icced68324.2025.11324743",
    "source": "IEEE",
    "abstract": "This study introduces Explain-then-Grade, an automated feedback framework designed for programming lab assignments using agent reasoning and large language models (LLMs). Unlike conventional auto-graders, which provide marks directly and general feedback, the proposed framework requires the agent to explain detected errors prior to assigning marks, thereby enhancing pedagogical value and transparency. The framework integrates sandboxed execution, on-the-fly test generation, and structured, stepwise explanatory reasoning, ensuring that students receive constructive, rubric-aligned feedback. To evaluate its effectiveness, the system was applied to anonymized submissions from a Data Mining module and complemented with open-source student code repositories. Performance was benchmarked against classic unit test-based auto-graders and LLM-only grading models, using five dimensions: grading accuracy, explanation quality, error coverage, and efficiency. Results demonstrate that Explain-then-Grade achieved higher grading reliability ($93 \\%$ accuracy, $\\kappa=0.85$), superior explanation quality (4.4/5), broader error coverage ($83.7 \\%$), and substantial time savings ($67 \\%$). These outcomes highlight its potential to support both traditional and open and distance learning (ODL) contexts by shifting automated assessment from mere evaluation toward formative, feedback-driven learning. The study establishes a structured agentic reasoning pipeline for reproducible and pedagogically aligned automated grading.",
    "title_zh": "基于代理推理的编程作业反馈系统",
    "abstract_zh": "本研究提出了一种名为“先解释后评分”（Explain-then-Grade）的自动化反馈框架，专为编程实验作业设计，利用智能体推理与大型语言模型（LLMs）实现。与传统自动评分系统直接给出分数和通用反馈不同，该框架要求智能体在打分前先解释所检测到的错误，从而显著提升教学价值与评分透明度。该框架融合了沙盒化执行、实时测试生成以及结构化、分步式的解释性推理机制，确保学生获得具有建设性且符合评分标准的反馈。\n\n为评估其有效性，系统被应用于某数据挖掘课程中匿名提交的作业，并结合开源学生代码仓库进行验证。性能对比了经典的基于单元测试的自动评分系统及仅使用LLM的评分模型，从五个维度进行衡量：评分准确性、解释质量、错误覆盖率和效率。结果表明，“先解释后评分”框架在各项指标上均表现优异：评分可靠性高达93%（准确率），Cohen's kappa值为0.85；解释质量达到4.4/5分；错误覆盖率达83.7%；同时节省了67%的评阅时间。\n\n这些成果凸显了该框架在支持传统教学与开放及远程学习（ODL）环境中的巨大潜力，推动自动化评估从单纯的评价功能转向以反馈为导向的形成性学习过程。本研究建立了一个结构化的智能体推理流程，实现了可复现且符合教学目标的自动化评分，为未来智能教育评估提供了可靠范式。"
  },
  {
    "date": "2026-1-13",
    "title": "Meet Your Mock Interviewer - MYMI: An AI Powered Mock Interview Simulation App",
    "authors": "Fasia Shahzad, Mariam Irfan Durrani, Muhammad Abdullah, Muhammad Ali",
    "publish": "2025 20th International Conference on Emerging Technologies (ICET)",
    "url": "https://doi.org/10.1109/icet66147.2025.11321463",
    "source": "IEEE",
    "abstract": "In the current job market, young graduates face challenges in technical interviews, despite having an extensive technical background, due to their limited communication ability and unfamiliarity with the standard interview methodology. The inability to communicate their technical expertise in an interview becomes a key factor of their failure. In order to bridge this gap, we propose Meet Your Mock Interviewer (MYMI), a web-based platform that aids aspiring software engineers prepare for technical interviews through AI-driven, voice-based simulations. The platform features an AI Interviewer that asks interview questions, listens to responses, and generates follow-up questions during the session. At the end of each interview session, a large language model evaluates the interviewee’s performance both in terms of coding performance and the ability to \"think out loud\", followed by a detailed feedback that can be tracked through a personalized dashboard with clear visual metrics. MYMI integrates LLM, and speech-to-text (STT) and text-tospeech (TTS) which powers the AI interviewer. MYMI features a code editor with a support for multiple languages, including Python, JavaScript, Java, and C++, allowing interviewees to practice in the coding language they are the most comfortable with. Combining AI evaluation and voice interactions with coding practice, MYMI bridges the gap between traditional interview preparation and real-world readiness, preparing young minds for the real-world technical interview.",
    "title_zh": "认识你的模拟面试官——MYMI：一款由人工智能驱动的模拟面试应用",
    "abstract_zh": "在当前的就业市场中，尽管应届毕业生拥有扎实的技术背景，却因沟通能力有限以及对标准面试流程不熟悉，在技术面试中面临诸多挑战。无法在面试中有效表达自己的技术专长，成为他们失败的关键因素。为弥补这一差距，我们提出了“Meet Your Mock Interviewer”（MYMI）——一个基于网络的平台，通过人工智能驱动的语音模拟，帮助有志于成为软件工程师的年轻人更好地准备技术面试。\n\nMYMI平台配备了一位AI面试官，能够提出面试问题、听取应答，并在对话过程中生成追问问题，实现高度仿真的面试体验。每次面试结束后，大型语言模型（LLM）将从编码表现和“边思考边表达”（think out loud）的能力两个维度对面试者进行评估，并提供详尽的反馈报告。所有反馈均可通过个性化的仪表盘进行追踪，以清晰的可视化数据呈现进步情况。\n\nMYMI集成了大语言模型（LLM）、语音转文本（STT）和文本转语音（TTS）技术，支撑其AI面试官的核心功能。平台还内置支持多种编程语言的代码编辑器，包括Python、JavaScript、Java和C++，使用户能够在最熟悉的编程环境中进行练习。\n\n通过结合AI评估、语音交互与实际编码训练，MYMI成功弥合了传统面试准备与真实职场需求之间的鸿沟，帮助年轻人才全面提升应对现实技术面试的综合能力。"
  },
  {
    "date": "2026-1-13",
    "title": "LLM-enhanced Intent-Aware for Proactive Decision Support Services in Industrial Activities_supp1-3650172.pdf",
    "authors": "Hongwei Jiang",
    "publish": "N/A",
    "url": "https://doi.org/10.1109/tase.2025.3650172/mm1",
    "source": "IEEE",
    "abstract": "The growing complexity of industrial systems demands a transition from passive monitoring to proactive decision support, a shift that hinges on advanced intelligent perception. However, most systems remain confined to brittle, rule-based logic, which operates on fixed symptom-to-action mappings and thus cannot perceive the underlying, context-dependent operational intent. This perceptual gap is particularly detrimental especially in fault diagnosis, where this inability to adapt leads to frequent misdiagnoses and costly downtime. To overcome this limitation, this paper introduces the Intent-Aware Enhancement Framework (IAEF)<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>, which replaces static rules by actively creating and reasoning over a dynamic causal model. This is achieved through two core method. The Information Theory-guided Causal Graph Revision (ITCGR) algorithm provides the foundation by constructing a reliable causal model, uniquely leveraging information-theoretic metrics to guide an LLM for verifiable revisions on sparse data. Building on this model, the Multi-scale Adaptive Path Reasoning (MAPR) method then infers the true operational intent, employing a novel adaptive fusion model to robustly navigate complex inference chains. Experimental validation in a real-world case demonstrates the framework’s ability to accurately diagnose fault root causes under varying conditions, a task where traditional systems fail. The proposed approach significantly outperforms baselines, providing a foundational methodology for advancing industrial intelligence.",
    "title_zh": "LLM增强的意图感知工业活动主动决策支持服务_supp1-3650172.pdf",
    "abstract_zh": "工业系统日益复杂的趋势，要求从被动监控转向主动决策支持，而这一转变的关键在于先进的智能感知能力。然而，目前大多数系统仍局限于脆弱的规则逻辑，其基于固定的症状-动作映射，无法感知上下文依赖的操作意图。这种感知上的差距在故障诊断中尤为致命，因为系统缺乏适应性，导致频繁误诊和高昂的停机成本。为克服这一局限，本文提出了一种意图感知增强框架（Intent-Aware Enhancement Framework, IAEF）<sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>，该框架以动态因果模型的主动构建与推理取代静态规则。这一目标通过两种核心方法实现：信息论引导的因果图修订（Information Theory-guided Causal Graph Revision, ITCGR）算法奠定了基础，它利用信息论度量指导大语言模型（LLM）对稀疏数据进行可验证的因果图修正，从而构建可靠的因果模型；在此基础上，多尺度自适应路径推理（Multi-scale Adaptive Path Reasoning, MAPR）方法进一步推断真实操作意图，采用一种新颖的自适应融合模型，有效应对复杂的推理链条。在真实案例中的实验验证表明，该框架能够在不同工况下准确诊断故障根源，而传统系统则难以胜任此类任务。所提方法显著优于基线方案，为推动工业智能化发展提供了基础性的方法论支撑。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: Assessing the Use of GenAI to Foster Algorithmic Thinking in an Introductory Engineering Course",
    "authors": "Juan D. Ortega-Alvarez, Campbell R. Bego, Andres Nieto Leal",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328388",
    "source": "IEEE",
    "abstract": "This work-in-progress research paper focuses on algorithmic thinking and GenAI use for programming within a first-year engineering course. In introductory programming courses, students may use GenAI to generate correct solutions without fully engaging in the assignments, thus circumventing the learning process. But students may also engage with GenAI in ways that improve their algorithmic thinking ability. Research is needed to understand whether and how GenAI can be integrated to improve first-year engineering students' programming skills. A necessary first step in this direction is establishing relevant competencies and assessments. In Fall 2024, students in an introductory engineering course at Virginia Tech were permitted to use GenAI within fair use conditions. At the end of the semester, students responded to two instruments: 1) an anonymous survey asking whether and how they used GenAI to submit assignments during the programming unit of the course, and 2) a simplified version of an existing algorithmic thinking instrument. Preliminary findings indicate that around 70% of students reported using GenAI to assist with programming assignments without explicit guidance, though over 80% characterized this use as occasional. More than 75% of students reported using GenAI primarily for syntax assistance. The algorithmic thinking results suggest substantial variability in skill level across students, regardless of their self-reported programming experience. This study suggests that algorithmic thinking, as measured by an abbreviated scale in introductory programming courses, may not correlate with other desirable programming outcomes, like assignment performance, and additional measures may be needed to evaluate the impact of GenAI.",
    "title_zh": "正在进行中：评估生成式人工智能在入门工程课程中促进算法思维的应用",
    "abstract_zh": "本项正在进行中的研究论文聚焦于算法思维与生成式人工智能（GenAI）在一年级工程课程编程教学中的应用。在入门级编程课程中，学生可能利用GenAI生成正确答案，而未充分参与作业任务，从而绕过了学习过程。然而，学生也可能以某些方式使用GenAI，进而提升其算法思维能力。因此，亟需开展研究，以理解GenAI如何以及在何种程度上能够被整合到教学中，以提升一年级工程专业学生的编程技能。迈向这一目标的必要第一步，是建立相关核心能力标准及评估方法。\n\n2024年秋季学期，弗吉尼亚理工大学一门入门级工程课程允许学生在合理使用范围内使用GenAI。学期末，学生们完成了两项调查工具：1）一份匿名问卷，询问他们在课程编程单元期间是否以及如何使用GenAI提交作业；2）一份现有算法思维测评工具的简化版本。初步结果显示，约70%的学生报告在没有明确指导的情况下使用GenAI辅助编程作业，但超过80%的学生将这种使用描述为“偶尔”行为。超过75%的学生表示，他们主要使用GenAI获取语法帮助。\n\n算法思维测评结果表明，学生之间的能力差异显著，且这种差异与学生自我报告的编程经验无关。该研究提示，在入门级编程课程中，通过简化的量表所测量的算法思维能力，可能与作业表现等其他理想的编程成果并无明显关联。因此，为全面评估GenAI的影响，可能需要引入更多元的评价指标。"
  },
  {
    "date": "2026-1-13",
    "title": "The Impact of a GenAI Integration on First-Year Engineering Students' Programming Outcomes",
    "authors": "Udit K. Das, Makenzie S. Yates, Kristina A. Bloch, Lilly Hagan, Elisabeth L. Thomas, Gabe Gatos, Alwin K. Rajkumar, Benarji Valavala, Seth Franco, Sudheer K. Divvela, Angela K. Thompson, Campbell R. Bego",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328708",
    "source": "IEEE",
    "abstract": "This full-length research study compares first-year engineering student performance on a summative programming assignment before and after integrating Generative AI (GenAI) into the assignment. The code-writing capabilities of GenAI technology can potentially help introductory engineering students with programming. However, the limitations of GenAI, especially its tendency to produce hallucinations, might confuse and/or overwhelm novice programmers. Using a quasi-experimental design, we compared student performance on a final programming project from two consecutive years: one without GenAI support (2022) and one with a guided GenAI integration (2023). The assignment was such that GenAI tools were not likely to complete it correctly solely from the written instructions, and thus students were required to think critically about both programming and GenAI to develop a successful program. Student-submitted programs were evaluated in terms of program accuracy, communication, and functionality using a scoring rubric. It was anticipated that GenAI would improve program functionality, but unknown whether it would have the same positive impact on accuracy and communication based on its limitations. Results revealed a significant overall improvement in programming outcomes from 2022 to 2023, with significantly higher scores for accuracy and communication observed for the with-GenAI group than the without-GenAI group. Functionality scores remained consistently high (at ceiling). These findings suggest that a guided GenAI integration can enhance novice student programming outcomes despite its limitations. GenAI tools are expected to become increasingly valuable for introductory engineering programming instruction and for programming as a field.",
    "title_zh": "生成式人工智能集成对一年级工程专业学生编程成果的影响",
    "abstract_zh": "本项全长度研究比较了在将生成式人工智能（GenAI）整合到作业中前后，一年级工程专业学生在总结性编程任务中的表现。GenAI技术的代码编写能力可能有助于初学工程的学生掌握编程技能。然而，GenAI存在局限性，尤其是其容易产生“幻觉”的特性，可能会使编程新手感到困惑甚至不知所措。本研究采用准实验设计，对比了连续两年学生在期末编程项目中的表现：2022年未使用GenAI支持，2023年则引入了指导性的GenAI整合。该任务的设计使得仅凭文字说明，GenAI工具难以正确完成，因此学生必须对编程和GenAI本身进行批判性思考，才能成功开发出程序。学生提交的程序依据程序准确性、沟通表达和功能实现三个维度，通过评分量表进行评估。研究预期GenAI能提升程序的功能性，但其对准确性和沟通表达的影响尚不明确，因受限于技术本身的缺陷。研究结果表明，从2022年到2023年，编程成果整体显著提升，使用GenAI组在准确性和沟通表达方面得分显著高于未使用GenAI组。而功能得分始终处于高水平（接近满分）。这些发现表明，尽管GenAI存在局限性，但在有指导的整合方式下，仍可有效提升初学者的编程学习成效。未来，GenAI工具预计将在工程入门编程教学以及整个编程领域中发挥越来越重要的作用。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: How Effective are Llm-Implemented Autograders for Programming Assignments Compared to Human Graders?",
    "authors": "Kevin Lewis, Hui Chen",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328152",
    "source": "IEEE",
    "abstract": "This research-to-practice WIP paper describes the development and evaluation of a generative Large Language Model (gLLM)-based autograder for computer programming assignments. Manual grading is becoming increasingly unsustainable due to growing student enrollment and the demand for timely, high-quality feedback. To address these challenges, this study explores the use of automated grading tools to reduce instructors' workload and improve scalability. The proposed autograder takes a “reverse-engineering” approach, i.e., it converts student code into structured natural language summaries, which are then compared against predefined grading rubrics. An evaluation is performed using an external dataset (the Menagerie dataset), which contains real student submissions graded by four human graders. The objective is to assess the alignment between grades assigned by the autograder and those assigned by human graders. Findings indicate that the autograder closely matches human grading when letter grades are considered, though it performs less accurately with fine-grained numerical scores. While not yet a complete substitute for human assessment, the autograder shows strong potential as a scalable, efficient tool for supporting grading in programming education.",
    "title_zh": "正在进行中：与人工评分相比，基于大语言模型的自动评分系统在编程作业评分中的有效性如何？",
    "abstract_zh": "本篇从研究到实践的进展论文描述了一种基于生成式大语言模型（gLLM）的自动评分系统在计算机编程作业中的开发与评估。由于学生人数持续增长，以及对及时、高质量反馈的需求日益增加，人工评分正变得越来越不可持续。为应对这些挑战，本研究探索了使用自动化评分工具以减轻教师工作负担并提升可扩展性。所提出的自动评分系统采用“逆向工程”方法：将学生的代码转换为结构化的自然语言摘要，然后与预设的评分标准进行比对。研究使用外部数据集（即Menagerie数据集）进行了评估，该数据集包含由四位人类评分员评定的真实学生提交作业。研究目标是评估自动评分系统与人类评分者之间评分结果的一致性。研究发现，当考虑字母等级时，自动评分系统与人类评分高度一致；但在细粒度数值分数方面表现稍差。尽管目前尚不能完全替代人工评估，但该自动评分系统展现出作为可扩展、高效支持编程教育评分工具的巨大潜力。"
  },
  {
    "date": "2026-1-13",
    "title": "Optimizing Secure Elements Implementation Methods for a seamless Post-Quantum Transition",
    "authors": "Eros Camacho-Ruiz, Pablo Navarro-Torrero, Macarena C. Martínez-Rodríguez, Piedad Brox",
    "publish": "2025 IEEE Symposium on Computers and Communications (ISCC)",
    "url": "https://doi.org/10.1109/iscc65549.2025.11326228",
    "source": "IEEE",
    "abstract": "The adoption of Post-Quantum Cryptography over the security network layer, such as Transport Layer Security, poses significant challenges, particularly in the context of Internet of Things (IoT) devices, where power and area constraints frequently limit the adoption of hardened security features. In addressing this challenge, hardware-based Secure Elements become a crucial component in facilitating cryptographic operations and storing secret keys within these frameworks. However, the design and validation of such hardware modules require substantial time investment. Consequently, this can result in the allocation of time that could be utilized for the development of other essential components of the Post-Quantum Transition. In this context, the present work proposes a methodology for the integration of Secure Elements on IoT devices, with the objective of reducing the time required for design and validation. To this end, two distinct categories of IoT devices (microcontrollers and embedded processors) have been employed to encompass the broadest possible range of IoT devices. The outcome of this study is the delivery of an open-source cryptographic library that can be deployed in any type of IoT devices. This library facilitates the implementation of Post-Quantum Cryptography in Secure Elements enabling crypto-agility and ensuring a smooth PostQuantum transition for IoT.",
    "title_zh": "优化安全元件的实现方法以实现平滑的后量子过渡",
    "abstract_zh": "在安全网络层（如传输层安全协议）中采用后量子密码学带来了重大挑战，尤其是在物联网（IoT）设备的背景下，这些设备通常受制于功耗和面积的限制，难以部署强化的安全功能。为应对这一挑战，基于硬件的可信安全元件（Secure Elements）成为实现加密操作和存储密钥的关键组件。然而，这类硬件模块的设计与验证需要大量时间投入，从而可能挤占本可用于开发后量子过渡其他关键组件的时间。针对这一问题，本文提出了一种在物联网设备中集成安全元件的方法论，旨在缩短设计与验证所需时间。为此，研究选取了两类典型的物联网设备——微控制器和嵌入式处理器，以覆盖尽可能广泛的物联网设备类型。本研究的成果是发布了一个开源密码学库，可部署于各类物联网设备中。该库支持在安全元件中实现后量子密码算法，具备密码灵活性（crypto-agility），并确保物联网设备能够平稳完成向后量子时代的过渡。"
  },
  {
    "date": "2026-1-13",
    "title": "Methods for Estimating Programming Logics Using Machine Learning that Adopts Syntax Trees as Training Data",
    "authors": "Mitsuhiro Sato, Ryo Onuma, Sho Onami, Hiroki Nakayama, Hiroaki Kaminaga, Youzou Miyadera, Shoichi Nakamura",
    "publish": "2025 IEEE International Conference on Computing (ICOCO)",
    "url": "https://doi.org/10.1109/icoco67189.2025.11334119",
    "source": "IEEE",
    "abstract": "Opportunities for conducting programming education have been increasing, and as such, the demand for its assistance is growing. In order to effectively instruct learners in programming exercises, it is important to grasp the situation of individual learners. However, it is often difficult to do so when a few teachers are responsible for a large number of learners. In addition, the directions taken to construct a program (called programming logics) differ by each learner, even for the same challenge in the programming exercise, which can be particularly difficult for teachers to grasp. While there are many methods for supporting programming exercises, none are able to deal with the diversity of programming logics. Our objective is therefore to develop methods for estimating programming logics from incomplete source codes under being written by individual learners. In this paper, we mainly describe methods for estimating programming logics by means of machine learning that adopts syntax trees as training data. Our experimental findings demonstrate the basic effectiveness of our methods.",
    "title_zh": "基于语法树作为训练数据的机器学习方法在编程逻辑估计中的应用",
    "abstract_zh": "开展编程教育的机会日益增多，因此对其支持的需求也在不断增长。为了有效指导学习者完成编程练习，掌握每位学习者的具体情况至关重要。然而，当少数教师需要负责大量学习者时，这种掌握往往十分困难。此外，即使面对相同的编程练习挑战，每位学习者所采用的程序构建方式（称为编程逻辑）也各不相同，这给教师理解带来了额外挑战。尽管已有多种方法可用于支持编程练习，但目前尚无一种能够有效应对编程逻辑的多样性。因此，我们的目标是开发一种方法，能够从学习者正在编写中的不完整源代码中估计其编程逻辑。本文主要介绍一种基于机器学习的方法，该方法以语法树作为训练数据来估计编程逻辑。实验结果表明，本方法具有基本的有效性。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: Exploratory Analysis of Code Quality Issues in CS1",
    "authors": "Isabela Vieira Rodrigues, Igor dos Santos Montagner",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328215",
    "source": "IEEE",
    "abstract": "In this Research-to-practice WIP paper we present an analysis of the integration of a code quality tool into a bootcamp-style CS1 course, with a focus on correlating quality issues with a superficial understanding of programming by examining the relationship between code quality issues and limited programming comprehension. Although initially studied in the context of Software Engineering courses, there has also been interest in including code quality in CS1/2 levels. In this paper we examine two main questions: (i) which types of errors do students make when solving CS1 coding questions?, and (ii) is there a correlation between certain types of errors and student performance? We hypothesize that the type and frequency of errors are inversely proportional to students' performance and proportional to assignment complexity. We added a code quality tool to all assignments of an intensive CS1 course and did a retrospective analysis using data from two course offerings in 2024 (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathrm{N}=66$</tex> students, <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathrm{N}=851$</tex> code submissions). We analyze 5 high-stakes exams and 5 low-stakes quizzes, computing the frequency and type of the issues flagged. We also correlate each issue type with students' performance. Our analysis shows that most code quality issues identified in student submissions are related to formatting and style, not to code structure. Tasks involving more complex data structures, such as lists and dictionaries, tend to have a higher frequency of code structure-related issues. However, student performance was inversely proportional to issues that were not related to code structure, such as formatting or incorrect use of Python features. Finally, high-performing students still produce code with a significant amount of code quality issues.",
    "title_zh": "开发中：对CS1代码质量问题的探索性分析",
    "abstract_zh": "在本篇“研究到实践”工作论文中，我们分析了将代码质量工具整合进以训练营模式开展的CS1课程中的实践情况，重点探讨了代码质量问题与学生对编程的浅层理解之间的关联，即通过考察代码质量缺陷与编程理解局限性之间的关系。尽管这类研究最初主要集中在软件工程课程中，但近年来也逐渐引起对在CS1/2级别引入代码质量关注的兴趣。本文主要探讨两个问题：(i) 学生在解决CS1编程题目时会犯哪些类型的错误？(ii) 某些特定类型的错误是否与学生表现存在相关性？我们假设：错误的类型和频率与学生表现呈负相关，而与作业复杂度呈正相关。为此，我们在一个高强度的CS1课程的所有作业中引入了代码质量工具，并基于2024年两次课程授课的数据（共66名学生，851次代码提交）进行了回顾性分析。我们分析了5次高权重考试和5次低权重测验，统计并分类了系统标记出的问题频率与类型，并进一步将每类问题与学生的成绩表现进行相关性分析。研究结果表明，学生提交代码中发现的大多数代码质量问题是关于格式与风格，而非代码结构本身。涉及更复杂数据结构（如列表和字典）的任务，其代码结构相关问题的出现频率更高。然而，学生的表现却与非结构类问题（如格式不当或Python特性误用）呈显著负相关。最后，值得注意的是，表现优异的学生依然会产生大量代码质量方面的问题。"
  },
  {
    "date": "2026-1-13",
    "title": "Enhancing Large Language Models for Automated Homework Assessment in Undergraduate Circuit Analysis",
    "authors": "Liangliang Chen, Huiru Xie, Zhihao Qin, Yiming Guo, Jacqueline Rohde, Ying Zhang",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328374",
    "source": "IEEE",
    "abstract": "This research full paper presents an enhancement pipeline for large language models (LLMs) in assessing homework for an undergraduate circuit analysis course, aiming to improve LLMs' capacity to provide personalized support to electrical engineering students. Existing evaluations have demonstrated that GPT-4o possesses promising capabilities in assessing student homework in this domain. Building on these findings, we enhance GPT-4o's performance through multi-step prompting, contextual data augmentation, and the incorporation of targeted hints. These strategies effectively address common errors observed in GPT-4o's responses when using simple prompts, leading to a substantial improvement in assessment accuracy. Specifically, the correct response rate for GPT-4o increases from 74.71% to 97.70% after applying the enhanced prompting and augmented data on entry-level circuit analysis topics. This work lays a foundation for the effective integration of LLMs into circuit analysis instruction and, more broadly, into engineering education.",
    "title_zh": "提升大型语言模型在本科生电路分析自动作业评估中的应用",
    "abstract_zh": "本文研究论文提出了一种针对大型语言模型（LLMs）在本科电路分析课程作业评估中的增强处理流程，旨在提升LLMs为电气工程学生提供个性化支持的能力。现有评估表明，GPT-4o在该领域对学生作业的评估中展现出令人瞩目的潜力。基于这些发现，我们通过多步提示设计、上下文数据增强以及引入针对性提示等策略，进一步提升了GPT-4o的表现。这些方法有效解决了在使用简单提示时GPT-4o常出现的错误，显著提高了评估准确性。具体而言，在基础电路分析主题上，应用增强提示与扩充数据后，GPT-4o的正确回答率从74.71%提升至97.70%。本研究为大型语言模型在电路分析教学中的有效整合奠定了基础，并为工程教育领域的广泛应用提供了重要参考。"
  },
  {
    "date": "2026-1-13",
    "title": "Comparative Evaluation of Large Language Models for Test-Skeleton Generation",
    "authors": "Subhang Boorlagadda, Nitya Naga Sai Atluri, Muhammet Mustafa Ölmez, Edward F. Gehringer",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328463",
    "source": "IEEE",
    "abstract": "This paper explores the use of Large Language Models (LLMs) to automate the generation of test skeletonsstructural templates that outline unit test coverage without implementing full test logic. Test skeletons are especially important in test-driven development (TDD), where they provide an early framework for systematic verification. Traditionally authored manually, their creation can be timeconsuming and error-prone, particularly in educational or large-scale development settings. We evaluate four LLMs-GPT-4, DeepSeek-Chat, Llama4-Maverick, and Gemma2-9Bon their ability to generate RSpec skeletons for a real-world Ruby class developed in a university software engineering course. Each model's output is assessed using static analysis and a blind expert review to measure structural correctness, clarity, maintainability, and conformance to testing best practices. The study reveals key differences in how models interpret code structure and testing conventions, offering insights into the practical challenges of using LLMs for automated test scaffolding. Our results show that DeepSeek generated the most maintainable and well-structured skeletons, while GPT-4 produced more complete but conventionally inconsistent output. The study reveals prompt design and contextual input as key quality factors.",
    "title_zh": "大型语言模型在测试骨架生成中的比较评估",
    "abstract_zh": "本文探讨了大型语言模型（LLMs）在自动化生成测试骨架（test skeletons）方面的应用，这些骨架是不包含完整测试逻辑的单元测试结构模板，仅用于概述测试覆盖范围。在测试驱动开发（TDD）中，测试骨架尤为重要，它们为系统性验证提供了早期框架。传统上，这些骨架由人工编写，其创建过程耗时且容易出错，尤其在教育环境或大规模开发项目中更为明显。本研究评估了四种LLM——GPT-4、DeepSeek-Chat、Llama4-Maverick和Gemma2-9B——在生成某所大学软件工程课程中实际开发的Ruby类的RSpec测试骨架方面的能力。通过静态分析与盲评专家评审相结合的方式，对各模型输出的结构正确性、清晰度、可维护性以及是否符合测试最佳实践进行了评估。研究揭示了不同模型在理解代码结构和测试规范方面的显著差异，深入反映了使用LLMs进行自动化测试 scaffolding 的实际挑战。结果表明，DeepSeek生成的测试骨架在可维护性和结构合理性方面表现最佳，而GPT-4虽生成内容更完整，但在测试规范一致性方面存在不足。研究还指出，提示设计（prompt design）和上下文输入是影响输出质量的关键因素。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: System Concept Compilation: A Generative AI Approach to Systems Modeling and Simulation",
    "authors": "Jon Wade, Richard Gessner",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328410",
    "source": "IEEE",
    "abstract": "This work-in-progress research-to-practice paper describes the design, deployment, and evaluation of a systems engineering modeling and simulation course that leverages generative artificial intelligence (AI) and cloud-based tools to focus on problem formulation and foundational principles. The approach significantly elevates the scope of the course by radically reducing the need for detailed supporting instruction on tools, languages, and syntax. A class of professional students with little or no programming or modeling experience was enabled to utilize modeling and simulation to address a real-world systems engineering challenge. Results indicate that student performance far exceeded what was achievable in the past using standard engineering approaches, with dramatically increased willingness and capability to apply modeling and simulation in professional practice. The success of this approach and lessons learned will inform the redesign of other courses in the systems engineering master's program, with potential implications for engineering education more broadly.",
    "title_zh": "正在进行中：系统概念汇编——一种生成式人工智能的系统建模与仿真方法",
    "abstract_zh": "本篇正在进行中的研究-实践论文描述了一门系统工程建模与仿真课程的设计、实施与评估，该课程利用生成式人工智能（AI）和基于云的工具，聚焦于问题定义与基础原理。这一方法显著拓展了课程的广度，从根本上减少了对工具、语言和语法等细节性教学的需求。一群几乎没有编程或建模经验的专业学生，成功运用建模与仿真技术应对了一个真实的系统工程挑战。结果表明，学生的表现远超以往采用传统工程方法所能达到的水平，其在专业实践中应用建模与仿真的意愿和能力均得到显著提升。该方法的成功经验及所获教训将为系统工程硕士项目中其他课程的重构提供参考，同时也可能对工程教育领域产生更广泛的影响。"
  },
  {
    "date": "2026-1-13",
    "title": "WIP: Automated Extraction of Domain-Specific Concept Maps Using a RAG-LLM Ensemble Framework",
    "authors": "Zane Hutchens, Qiong Cheng",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328309",
    "source": "IEEE",
    "abstract": "This work-in-progress research-to-practice paper explores the development of an explainable, AI-driven ensemble framework for automatically generating subject-specific concept hierarchies from eTextbooks. Concept graphs play a central role in modern intelligent tutoring systems (ITSs), as they organize domain knowledge and support the tracking of student progress while enabling personalized and adaptive learning pathways or recommendations. Recent studies have explored the use of large language models (LLMs) to extract concept maps, but the generalized nature of LLM training introduces challenges such as hallucinations, mathematical errors, and biases, leading to uncertainty in their outputs. To address these limitations, this study integrates retrieval-augmented generati6ton (RAG)-based techniques with LLMs including Gemini-1.5-flash and Gemma-3. We integrated these models with classical machine learning methods and evaluated our RAG-LLM framework using referencefree verification through multiple benchmarking methods, ensuring reliability and reducing uncertainty in the generated concept graphs. We have been employing CS2-DS as an example to investigate the efficacy of the RAG-based AI-driven ensemble approach. Our preliminary findings indicate good evaluation scores on the following test cases: relevance of answers, context faithfulness, context precision, and context recall. Further systematic investigation will focus on refining and evaluating the use of the framework and comparing different models and fine-tuning techniques.",
    "title_zh": "正在进行中：基于RAG-LLM集成框架的领域特定概念图自动提取",
    "abstract_zh": "本篇正在进行中的研究实践论文探讨了一种可解释的、基于人工智能的集成框架的开发，该框架能够从电子教科书中自动构建特定学科的概念层次结构。概念图在现代智能辅导系统（ITS）中起着核心作用，它组织领域知识，支持对学生学习进展的追踪，并实现个性化与自适应的学习路径或推荐。近期研究尝试利用大型语言模型（LLMs）提取概念图，但LLM训练的通用性带来了诸如幻觉、数学错误和偏见等问题，导致其输出存在不确定性。为解决这些局限性，本研究将基于检索增强生成（RAG）的技术与Gemini-1.5-flash、Gemma-3等大型语言模型相结合，并融合经典机器学习方法。我们通过无参考验证及多种基准测试方法对所提出的RAG-LLM框架进行了评估，以确保生成概念图的可靠性并降低不确定性。本文以CS2-DS为例，探究基于RAG的AI驱动集成方法的有效性。初步结果表明，在以下测试指标上取得了良好表现：答案的相关性、上下文忠实度、上下文精确率和上下文召回率。后续的系统性研究将聚焦于进一步优化和评估该框架的应用，并比较不同模型及微调技术的效果。"
  },
  {
    "date": "2026-1-13",
    "title": "Code Insight: Evaluating an Active Learning Framework for Novice Programmers to Promote the Development of Code Review Skills",
    "authors": "Keerti Banweer, Deborah Trytten",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328622",
    "source": "IEEE",
    "abstract": "The full research paper describes an active learning based in-class intervention to encourage the development of code review and debugging skills in students from the CS program. The rapid proliferation of AI-based applications has heightened the importance of code review and debugging skills among software developers. Organizations leverage code review processes not only to ensure software quality and accuracy but also to facilitate knowledge transfer, promote productive collaboration, maintain consistency, and share ideas. However, incorporating code review practices into classroom settings presents challenges due to the associated heavy workload, often resulting in low student motivation and participation. To address these issues, we propose an in-class active learning framework, Code Insight, which integrates seamlessly into class lectures without adding extra workload for students or additional grading for instructors. Recognizing that beginner programmers have limited knowledge and experience with programming concepts, the goal of this study is to provide strategic guidance to help students effectively and systematically review, analyze, and evaluate existing code written by others, thereby gaining a deeper understanding of the code. In our study, students participated in the Code Insight activity during class, using a classroom response system to report the correctness of provided code through multiple-choice questions. The impact of Code Insight on learning is evaluated by collecting student feedback at the end of the semester. Our findings indicate that the Code Insight activity presents a sufficient challenge for students, thereby improving their learning experience and highlighting the necessity of integrating more extensive code review practices in entry-level programming courses. Students expressed a preference for these activities over traditional lectures, noting that they helped them debug their programs by identifying and fixing errors, and they feel confident in writing a program and addressing any issues through complex debugging tasks. The proposed intervention provides a platform for students to discuss misconceptions, visualize multiple problem-solving approaches, and thoroughly understand existing code.",
    "title_zh": "代码洞察：评估一种面向新手程序员的主动学习框架，以促进代码审查能力的发展",
    "abstract_zh": "完整的研究报告描述了一种基于主动学习的课堂干预方法，旨在促进计算机科学（CS）专业学生代码审查与调试技能的发展。随着基于人工智能的应用程序迅速普及，软件开发人员掌握代码审查与调试技能的重要性日益凸显。组织机构通过代码审查流程不仅确保软件的质量与准确性，还实现知识传递、促进高效协作、保持一致性以及分享创意。然而，将代码审查实践引入课堂教学面临诸多挑战，主要源于其带来的繁重工作量，常常导致学生参与度低、积极性不足。为解决这些问题，我们提出了一种名为“Code Insight”的课堂主动学习框架，该框架可无缝融入常规课程讲授中，既不会增加学生的额外负担，也无需教师承担额外的评分工作。\n\n考虑到初学者在编程概念方面的知识和经验有限，本研究的目标是提供战略性指导，帮助学生有效且系统地对他人编写的代码进行审查、分析与评估，从而更深入地理解代码内涵。在本研究中，学生在课堂上参与Code Insight活动，利用课堂应答系统通过多项选择题报告所提供代码的正确性。学期末通过收集学生反馈来评估Code Insight对学生学习效果的影响。研究结果表明，Code Insight活动为学生提供了适度的挑战，显著提升了他们的学习体验，并凸显了在入门级编程课程中更广泛融入代码审查实践的必要性。学生们普遍表示更偏好此类活动而非传统授课，认为这些活动有助于他们通过识别并修复错误来调试自己的程序，并增强了他们在编写程序及应对复杂调试任务时的信心。所提出的干预措施为学生提供了讨论误解、可视化多种解题思路以及深入理解现有代码的平台。"
  },
  {
    "date": "2026-1-13",
    "title": "Code Comprehension for Novice Students: Teaching, Assessment, Tools, and Challenges",
    "authors": "Valéria Cavalcanti, Wilkerson L. Andrade",
    "publish": "2025 IEEE Frontiers in Education Conference (FIE)",
    "url": "https://doi.org/10.1109/fie63693.2025.11328616",
    "source": "IEEE",
    "abstract": "This Research Full Paper presents a systematic literature review on code compression for novice students. Code comprehension is a fundamental research field in software development, especially in the current context where Large Language Models (LLMs) are transforming programming practices by automatically generating code. This work addresses four central questions: (1) What are the most effective strategies for teaching code comprehension? (2) What methods are used to assess this skill? (3) What tools support this process? (4) What challenges do students face? The methodology integrates an AI-powered tool to analyze more than 18,000 articles, resulting in a selection of 47 relevant studies. The reviewed studies highlight the importance of adopting teaching strategies that help students build solid mental models before they begin writing code. Tools that incorporate such instructional strategies are essential to personalize learning and overcome the challenges faced by novice programmers. Evaluation methods are also evolving, moving beyond traditional assessments to include interactive and formative approaches. This review synthesizes the current state of research and offers recommendations for educators, researchers, and developers of educational tools aimed at fostering code comprehension skills.",
    "title_zh": "代码理解对初学者的意义：教学、评估、工具与挑战",
    "abstract_zh": "本文研究论文系统地综述了针对初学者的代码压缩相关文献。代码理解是软件开发领域的一个基础性研究方向，尤其是在当前大型语言模型（LLMs）正通过自动生成代码而深刻改变编程实践的背景下。本研究围绕四个核心问题展开：（1）教授代码理解最有效的策略是什么？（2）目前采用哪些方法来评估这一能力？（3）有哪些工具能够支持该过程？（4）学生在学习过程中面临哪些挑战？研究方法结合了一款人工智能驱动的工具，对超过18,000篇文献进行了分析，最终筛选出47项相关研究。所回顾的研究强调，在学生开始编写代码之前，采用有助于构建扎实心智模型的教学策略至关重要。能够融入此类教学理念的工具对于实现个性化学习、帮助初学者克服编程障碍具有关键作用。同时，评估方法也在不断发展，逐渐从传统的考核方式转向更具互动性和形成性的评价方式。本综述总结了当前研究的最新进展，并为教育工作者、研究人员以及教育类工具开发者提供了提升代码理解能力的相关建议。"
  }
]