[
  {
    "date": "2025-12-01",
    "title": "Bounded treewidth, multiple context-free grammars, and downward closures",
    "authors": "C. Aiswarya, Pascal Baumann, Prakash Saivasan, Lia Schütze, Georg Zetzsche",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01973v1",
    "source": "arXiv",
    "abstract": "The reachability problem in multi-pushdown automata (MPDA) has many applications in static analysis of recursive programs. An example is safety verification of multi-threaded recursive programs with shared memory. Since these problems are undecidable, the literature contains many decidable (and efficient) underapproximations of MPDA. A uniform framework that captures many of these underapproximations is that of bounded treewidth (tw): To each execution of the MPDA, we associate a graph; then we consider the subset of all graphs that have a wt at most $k$, for some constant $k$. In fact, bounding tw is a generic approach to obtain classes of systems with decidable reachability, even beyond MPDA underapproximations. The resulting systems are also called MSO-definable bounded-tw systems. While bounded tw is a powerful tool for reachability and similar types of analysis, the word languages (i.e. action sequences corresponding to executions) of these systems remain far from understood. For the slight restriction of bounded special tw, or \"bounded-stw\" (which is equivalent to bounded tw on MPDA, and even includes all bounded-tw systems studied in the literature), this work reveals a connection with multiple context-free languages (MCFL), a concept from computational linguistics. We show that the word languages of MSO-definable bounded-stw systems are exactly the MCFL. We exploit this connection to provide an optimal algorithm for computing downward closures (dcl) for MSO-definable bounded-stw systems. Computing dcl is a notoriously difficult task that has many applications in the verification of complex systems: As an example application, we show that in programs with dynamic spawning of MSO-definable bounded-stw processes, safety verification has the same complexity as in the case of processes with sequential recursive processes.",
    "title_zh": "有界树宽、多上下文无关文法与向下封闭性",
    "abstract_zh": "多栈下推自动机（MPDA）中的可达性问题在递归程序的静态分析中具有广泛的应用。例如，它可用于具有共享内存的多线程递归程序的安全性验证。由于这些问题本质上是不可判定的，文献中提出了许多可判定且高效的MPDA的近似方法。一种能够统一描述其中许多近似方法的框架是“有界树宽”（bounded treewidth, 简称tw）：对于MPDA的每一次执行，我们将其关联为一个图；然后考虑所有树宽至多为某个常数 $k$ 的图所构成的子集。事实上，对树宽进行限制是一种通用的方法，用于构造具有可判定可达性的系统类，不仅限于MPDA的近似，也适用于更广泛的系统。这类系统也被称为MSO可定义的有界树宽系统。\n\n尽管有界树宽在可达性及类似分析中是一个强大的工具，但这些系统对应的字语言（即对应于执行的动作序列）至今仍远未被充分理解。本研究针对有界特殊树宽（bounded special treewidth，简称“有界-stw”）这一稍作限制的情形——该情形在MPDA上等价于有界树宽，并且包含了文献中所有已研究的有界树宽系统——揭示了其与多重上下文无关语言（Multiple Context-Free Languages, MCFL）之间的联系，MCFL是计算语言学中的一个重要概念。我们证明：MSO可定义的有界-stw系统的字语言恰好就是MCFL。\n\n利用这一联系，我们提出了一种计算此类系统向下闭包（downward closure, dcl）的最优算法。向下闭包的计算一向是一项极具挑战性的任务，在复杂系统的验证中具有众多应用。作为具体应用示例，我们展示了：在动态生成MSO可定义有界-stw进程的程序中，安全性验证的复杂度与仅包含顺序递归进程的程序情况相同。"
  },
  {
    "date": "2025-12-01",
    "title": "Latent Debate: A Surrogate Framework for Interpreting LLM Thinking",
    "authors": "Lihu Chen, Xiang Yin, Francesca Toni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01909v1",
    "source": "arXiv",
    "abstract": "Understanding the internal thinking process of Large Language Models (LLMs) and the cause of hallucinations remains a key challenge. To this end, we introduce latent debate, a novel framework for interpreting model predictions through the lens of implicit internal arguments. Unlike the current work of self-consistency and multi-agent debate, which relies on explicit debates among multiple answers or multiple models, latent debate captures the hidden supporting and attacking signals that arise within a single model during a single inference. We first present a model- and task-agnostic conceptual framework, and then instantiate it symbolically to approximate the thinking process of LLMs on True/False prediction tasks. Empirical studies demonstrate that latent debate is a faithful structured surrogate model that has highly consistent predictions with the original LLM. Beyond interpretability, we demonstrate that latent debate provides a strong baseline for hallucination detection. Further analysis reveals strong correlations between hallucinations and debate patterns, such as a high degree of latent debates in the middle layers is linked to a higher risk of hallucinations. These findings position latent debate as a potential framework for understanding internal mechanisms of LLMs, especially for scenarios where internal (dis)agreements appear during the inference steps.",
    "title_zh": "潜在辩论：一种用于解释大语言模型思维的代理框架",
    "abstract_zh": "理解大型语言模型（LLMs）的内部思维过程及其产生幻觉的原因，仍是当前面临的关键挑战。为此，我们提出了一种名为“潜在辩论”（latent debate）的新框架，通过捕捉模型内部隐含的论证过程来解释其预测结果。与现有的自一致性方法及多智能体辩论方法不同，后者依赖于多个答案或多个模型之间的显式辩论，潜辩论则在单次推理过程中，从单一模型内部提取出隐含的支持与反驳信号。我们首先提出一个模型和任务无关的概念性框架，随后以符号化方式具体实现该框架，以近似LLM在真假判断任务中的思考过程。实证研究表明，潜辩论是一种忠实且结构化的替代模型，其预测结果与原始LLM高度一致。除了提升可解释性外，我们还证明了潜辩论在幻觉检测方面具有强大的基线性能。进一步分析揭示，幻觉与辩论模式之间存在显著相关性：例如，中间层中较高的潜在辩论强度与更高的幻觉风险密切相关。这些发现表明，潜辩论有望成为理解LLM内部机制的一种有效框架，尤其适用于推理过程中出现内部（不）一致性的场景。"
  },
  {
    "date": "2025-12-01",
    "title": "H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons",
    "authors": "Cheng Gao, Huimin Chen, Chaojun Xiao, Zhiyi Chen, Zhiyuan Liu, Maosong Sun",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01797v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.",
    "title_zh": "H神经元：关于与幻觉相关神经元的存在、影响及起源",
    "abstract_zh": "大型语言模型（LLMs）经常产生幻觉——即看似合理但事实错误的输出——这严重削弱了其可靠性。尽管以往的研究已从训练数据和目标等宏观角度探讨过幻觉现象，但其底层的神经元级机制仍鲜有深入探索。本文从三个角度对大型语言模型中的幻觉相关神经元（H-Neurons）进行了系统性研究：识别、行为影响及其起源。在识别方面，我们发现仅占总神经元数量不到0.1%的极少数神经元即可可靠预测幻觉的发生，并且在多种不同情境下均表现出强大的泛化能力。在行为影响方面，通过受控干预实验表明，这些神经元与过度顺从行为存在因果关联。关于其起源，我们追溯发现这些神经元可回溯至预训练的基础模型，且在后续任务中仍能有效预测幻觉，表明它们是在预训练阶段就已形成的。我们的研究将宏观层面的行为模式与微观层面的神经机制相连接，为构建更可靠的大型语言模型提供了重要启示。"
  },
  {
    "date": "2025-12-01",
    "title": "Beware of Reasoning Overconfidence: Pitfalls in the Reasoning Process for Multi-solution Tasks",
    "authors": "Jiannan Guan, Qiguang Chen, Libo Qin, Dengyun Peng, Jinhao Liu, Liangyu Huo, Jian Xie, Wanxiang Che",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01725v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) excel in reasoning tasks requiring a single correct answer, but they perform poorly in multi-solution tasks that require generating comprehensive and diverse answers. We attribute this limitation to \\textbf{reasoning overconfidence}: a tendency to express undue certainty in an incomplete solution set. To examine the effect, we introduce \\textit{MuSoBench}, a benchmark of multi-solution problems. Experiments show that the conventional short chain-of-thought (Short-CoT) prompting paradigm exhibits pronounced overconfidence, whereas the emerging long chain-of-thought (Long-CoT) approach mitigates it through iterative exploration and self-reflection. We further characterise observable behaviours and influential factors. To probe the underlying cause, we propose the \\textbf{cognitive-rigidity hypothesis}, which posits that overconfidence arises when the reasoning process prematurely converges on a narrow set of thought paths. An attention-entropy analysis offers preliminary support for this view. These findings provide tools for assessing the completeness of LLM reasoning and highlight the need to move evaluation beyond single-answer accuracy toward comprehensive exploration.",
    "title_zh": "警惕推理过度自信：多解任务中推理过程的陷阱",
    "abstract_zh": "大型语言模型（LLMs）在需要单一正确答案的推理任务中表现优异，但在需要生成全面且多样答案的多解任务中表现不佳。我们认为这一局限性源于**推理过度自信**：即在解决方案集不完整的情况下，仍表现出过度的确定性。为探究该现象的影响，我们提出了一个名为 \\textit{MuSoBench} 的多解问题基准测试。实验表明，传统的短链式思维（Short-CoT）提示范式表现出显著的过度自信，而新兴的长链式思维（Long-CoT）方法通过迭代探索与自我反思有效缓解了这一问题。我们进一步分析了可观察的行为特征及其影响因素。为深入探究其根本原因，我们提出**认知僵化假说**，认为过度自信产生于推理过程过早收敛到少数狭窄的思维路径。注意力熵分析为此观点提供了初步支持。这些发现为评估大模型推理的完整性提供了新工具，并强调应将评估标准从单一答案的准确性拓展至对全面探索能力的关注。"
  },
  {
    "date": "2025-12-01",
    "title": "Package Dashboard: A Cross-Ecosystem Framework for Dual-Perspective Analysis of Software Packages",
    "authors": "Ziheng Liu, Runzhi He, Minghui Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01630v1",
    "source": "arXiv",
    "abstract": "Software supply chain attacks have revealed blind spots in existing SCA tools, which are often limited to a single ecosystem and assess either software artifacts or community activity in isolation. This fragmentation across tools and ecosystems forces developers to manually reconcile scattered data, undermining risk assessments. We present Package Dashboard, a cross-ecosystem framework that provides a unified platform for supply chain analysis, enabling a holistic, dual-perspective risk assessment by integrating package metadata, vulnerability information, and upstream community health metrics. By combining dependency resolution with repository analysis, it reduces cognitive load and improves traceability. Demonstrating the framework's versatility, a large-scale study of 374,000 packages across five Linux distributions shows its ability to uncover not only conventional vulnerabilities and license conflicts but also overlooked risks such as archived or inaccessible repositories. Ultimately, Package Dashboard provides a unified view of risk, equipping developers and DevSecOps engineers with actionable insights to strengthen the transparency, trustworthiness, and traceability of open-source ecosystems. Package Dashboard is publicly available at https://github.com/n19htfall/PackageDashboard, and a demonstration video can be found at https://youtu.be/y9ncftP8KPQ. Besides, the online version is available at https://pkgdash.osslab-pku.org.",
    "title_zh": "包仪表盘：面向软件包的跨生态系统双重视角分析框架",
    "abstract_zh": "软件供应链攻击暴露出现有软件成分分析（SCA）工具的盲点，这些工具通常局限于单一生态系统，且要么仅评估软件构件，要么孤立地分析社区活动。这种工具与生态系统的割裂，迫使开发者手动整合分散的数据，从而削弱了风险评估的有效性。我们提出了 Package Dashboard——一个跨生态系统的框架，提供统一的供应链分析平台，通过整合包元数据、漏洞信息以及上游社区健康度指标，实现全面的双重视角风险评估。该框架结合依赖解析与仓库分析，降低了认知负担，提升了可追溯性。通过一项涵盖五个 Linux 发行版共 37.4 万个软件包的大规模研究，展示了该框架的多功能性：不仅能够发现传统的漏洞和许可证冲突，还能揭示被忽视的风险，如已归档或无法访问的代码仓库。最终，Package Dashboard 提供了一个统一的风险视图，使开发者和 DevSecOps 工程师能够获得可操作的洞察，从而增强开源生态在透明度、可信度和可追溯性方面的表现。Package Dashboard 已公开发布于 https://github.com/n19htfall/PackageDashboard，演示视频可访问 https://youtu.be/y9ncftP8KPQ。此外，在线版本也可通过 https://pkgdash.osslab-pku.org 获取。"
  },
  {
    "date": "2025-12-01",
    "title": "EmoRAG: Evaluating RAG Robustness to Symbolic Perturbations",
    "authors": "Xinyun Zhou, Xinfeng Li, Yinan Peng, Ming Xu, Xuanwang Zhang, Miao Yu, Yidong Wang, Xiaojun Jia, Kun Wang, Qingsong Wen, XiaoFeng Wang, Wei Dong",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01335v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation (RAG) systems are increasingly central to robust AI, enhancing large language model (LLM) faithfulness by incorporating external knowledge. However, our study unveils a critical, overlooked vulnerability: their profound susceptibility to subtle symbolic perturbations, particularly through near-imperceptible emoticon tokens such as \"(@_@)\" that can catastrophically mislead retrieval, termed EmoRAG. We demonstrate that injecting a single emoticon into a query makes it nearly 100% likely to retrieve semantically unrelated texts that contain a matching emoticon. Our extensive experiment across general question-answering and code domains, using a range of state-of-the-art retrievers and generators, reveals three key findings: (I) Single-Emoticon Disaster: Minimal emoticon injections cause maximal disruptions, with a single emoticon almost 100% dominating RAG output. (II) Positional Sensitivity: Placing an emoticon at the beginning of a query can cause severe perturbation, with F1-Scores exceeding 0.92 across all datasets. (III) Parameter-Scale Vulnerability: Counterintuitively, models with larger parameters exhibit greater vulnerability to the interference. We provide an in-depth analysis to uncover the underlying mechanisms of these phenomena. Furthermore, we raise a critical concern regarding the robustness assumption of current RAG systems, envisioning a threat scenario where an adversary exploits this vulnerability to manipulate the RAG system. We evaluate standard defenses and find them insufficient against EmoRAG. To address this, we propose targeted defenses, analyzing their strengths and limitations in mitigating emoticon-based perturbations. Finally, we outline future directions for building robust RAG systems.",
    "title_zh": "EmoRAG：评估RAG对符号扰动的鲁棒性",
    "abstract_zh": "检索增强生成（RAG）系统正日益成为构建可靠人工智能的核心，通过引入外部知识来提升大语言模型（LLM）的准确性与可信度。然而，我们的研究揭示了一个被严重忽视的关键漏洞：RAG系统对细微符号扰动具有极高的敏感性，尤其是通过几乎不可察觉的表情符号令牌（如“(@_@)”）进行的干扰，这种现象被称为EmoRAG。我们证明，仅在查询中注入一个表情符号，就几乎100%导致系统检索到语义无关但包含相同表情符号的文本。我们在通用问答和代码领域进行了广泛实验，使用多种前沿检索器与生成器，得出三个关键发现：（I）单表情符号灾难效应：极少量的表情符号注入即可引发最大破坏，单个表情符号几乎能完全主导RAG系统的输出；（II）位置敏感性：将表情符号置于查询开头时，会造成严重扰动，在所有数据集上F1分数均超过0.92；（III）参数规模脆弱性：出人意料的是，参数量更大的模型反而对这类干扰表现出更高的脆弱性。我们深入分析了这些现象背后的机制。此外，我们对当前RAG系统普遍假设的鲁棒性提出严峻质疑，并设想了一种攻击场景——攻击者可利用此漏洞操纵RAG系统。我们评估了现有标准防御措施，发现其对EmoRAG均无效。为此，我们提出了针对性的防御方案，并分析了它们在缓解表情符号扰动方面的优势与局限性。最后，我们展望了未来构建更具鲁棒性的RAG系统的若干方向。"
  },
  {
    "date": "2025-12-01",
    "title": "Large Language Models Cannot Reliably Detect Vulnerabilities in JavaScript: The First Systematic Benchmark and Evaluation",
    "authors": "Qingyuan Fei, Xin Liu, Song Li, Shujiang Wu, Jianwei Hou, Ping Chen, Zifeng Kang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01255v1",
    "source": "arXiv",
    "abstract": "Researchers have proposed numerous methods to detect vulnerabilities in JavaScript, especially those assisted by Large Language Models (LLMs). However, the actual capability of LLMs in JavaScript vulnerability detection remains questionable, necessitating systematic evaluation and comprehensive benchmarks. Unfortunately, existing benchmarks suffer from three critical limitations: (1) incomplete coverage, such as covering a limited subset of CWE types; (2) underestimation of LLM capabilities caused by unreasonable ground truth labeling; and (3) overestimation due to unrealistic cases such as using isolated vulnerable files rather than complete projects. In this paper, we introduce, for the first time, three principles for constructing a benchmark for JavaScript vulnerability detection that directly address these limitations: (1) comprehensiveness, (2) no underestimation, and (3) no overestimation. Guided by these principles, we propose FORGEJS, the first automatic benchmark generation framework for evaluating LLMs' capability in JavaScript vulnerability detection. Then, we use FORGEJS to construct ARENAJS-the first systematic benchmark for LLM-based JavaScript vulnerability detection-and further propose JUDGEJS, an automatic evaluation framework. We conduct the first systematic evaluation of LLMs for JavaScript vulnerability detection, leveraging JUDGEJS to assess seven popular commercial LLMs on ARENAJS. The results show that LLMs not only exhibit limited reasoning capabilities, but also suffer from severe robustness defects, indicating that reliable JavaScript vulnerability detection with LLMs remains an open challenge.",
    "title_zh": "大型语言模型无法可靠检测 JavaScript 中的漏洞：首个系统性基准测试与评估",
    "abstract_zh": "研究人员提出了多种检测 JavaScript 漏洞的方法，尤其是借助大型语言模型（LLMs）的方法。然而，LLMs 在 JavaScript 漏洞检测中的实际能力仍存疑，亟需进行系统性评估和全面的基准测试。遗憾的是，现有的基准测试存在三个关键缺陷：（1）覆盖不全，例如仅涵盖有限的 CWE 类型；（2）由于不合理的真实答案标注，低估了 LLM 的能力；（3）由于使用孤立的漏洞文件而非完整项目等不切实际的场景，导致高估了 LLM 的表现。本文首次提出构建 JavaScript 漏洞检测基准测试的三项基本原则，以直接应对上述问题：（1）全面性，（2）避免低估，（3）避免高估。基于这些原则，我们提出了 FORGEJS——首个用于评估 LLM 在 JavaScript 漏洞检测中能力的自动化基准生成框架。随后，我们利用 FORGEJS 构建了 ARENAJS，这是首个面向基于 LLM 的 JavaScript 漏洞检测的系统性基准测试，并进一步提出了 JUDGEJS——一个自动化评估框架。我们首次对 LLM 在 JavaScript 漏洞检测中的能力进行了系统性评估，借助 JUDGEJS 在 ARENAJS 上对七款主流商业 LLM 进行了评测。结果表明，LLM 不仅推理能力有限，还存在严重的鲁棒性缺陷，说明基于 LLM 实现可靠的 JavaScript 漏洞检测仍是未解难题。"
  },
  {
    "date": "2025-12-01",
    "title": "Beyond Greenfield: AI-Driven Productivity in Documentation and Brownfield Engineering",
    "authors": "Krishna Kumaar Sharma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01155v1",
    "source": "arXiv",
    "abstract": "Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and reduced rework for 83% during the Define phase. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.",
    "title_zh": "超越绿field：人工智能驱动的文档编制与棕地工程生产率",
    "abstract_zh": "涉及遗留系统、文档不完整以及架构知识碎片化的棕地工程工作，对大型语言模型（LLM）的有效应用带来了独特挑战。以往研究多集中于绿地项目或合成任务，缺乏针对复杂、上下文密集型环境的结构化工作流程。本文提出“发现-定义-交付”（Discover-Define-Deliver, D3）框架，这是一种基于LLM辅助的规范化工作流程，结合了角色分离的提示策略与实际应用的最佳实践，以应对棕地系统中的不确定性。该框架采用双代理提示架构：构建者（Builder）模型生成候选输出，评审者（Reviewer）模型则提供结构化反馈以提升结果可靠性。我开展了一项探索性调查研究，共有52名软件从业者将D3工作流程应用于真实工程任务，包括遗留系统探索、文档重建和架构重构。受访者报告称，在任务清晰度、文档质量及认知负荷方面均有感知改善，并自我评估出生产力提升。在本探索性研究中，参与者报告的加权平均生产力提升达26.9%，约77%的参与者感受到认知负荷降低，83%的参与者在“定义”阶段减少了返工。由于这些数据为自报结果，未经过对照实验验证，因此应视为初步反映从业者态度的证据，而非因果关系的证明。研究结果揭示了结构化LLM工作流程在遗留系统工程中的潜力与局限，也为未来开展受控评估提供了依据。"
  },
  {
    "date": "2025-12-01",
    "title": "AlignSAE: Concept-Aligned Sparse Autoencoders",
    "authors": "Minglai Yang, Xinyu Guo, Mihai Surdeanu, Liangming Pan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.02004v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) encode factual knowledge within hidden parametric spaces that are difficult to inspect or control. While Sparse Autoencoders (SAEs) can decompose hidden activations into more fine-grained, interpretable features, they often struggle to reliably align these features with human-defined concepts, resulting in entangled and distributed feature representations. To address this, we introduce AlignSAE, a method that aligns SAE features with a defined ontology through a \"pre-train, then post-train\" curriculum. After an initial unsupervised training phase, we apply supervised post-training to bind specific concepts to dedicated latent slots while preserving the remaining capacity for general reconstruction. This separation creates an interpretable interface where specific relations can be inspected and controlled without interference from unrelated features. Empirical results demonstrate that AlignSAE enables precise causal interventions, such as reliable \"concept swaps\", by targeting single, semantically aligned slots.",
    "title_zh": "AlignSAE：概念对齐的稀疏自编码器",
    "abstract_zh": "大型语言模型（LLMs）将事实知识编码在难以检查或控制的隐藏参数空间中。尽管稀疏自编码器（SAEs）能够将隐藏激活分解为更细粒度、可解释的特征，但它们常常难以可靠地将这些特征与人类定义的概念对齐，导致特征表示纠缠且分布广泛。为解决这一问题，我们提出了AlignSAE方法，通过“先预训练，再后训练”的教学范式，将SAE特征与特定本体（ontology）对齐。在初始的无监督训练阶段之后，我们引入有监督的后训练过程，将特定概念绑定到专用的潜在槽位，同时保留其余容量用于通用重建。这种分离机制构建了一个可解释的接口，使得特定关系可以被独立观察和控制，而不会受到无关特征的干扰。实证结果表明，AlignSAE能够实现精确的因果干预，例如通过针对单一语义对齐的槽位，可靠地执行“概念替换”等操作。"
  },
  {
    "date": "2025-12-01",
    "title": "How Far Are We from Genuinely Useful Deep Research Agents?",
    "authors": "Dingling Zhang, He Zhu, Jincheng Ren, Kangqi Song, Xinran Zhou, Boyu Feng, Shudong Liu, Jiabin Luo, Weihao Xie, Zhaohui Wang, Tianrui Qin, King Zhu, Yuqing Wang, Qianben Chen, Yuchen Eleanor Jiang, Wei Wang, Jiaheng Liu, Wangchunshu Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01948v1",
    "source": "arXiv",
    "abstract": "Deep Research Agents (DRAs) aim to automatically produce analyst-level reports through iterative information retrieval and synthesis. However, most existing DRAs were validated on question-answering benchmarks, while research on generating comprehensive reports remains overlooked. Worse, current benchmarks for report synthesis suffer from task complexity and subjective metrics -- this fails to reflect user demands and limits the practical utility of generated reports. To address these gaps, we present Fine-grained DEepResearch bench (FINDER), an enhanced benchmark consisting of 100 human-curated research tasks with 419 structured checklist items that standardize report structure, analytical depth, and factual grounding. Based on approximately 1,000 reports produced by mainstream DRAs, we further propose Deep rEsearch Failure Taxonomy (DEFT), the first failure taxonomy for deep research agents. DEFT contains 14 fine-grained failure modes across reasoning, retrieval, and generation, and is built upon grounded theory with human-LLM co-annotating and inter-annotator reliability validation. Our experimental findings reveal that current DRAs struggle not with task comprehension but with evidence integration, verification, and reasoning-resilient planning.",
    "title_zh": "我们距离真正有用的深度研究代理还有多远？",
    "abstract_zh": "深度研究代理（Deep Research Agents, DRAs）旨在通过迭代式的信息检索与综合，自动生成达到分析师水平的报告。然而，目前大多数DRAs仅在问答基准上进行验证，而针对生成综合性报告的研究却长期被忽视。更严重的是，现有的报告合成基准存在任务复杂度高、评估指标主观性强等问题，无法真实反映用户需求，也限制了生成报告的实际应用价值。为弥补这些不足，我们提出了细粒度深度研究基准（Fine-grained DEepResearch bench, FINDER），这是一个增强型基准，包含100个由人工精心设计的研究任务，以及419项结构化检查清单条目，用于标准化报告的结构、分析深度和事实依据。基于约1,000份主流DRAs生成的报告，我们进一步提出了深度研究失败分类体系（Deep rEsearch Failure Taxonomy, DEFT），这是首个针对深度研究代理的失败分类体系。DEFT涵盖了推理、检索和生成三个维度中的14种细粒度失败模式，并基于扎根理论，通过人类与大模型协同标注及标注者间一致性验证构建而成。我们的实验发现表明，当前DRAs的问题并不在于任务理解能力，而在于证据整合、验证能力以及具备抗干扰性的推理规划能力。"
  },
  {
    "date": "2025-12-01",
    "title": "InnoGym: Benchmarking the Innovation Potential of AI Agents",
    "authors": "Jintian Zhang, Kewei Xu, Jingsheng Zheng, Zhuoyun Yu, Yuqi Zhu, Yujie Luo, Lanning Wei, Shuofei Qiao, Lun Du, Da Zheng, Shumin Deng, Huajun Chen, Ningyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01822v1",
    "source": "arXiv",
    "abstract": "LLMs and Agents have achieved impressive progress in code generation, mathematical reasoning, and scientific discovery. However, existing benchmarks primarily measure correctness, overlooking the diversity of methods behind solutions. True innovation depends not only on producing correct answers but also on the originality of the approach. We present InnoGym, the first benchmark and framework designed to systematically evaluate the innovation potential of AI agents. InnoGym introduces two complementary metrics: performance gain, which measures improvement over the best-known solutions, and novelty, which captures methodological differences from prior approaches. The benchmark includes 18 carefully curated tasks from real-world engineering and scientific domains, each standardized through resource filtering, evaluator validation, and solution collection. In addition, we provide iGym, a unified execution environment for reproducible and long-horizon evaluations. Extensive experiments show that while some agents produce novel approaches, their lack of robustness limits performance gains. These results highlight a key gap between creativity and effectiveness, underscoring the need for benchmarks that evaluate both.",
    "title_zh": "InnoGym：评估AI代理的创新潜力",
    "abstract_zh": "大语言模型（LLMs）与智能体在代码生成、数学推理和科学发现等领域取得了令人瞩目的进展。然而，现有的评估基准主要关注答案的正确性，忽视了不同解决方案背后的多样性方法。真正的创新不仅依赖于得出正确答案，更在于方法上的原创性。为此，我们提出了InnoGym——首个系统性评估AI智能体创新能力的基准与框架。InnoGym引入了两个互补的度量指标：性能提升（performance gain），用于衡量相对于已有最优解的改进程度；新颖性（novelty），用于捕捉与以往方法在策略上的差异。该基准包含18个来自真实工程与科学领域的精心筛选任务，每项任务均通过资源过滤、评估器验证和解法收集进行了标准化处理。此外，我们还提供了iGym，一个统一的执行环境，支持可复现且长周期的评估。大量实验表明，尽管某些智能体能够提出新颖的方法，但其缺乏鲁棒性限制了性能的提升。这些结果揭示了创造力与实际有效性之间存在显著差距，凸显出亟需同时评估创新性与有效性的评测体系。"
  },
  {
    "date": "2025-12-01",
    "title": "CoSineVerifier: Tool-Augmented Answer Verification for Computation-Oriented Scientific Questions",
    "authors": "Ruixiang Feng, Zhenwei An, Yuntao Wen, Ran Le, Yiming Jia, Chen Yang, Zongchao Chen, Lisi Chen, Shen Gao, Shuo Shang, Yang Song, Tao Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01224v1",
    "source": "arXiv",
    "abstract": "Answer verification methods are widely employed in language model training pipelines spanning data curation, evaluation, and reinforcement learning with verifiable rewards (RLVR). While prior work focus on developing unified verifiers applicable across multiple reasoning scenarios, significant challenges remain in computation-oriented scientific domains, such as algebraic equivalence checking and physical constant substitution. In this paper, we introduce \\model, a tool-augmented verifier that leverages external executors to perform precise computations and symbolic simplifications. \\model enables robust verification that goes beyond simple semantic matching. We propose a novel two-stage pipeline, which begin with cold-start fine-tuning and followed by multi-turn reinforcement learning with tool integration. Extensive experiments conducted on STEM subjects, general QA, and long-form reasoning tasks demonstrates strong generalization of \\model. The results shows that the \\model achieves state-of-the-art performance on VerifyBench-Hard and SCI-Bench. And we also employ our \\model in RLVR as a reward model, the results show that it consistently outperforms both rubric-based and model-based verifiers on AIME'24 and AIME'25, demonstrating strong potential to enhance reasoning capabilities of LLM. Our model is released at \\hyperlink{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}.",
    "title_zh": "CosineVerifier：面向计算型科学问题的工具增强型答案验证",
    "abstract_zh": "答案验证方法被广泛应用于语言模型训练流程中的数据整理、评估以及基于可验证奖励的强化学习（RLVR）等环节。尽管以往研究致力于开发适用于多种推理场景的统一验证器，但在以计算为核心的科学领域（如代数等价性检查和物理常数代入）仍面临显著挑战。本文提出 \\model，一种基于工具增强的验证器，通过调用外部执行器进行精确计算与符号化简化，实现超越简单语义匹配的稳健验证。我们设计了一种新颖的两阶段流水线：首先进行冷启动微调，随后结合工具集成开展多轮强化学习。在STEM学科、通用问答及长文本推理任务上的大量实验表明，\\model 具有出色的泛化能力。结果表明，\\model 在 VerifyBench-Hard 和 SCI-Bench 基准上均达到当前最优性能。此外，我们将 \\model 应用于 RLVR 作为奖励模型，在 AIME'24 和 AIME'25 上的表现持续优于基于评分标准和基于模型的验证器，充分展示了其提升大语言模型推理能力的巨大潜力。我们的模型已开源发布于 \\hyperlink{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}{https://huggingface.co/Nanbeige/CoSineVerifier-Tool-4B}。"
  },
  {
    "date": "2025-12-01",
    "title": "Generating REST API Tests With Descriptive Names",
    "authors": "Philip Garrett, Juan P. Galeotti, Andrea Arcuri, Alexander Poth, Olsi Rrjolli",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01690v1",
    "source": "arXiv",
    "abstract": "Automated test generation has become a key technique for ensuring software quality, particularly in modern API-based architectures. However, automatically generated test cases are typically assigned non-descriptive names (e.g., test0, test1), which reduces their readability and hinders their usefulness during comprehension and maintenance. In this work, we present three novel deterministic techniques to generate REST API test names. We then compare eight techniques in total for generating descriptive names for REST API tests automatically produced by the fuzzer EvoMaster, using 10 test cases generated for 9 different open-source APIs. The eight techniques include rule-based heuristics and large language model (LLM)-based approaches. Their effectiveness was empirically evaluated through two surveys (involving up to 39 people recruited via LinkedIn). Our results show that a rule-based approach achieves the highest clarity ratings among deterministic methods, performs on par with state-of-the-art LLM-based models such as Gemini and GPT-4o, and significantly outperforms GPT-3.5. To further evaluate the practical impact of our results, an industrial case study was carried out with practitioners who actively use EvoMaster at Volkswagen AG. A developer questionnaire was then carried out based on the use of EvoMaster on four different APIs by four different users, for a total of 74 evaluated test cases. Feedback from practitioners further confirms that descriptive names produced by this approach improve test suite readability. These findings highlight that lightweight, deterministic techniques can serve as effective alternatives to computationally expensive and security-sensitive LLM-based approaches for automated system-level test naming, providing a practical step toward more developer-friendly API test generation.",
    "title_zh": "使用描述性名称生成 REST API 测试",
    "abstract_zh": "自动化测试生成已成为确保软件质量的关键技术，尤其在现代基于API的架构中。然而，自动生成的测试用例通常被赋予非描述性的名称（如 test0、test1），这降低了其可读性，阻碍了在理解与维护过程中的实用性。本文提出三种新颖的确定性技术，用于生成REST API测试用例的描述性名称。随后，我们对八种不同方法进行了比较研究，这些方法旨在自动为fuzzer EvoMaster生成的REST API测试用例命名，实验基于9个不同的开源API所生成的共10组测试用例。这八种方法包括基于规则的启发式策略和基于大语言模型（LLM）的方法。通过两次调查（最多招募39名来自LinkedIn的参与者）对这些方法的有效性进行了实证评估。结果表明，基于规则的方法在确定性方法中获得了最高的清晰度评分，其表现与当前最先进的LLM模型（如Gemini和GPT-4o）相当，并显著优于GPT-3.5。为进一步验证研究成果的实际影响，我们在大众汽车集团（Volkswagen AG）开展了一项工业案例研究，针对实际使用EvoMaster的工程师进行调研。基于四位不同用户在四个不同API上使用EvoMaster所产生的共计74个测试用例，我们发放了开发者问卷。实践者的反馈进一步证实，该方法生成的描述性名称显著提升了测试套件的可读性。这些发现表明，轻量级且确定性的技术可作为计算成本高昂且存在安全风险的LLM方法的有效替代方案，为实现更贴近开发人员需求的自动化系统级测试命名提供了一条切实可行的路径。"
  },
  {
    "date": "2025-12-01",
    "title": "Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems",
    "authors": "Dengyun Peng, Qiguang Chen, Bofei Liu, Jiannan Guan, Libo Qin, Zheng Yan, Jinhao Liu, Jianshu Zhang, Wanxiang Che",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01661v1",
    "source": "arXiv",
    "abstract": "Ensuring LLM reliability requires not only solving complex problems but also recognizing when a problem is unsolvable. Current models often struggle to distinguish objective unsolvability (inherent contradictions in the problem) from subjective capability limitations (problems beyond the model's competence), which leads to hallucinations and overconfidence. To address this, we propose UnsolvableQA and UnsolvableRL to solve feasible problems, detect inherent contradictions, and prudently refuse tasks beyond capability. Specifically, we construct UnsolvableQA, a dataset of paired solvable and unsolvable instances derived via a dual-track methodology: programmatic generation for logic puzzles and a novel \"Reverse Construction\" method that injects contradictions into valid reasoning chains for mathematics. Building on this dataset, we introduce UnsolvableRL, a reinforcement learning framework with three reward components jointly accounting for accuracy, unsolvability, and difficulty. Empirical results show that our approach achieves near-perfect unsolvability detection while also improving accuracy on solvable tasks. Crucially, we identify Capability Collapse, demonstrating that explicit exposure to unsolvable data is indispensable for preventing models from becoming systematically overconfident. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA.",
    "title_zh": "学习可解性的边界：对齐大语言模型以识别无法求解的问题",
    "abstract_zh": "确保大语言模型（LLM）的可靠性，不仅需要解决复杂问题，还必须能够识别问题是否本质上不可解。当前模型往往难以区分客观不可解性（问题本身存在内在矛盾）与主观能力局限性（问题超出模型的能力范围），这导致了幻觉现象和过度自信。为应对这一挑战，我们提出了 UnsolvableQA 和 UnsolvableRL，旨在有效处理可解问题，检测内在矛盾，并审慎拒绝超出自身能力的任务。\n\n具体而言，我们构建了 UnsolvableQA——一个通过双轨方法生成的配对数据集，包含可解与不可解实例：一方面采用程序化生成方法构造逻辑谜题；另一方面提出一种新颖的“逆向构造”方法，将矛盾注入有效的数学推理链中，从而生成具有内在不一致性的题目。基于该数据集，我们进一步引入 UnsolvableRL，这是一种强化学习框架，包含三个奖励成分，共同权衡准确性、不可解性判断以及任务难度。\n\n实验结果表明，我们的方法在不可解性检测上达到了接近完美的表现，同时也在可解任务上提升了准确率。尤为重要的是，我们发现了“能力坍缩”（Capability Collapse）现象，证明了模型必须经过不可解数据的显式训练，才能有效避免系统性地过度自信。我们的代码与数据已公开，详见 https://github.com/sfasfaffa/unsolvableQA。"
  },
  {
    "date": "2025-12-01",
    "title": "Multi-Path Collaborative Reasoning via Reinforcement Learning",
    "authors": "Jindi Lv, Yuhao Zhou, Zheng Zhu, Xiaofeng Wang, Guan Huang, Jiancheng Lv",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01485v1",
    "source": "arXiv",
    "abstract": "Chain-of-Thought (CoT) reasoning has significantly advanced the problem-solving capabilities of Large Language Models (LLMs), yet conventional CoT often exhibits internal determinism during decoding, limiting exploration of plausible alternatives. Recent methods attempt to address this by generating soft abstract tokens to enable reasoning in a continuous semantic space. However, we find that such approaches remain constrained by the greedy nature of autoregressive decoding, which fundamentally isolates the model from alternative reasoning possibilities. In this work, we propose Multi-Path Perception Policy Optimization (M3PO), a novel reinforcement learning framework that explicitly injects collective insights into the reasoning process. M3PO leverages parallel policy rollouts as naturally diverse reasoning sources and integrates cross-path interactions into policy updates through a lightweight collaborative mechanism. This design allows each trajectory to refine its reasoning with peer feedback, thereby cultivating more reliable multi-step reasoning patterns. Empirical results show that M3PO achieves state-of-the-art performance on both knowledge- and reasoning-intensive benchmarks. Models trained with M3PO maintain interpretability and inference efficiency, underscoring the promise of multi-path collaborative learning for robust reasoning.",
    "title_zh": "基于强化学习的多路径协同推理",
    "abstract_zh": "思维链（Chain-of-Thought, CoT）推理显著提升了大型语言模型（LLMs）的问题解决能力，但传统的CoT在解码过程中往往表现出内部确定性，限制了对合理备选方案的探索。近期的方法尝试通过生成软抽象标记，使推理在连续语义空间中进行，以缓解这一问题。然而，我们发现这些方法仍受限于自回归解码的贪婪特性，从根本上将模型与潜在的其他推理路径隔离开来。在本工作中，我们提出了一种名为多路径感知策略优化（Multi-Path Perception Policy Optimization, M3PO）的新颖强化学习框架，该框架显式地将集体洞察注入推理过程。M3PO利用并行策略滚动作为天然多样化的推理来源，并通过轻量级协作机制将跨路径交互整合到策略更新中。这种设计使得每条推理轨迹能够借助同伴反馈不断优化自身推理，从而培养出更可靠、多步连贯的推理模式。实验结果表明，M3PO在知识密集型和推理密集型基准测试上均达到了当前最优性能。使用M3PO训练的模型保持了良好的可解释性与推理效率，凸显了多路径协同学习在实现稳健推理方面的巨大潜力。"
  },
  {
    "date": "2025-12-01",
    "title": "Differentiable Weightless Controllers: Learning Logic Circuits for Continuous Control",
    "authors": "Fabian Kresse, Christoph H. Lampert",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01467v1",
    "source": "arXiv",
    "abstract": "We investigate whether continuous-control policies can be represented and learned as discrete logic circuits instead of continuous neural networks. We introduce Differentiable Weightless Controllers (DWCs), a symbolic-differentiable architecture that maps real-valued observations to actions using thermometer-encoded inputs, sparsely connected boolean lookup-table layers, and lightweight action heads. DWCs can be trained end-to-end by gradient-based techniques, yet compile directly into FPGA-compatible circuits with few- or even single-clock-cycle latency and nanojoule-level energy cost per action. Across five MuJoCo benchmarks, including high-dimensional Humanoid, DWCs achieve returns competitive with weight-based policies (full precision or quantized neural networks), matching performance on four tasks and isolating network capacity as the key limiting factor on HalfCheetah. Furthermore, DWCs exhibit structurally sparse and interpretable connectivity patterns, enabling a direct inspection of which input thresholds influence control decisions.",
    "title_zh": "可微分无权重控制器：用于连续控制的逻辑电路学习",
    "abstract_zh": "我们研究了连续控制策略是否可以被表示并学习为离散逻辑电路，而非连续的神经网络。为此，我们提出了可微无权控制器（Differentiable Weightless Controllers, DWCs），这是一种符号可微的架构，通过热编码输入、稀疏连接的布尔查找表层以及轻量级动作输出头，将实值观测映射为动作。DWCs 可以通过基于梯度的方法端到端训练，同时能够直接编译为适用于 FPGA 的电路，在仅需一至数个时钟周期的延迟下完成计算，并实现每动作纳焦级别的能耗。在五个 MuJoCo 基准任务中，包括高维的人形机器人（Humanoid）任务，DWCs 所获得的回报与基于权重的策略（全精度或量化神经网络）相当，在四项任务上表现匹配，而在 HalfCheetah 任务中，性能受限于网络容量。此外，DWCs 展现出结构稀疏且可解释的连接模式，使得可以直接观察哪些输入阈值影响了控制决策。"
  },
  {
    "date": "2025-12-01",
    "title": "BackportBench: A Multilingual Benchmark for Automated Backporting of Patches",
    "authors": "Zhiqing Zhong, Jiaming Huang, Pinjia He",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01396v1",
    "source": "arXiv",
    "abstract": "Many modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics. To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.",
    "title_zh": "BackportBench：一个用于自动化补丁回溯的多语言基准测试",
    "abstract_zh": "许多现代软件项目迅速演进，以集成新功能和安全补丁。用户及时更新依赖项至更安全的版本至关重要，但许多人仍使用较旧且存在漏洞的包版本，因为升级可能困难，并可能导致现有代码库中断。软件开发者可以通过将安全补丁回溯到旧版本来缓解这一问题。然而，手动回溯补丁既耗时又容易出错。现有自动化回溯技术在通用软件上的有效性尚不明确，因为它们通常仅针对代码片段或函数级别的补丁回溯场景，且评估指标不够完善。为促进自动化回溯技术的研发与评估，我们提出了 BackportBench——首个针对补丁回溯问题的综合性基准套件。BackportBench 是一个多语言基准，包含来自 PyPI、Maven 和 npm 的 202 个补丁回溯问题，每个问题均配有可执行的 Docker 环境及相关测试用例。我们利用 BackportBench 对现有的补丁移植方法以及具有潜在适应能力的基于大模型（LLM）的技术进行了评估。结果表明，代理式（agentic）方法在需要逻辑和结构层面修改的案例中显著优于传统补丁移植方法。然而，不同编程语言下的表现存在差异。基于这些发现，我们为未来研究者和软件实践者在自动化回溯领域的研究工作提供了若干启示。"
  },
  {
    "date": "2025-12-01",
    "title": "PromptBridge: Cross-Model Prompt Transfer for Large Language Models",
    "authors": "Yaxuan Wang, Quan Liu, Zhenting Wang, Zichao Li, Wei Wei, Yang Liu, Yujia Bao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01420v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.",
    "title_zh": "PromptBridge：大语言模型间的跨模型提示传递",
    "abstract_zh": "大型语言模型（LLMs）支撑着代码生成、数学推理以及基于代理的工作流等各类应用。在实际使用中，系统通过商业API或开源部署方式调用LLM，而模型生态（如GPT、Claude、Llama等）正迅速演进。这种快速迭代迫使用户频繁更换模型，原因包括性能能力、成本、部署限制和隐私需求。然而，提示词（prompt）对模型极为敏感：直接将为某一模型精心设计的提示复用于另一模型，往往导致性能显著下降，远不如针对目标模型专门优化的提示。我们称这一现象为“模型漂移”（Model Drifting）。通过对多种LLM配置进行广泛的实证分析，我们发现模型漂移不仅普遍存在，且影响严重。\n\n为应对这一挑战，我们提出PromptBridge——一种无需训练的框架，能够在模型切换时保持提示的有效性，实现跨模型提示迁移，而无需耗费大量成本进行每项任务或每个模型的重新优化。PromptBridge仅需少量对齐任务即可完成校准。其核心流程首先采用**模型自适应反射式提示演化**（Model-Adaptive Reflective Prompt Evolution, MAP-RPE），通过迭代式的反思优化与量化评估，生成针对特定任务和特定模型的最优提示。随后，利用源模型与目标模型之间经校准的提示对，PromptBridge学习建立一个跨模型的提示映射关系。在测试阶段，即面对未见过的任务时，只需输入源模型的提示，该映射即可直接生成适用于目标模型的优化后提示。\n\n在单智能体与多智能体场景下的实验表明，PromptBridge能够持续提升下游任务的准确率，同时大幅降低模型迁移的工作量。相关代码即将开源。"
  },
  {
    "date": "2025-12-01",
    "title": "GPTrace: Effective Crash Deduplication Using LLM Embeddings",
    "authors": "Patrick Herter, Vincent Ahlrichs, Ridvan Açilan, Julian Horsch",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01609v1",
    "source": "arXiv",
    "abstract": "Fuzzing is a highly effective method for uncovering software vulnerabilities, but analyzing the resulting data typically requires substantial manual effort. This is amplified by the fact that fuzzing campaigns often find a large number of crashing inputs, many of which share the same underlying bug. Crash deduplication is the task of finding such duplicate crashing inputs and thereby reducing the data that needs to be examined. Many existing deduplication approaches rely on comparing stack traces or other information that is collected when a program crashes. Although various metrics for measuring the similarity of such pieces of information have been proposed, many do not yield satisfactory deduplication results. In this work, we present GPTrace, a deduplication workflow that leverages a large language model to evaluate the similarity of various data sources associated with crashes by computing embedding vectors and supplying those as input to a clustering algorithm. We evaluate our approach on over 300 000 crashing inputs belonging to 50 ground truth labels from 14 different targets. The deduplication results produced by GPTrace show a noticeable improvement over hand-crafted stack trace comparison methods and even more complex state-of-the-art approaches that are less flexible.",
    "title_zh": "GPTrace：利用大语言模型嵌入实现高效的崩溃去重",
    "abstract_zh": "模糊测试是一种高效发现软件漏洞的方法，但分析由此产生的数据通常需要大量手动工作。这一问题在模糊测试活动中尤为突出，因为这类活动往往会产生大量导致程序崩溃的输入，而其中许多崩溃实际上源于同一个根本性缺陷。崩溃去重的任务就是识别这些重复的崩溃输入，从而减少需要人工审查的数据量。现有的多数去重方法依赖于比较程序崩溃时收集的堆栈跟踪或其他相关信息。尽管已提出多种衡量此类信息相似性的度量方法，但许多方法的去重效果并不理想。本文提出了一种名为 GPTrace 的去重工作流，该方法利用大语言模型对与崩溃相关的多种数据源进行相似性评估，通过计算嵌入向量（embedding vectors），并将这些向量作为输入提供给聚类算法。我们在来自 14 个不同目标、包含 50 个真实标签的超过 30 万条崩溃输入上评估了该方法。实验结果表明，GPTrace 生成的去重效果明显优于手工设计的堆栈跟踪比对方法，甚至在灵活性较差的情况下，也优于一些更复杂的前沿先进方法。"
  },
  {
    "date": "2025-12-01",
    "title": "hls4ml: A Flexible, Open-Source Platform for Deep Learning Acceleration on Reconfigurable Hardware",
    "authors": "Jan-Frederik Schulte, Benjamin Ramhorst, Chang Sun, Jovan Mitrevski, Nicolò Ghielmetti, Enrico Lupi, Dimitrios Danopoulos, Vladimir Loncar, Javier Duarte, David Burnette, Lauri Laatu, Stylianos Tzelepis, Konstantinos Axiotis, Quentin Berthet, Haoyan Wang, Paul White, Suleyman Demirsoy, Marco Colombo, Thea Aarrestad, Sioni Summers, Maurizio Pierini, Giuseppe Di Guglielmo, Jennifer Ngadiuba, Javier Campos, Ben Hawks, Abhijith Gandrakota, Farah Fahim, Nhan Tran, George Constantinides, Zhiqiang Que, Wayne Luk, Alexander Tapper, Duc Hoang, Noah Paladino, Philip Harris, Bo-Cheng Lai, Manuel Valentin, Ryan Forelli, Seda Ogrenci, Lino Gerlach, Rian Flynn, Mia Liu, Daniel Diaz, Elham Khoda, Melissa Quinnan, Russell Solares, Santosh Parajuli, Mark Neubauer, Christian Herwig, Ho Fung Tsoi, Dylan Rankin, Shih-Chieh Hsu, Scott Hauck",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01463v1",
    "source": "arXiv",
    "abstract": "We present hls4ml, a free and open-source platform that translates machine learning (ML) models from modern deep learning frameworks into high-level synthesis (HLS) code that can be integrated into full designs for field-programmable gate arrays (FPGAs) or application-specific integrated circuits (ASICs). With its flexible and modular design, hls4ml supports a large number of deep learning frameworks and can target HLS compilers from several vendors, including Vitis HLS, Intel oneAPI and Catapult HLS. Together with a wider eco-system for software-hardware co-design, hls4ml has enabled the acceleration of ML inference in a wide range of commercial and scientific applications where low latency, resource usage, and power consumption are critical. In this paper, we describe the structure and functionality of the hls4ml platform. The overarching design considerations for the generated HLS code are discussed, together with selected performance results.",
    "title_zh": "hls4ml：一个灵活的开源平台，用于可重构硬件上的深度学习加速",
    "abstract_zh": "我们介绍了hls4ml，这是一个免费且开源的平台，可将现代深度学习框架中的机器学习（ML）模型转换为高层次综合（HLS）代码，从而能够集成到现场可编程门阵列（FPGA）或专用集成电路（ASIC）的完整设计中。凭借其灵活且模块化的设计，hls4ml支持多种深度学习框架，并可针对来自多个厂商的HLS编译器进行部署，包括Vitis HLS、Intel oneAPI和Catapult HLS。结合更广泛的软硬件协同设计生态系统，hls4ml已在众多商业和科学应用中实现了机器学习推理的加速，这些应用对低延迟、资源占用和功耗控制具有严格要求。本文详细描述了hls4ml平台的结构与功能，探讨了生成HLS代码时的核心设计考量，并展示了部分性能评估结果。"
  },
  {
    "date": "2025-12-01",
    "title": "ICAD-LLM: One-for-All Anomaly Detection via In-Context Learning with Large Language Models",
    "authors": "Zhongyuan Wu, Jingyuan Wang, Zexuan Cheng, Yilong Zhou, Weizhi Wang, Juhua Pu, Chao Li, Changqing Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01672v1",
    "source": "arXiv",
    "abstract": "Anomaly detection (AD) is a fundamental task of critical importance across numerous domains. Current systems increasingly operate in rapidly evolving environments that generate diverse yet interconnected data modalities -- such as time series, system logs, and tabular records -- as exemplified by modern IT systems. Effective AD methods in such environments must therefore possess two critical capabilities: (1) the ability to handle heterogeneous data formats within a unified framework, allowing the model to process and detect multiple modalities in a consistent manner during anomalous events; (2) a strong generalization ability to quickly adapt to new scenarios without extensive retraining. However, most existing methods fall short of these requirements, as they typically focus on single modalities and lack the flexibility to generalize across domains. To address this gap, we introduce a novel paradigm: In-Context Anomaly Detection (ICAD), where anomalies are defined by their dissimilarity to a relevant reference set of normal samples. Under this paradigm, we propose ICAD-LLM, a unified AD framework leveraging Large Language Models' in-context learning abilities to process heterogeneous data within a single model. Extensive experiments demonstrate that ICAD-LLM achieves competitive performance with task-specific AD methods and exhibits strong generalization to previously unseen tasks, which substantially reduces deployment costs and enables rapid adaptation to new environments. To the best of our knowledge, ICAD-LLM is the first model capable of handling anomaly detection tasks across diverse domains and modalities.",
    "title_zh": "ICAD-LLM：基于大语言模型上下文学习的通用异常检测",
    "abstract_zh": "异常检测（AD）是一项在众多领域中具有根本重要性的任务。当前系统越来越多地运行在快速演变的环境中，这些环境生成多样但相互关联的数据模态——例如时间序列、系统日志和表格记录——这在现代IT系统中尤为典型。因此，在此类环境中有效的异常检测方法必须具备两项关键能力：（1）能够在统一框架内处理异构数据格式，使模型在异常事件发生时能够以一致的方式处理并检测多种数据模态；（2）具备强大的泛化能力，能够在无需大量重新训练的情况下快速适应新场景。然而，大多数现有方法未能满足这些要求，因为它们通常仅关注单一模态，缺乏跨领域的灵活性。为弥补这一差距，我们提出一种新范式：上下文内异常检测（ICAD），其中异常被定义为与一组相关正常样本的不相似性。在此范式下，我们提出了ICAD-LLM，一种利用大语言模型的上下文学习能力来统一处理异构数据的异常检测框架。大量实验表明，ICAD-LLM在性能上可与特定任务的异常检测方法相媲美，并展现出对先前未见过的任务的强大泛化能力，显著降低了部署成本，实现了对新环境的快速适应。据我们所知，ICAD-LLM是首个能够跨多样化领域和数据模态执行异常检测任务的模型。"
  },
  {
    "date": "2025-12-01",
    "title": "Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry - an Experience Report",
    "authors": "Pankaj Jalore, Y. Raghu Reddy, Vasudeva Varma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01523v1",
    "source": "arXiv",
    "abstract": "Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled \"AI in Software Engineering\" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.",
    "title_zh": "与产业合作开展在线多机构研究级软件工程课程的教学——经验报告",
    "abstract_zh": "新冠疫情使在线教学与学习变得普遍可接受，学生、教师以及行业专业人士都已对此模式感到舒适。这种舒适感可以被充分利用，以开展跨机构的在线研究级课程，尤其是在某些单一机构可能缺乏足够师资来授课和/或招收研究型学生的情况下。如果该课程主题对行业具有吸引力，在线形式也便于行业专家轻松参与和贡献。软件工程中的高级专题尤其适合尝试这种教学模式，因为行业通常希望将软件工程领域的最新进展融入自身实践，因此更有可能愿意参与其中。本文描述了两所院校联合开设“人工智能在软件工程中的应用”课程的一次实验，该课程有活跃的行业参与，并分享了我们及学生们的体验。我们认为，这种协作式教学模式可被任何规模较小、难以独立开设研究级课程的计算机科学应用领域院校采用，以实现高质量的研究级课程教学。"
  },
  {
    "date": "2025-12-01",
    "title": "LLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation",
    "authors": "Wenhao Wang, Yanyan Li, Long Jiao, Jiawei Yuan",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.02002v1",
    "source": "arXiv",
    "abstract": "Recent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating se- mantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.",
    "title_zh": "基于静态文本模拟的大型语言模型驱动纠错机器人操作代码生成",
    "abstract_zh": "近年来，大型语言模型（LLMs）在生成机器人操作代码方面展现出巨大潜力，为实现由LLM驱动的机器人系统提供了可能。为了提升LLM生成的操作代码的可靠性，现有研究越来越多地采用基于代码执行过程中观察反馈的修正设计。然而，这些设计中的代码执行依赖于物理实验或定制化的仿真环境，受限于环境配置复杂度高以及潜在的长时间执行问题，导致其实际部署受到限制。本文探索了直接利用LLM实现机器人操作代码静态仿真的可行性，并基于此设计了一种新型可靠的、由LLM驱动的代码修正生成框架。我们的框架将LLM配置为具备增强能力的静态仿真器，能够通过解析动作、推理状态转移、分析执行结果，并生成准确反映轨迹动态的语义化观测信息，从而可靠地模拟机器人代码的执行过程。为验证该框架的性能，我们在多种不同机器人（包括无人机和小型地面车辆）上进行了各类操作任务的实验。实验结果不仅证明了我们基于文本的静态仿真具有高度准确性，也验证了所提出的LLM驱动修正框架在代码生成方面的可靠性：其性能可与当前最先进的方法相媲美，且无需依赖物理实验或动态仿真器进行代码执行。"
  },
  {
    "date": "2025-12-01",
    "title": "Tahr: The Generative Attribute Grammar Framework",
    "authors": "Matteo Ciccaglione, Pierciro Caliandro, Alessandro Pellegrini",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01872v1",
    "source": "arXiv",
    "abstract": "In this article, we present Tahr, a framework that allows taking attribute grammar specifications and generating a set of software artefacts that can be used programmatically to operate on text compliant with the grammars. Tahr can be used as an algorithmic workbench to test different manipulations of attribute grammars and support translation between different languages out of the box. We describe the framework's organisation, how the user can specify an attribute grammar, and the generated software artefacts. We also discuss how Tahr deals with ambiguous grammar specifications, and how this ambiguity can be effectively exploited when using attribute grammars for text generation. We test the correctness of Tahr by showing the practical possibility of translating MIPS programs into their corresponding equivalents for x86 architectures and a custom virtual machine.",
    "title_zh": "塔尔：生成式属性语法框架",
    "abstract_zh": "在本文中，我们介绍了 Tahr 框架，该框架能够接收属性文法规范，并生成一组可编程使用的软件构件，用于操作符合这些文法的文本。Tahr 可用作算法实验平台，以测试不同的属性文法变换，并开箱即用地支持多种语言之间的转换。我们描述了该框架的组织结构，用户如何指定属性文法，以及生成的软件构件。此外，我们还讨论了 Tahr 如何处理文法规范中的歧义性问题，以及在使用属性文法进行文本生成时，如何有效利用这种歧义性。通过将 MIPS 程序成功转换为对应 x86 架构和自定义虚拟机的等价程序，我们验证了 Tahr 的正确性。"
  },
  {
    "date": "2025-12-01",
    "title": "2D-ThermAl: Physics-Informed Framework for Thermal Analysis of Circuits using Generative AI",
    "authors": "Soumyadeep Chandra, Sayeed Shafayet Chowdhury, Kaushik Roy",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01163v1",
    "source": "arXiv",
    "abstract": "Thermal analysis is increasingly critical in modern integrated circuits, where non-uniform power dissipation and high transistor densities can cause rapid temperature spikes and reliability concerns. Traditional methods, such as FEM-based simulations offer high accuracy but computationally prohibitive for early-stage design, often requiring multiple iterative redesign cycles to resolve late-stage thermal failures. To address these challenges, we propose 'ThermAl', a physics-informed generative AI framework which effectively identifies heat sources and estimates full-chip transient and steady-state thermal distributions directly from input activity profiles. ThermAl employs a hybrid U-Net architecture enhanced with positional encoding and a Boltzmann regularizer to maintain physical fidelity. Our model is trained on an extensive dataset of heat dissipation maps, ranging from simple logic gates (e.g., inverters, NAND, XOR) to complex designs, generated via COMSOL. Experimental results demonstrate that ThermAl delivers precise temperature mappings for large circuits, with a root mean squared error (RMSE) of only 0.71°C, and outperforms conventional FEM tools by running up to ~200 times faster. We analyze performance across diverse layouts and workloads, and discuss its applicability to large-scale EDA workflows. While thermal reliability assessments often extend beyond 85°C for post-layout signoff, our focus here is on early-stage hotspot detection and thermal pattern learning. To ensure generalization beyond the nominal operating range 25-55°C, we additionally performed cross-validation on an extended dataset spanning 25-95°C maintaining a high accuracy (<2.2% full-scale RMSE) even under elevated temperature conditions representative of peak power and stress scenarios.",
    "title_zh": "2D-ThermAl：基于生成式人工智能的电路热分析物理信息框架",
    "abstract_zh": "热分析在现代集成电路中日益关键，因为非均匀的功耗分布和高密度的晶体管布局可能导致快速的温度飙升以及可靠性问题。传统的有限元方法（FEM）仿真虽然精度较高，但在早期设计阶段计算成本过高，往往需要多次迭代重设计才能解决后期出现的热失效问题。为应对这些挑战，我们提出了一种物理信息驱动的生成式人工智能框架——ThermAl，该框架能够直接从输入活动配置中有效识别热源，并估算全芯片的瞬态与稳态温度分布。ThermAl采用一种结合位置编码与玻尔兹曼正则化的混合U-Net架构，以保持物理一致性。我们的模型基于大量由COMSOL生成的功耗分布图进行训练，涵盖从简单逻辑门（如反相器、NAND、XOR）到复杂电路设计的多种结构。实验结果表明，ThermAl可对大规模电路实现精确的温度映射，均方根误差（RMSE）仅为0.71°C，且运行速度比传统FEM工具快达约200倍。我们在多种版图布局和工作负载下评估了其性能，并探讨了其在大规模EDA流程中的适用性。尽管热可靠性评估通常需覆盖超过85°C的范围以用于布局后签核，但本文重点在于早期阶段的热点检测与热模式学习。为确保模型在额定工作温度范围（25–55°C）之外仍具备良好泛化能力，我们进一步在扩展数据集（25–95°C）上进行了交叉验证，在峰值功耗和应力场景所代表的高温条件下，依然保持了较高的精度（全量程RMSE低于2.2%）。"
  },
  {
    "date": "2025-12-01",
    "title": "LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM",
    "authors": "Yuxin Zhang, Yuxia Zhang, Zeyu Sun, Yanjie Jiang, Hui Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01356v1",
    "source": "arXiv",
    "abstract": "Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.",
    "title_zh": "劳拉：基于上下文增强的检索增强型大语言模型提升代码审查生成",
    "abstract_zh": "代码审查对于确保软件质量和可维护性至关重要。随着软件规模和复杂性的迅速增长，代码审查因其耗时、需要专业知识以及经验丰富的开发者资源短缺，已成为开发流程中的瓶颈。目前已有多种方法被提出，用于基于检索、神经机器翻译、预训练模型或大型语言模型（LLMs）自动生成代码审查意见。这些方法主要依赖于历史代码变更和评论数据。然而，大量对代码审查至关重要的信息，如代码变更的上下文背景以及以往的审查知识，却常常被忽视。\n\n本文提出了一种基于大语言模型的、融合审查知识与上下文感知的代码审查生成框架，命名为LAURA。该框架通过整合审查示例检索、上下文增强和系统性引导机制，显著提升了ChatGPT-4o和DeepSeek v3在生成代码审查评论方面的表现。此外，鉴于现有数据集中存在大量低质量的审查评论，我们还构建了一个高质量的数据集。实验结果表明，对于两个模型而言，LAURA在42.2%和40.4%的情况下生成的评论要么完全正确，要么至少对开发者具有实际帮助，显著优于现有的最先进基线方法。进一步的消融实验证明，LAURA框架中的所有组件均对提升评论质量起到了积极作用。"
  },
  {
    "date": "2025-12-01",
    "title": "Learned-Rule-Augmented Large Language Model Evaluators",
    "authors": "Jie Meng, Jin Mao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01958v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.",
    "title_zh": "基于学习规则的大型语言模型评估器",
    "abstract_zh": "大型语言模型（LLMs）主要被用作自然语言生成（NLG）任务的评估工具，但其在更广泛评估场景中的应用仍较为有限。本文探讨了将LLMs作为跨多种任务的通用评估器的潜力。尽管基于LLM的评估方法在不同领域已取得一定进展，但现有方法由于依赖于昂贵且人工设计的评估准则，难以实现良好泛化，这些准则往往与标注数据及LLM自身的理解存在偏差。为解决上述挑战，我们提出了一种规则增强型评估范式。首先，我们引入一种规则提炼方法，利用LLM辅助的蒙特卡洛树搜索（MCTS）从数据中自动提取评分规则，从而缓解可扩展性问题，并提升与数据的一致性。其次，为使LLM能够有效应用所学规则，我们提出了两种策略：（1）规则链（Chain-of-Rule, CoR），引导LLM遵循提炼出的规则；（2）通过强化学习训练一个规则增强型LLM评估器（RuAE），进一步弥合规则与LLM推理能力之间的差距。在多种任务上的大量实验表明，该方法在不同评估场景中均展现出优异的有效性和泛化能力。"
  },
  {
    "date": "2025-12-01",
    "title": "Agentic Policy Optimization via Instruction-Policy Co-Evolution",
    "authors": "Han Zhou, Xingchen Wan, Ivan Vulić, Anna Korhonen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01945v1",
    "source": "arXiv",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has advanced the reasoning capability of large language models (LLMs), enabling autonomous agents that can conduct effective multi-turn and tool-integrated reasoning. While instructions serve as the primary protocol for defining agents, RLVR typically relies on static and manually designed instructions. However, those instructions may be suboptimal for the base model, and the optimal instruction may change as the agent's policy improves and explores the interaction with the environment. To bridge the gap, we introduce INSPO, a novel Instruction-Policy co-evolution framework that integrates instruction optimization as a dynamic component of the reinforcement learning (RL) loop. INSPO maintains a dynamic population of instruction candidates that are sampled with questions, where reward signals in RL loops are automatically attributed to each instruction, and low performers are periodically pruned. New instructions are generated and verified through an on-policy reflection mechanism, where an LLM-based optimizer analyzes past experience from a replay buffer and evolves more effective strategies given the current policy. We conduct extensive experiments on multi-turn retrieval and reasoning tasks, demonstrating that INSPO substantially outperforms strong baselines relying on static instructions. INSPO discovers innovative instructions that guide the agent toward more strategic reasoning paths, achieving substantial performance gains with only a marginal increase in computational overhead.",
    "title_zh": "通过指令-策略共同进化实现的代理策略优化",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）显著提升了大型语言模型（LLMs）的推理能力，使得自主智能体能够开展高效、多轮次且融合工具的复杂推理。尽管指令是定义智能体行为的主要机制，但传统RLVR通常依赖于静态且人工设计的指令。然而，这些指令可能并不适用于基础模型，且随着智能体策略的优化以及与环境交互的深入，最优指令本身也可能发生变化。为弥合这一差距，我们提出INSPO——一种全新的指令-策略协同进化框架，将指令优化作为强化学习（RL）循环中的动态组成部分。INSPO维护一个动态的指令候选池，这些指令与问题一同采样，并在RL循环中自动根据奖励信号对每条指令进行评估，表现不佳的指令会定期被剔除。新的指令通过一种基于策略的反思机制生成并验证：由一个基于LLM的优化器分析回放缓冲区中的历史经验，根据当前策略演化出更有效的推理策略。我们在多轮检索与推理任务上进行了大量实验，结果表明，相较于依赖静态指令的强基线方法，INSPO表现出显著优势。INSPO能够发现创新性的指令，引导智能体走向更具战略性的推理路径，在仅带来微小计算开销增加的情况下实现了显著的性能提升。"
  },
  {
    "date": "2025-12-01",
    "title": "OpenDORS: A dataset of openly referenced open research software",
    "authors": "Stephan Druskat, Lars Grunske",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01570v1",
    "source": "arXiv",
    "abstract": "In many academic disciplines, software is created during the research process or for a research purpose. The crucial role of software for research is increasingly acknowledged. The application of software engineering to research software has been formalized as research software engineering, to create better software that enables better research. Despite this, large-scale studies of research software and its development are still lacking. To enable such studies, we present a dataset of 134,352 unique open research software projects and 134,154 source code repositories referenced in open access literature. Each dataset record identifies the referencing publication and lists source code repositories of the software project. For 122,425 source code repositories, the dataset provides metadata on latest versions, license information, programming languages and descriptive metadata files. We summarize the distributions of these features in the dataset and describe additional software metadata that extends the dataset in future work. Finally, we suggest examples of research that could use the dataset to develop a better understanding of research software practice in RSE research.",
    "title_zh": "OpenDORS：一个开放引用的开源研究软件数据集",
    "abstract_zh": "在许多学术领域中，研究过程中或为研究目的而开发的软件日益普遍。人们越来越认识到软件在科研中的关键作用。将软件工程方法应用于科研软件，已正式发展为“科研软件工程”（Research Software Engineering），旨在创建更优质的软件，从而推动更高质量的研究。然而，目前针对科研软件及其开发的大规模研究仍十分有限。为支持此类研究，我们构建了一个包含134,352个独立的开源科研软件项目以及134,154个在开放获取文献中被引用的源代码仓库的数据集。每个数据条目均标识出引用的出版物，并列出该软件项目的源代码仓库。对于其中122,425个源代码仓库，本数据集还提供了最新版本信息、许可证信息、编程语言以及描述性元数据文件等信息。我们对数据集中各项特征的分布进行了总结，并描述了未来工作可进一步扩展的其他软件元数据。最后，我们提出若干研究案例，展示如何利用该数据集深入理解科研软件工程领域的实践现状。"
  },
  {
    "date": "2025-12-01",
    "title": "SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry",
    "authors": "Daniel Armstrong, Zlatko Jončev, Andres M Bran, Philippe Schwaller",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01507v1",
    "source": "arXiv",
    "abstract": "Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.",
    "title_zh": "合成策略：从大语言模型中提取并形式化有机化学领域的潜在战略洞见",
    "abstract_zh": "现代计算机辅助合成规划（CASP）系统在生成化学上合理的反应步骤方面展现出巨大潜力，但在融入战略层面的考量（如汇聚式组装、保护基最小化以及最优环形成序列）方面仍面临挑战。我们提出一种新方法，利用大型语言模型将合成知识提炼为代码形式。我们的系统分析合成路线，并将各类战略原则转化为Python函数，以表示多样化的战略与战术规则，例如功能团转化策略和环构建策略。通过将这些知识形式化为可验证的代码而非简单的启发式规则，我们构建了可测试、可解释的合成策略表达方式。我们已公开完整的代码库及USPTO-ST数据集——该数据集包含带有战略标签注释的合成路线。这一框架为CASP带来了全新能力：基于自然语言的路线检索，在我们的基准测试中实现了75%的Top-3准确率。此外，我们通过时间趋势分析对所构建的库进行了验证，并展示了化学直觉性强的路线聚类结果，其划分粒度优于以往常见的方法。本研究弥合了CASP领域中战术与战略之间的鸿沟，使得合成路线能够依据战略标准进行指定、搜索与评估，而不再仅依赖结构相似性。"
  },
  {
    "date": "2025-12-01",
    "title": "A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building",
    "authors": "Daull Xavier, Patrice Bellot, Emmanuel Bruno, Vincent Martin, Elisabeth Murisasco",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01434v1",
    "source": "arXiv",
    "abstract": "We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.",
    "title_zh": "一种灵活的多智能体LLM-人类协作框架，用于快速实现经人类验证的工具构建",
    "abstract_zh": "我们介绍了CollabToolBuilder，这是一个灵活的多智能体大语言模型框架，采用“人类在环”（HITL）指导机制，通过迭代学习为特定目标构建工具，从而在最小化任务/领域适应时间和人工反馈收集成本的同时，与人类意图和流程保持一致。该架构通过四个专业智能体（教练、编码员、批评家、资本化者）协作，利用强化的动态提示和系统化的人类反馈集成，实现工具的生成与验证，以强化各智能体在达成目标与满足约束条件方面的角色。本研究可视为一种系统级整合方法，融合了多智能体上下文学习、HITL控制以及可复用工具资本化技术，适用于复杂迭代性问题，如科学文献生成。我们通过初步实验（例如，根据摘要生成前沿研究论文或专利）展示了其应用效果，并探讨了其在其他迭代式问题求解场景中的适用性。"
  },
  {
    "date": "2025-12-01",
    "title": "Drafting and Multi-Input Switching in Digital Dynamic Timing Simulation for Multi-Input Gates",
    "authors": "Arman Ferdowsi, Ulrich Schmid, Josef Salzmann",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01309v1",
    "source": "arXiv",
    "abstract": "We present a prototype multi-input gate extension of the publicly available Involution Tool for accurate digital timing simulation and power analysis of integrated circuits introduced by Oehlinger et al. (Integration, 2021). Relying on discrete event simulation, the Involution Tool allows fast timing simulation of circuits made up of an arbitrary composition of supported gates, provides automatic random input stimulus generation, and supports parameter sweeping. It also enables a detailed comparison of the delay predictions obtained by different models, including pure and inertial delays as well as digitized SPICE-generated reference traces. Our extension added support for 2-input gates like NOR and NAND, by implementing novel analytic delay formulas obtained via a refined analysis of a recently proposed thresholded first-order hybrid model of such gates. The resulting formulas faithfully cover not only multi-input switching effects (also known as Charlie effects), but also the decay of short pulses (aka Drafting effects). Besides the fact that our analytic models not only allow the derivation of closed-form delay formulas for arbitrary compositions of such gates, they are also key for a strikingly simple procedure for model parametrization, i.e., for gate characterization, which only needs three characteristic delay values. Using the extended Involution Tool, we compare the delay and power predictions for some benchmarking circuits stimulated by randomly generated input traces. Overall, our results reveal considerably improved prediction accuracy compared to the original Involution Tool, without a noticeable performance penalty.",
    "title_zh": "数字动态时序仿真中多输入门的布线与多输入切换",
    "abstract_zh": "我们提出了一种原型多输入门扩展版本的公开可用Involution工具，该工具由Oehlinger等人（Integration, 2021）引入，用于集成电路的精确数字时序仿真与功耗分析。基于离散事件仿真，Involution工具能够快速对任意组合的受支持门电路进行时序仿真，提供自动随机输入激励生成功能，并支持参数扫描。此外，它还能够对不同模型所获得的延迟预测结果进行详细比较，包括纯延迟、惯性延迟以及由SPICE数字化生成的参考波形。我们的扩展通过实现一种基于近期提出的阈值型一阶混合模型的精细化分析所得的新颖解析延迟公式，增加了对NOR和NAND等双输入门的支持。这些新推导出的公式不仅准确涵盖了多输入切换效应（又称Charlie效应），还能有效描述短脉冲的衰减现象（即Drafting效应）。更重要的是，由于这些解析模型的存在，不仅可以为任意组合的此类门电路推导出闭式延迟表达式，而且使得模型参数化过程——即门电路特性表征——变得极为简便，仅需三个特征延迟值即可完成。利用扩展后的Involution工具，我们对若干基准电路在随机生成输入波形激励下的延迟与功耗预测进行了对比分析。总体而言，与原始的Involution工具相比，我们的方法显著提升了预测精度，同时未带来明显的性能开销。"
  },
  {
    "date": "2025-12-01",
    "title": "Reverse Engineering and Control-Aware Security Analysis of the ArduPilot UAV Framework",
    "authors": "Yasaswini Konapalli, Lotfi Ben Othmane, Cihan Tunc, Feras Benchellal, Likhita Mudagere",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01164v1",
    "source": "arXiv",
    "abstract": "Unmanned Aerial Vehicle (UAV) technologies are gaining high interest for many domains, which makes UAV security of utmost importance. ArduPilot is among the most widely used open-source autopilot UAV frameworks; yet, many studies demonstrate the vulnerabilities affecting such systems. Vulnerabilities within its communication subsystems (including WiFi, telemetry, or GPS) expose critical entry points, and vulnerabilities in Ardupilot can affect the control procedure. In this paper, we reconstruct the software architecture and the control models implemented by ArduPilot and then examine how these control models could potentially misused to induce malicious behaviors while relying on legitimate inputs.",
    "title_zh": "阿鲁达飞行器无人机框架的逆向工程与控制感知安全分析",
    "abstract_zh": "无人机（UAV）技术在众多领域正受到高度关注，这使得无人机安全变得至关重要。ArduPilot 是目前最广泛使用的开源自动驾驶无人机框架之一；然而，多项研究已揭示了此类系统中存在的诸多漏洞。其通信子系统（包括WiFi、遥测或GPS）中的漏洞暴露了关键的攻击入口，而ArduPilot中的漏洞可能影响控制流程。本文重构了ArduPilot所实现的软件架构与控制模型，并进一步分析这些控制模型在依赖合法输入的情况下，可能被滥用以引发恶意行为。"
  },
  {
    "date": "2025-12-01",
    "title": "Rectifying LLM Thought from Lens of Optimization",
    "authors": "Junnan Liu, Hongwei Liu, Songyang Zhang, Kai Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01925v1",
    "source": "arXiv",
    "abstract": "Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these advances, long-CoT LLMs often exhibit suboptimal reasoning behaviors, such as overthinking and excessively protracted reasoning chains, which can impair performance. In this paper, we analyze reasoning processes through an optimization lens, framing CoT as a gradient descent procedure where each reasoning step constitutes an update toward problem resolution. Building on this perspective, we introduce RePro (Rectifying Process-level Reward), a novel approach to refine LLM reasoning during post-training. RePro defines a surrogate objective function to assess the optimization process underlying CoT, utilizing a dual scoring mechanism to quantify its intensity and stability. These scores are aggregated into a composite process-level reward, seamlessly integrated into reinforcement learning with verifiable rewards (RLVR) pipelines to optimize LLMs. Extensive experiments across multiple reinforcement learning algorithms and diverse LLMs, evaluated on benchmarks spanning mathematics, science, and coding, demonstrate that RePro consistently enhances reasoning performance and mitigates suboptimal reasoning behaviors.",
    "title_zh": "从优化的视角修正大语言模型的思维",
    "abstract_zh": "近年来，大型语言模型（LLMs）的进展主要得益于其涌现的推理能力，尤其是通过长链式思维（Chain-of-Thought, CoT）提示方法，实现了对问题的深入探索与审慎思考。尽管取得了显著进步，但采用长CoT的LLMs仍常表现出次优的推理行为，如过度思考和推理链条过长，这些现象会损害模型的整体表现。本文从优化视角分析推理过程，将CoT建模为一种梯度下降过程，其中每一步推理都可视为向问题求解方向的一次更新。基于这一观点，我们提出RePro（过程级奖励修正，Rectifying Process-level Reward），一种在后训练阶段优化LLM推理的新方法。RePro定义了一个代理目标函数，用于评估CoT背后的优化过程，并采用双评分机制来量化该过程的强度与稳定性。这两个评分被整合为一个综合的过程级奖励信号，并无缝嵌入到可验证奖励的强化学习（RLVR）框架中，以优化LLM的表现。在涵盖数学、科学和编程等多个领域的基准测试上，针对多种强化学习算法和不同规模LLMs的大量实验表明，RePro能够持续提升推理性能，并有效缓解次优推理行为。"
  },
  {
    "date": "2025-12-01",
    "title": "Behind the Curtain: How Shared Hosting Providers Respond to Vulnerability Notifications",
    "authors": "Giada Stivala, Rafael Mrowczynski, Maria Hellenthal, Giancarlo Pellegrino",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01891v1",
    "source": "arXiv",
    "abstract": "Large-scale vulnerability notifications (VNs) can help hosting provider organizations (HPOs) identify and remediate security vulnerabilities that attackers can exploit in data breaches or phishing campaigns. Previous VN studies have primarily focused on factors under the control of reporters, such as sender reputation, email formatting, and communication channels. Despite these efforts, remediation rates for vulnerability notifications continue to remain consistently low. This paper presents the first in-depth study of how HPOs process vulnerability notifications internally and what organizational and operational factors influence VN effectiveness. We examine the problem from a different perspective to provide the first detailed understanding of the reasons behind persistently low remediation rates. Instead of manipulating parameters of VN campaigns, we interview hosting providers directly, investigating how they handle vulnerability notifications and what factors may influence VN effectiveness, such as VN awareness and reachability, HPOs' service models, and perceived security risks. We conducted semi-structured interviews with 24 HPOs across shared hosting and web development services, representing varied company sizes and operator roles. Our findings reveal practical insights on VN processing and abuse workflows. While some providers remain hard to reach due to complex infrastructures, most report routinely handling VNs. However, limited remediation often stems from strict responsibility boundaries, where web application issues are seen as the customer's domain. Low hosting fees and high volumes of daily compromises further discourage both proactive and reactive measures. Our findings show that HPOs blame negligent website owners, and prior works on website owners confirms they often undervalue their sites or lack security know-how.",
    "title_zh": "幕后真相：共享主机服务商如何应对漏洞通知",
    "abstract_zh": "大规模漏洞通知（Vulnerability Notifications, VNs）有助于托管服务提供商组织（Hosting Provider Organizations, HPOs）识别并修复攻击者可能在数据泄露或网络钓鱼活动期间利用的安全漏洞。以往的漏洞通知研究主要关注报告者可控的因素，如发送方信誉、邮件格式和通信渠道等。尽管已有这些努力，漏洞通知的修复率却始终维持在较低水平。本文首次深入研究了HPO内部如何处理漏洞通知，以及影响漏洞通知有效性的组织与运营因素。我们从一个全新的视角出发，旨在首次全面理解持续低修复率的根本原因。不同于以往通过调整漏洞通知活动参数来提升效果的做法，我们直接对托管服务商进行访谈，探究其处理漏洞通知的实际流程，以及可能影响通知有效性的因素，如漏洞通知的可见性与可及性、HPO的服务模式，以及对安全风险的认知程度。\n\n我们对24家涵盖共享托管和网页开发服务的HPO进行了半结构化访谈，覆盖不同规模的企业及不同的运营角色。研究发现揭示了关于漏洞通知处理与滥用工作流的实用洞见：虽然部分提供商因复杂的基础设施而难以联系，但大多数机构表示日常都会处理漏洞通知。然而，修复行动受限的主要原因在于责任边界过于严格——Web应用问题通常被视为客户的责任范围。低廉的托管费用以及每日大量遭受入侵的情况，进一步削弱了HPO采取主动或被动应对措施的积极性。我们的研究结果表明，HPO往往将责任归咎于疏于管理的网站所有者；而此前针对网站所有者的研究也证实，他们常常低估自身站点的重要性，或缺乏基本的安全知识。"
  },
  {
    "date": "2025-12-01",
    "title": "Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability",
    "authors": "Jinghan Jia, Nathalie Baracaldo, Sijia Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01848v1",
    "source": "arXiv",
    "abstract": "Large reasoning models (LRMs) extend large language models by generating explicit chain-of-thought (CoT) reasoning, significantly improving mathematical and logical problem solving. However, this explicit reasoning process also introduces new safety risks, as unsafe behaviors often emerge within intermediate reasoning trajectories, even when final answers appear harmless. Existing safety alignment approaches primarily rely on supervised fine-tuning (SFT) over safety-oriented long CoT datasets. While intuitive, we find that SFT produces inconsistent safety improvements, degrades reasoning ability, and generalizes poorly across model families. These limitations suggest that purely supervised approaches are insufficient for robust safety alignment in LRMs. To address this, we investigate reinforcement learning (RL) as a complementary optimization framework for LRM safety training. Unlike SFT, RL directly optimizes model policies with reward feedback, enabling more adaptive and stable alignment. Extensive experiments across multiple model families and benchmarks show that RL achieves stronger and more consistent safety gains while maintaining reasoning competence. Further analysis of reflection dynamics and token-level entropy reveals that RL suppresses unsafe exploratory reasoning while preserving reflective depth, leading to safer and more reliable reasoning processes.",
    "title_zh": "超越SFT：基于强化学习实现更安全且具备更强推理能力的大规模推理模型",
    "abstract_zh": "大型推理模型（LRMs）通过生成显式的思维链（CoT）推理过程，扩展了大型语言模型的能力，显著提升了数学与逻辑问题的求解效果。然而，这种显式推理过程也带来了新的安全风险：不安全行为往往出现在中间推理轨迹中，即使最终答案看似无害。现有的安全对齐方法主要依赖于在面向安全的长思维链数据集上进行监督微调（SFT）。尽管这一方法直观易懂，但我们发现SFT在安全性提升方面表现不一致，会削弱模型的推理能力，并且在不同模型家族间泛化能力较差。这些局限性表明，仅依靠监督学习的方法不足以实现LRM的稳健安全对齐。为此，我们探索强化学习（RL）作为LRM安全训练的补充优化框架。与SFT不同，RL通过奖励反馈直接优化模型策略，能够实现更自适应、更稳定的对齐效果。在多个模型家族和基准测试上的大量实验表明，RL不仅实现了更强且更一致的安全性提升，同时保持了良好的推理能力。进一步对反思动态和词元级熵的分析显示，RL有效抑制了不安全的探索性推理，同时保留了深度反思能力，从而形成了更安全、更可靠的推理过程。"
  },
  {
    "date": "2025-12-01",
    "title": "Automating modeling in mechanics: LLMs as designers of physics-constrained neural networks for constitutive modeling of materials",
    "authors": "Marius Tacke, Matthias Busch, Kian Abdolazizi, Jonas Eichinger, Kevin Linka, Christian Cyron, Roland Aydin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01735v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-based agentic frameworks increasingly adopt the paradigm of dynamically generating task-specific agents. We suggest that not only agents but also specialized software modules for scientific and engineering tasks can be generated on demand. We demonstrate this concept in the field of solid mechanics. There, so-called constitutive models are required to describe the relationship between mechanical stress and body deformation. Constitutive models are essential for both the scientific understanding and industrial application of materials. However, even recent data-driven methods of constitutive modeling, such as constitutive artificial neural networks (CANNs), still require substantial expert knowledge and human labor. We present a framework in which an LLM generates a CANN on demand, tailored to a given material class and dataset provided by the user. The framework covers LLM-based architecture selection, integration of physical constraints, and complete code generation. Evaluation on three benchmark problems demonstrates that LLM-generated CANNs achieve accuracy comparable to or greater than manually engineered counterparts, while also exhibiting reliable generalization to unseen loading scenarios and extrapolation to large deformations. These findings indicate that LLM-based generation of physics-constrained neural networks can substantially reduce the expertise required for constitutive modeling and represent a step toward practical end-to-end automation.",
    "title_zh": "力学建模的自动化：大语言模型作为物理约束神经网络的设计者，用于材料本构建模",
    "abstract_zh": "基于大型语言模型（LLM）的智能体框架正越来越多地采用动态生成任务特定智能体的范式。我们提出，不仅智能体本身，针对科学与工程任务的专用软件模块也可以按需生成。我们在固体力学领域验证了这一概念：在该领域中，所谓的本构模型用于描述机械应力与物体变形之间的关系。本构模型对于材料的科学理解及工业应用都至关重要。然而，即便是近期的数据驱动型本构建模方法，如本构人工神经网络（CANNs），仍然需要大量专家知识和人工投入。本文提出一种框架，由LLM根据用户提供的材料类别和数据集，按需生成定制化的CANN。该框架涵盖了基于LLM的网络架构选择、物理约束的集成以及完整代码的自动生成。在三个基准问题上的评估表明，LLM生成的CANN在精度上可媲美甚至优于人工设计的模型，同时在未见载荷场景下表现出可靠的泛化能力，并能有效外推至大变形情形。这些结果表明，基于LLM生成物理约束神经网络的方法能够显著降低本构建模对专业知识的需求，是迈向实用化端到端自动化的重要一步。"
  },
  {
    "date": "2025-12-01",
    "title": "StarDist: A Code Generator for Distributed Graph Algorithms",
    "authors": "Barenya Kumar Nandy, Rupesh Nasre",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01646v1",
    "source": "arXiv",
    "abstract": "Relational data, occurring in the real world, are often structured as graphs, which provide the logical abstraction required to make analytical derivations simpler. As graphs get larger, the irregular access patterns exhibited in most graph algorithms, hamper performance. This, along with NUMA and physical memory limits, results in scaling complexities with sequential/shared memory frameworks. StarPlat's MPI backend abstracts away the programmatic complexity involved in designing optimal distributed graph algorithms. It provides an instrument for coding graph algorithms that scale over distributed memory. In this work, we provide an analysis-transformation framework that leverages general semantics associated with iterations involving nodes and their neighbors, within StarPlat, to aggregate communication. The framework scans for patterns that warrant re-ordering in neighborhood access patterns, aggregate communication, and avoid communication altogether with opportunistic caching in reduction constructs. We also architect an optimized bulk-reduction substrate using Open MPI's passive Remote Memory Access (RMA) constructs. We applied our optimization logic to StarPlat's distributed backend and outperformed d-Galois by 2.05 and DRONE by 1.44 times in Single Source Shortest Paths across several big data graphs.",
    "title_zh": "StarDist：分布式图算法代码生成器",
    "abstract_zh": "现实世界中的关系型数据通常以图的形式组织，这种结构提供了使分析推导更简单的逻辑抽象。随着图的规模不断增大，大多数图算法表现出的不规则访问模式会严重制约性能。加之NUMA架构和物理内存容量的限制，使得在顺序/共享内存框架下实现可扩展性变得复杂。StarPlat的MPI后端抽象了设计最优分布式图算法所涉及的编程复杂性，提供了一种可在分布式内存环境中实现可扩展性的图算法编码工具。在本研究中，我们提出了一种分析-转换框架，该框架利用StarPlat中与节点及其邻居迭代相关的通用语义，实现通信聚合。该框架通过扫描识别出需要重新排序邻域访问模式的模式，对通信进行聚合，并在归约操作中借助机会性缓存避免通信开销。此外，我们还基于Open MPI的被动远程内存访问（RMA）机制，构建了一个优化的批量归约基础组件。将我们的优化逻辑应用于StarPlat的分布式后端，在多个大数据图上的单源最短路径（SSSP）任务中，性能分别优于d-Galois 2.05倍和DRONE 1.44倍。"
  },
  {
    "date": "2025-12-01",
    "title": "Velocity-Adaptive Access Scheme for Semantic-Aware Vehicular Networks: Joint Fairness and AoI Optimization",
    "authors": "Xiao Xu, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01571v1",
    "source": "arXiv",
    "abstract": "In this paper, we address the problem of fair access and Age of Information (AoI) optimization in 5G New Radio (NR) Vehicle to Everything (V2X) Mode 2. Specifically, vehicles need to exchange information with the road side unit (RSU). However, due to the varying vehicle speeds leading to different communication durations, the amount of data exchanged between different vehicles and the RSU may vary. This may poses significant safety risks in high-speed environments. To address this, we define a fairness index through tuning the selection window of different vehicles and consider the image semantic communication system to reduce latency. However, adjusting the selection window may affect the communication time, thereby impacting the AoI. Moreover, considering the re-evaluation mechanism in 5G NR, which helps reduce resource collisions, it may lead to an increase in AoI. We analyze the AoI using Stochastic Hybrid System (SHS) and construct a multi-objective optimization problem to achieve fair access and AoI optimization. Sequential Convex Approximation (SCA) is employed to transform the non-convex problem into a convex one, and solve it using convex optimization. We also provide a large language model (LLM) based algorithm. The scheme's effectiveness is validated through numerical simulations.",
    "title_zh": "面向语义感知车联网的速率自适应接入方案：联合公平性与信息年龄优化",
    "abstract_zh": "本文针对5G新空口（NR）车联网（V2X）模式2中的公平接入与信息时效性（Age of Information, AoI）优化问题展开研究。具体而言，车辆需与路边单元（RSU）进行信息交换。然而，由于车辆速度差异导致通信时长不一，不同车辆与RSU之间交换的数据量存在显著差异，这在高速场景下可能带来严重的安全风险。为应对这一挑战，本文通过调节不同车辆的选择窗口来定义公平性指标，并引入图像语义通信系统以降低传输延迟。然而，调整选择窗口可能影响通信时长，进而对AoI产生不利影响。此外，考虑到5G NR中引入的重评估机制有助于减少资源冲突，但该机制也可能导致AoI上升。为此，本文采用随机混合系统（Stochastic Hybrid System, SHS）对AoI进行建模，并构建了一个多目标优化问题，旨在实现公平接入与AoI优化的平衡。通过序列凸逼近（Sequential Convex Approximation, SCA）方法，将非凸优化问题转化为凸问题，并利用凸优化技术求解。同时，本文还提出了一种基于大语言模型（Large Language Model, LLM）的算法。仿真结果验证了所提方案的有效性。"
  },
  {
    "date": "2025-12-01",
    "title": "ZIP-RC: Zero-overhead Inference-time Prediction of Reward and Cost for Adaptive and Interpretable Generation",
    "authors": "Rohin Manvi, Joey Hong, Tim Seyde, Maxime Labonne, Mathias Lechner, Sergey Levine",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01457v1",
    "source": "arXiv",
    "abstract": "Large language models excel at reasoning but lack key aspects of introspection, including anticipating their own success and the computation required to achieve it. Humans use real-time introspection to decide how much effort to invest, when to make multiple attempts, when to stop, and when to signal success or failure. Without this, LLMs struggle to make intelligent meta-cognition decisions. Test-time scaling methods like Best-of-N drive up cost and latency by using a fixed budget of samples regardless of the marginal benefit of each one at any point in generation, and the absence of confidence signals can mislead people, prevent appropriate escalation to better tools, and undermine trustworthiness. Learned verifiers or reward models can provide confidence estimates, but do not enable adaptive inference and add substantial cost by requiring extra models or forward passes. We present ZIP-RC, an adaptive inference method that equips models with zero-overhead inference-time predictions of reward and cost. At every token, ZIP-RC reuses reserved or unused logits in the same forward pass as next-token prediction to output a joint distribution over final reward and remaining length -- no extra models, architecture change, or inference overhead. This full joint distribution is used to compute a sampling utility which is the linear combination of the expected maximum reward, total compute, and latency of set of samples if generated to completion. During inference, we maximize this utility with meta-actions that determine which prefix of tokens to continue or initiate sampling from. On mixed-difficulty mathematical benchmarks, ZIP-RC improves accuracy by up to 12% over majority voting at equal or lower average cost, and traces smooth Pareto frontiers between quality, compute, and latency. By providing real-time reward-cost introspection, ZIP-RC enables adaptive, efficient reasoning.",
    "title_zh": "ZIP-RC：零开销推理时奖励与成本预测，实现自适应且可解释的生成",
    "abstract_zh": "大型语言模型在推理方面表现出色，但缺乏自我反思的关键要素，例如预判自身成功可能性以及实现该成功的计算成本。人类会通过实时的自我反思来决定投入多少努力、何时进行多次尝试、何时停止，以及何时宣告成功或失败。若缺少这种能力，LLM 难以做出智能的元认知决策。现有的测试时扩展方法（如 Best-of-N）会因采用固定样本预算而增加成本和延迟，无论每个样本在生成过程中的边际收益如何；同时，由于缺乏置信度信号，容易误导用户，阻碍向更优工具的及时升级，并削弱可信度。虽然可学习的验证器或奖励模型能提供置信度估计，但它们无法实现自适应推理，且需额外模型或前向传播，带来显著开销。\n\n我们提出 ZIP-RC，一种自适应推理方法，使模型能够在不增加开销的情况下，在推理阶段实时预测奖励与成本。在每一 token 生成时，ZIP-RC 利用同一前向传播中预留或未使用的 logits，直接输出最终奖励与剩余长度的联合分布——无需额外模型、架构修改或推理开销。这一完整的联合分布用于计算“采样效用”，即一组样本若被完整生成后的期望最大奖励、总计算量和延迟的线性组合。在推理过程中，我们通过元动作（meta-actions）最大化该效用，以决定应继续哪个 token 前缀，或从何处启动采样。\n\n在混合难度的数学基准测试中，ZIP-RC 在平均成本相等或更低的前提下，相比多数投票法准确率最高提升 12%；并呈现出质量、计算量与延迟之间的平滑帕累托前沿。通过提供实时的奖励-成本自我反思能力，ZIP-RC 实现了高效、自适应的推理。"
  },
  {
    "date": "2025-12-01",
    "title": "LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost",
    "authors": "Donghao Huang, Shila Chew, Anna Dutkiewicz, Zhaoxia Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01232v1",
    "source": "arXiv",
    "abstract": "Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.",
    "title_zh": "基于大模型的评测系统在可扩展测试覆盖率评估中的应用：准确性、操作可靠性与成本",
    "abstract_zh": "在大规模软件测试覆盖评估中，质量保证（QA）流程仍面临瓶颈。本文提出一种面向生产环境、基于评分标准的框架——LLM-as-a-Judge（LAJ），用于评估Gherkin验收测试，并输出结构化JSON结果。我们在100个专家标注脚本上，对20种模型配置（包括GPT-4、GPT-5在不同推理强度下的变体以及开源权重模型）进行了5轮共500次评估，首次系统性地分析了准确性、运行可靠性与成本之间的关系。我们引入“首次尝试完成率”（Evaluation Completion Rate at 1, ECR@1）指标，量化首次尝试的成功率，结果显示可靠性介于85.4%至100.0%之间，且重试带来的成本影响显著。研究发现，小型模型可超越大型模型：GPT-4o Mini在准确率（6.07 MAAE）、可靠性（96.6% ECR@1）和成本（每千次仅$1.01）方面表现最优，相比GPT-5（高推理强度）实现78倍的成本降低，同时提升准确率。推理强度的影响具有模型族依赖性：GPT-5随推理强度增加而表现提升，且具备可预测的准确率-成本权衡；而开源模型在推理强度提高时，各项性能均呈下降趋势。总体来看，成本跨度达175倍（每千次$0.45至$78.96）。我们已公开数据集、框架及代码，以支持研究复现与实际部署。"
  },
  {
    "date": "2025-12-01",
    "title": "Teaching by Failure: Counter-Example-Driven Curricula for Transformer Self-Improvement",
    "authors": "Harshil Vejendla",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.01187v1",
    "source": "arXiv",
    "abstract": "Transformer models often exhibit brittle extrapolation, failing on inputs that are longer or structurally more complex than those seen during training. We introduce Counter-Example-Driven Curricula (CEDC), an automated framework that improves model robustness by iteratively focusing on its own failures. At each step, CEDC uses the current model to generate a diverse set of candidate problems, employs a fast, executable verifier to identify incorrect predictions (counter-examples), and then fine-tunes the model on a dataset enriched with these discovered failures. We evaluate CEDC on a suite of algorithmic and natural language tasks, including integer addition, sorting, Dyck-2 language recognition, and three text classification benchmarks. Compared to static training and standard curriculum learning baselines, CEDC achieves up to 30x greater length extrapolation, is 3.75x more computationally efficient than uniform data augmentation, and requires no manual difficulty heuristics. We provide a detailed analysis of the counter-examples, showing how the curriculum naturally adapts to target progressively more complex error modes. Our findings establish verifier-guided, failure-driven learning as a simple, powerful, and efficient paradigm for enhancing the generalization capabilities of Transformer models.",
    "title_zh": "通过失败教学：基于反例驱动的Transformer自我改进课程",
    "abstract_zh": "Transformer 模型常常表现出脆弱的外推能力，对于训练中未见过的更长或结构更复杂的输入会失效。我们提出了反例驱动课程学习（Counter-Example-Driven Curricula, CEDC），这是一种自动化的框架，通过迭代聚焦于模型自身的失败来提升其鲁棒性。在每一步中，CEDC 利用当前模型生成多样化的候选问题，使用一个快速可执行的验证器识别出错误预测（即反例），然后在包含这些发现失败的新数据集上对模型进行微调。我们在一系列算法和自然语言任务上评估了 CEDC，包括整数加法、排序、Dyck-2 语言识别以及三个文本分类基准。与静态训练和标准课程学习基线相比，CEDC 实现了高达 30 倍的长度外推能力提升，计算效率比均匀数据增强高出 3.75 倍，且无需人工设定难度启发式。我们对反例进行了详细分析，展示了课程如何自然地逐步适应目标更复杂的错误模式。我们的研究结果确立了验证器引导、以失败为导向的学习是一种简单、强大且高效的范式，能够显著增强 Transformer 模型的泛化能力。"
  },
  {
    "date": "2025-12-1",
    "title": "Efficient SIMD and Shared-Memory Parallelization of 3D Acoustic Wave Propagation Simulation",
    "authors": "Chahinèze Ztoti, Claude Tadonki, Roblex Nana Tchakoute, Hervé Chauris",
    "publish": "2025 IEEE/SBC 37th International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)",
    "url": "https://doi.org/10.1109/sbac-padw69789.2025.00014",
    "source": "IEEE",
    "abstract": "We are interested in the implementation of a mesh-based modeling for a numerical simulation of acoustic wave propagation. Considering a 2D validated version, we derive a 3D design by extending the spatial domain with a third dimension. The dimension n here refers to the spatial domain, which is modeled as a n-dimensional mesh grid augmented by a time axis. With this 4D model, considering large-scale scenarios goes with a significant demand of memory space, which can therefore justify delving into the domain decomposition strategy in the perspective of running on a distributed memory parallel machine or a cluster of standard processors. We investigate the required volume of memory and make it minimal considering the specific rules of the simulation. Next, beside ordinary code refactoring and optimization, we explore all levers of computing power at the level of a single processor, more precisely multi-thread parallelism and SIMD. Experimental results with various scenarios illustrate the possibility to handle bigger instances and an impressive global speedup (×20 on a specific execution scenario) compared to the original version of the code. A natural step further for this work is the design and implementation of distributed memory parallel version through domain decomposition, and GPU acceleration.",
    "title_zh": "三维声波传播模拟的高效SIMD与共享内存并行化",
    "abstract_zh": "我们对基于网格的建模在声波传播数值模拟中的实现感兴趣。以一个经过验证的二维版本为基础，通过在空间域中引入第三个维度，推导出三维设计。这里的“n”指空间域，被建模为一个n维网格，并通过增加时间轴扩展为四维模型。采用这种四维模型，在处理大规模场景时会带来显著的内存需求，因此有必要从在分布式内存并行机或标准处理器集群上运行的角度出发，深入研究域分解策略。我们分析了模拟所需的内存容量，并根据模拟的具体规则尽可能地将其最小化。此外，除了常规的代码重构与优化外，我们还探索了单个处理器层面的所有计算能力提升手段，特别是多线程并行和SIMD（单指令多数据）技术。在多种不同场景下的实验结果表明，该方法能够处理更大规模的问题实例，并且相较于原始代码版本，实现了惊人的整体加速比（在特定执行场景下达到×20）。这项工作的下一步自然是在域分解的基础上，设计并实现分布式内存并行版本，以及探索GPU加速方案。"
  },
  {
    "date": "2025-12-1",
    "title": "Neural Network Models for Cross-Language Code Synthesis and Translation",
    "authors": "Amrutha Muralidhar, Ananya Aithal, G Sanjana Hebbar, Kavitha Sooda",
    "publish": "2025 IEEE International Conference on Contemporary Computing and Communications (InC4)",
    "url": "https://doi.org/10.1109/inc465408.2025.11256291",
    "source": "IEEE",
    "abstract": "Code translation between programming languages is a complex task that poses significant challenges in maintaining both the structure and functionality of the translated code. This work evaluates the performance of three neural network models: TransCoder, CodeT5, and CodeBERT, using the CodeXGlue dataset, which is designed to benchmark code translation tasks. Two evaluation metrics: Code Similarity Score (CSS) and Overall Execution Score (OES) were used to assess the models, addressing the lack of comprehensive benchmarking in existing research. It finds that TransCoder performs well on simpler tasks but struggles with Python to Java, yielding a low CSS of 24.2. CodeBERT performs reasonably well in Python to Java, with a CSS of 60.5 and OES of 68.6, but struggles with semantic errors and complex control flows. CodeT5 outperforms both in Python to Java, with higher CSS of 65.0 and OES of 72.4, although it faces issues with deeply nested logic. These insights help developers, students, and educators make informed choices, optimizing translation accuracy and performance.",
    "title_zh": "用于跨语言代码生成与翻译的神经网络模型",
    "abstract_zh": "编程语言之间的代码翻译是一项复杂任务，面临着保持代码结构和功能一致性的重大挑战。本研究基于CodeXGlue数据集，对三种神经网络模型——TransCoder、CodeT5和CodeBERT的性能进行了评估，该数据集旨在用于基准测试代码翻译任务。研究采用两种评估指标：代码相似度得分（CSS）和整体执行得分（OES），以弥补现有研究中缺乏全面基准测试的不足。结果表明，TransCoder在简单任务上表现良好，但在Python到Java的翻译中表现不佳，CSS仅为24.2。CodeBERT在Python到Java翻译中表现尚可，CSS为60.5，OES为68.6，但对语义错误和复杂控制流处理能力较弱。相比之下，CodeT5在Python到Java翻译中表现最优，CSS达到65.0，OES为72.4，尽管在深层嵌套逻辑处理方面仍存在一些问题。这些发现有助于开发者、学生和教育工作者做出更明智的选择，从而优化代码翻译的准确性和性能。"
  },
  {
    "date": "2025-12-1",
    "title": "Improving Hardware Requirements for Fault-Tolerant Quantum Computing by Optimizing Error Budget Distributions",
    "authors": "Tobias V. Forster, Nils Quetschlich, Mathias Soeken, Robert Wille",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00079",
    "source": "IEEE",
    "abstract": "Despite significant progress in quantum computing in recent years, executing quantum circuits for practical problems remains challenging due to error-prone quantum hardware. Hence, quantum error correction becomes essential but induces significant overheads in qubits and execution time, often by orders of magnitude. Obviously, these overheads must be reduced. Since many quantum applications can tolerate some noise, end users can provide a maximum tolerated error, the error budget, to be considered during compilation and execution. This error budget, or, more precisely, its distribution, can be a key factor in achieving the overhead reduction. Conceptually, an errorcorrected quantum circuit can be divided into different parts that each have a specific purpose. Errors can happen in any of these parts and their errors sum up to the mentioned error budget-but how to distribute it among them actually constitutes a degree of freedom. This work is based on the idea that some of the circuit parts can compensate for errors more efficiently than others. Consequently, these parts should contribute more to satisfy the total error budget than the parts where it is more costly. However, this poses the challenge of finding optimal distributions. We address this challenge not only by providing general guidelines on distributing the error budget, but also a method that automatically determines resource-efficient distributions for arbitrary circuits by training a machine learning model on an accumulated dataset. The approach is evaluated by analyzing the machine learning model's predictions on so far unseen data, reducing the estimated space-time costs for more than 75% of the considered quantum circuits, with an average reduction of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1 5. 6 \\%}$</tex>, including cases without improvement, and a maximum reduction of <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{7 7. 7 \\%}$</tex>.",
    "title_zh": "通过优化错误预算分布提升容错量子计算的硬件需求",
    "abstract_zh": "尽管近年来量子计算取得了显著进展，但由于量子硬件固有的错误特性，执行用于实际问题的量子电路仍然面临巨大挑战。因此，量子纠错变得至关重要，但其带来的量子比特和执行时间开销往往高达数个数量级，显然必须加以降低。由于许多量子应用能够容忍一定程度的噪声，终端用户可以在编译和执行过程中提供一个可接受的最大误差值，即“误差预算”，以指导优化过程。这一误差预算，更准确地说是其分配方式，可能成为实现开销降低的关键因素。从概念上讲，一个经过纠错的量子电路可以被划分为若干部分，每一部分具有特定的功能。错误可能发生在这些任意部分中，而所有部分的误差总和即为所设定的误差预算——然而，如何在各部分之间分配该预算实际上构成了一个可调节的自由度。本文基于这样一个核心思想：某些电路部分比其他部分更能高效地补偿误差，因此应承担更大的误差贡献份额，而那些纠错成本较高的部分则应分配较少的误差预算。然而，如何找到最优的分配方案仍是一个挑战。我们不仅提出了关于误差预算分配的一般性指导原则，还提出了一种方法，通过在累积数据集上训练机器学习模型，自动为任意电路确定资源高效的误差分配方案。该方法通过分析机器学习模型对尚未见过的数据的预测表现进行了评估，结果显示，在超过75%的考虑电路中，估计的空间-时间开销得到了降低，平均降幅达15.6%（包括未改善的情况），最大降幅甚至达到77.7%。"
  },
  {
    "date": "2025-12-1",
    "title": "TinyLLaMA-based Expert System for IoT Device Security in Application-Specific Domains",
    "authors": "Roshani Parmar, Nagendra Gajjar",
    "publish": "2025 3rd International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI)",
    "url": "https://doi.org/10.1109/icoici65217.2025.11253384",
    "source": "IEEE",
    "abstract": "The rapid development of Internet of Things (IoT) equipment in domains such as smart homes, agriculture, healthcare services, and industry has intensified concerns about security weaknesses and context-aware safety strategies. This article introduces a lightweight AI-based expert assistant Fine-Tuning TinyLlama model, which recommends appropriate authentication methods, identifies possible attacks, and adapts the authentication Method to specific IoT applications and Device contexts. The system operates as a domain-specific advisory tool, rather than directly enforcing security measures in the field, which enables flexible integration into various IoT environments. According to the application and device parameters, an accurate context-driven response was produced using a custom-built dataset and a fine-tuning process. Performance evaluation demonstrated that the system learned effectively, producing high-quality predictions with a final perplexity of 2.41 and accuracy of 85.71%. The suggested assistant’s lightweight design makes it especially suitable for deployment in conditions with limited resources while maintaining flexibility in different IoT domains. The results demonstrate how it can be integrated by integrating AI models in IoT security infrastructure.",
    "title_zh": "基于TinyLLaMA的特定应用领域物联网设备安全专家系统",
    "abstract_zh": "物联网（IoT）设备在智能家居、农业、医疗保健服务和工业等领域的快速发展，加剧了人们对安全漏洞以及上下文感知安全策略的关注。本文介绍了一种基于轻量级人工智能的专家助手——微调后的TinyLlama模型，该模型能够推荐合适的认证方法，识别潜在攻击，并根据特定的物联网应用和设备上下文动态调整认证方式。该系统作为领域专用的咨询工具运行，而非直接在实际环境中强制执行安全措施，因此可灵活集成到各种物联网环境中。基于应用和设备参数，通过自建数据集与微调过程，系统生成了精准的上下文驱动响应。性能评估表明，该系统学习效果良好，预测质量高，最终困惑度为2.41，准确率达到85.71%。所提出的助手具有轻量化设计，特别适用于资源受限环境下的部署，同时在不同物联网领域中仍保持高度灵活性。研究结果展示了将AI模型融入物联网安全基础设施的可行性与潜力。"
  },
  {
    "date": "2025-12-1",
    "title": "On Using LLMs for Vulnerability Classification",
    "authors": "Rustam Talibzade, Idilio Drago, Francesco Bergadano",
    "publish": "Proceedings of the 2025 Workshop on Large AI Systems and Models with Privacy and Security Analysis",
    "url": "https://doi.org/10.1145/3733800.3763267",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "使用大语言模型进行漏洞分类",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-1",
    "title": "Evolution and Applications of Codeless AI Model Generation Tools for AI-Driven Education",
    "authors": "Sang Tae Kim, Yeon Kyu Kim, Ju Won Park, Ki Su Kim, Tae Ho Kim",
    "publish": "2025 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC)",
    "url": "https://doi.org/10.1109/weef-gedc66748.2025.11256493",
    "source": "IEEE",
    "abstract": "Codeless or no-code AI model generation tools have evolved from Automated Machine Learning (AutoML) to no-code AI platforms, significantly lowering the barrier to AI development. Traditionally, building AI models required extensive programming skills and domain expertise. However, the emergence of AutoML facilitated automated training and optimization, enabling non-experts to leverage machine learning through platforms such as Google AutoML and Microsoft Azure ML. Furthermore, advancements in drag-and-drop code-free AI tools, including Google Vertex AI, IBM Watson AutoAI, and DataRobot, have made AI model development more intuitive. The integration of generative AI has further streamlined model creation, allowing AI models to be built and optimized using natural language inputs, as demonstrated by tools such as ChatGPT API, OpenAI Codex, and Google Bard. Code-free AI tools have broad applications across various industries, enterprises, startups, SMEs, the public sector, and education. Notably, in the education sector, these tools enable educators, students, and administrators to integrate AI-driven solutions without requiring programming expertise, thereby enhancing accessibility and innovation. Despite their advantages, codeless AI tools face challenges related to limited customization for complex AI models, data quality and ethical concerns, and the high costs of cloud-based AI solutions. Future advancements in generative AI are expected to expand the capabilities of these tools, while more user-friendly interfaces will drive broader adoption among non-technical users. Additionally, enhanced AI regulations and ethical frameworks will contribute to greater reliability and transparency in AI models. As code-free AI model generation tools continue to evolve, they are expected to play a crucial role in automating AI development and enhancing accessibility. Their widespread adoption across academic fields, startups, SMEs, and the public sector will contribute to making AI development more inclusive and efficient, fostering innovation across various domains.",
    "title_zh": "无代码AI模型生成工具的演进与在人工智能驱动教育中的应用",
    "abstract_zh": "无需编写代码或低代码的AI模型生成工具已从自动化机器学习（AutoML）发展为无代码AI平台，显著降低了AI开发的门槛。传统上，构建AI模型需要深厚的编程技能和领域专业知识。然而，随着AutoML的出现，自动化训练与优化成为可能，使非专业人士也能通过Google AutoML、Microsoft Azure ML等平台使用机器学习技术。此外，拖拽式无代码AI工具（如Google Vertex AI、IBM Watson AutoAI和DataRobot）的不断进步，使AI模型开发变得更加直观易用。生成式AI的融合进一步简化了模型创建流程，允许用户通过自然语言输入来构建和优化AI模型，例如ChatGPT API、OpenAI Codex和Google Bard等工具便体现了这一趋势。\n\n无代码AI工具在各行各业均有广泛应用，涵盖企业、初创公司、中小企业、公共部门以及教育领域。尤其在教育领域，这些工具使教师、学生和管理人员能够在无需编程知识的情况下集成AI驱动的解决方案，从而提升可及性与创新能力。尽管具有诸多优势，无代码AI工具仍面临一些挑战：对复杂AI模型的定制能力有限，数据质量与伦理问题突出，以及基于云的AI解决方案成本较高。\n\n展望未来，生成式AI的持续进步有望拓展这些工具的功能边界，而更加友好的用户界面将推动非技术人员更广泛地采用。同时，更完善的AI监管政策与伦理框架也将提升AI模型的可靠性与透明度。随着无代码AI模型生成工具的不断发展，它们将在自动化AI开发、提升可访问性方面发挥关键作用。其在学术研究、初创企业、中小企业及公共部门的广泛应用，将进一步推动AI开发的包容性与效率，促进各领域的创新与发展。"
  },
  {
    "date": "2025-12-1",
    "title": "Towards an Interpretable Science of Deep Learning for Secure Software Engineering: A Causal Inference View",
    "authors": "Denys Poshyvanyk",
    "publish": "2025 IEEE 36th International Symposium on Software Reliability Engineering Workshops (ISSREW)",
    "url": "https://doi.org/10.1109/issrew67781.2025.00031",
    "source": "IEEE",
    "abstract": "Neural Code Models (NCMs) are rapidly progressing from research prototypes to commercial developer tools. As such, understanding the capabilities and limitations of such models is becoming critical. However, the abilities of these models are typically measured using automated metrics that often only reveal a portion of their real-world performance. While, in general, the performance of NCMs appears promising, currently much is unknown about how such models arrive at decisions or whether practitioners trust NCMs' outcomes. In this talk, I will introduce doCode, a post hoc interpretability framework specific to NCMs that can explain model predictions. doCode is based upon causal inference to enable programming languageoriented explanations. While the theoretical underpinnings of doCode are extensible to exploring different model properties, we provide a concrete instantiation that aims to mitigate the impact of spurious correlations by grounding explanations of model behavior in properties of programming languages. doCode can generate causal explanations based on Abstract Syntax Tree information and software engineeringbased interventions. To demonstrate the practical benefit of doCode, I will present empirical results of using doCode for detecting confounding bias in NCMs as well as detecting code smells in the code generated by state-of-the-art NCMs, such as CodeLlama and Mistral. Finally, I will showcase results of our recent work on how causal inference can be used in the context of secure software engineering research.",
    "title_zh": "面向可解释的深度学习科学以保障软件工程：因果推断视角",
    "abstract_zh": "神经代码模型（Neural Code Models, NCMs）正迅速从研究原型演变为商用开发者工具。因此，理解这些模型的能力与局限性变得日益关键。然而，目前对这些模型能力的评估通常依赖于自动化指标，而这些指标往往只能揭示其真实性能的一小部分。尽管总体上NCMs的表现令人鼓舞，但关于这些模型如何做出决策，以及从业者是否信任其输出结果，仍存在大量未知之处。在本次演讲中，我将介绍doCode——一种专为NCMs设计的后验可解释性框架，能够解释模型的预测结果。doCode基于因果推断，旨在提供面向编程语言的解释。虽然doCode的理论基础具有可扩展性，可用于探索不同模型属性，但我们提供了一个具体实例，旨在通过将模型行为的解释建立在编程语言特性基础上，来缓解虚假相关性的影响。doCode能够基于抽象语法树（AST）信息和软件工程干预措施生成因果解释。为了展示doCode的实际价值，我将呈现使用doCode检测NCMs中混杂偏差，以及识别由最先进的NCMs（如CodeLlama和Mistral）生成代码中的代码异味（code smells）的实证结果。最后，我将分享我们近期在安全软件工程研究中利用因果推断的最新成果。"
  },
  {
    "date": "2025-12-1",
    "title": "HFSD Workshop Keynote: ISSREW 2025",
    "authors": "Rafael Maiani de Mello",
    "publish": "2025 IEEE 36th International Symposium on Software Reliability Engineering Workshops (ISSREW)",
    "url": "https://doi.org/10.1109/issrew67781.2025.00025",
    "source": "IEEE",
    "abstract": "Over the past two decades, the software engineering research community has increasingly focused on investigating the human and social aspects of the field. Not rarely, investigations on social aspects still raise controversial opinions on relevance and validity. Besides, it is no secret that sampling and recruiting human participants remain a cornerstone issue. Despite these obstacles, it is undeniable that shifting focus to human-centered investigations led the field to mature in qualitative research, also helping to bridge the gap between research and practice. More recently, the surge in Generative AI has significantly impacted software engineering research,accounting for a substantial share of scientific publications since 2023Ȕ although it has so far only timidly addressed qualitative research. In this keynote, we will engage in a bold yet smooth and open discussion about the current potential of Generative AI to support human-centered studies in Software Engineering, considering the different stages of the research process.",
    "title_zh": "HFSD研讨会主题演讲：ISSREW 2025",
    "abstract_zh": "过去二十年来，软件工程研究界越来越关注该领域的人员与社会因素。然而，对社会层面的研究仍时常引发关于其相关性和有效性的争议。此外，众所周知，招募和选取人类参与者始终是研究中的核心难题。尽管存在这些挑战，不可否认的是，将研究重点转向以人为本的探索，推动了定性研究的发展，也促进了研究与实践之间的鸿沟弥合。最近，生成式人工智能的兴起对软件工程研究产生了显著影响，自2023年以来，它已占据科学出版物中相当大的比例；然而，目前它在定性研究方面的应用仍较为谨慎。在本次主题演讲中，我们将以大胆而平和、开放的方式，探讨生成式人工智能在支持软件工程中以人为本研究方面的当前潜力，涵盖研究过程的不同阶段。"
  },
  {
    "date": "2025-12-1",
    "title": "From Static to Quasi-Dynamic: Reconsidering Scheduling and Memory in SDF Compilers",
    "authors": "Pedro Ciambra, Anaëlle Cloarec, Hervé Yviquel, Mickaël Dardaillon, Maxime Pelcat",
    "publish": "2025 IEEE/SBC 37th International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)",
    "url": "https://doi.org/10.1109/sbac-padw69789.2025.00012",
    "source": "IEEE",
    "abstract": "Synchronous Dataflow (SDF) is a popular Model of Computation (MoC) for signal processing applications, thanks to its static analizability and provably deadlock-free execution. SDF compilers have traditionally prioritized static schedulers for their low runtime latency, particularly for signal processing and embedded systems. However, the conventional static technique of converting of multi-rate graphs to single-rate equivalents introduces scalability challenges through exponential graph growth and lost coarse-grained symmetry information. We revisit the idea of runtime scheduling for static dataflow and explore a tradeoff between latency, binary size and compilation time.Our approach introduces a specialized “quasi-dynamic” runtime scheduler and memory manager that leverages static topology information to precompute buffer sizes and allows out-of-order execution of actor firings, while thread assignment and memory allocation are handled at runtime through the OpenMP runtime and standard allocation primitives (malloc). By preserving multi-rate actor relationships, we avoid the node explosion inherent to single-rate conversion and improve the feasibility of SDF for a previously unreachable class of workloads. Comparative analysis of the current prototype against the Preesm static scheduler on the degridder radio astronomy application show, on average, 12.2x compilation time speedup and 4.4x smaller binary sizes, while only suffering 1.4x slowdown.",
    "title_zh": "从静态到准动态：重新审视SDF编译器中的调度与内存问题",
    "abstract_zh": "同步数据流（Synchronous Dataflow, SDF）是一种在信号处理应用中广受欢迎的计算模型（Model of Computation, MoC），得益于其静态可分析性以及可证明的无死锁执行特性。传统上，SDF编译器优先采用静态调度器，以实现低运行时延迟，尤其适用于信号处理和嵌入式系统。然而，将多速率图转换为单速率等价形式的传统静态方法，会因图的指数级增长以及粗粒度对称性信息的丢失而带来可扩展性挑战。本文重新审视了静态数据流中的运行时调度思想，并探索了延迟、二进制文件大小与编译时间之间的权衡。\n\n我们的方法引入了一种专门设计的“准动态”运行时调度器和内存管理器，该机制利用静态拓扑信息预先计算缓冲区大小，同时允许操作符（actor）的非顺序触发，而线程分配和内存分配则通过OpenMP运行时环境及标准分配原语（如malloc）在运行时完成。通过保留多速率操作符之间的关系，我们避免了单速率转换所固有的节点爆炸问题，从而显著提升了SDF在以往难以处理的一类工作负载上的可行性。\n\n针对当前原型与Preesm静态调度器在射电天文去相关（degridder）应用上的对比分析表明：平均而言，我们的方法实现了12.2倍的编译速度提升，二进制文件尺寸缩小4.4倍，仅带来1.4倍的性能下降。"
  },
  {
    "date": "2025-12-1",
    "title": "Nano-Probing Technique for Stuck-at Fault of System on Chip (SoC)",
    "authors": "Xixiong Wei, Xinyi Lin, Shilu Zhou, Na Mei, Shuai Wang, Minqiang Peng, Keqing Ouyang",
    "publish": "2025 IEEE 32nd International Symposium on the Physical and Failure Analysis of Integrated Circuits (IPFA)",
    "url": "https://doi.org/10.1109/ipfa65338.2025.11256599",
    "source": "IEEE",
    "abstract": "As the semiconductor industry progresses toward Very Large Scale Integration (VLSI), traditional failure analysis techniques are increasingly challenged to address subtle resistive failure mechanisms such as transition faults, bridging defects, and slow-to-rise/fall anomalies. Nano-probing (NP), an advanced technique combining scanning electron microscopy (SEM) with nanoscale electrical probing, has emerged to overcome these limitations. Among NP methodologies, Electron Beam Absorbed Current (EBAC) is widely employed for path-level local fault isolation, while Conductive Atomic Force Microscopy (C-AFM) enables transistor-level fault localization. Stuck-at faults (SAFs), a dominant contributor to yield loss in modern semiconductor manufacturing, become increasingly critical as integrated circuits (ICs) grow in logical complexity and physical scale. Although SAF localization is typically achieved through Design-for-Testability (DFT) diagnostic tools, these tools only provide probabilistic identification of suspected nets and cells. This paper demonstrates the application of NP technology to SAF diagnosis through three case studies, highlighting its superior spatial resolution, quantitative defect characterization capability, and compatibility with DFT-guided workflows.",
    "title_zh": "片上系统（SoC）中固定故障的纳米探测技术",
    "abstract_zh": "随着半导体行业向超大规模集成（VLSI）发展，传统的失效分析技术在应对诸如转换故障、桥接缺陷以及上升/下降缓慢等细微的电阻性失效机制方面面临日益严峻的挑战。纳米探针技术（Nano-probing, NP）作为一种结合扫描电子显微镜（SEM）与纳米级电学探测的先进方法，应运而生以克服这些局限。在各类NP技术中，电子束吸收电流法（EBAC）被广泛用于电路路径级别的局部故障定位，而导电原子力显微镜（C-AFM）则可实现晶体管级别的故障精确定位。在现代半导体制造中，固定型故障（Stuck-at Faults, SAFs）是导致良率损失的主要因素之一，随着集成电路（IC）逻辑复杂度和物理规模的不断增长，其重要性愈发凸显。尽管SAF的定位通常依赖于可测性设计（DFT）诊断工具，但这些工具仅能提供疑似网络和单元的概率性识别结果。本文通过三个案例研究，展示了纳米探针技术在SAF诊断中的应用，突显了其卓越的空间分辨率、定量缺陷表征能力，以及与DFT引导工作流程的良好兼容性。"
  },
  {
    "date": "2025-12-1",
    "title": "Industry Track Keynote: ISSREW 2025",
    "authors": "Bruno Fonseca",
    "publish": "2025 IEEE 36th International Symposium on Software Reliability Engineering Workshops (ISSREW)",
    "url": "https://doi.org/10.1109/issrew67781.2025.00009",
    "source": "IEEE",
    "abstract": "The introduction of AI into the developer workflow has fundamentally changed the conversation around productivity, but merely adopting tools is not enough. Drawing on insights from the 2025 DORA State of AI-assisted Software Development report, this keynote argues that AI is an amplifier that magnifies an organization's pre-existing technical and cultural capabilities. It will show why the greatest returns on AI investment come not from the models themselves, but from the maturity of the underlying software delivery system. We will explore a real-world transformation, using the journey of Unico IDTech https://unico.io as a prime example. This story demonstrates how creating a robust and consistent engineering structure Dev Prime coupled with a radical shift to user-centric monitoring SLOs and reliability engineering created the necessary high-quality Platform foundation. When this foundation is present-characterized by clear governance, healthy data ecosystems, and foundational practices-AI's benefits such as throughput and organizational performance gains are dramatically amplified. This session provides technology leaders with a clear, data-driven mandate: to maximize the value of AI, you must first invest in and rationalize your foundational structure, treating your internal platform as the critical enabler for sustainable AI-driven excellence.",
    "title_zh": "产业论坛主旨演讲：ISSREW 2025",
    "abstract_zh": "将人工智能引入开发工作流程，从根本上改变了关于生产力的讨论，但仅仅采用工具是远远不够的。基于《2025年DORA人工智能辅助软件开发现状报告》的洞察，本次主题演讲指出：人工智能是一种放大器，它会放大组织既有的技术与文化能力。我们将阐明，AI投资所能带来的最大回报，并不来自模型本身，而源于其背后软件交付体系的成熟度。通过Unico IDTech（https://unico.io）的真实转型案例，我们将深入探讨这一变革过程。该案例展示了如何通过构建稳健且一致的工程架构——Dev Prime，以及彻底转向以用户为中心的监控指标（SLOs）和可靠性工程，打造了高质量的平台基础。当这一基础具备时——表现为清晰的治理机制、健康的生态系统以及扎实的基础实践——人工智能所带来的吞吐量提升和组织绩效改善将被显著放大。本场演讲为技术领导者提供了一个清晰、数据驱动的行动纲领：要最大化AI的价值，必须首先投资并优化自身的基础架构，将内部平台视为实现可持续AI卓越的核心驱动力。"
  },
  {
    "date": "2025-12-1",
    "title": "Rule-Based Hardware-Configurable Static Analysis for Quantum Programs",
    "authors": "Yi-Ting Chen, Lauren Capelluto, Ryan Shaffer, Jeffrey Heckey",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00087",
    "source": "IEEE",
    "abstract": "The rapid evolution of quantum hardware necessitates an adaptable static analysis framework for validating quantum programs. In this work, we introduce SHARP, a rule-based static analysis framework designed for OpenQASM that decouples hardware-specific constraints from the validation engine. By employing a rule-based approach, SHARP allows quantum computing services to validate programs against evolving instruction set architectures (ISAs) without having to modify the core analysis engine. SHARP achieves this by ingesting ISA descriptions as standalone data, making the validation engine resilient to hardware updates. Furthermore, the framework employs an analysis-driven validation mechanism that enables multi-stage validation, simplifying rule construction and enhancing extensibility. We demonstrate how SHARP supports hardware-specific validation tasks and discuss its impact on quantum software development, including language decoupling, program-level constraint validation, and feature access control. Our findings suggest that SHARP provides a path toward a scalable and maintainable programming interface for quantum computing.",
    "title_zh": "基于规则的可硬件配置静态分析量子程序",
    "abstract_zh": "量子硬件的快速演进要求具备灵活性的静态分析框架，以验证量子程序。本文提出SHARP，一个基于规则的静态分析框架，专为OpenQASM设计，能够将硬件相关约束与验证引擎解耦。通过采用基于规则的方法，SHARP使量子计算服务能够在不修改核心分析引擎的前提下，对不断演进的指令集架构（ISA）进行程序验证。SHARP通过将ISA描述作为独立数据输入，使验证引擎具备抵御硬件更新的能力。此外，该框架采用基于分析的验证机制，支持多阶段验证，简化了规则构建过程，并增强了可扩展性。我们展示了SHARP如何支持针对特定硬件的验证任务，并探讨了其对量子软件开发的影响，包括语言解耦、程序级约束验证以及功能访问控制。研究结果表明，SHARP为实现可扩展且易于维护的量子计算编程接口提供了一条可行路径。"
  },
  {
    "date": "2025-12-1",
    "title": "Secure Quantum Circuit Compilation Methodology for Untrusted Compilers",
    "authors": "Subrata Das, Swaroop Ghosh",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00239",
    "source": "IEEE",
    "abstract": "The success of quantum circuits in providing reliable outcomes for a given problem depends on the gate count and depth in near-term noisy quantum computers. A circuit (that implements a given function) with a low gate count and short depth is more likely to give a correct solution than the circuit variant with a higher gate count and depth. As such, quantum circuit compilers that decompose high-level gates to native gates of the hardware and optimize the circuit play a key role in quantum computing. However, the quality and time complexity of the optimization process can vary significantly especially for practically relevant large-scale quantum circuits. As a result, third-party (often less-trusted/untrusted/unreliable) compilers have emerged, claiming to provide better and faster optimization of complex quantum circuits than so-called trusted compilers. However, untrusted compilers, with their varying adversarial motives ranging from semi-honest to malicious can pose severe security risks such as counterfeiting the sensitive intellectual property (IP) embedded within the quantum circuit. We propose an obfuscation technique for quantum circuits using randomized reversible gates to protect them from such attacks during compilation. The idea is to insert a small random circuit into the original circuit and send it to the untrusted compiler. Since the circuit function is corrupted, the adversary (i.e., an untrusted compiler) may get incorrect IP. However, the user may also get incorrect output post-compilation (even though highly optimized). To circumvent this issue, we concatenate the inverse of the random circuit in the compiled circuit to recover the original functionality. We demonstrate the practicality of our method by conducting exhaustive experiments on a set of benchmark circuits and measuring the quality of obfuscation by calculating the Total Variation Distance (TVD) and Degree of Functional Corruption (DFC) metrics. Our method achieves TVD of up to 1.92, indicating substantial functional corruption, and performs at least <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$2 x$</tex> better than a previously reported obfuscation method. We also attained a DFC as low as −0.75, approaching the −1 score that represents maximal functional corruption, further ensuring the robustness of our proposed method against counterfeiting. We also propose a novel adversarial reverse engineering (RE) approach and show that the proposed obfuscation is resilient against RE attacks. The proposed technique introduces minimal degradation in fidelity (<tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\sim 1 \\%$</tex> to <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\sim 3 \\%$</tex> on average).",
    "title_zh": "不受信任编译器的量子电路安全编译方法",
    "abstract_zh": "在近期的噪声量子计算机中，量子电路能否为特定问题提供可靠结果，取决于其门数和深度。对于实现某一功能的电路而言，门数较少、深度较短的电路比门数较多、深度较长的变体更有可能给出正确解。因此，将高层门分解为硬件原生门并优化电路的量子电路编译器，在量子计算中起着关键作用。然而，尤其对于实际应用中的大规模量子电路，优化过程的质量和时间复杂度可能存在显著差异。由此催生了第三方（通常为不可信或不可靠）编译器，它们声称能比所谓的“可信编译器”更高效、更优地优化复杂的量子电路。但这些不可信编译器可能具有从半诚实到恶意等不同动机，会带来严重的安全风险，例如窃取嵌入在量子电路中的敏感知识产权（IP）。为此，我们提出一种基于随机可逆门的量子电路混淆技术，以在编译过程中保护电路免受此类攻击。\n\n该方法的核心思想是：在原始电路中插入一个小型随机电路，并将其发送给不可信编译器。由于电路功能已被破坏，攻击者（即不可信编译器）可能获得错误的知识产权信息。然而，用户在编译后也可能得到错误的输出（尽管电路已高度优化）。为解决这一问题，我们在编译后的电路末尾拼接该随机电路的逆电路，从而恢复原始功能。\n\n我们通过在一组基准电路上进行详尽实验，验证了该方法的实用性，并通过计算总变差距离（TVD）和功能破坏度（DFC）指标来衡量混淆效果。实验结果表明，我们的方法最高可达到1.92的TVD值，表明存在显著的功能性破坏；且性能至少优于此前报道的混淆方法2倍以上。同时，我们实现了最低达−0.75的DFC值，接近代表最大功能破坏的−1分，进一步证明了所提方法对仿冒攻击的强大抗性。\n\n此外，我们还提出了一种新颖的对抗性逆向工程（RE）方法，并证明所提出的混淆技术能够有效抵御此类攻击。所提技术仅带来极小的保真度下降（平均约为1%至3%），表现出良好的实用性和可靠性。"
  },
  {
    "date": "2025-12-1",
    "title": "AI-Driven Reliability Through Anomaly Detection System in Industry 4.0",
    "authors": "Igor Wiese, George da Silva B. Souza, Jairo Souza, Leo Fernandes, Maria Eduarda T. S. Ikeda, Daniel Oliveira dos Santos, Ismael Trindade Fraga, Renato Torres Pinto, Erick Barboza, Baldoino Fonseca, Márcio Ribeiro",
    "publish": "2025 IEEE 36th International Symposium on Software Reliability Engineering Workshops (ISSREW)",
    "url": "https://doi.org/10.1109/issrew67781.2025.00047",
    "source": "IEEE",
    "abstract": "In the Industry 4.0 landscape, ensuring data reliability is a critical challenge. This paper presents a novel approach to detecting production anomalies and providing actionable, context-aware explanations. We aim to help the process and quality assurance teams understand the production anomalies. To achieve this, we implemented a real-time data architecture for RFID manufacturing and built an anomaly detection system based on two algorithms, Isolation Forest and Local Outlier Factor, to identify production anomalies. We leverage two Large Language Models (LLMs), Phi-4 and Llama 3.2, enriched with historical production data, to generate explanations for the identified anomalies. Our findings demonstrate high performance between the detection algorithms. More importantly, expert evaluations confirm that LLMs, particularly Phi-4, can produce technically detailed and actionable explanations about the anomaly cases, thereby enhancing operational decision-making.",
    "title_zh": "工业4.0中基于人工智能的异常检测系统实现可靠性提升",
    "abstract_zh": "在工业4.0的背景下，确保数据可靠性是一项关键挑战。本文提出了一种新颖的方法，用于检测生产异常，并提供可操作的、具有上下文感知能力的解释。我们的目标是帮助工艺部门和质量保证团队理解生产过程中的异常情况。为此，我们构建了基于RFID制造的实时数据架构，并采用两种算法——孤立森林（Isolation Forest）与局部离群因子（Local Outlier Factor）——实现了异常检测系统，以识别生产过程中的异常事件。同时，我们利用两个大型语言模型（LLMs），即Phi-4和Llama 3.2，并结合历史生产数据进行增强，生成对所识别异常的详细解释。研究结果表明，两种检测算法之间表现出优异的性能。更重要的是，专家评估证实，尤其是Phi-4模型，能够生成技术细节丰富且具有实际操作指导意义的异常解释，从而显著提升运营决策的质量与效率。"
  },
  {
    "date": "2025-12-1",
    "title": "CleanQRL: Lightweight Single-File Implementations of Quantum Reinforcement Learning Algorithms",
    "authors": "Georg Kruse, Rodrigo Coelho, Andreas Rosskopf, Robert Wille, Jeanette Miriam Lorenz",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00181",
    "source": "IEEE",
    "abstract": "At the interception between quantum computing and machine learning, Quantum Reinforcement Learning (QRL) has emerged as a promising research field. Due to its novelty, a standardized and comprehensive collection for QRL algorithms has not yet been established. Researchers rely on numerous software stacks for classical Reinforcement Learning (RL) as well as on various quantum computing frameworks for the implementation of the quantum subroutines of their QRL algorithms. Inspired by the CleanRL library for classical RL algorithms, we present CleanQRL, a library that offers singlescript implementations of many QRL algorithms. Our library provides clear and easy to understand scripts that researchers can quickly adapt to their own needs. Alongside ray tune for distributed computing and streamlined hyperparameter tuning, CleanQRL uses weights&biases to log important metrics, which facilitates benchmarking against other classical and quantum implementations. The CleanQRL library enables researchers to easily transition from theoretical considerations to practical applications.",
    "title_zh": "CleanQRL：量子强化学习算法的轻量级单文件实现",
    "abstract_zh": "在量子计算与机器学习的交汇处，量子强化学习（Quantum Reinforcement Learning, QRL）已成为一个前景广阔的科研领域。由于该领域尚处于发展初期，目前尚未建立起一套标准化且全面的QRL算法集合。研究人员通常依赖于众多经典强化学习（RL）软件框架，以及多种量子计算平台来实现其QRL算法中的量子子程序。受经典RL领域CleanRL库的启发，我们提出了CleanQRL——一个提供多种QRL算法单脚本实现的开源库。该库提供了清晰、易懂的代码脚本，使研究者能够快速根据自身需求进行修改和应用。同时，CleanQRL结合Ray Tune实现分布式计算与高效超参数调优，并利用Weights & Biases进行关键指标的日志记录，从而便于与其它经典及量子实现方案进行基准对比。CleanQRL极大地简化了从理论探索到实际应用的转化过程，助力研究人员更高效地推进量子强化学习的研究。"
  },
  {
    "date": "2025-12-1",
    "title": "Quantum Circuit Optimization for the Fault-Tolerance Era: Do We Have to Start from Scratch?",
    "authors": "Tobias V. Forster, Nils Quetschlich, Robert Wille",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00070",
    "source": "IEEE",
    "abstract": "Quantum computing has made significant advancements in the last years in both hardware and software. Unfortunately, the currently available Noisy Intermediate-Scale Quantum (NISQ) hardware is still heavily affected by noise. Many optimization techniques have been developed to reduce the negative effects thereof, which, however, only works up to a certain point. Therefore, scaling quantum applications from currently considered small research examples to industrial applications requires error-correction techniques to execute quantum circuits in a fault-tolerant fashion and enter the Fault-Tolerant Quantum Computing (FTQC) era. These error-correction techniques introduce dramatic qubit overheads, leading to the requirement of tens of thousands of qubits already for toy-sized examples. Hence, quantum circuit optimization that reduces qubit overheads when shifting from the NISQ to the FTQC era is essential. This raises the question, whether we need to start from scratch, or whether current state-of-the-art optimization techniques can be used as a basis for this. To approach this question, this work investigates the effects of different optimization passes on a representative selection of quantum circuits. Since hardly any tools to automatically design and evaluate FTQC quantum circuits exist yet, we utilize resource estimation to compare the (potential) benefits gained by applying NISQ quantum circuit optimization to estimated FTQC resource requirements. The Results indicate that, indeed, the estimated resource requirements for FTQC can be improved by applying NISQ quantum circuit optimization techniques. At the same time, more detailed investigations show what techniques lead to more benefits for FTQC compared to others, providing guidelines for the transfer of NISQ optimization techniques to the FTQC era.",
    "title_zh": "容错时代量子电路优化：我们是否必须从头开始？",
    "abstract_zh": "近年来，量子计算在硬件和软件方面均取得了显著进展。然而，目前可用的含噪声中等规模量子（NISQ）硬件仍受到噪声的严重影响。为此，人们开发了多种优化技术以减轻其负面影响，但这些方法的效果存在上限。因此，要将当前的小规模研究性量子应用扩展至工业级应用，必须采用纠错技术，实现量子电路的容错运行，从而进入容错量子计算（FTQC）时代。这些纠错技术带来了巨大的量子比特开销，仅对小型示例而言，就已需要数万量子比特。因此，在从NISQ时代向FTQC时代过渡的过程中，减少量子比特开销的量子电路优化至关重要。这引发了一个关键问题：我们是否需要从零开始设计新方法，还是可以基于现有的先进优化技术进行演进？为回答这一问题，本文研究了不同优化流程对一组具有代表性的量子电路的影响。由于目前尚缺乏能够自动设计和评估FTQC量子电路的工具，我们采用资源估算方法，比较在NISQ阶段应用量子电路优化技术对估算的FTQC资源需求所带来的潜在收益。结果表明，确实可以通过应用NISQ阶段的量子电路优化技术来改善FTQC的资源估算需求。同时，更深入的分析揭示了哪些优化技术对FTQC带来的效益更为显著，从而为将NISQ优化技术迁移至FTQC时代提供了指导性建议。"
  },
  {
    "date": "2025-12-1",
    "title": "Agent-Q: Fine-Tuning Large Language Models for Quantum Circuit Generation and Optimization",
    "authors": "Linus Jern, Valter Uotila, Cong Yu, Bo Zhao",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00179",
    "source": "IEEE",
    "abstract": "Large language models (LLMs) have achieved remarkable outcomes in complex problems, including math, coding, and analyzing large amounts of scientific reports. Yet, few works have explored the potential of LLMs in quantum computing. The most challenging problem is to leverage LLMs to automatically generate quantum circuits at a large scale. Fundamentally, the existing pre-trained LLMs lack the knowledge of quantum circuits. In this paper, we address this challenge by fine-tuning LLMs and injecting the domain-specific knowledge of quantum computing. We describe Agent-Q, an LLM fine-tuning system to generate and optimize quantum circuits. In particular, agentQ implements the mechanisms to generate training data sets and constructs an end-to-end pipeline to fine-tune pre-trained LLMs to generate parameterized quantum circuits for various optimization problems. Agent-Q provides <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\mathbf{1 4, 0 0 0}$</tex> quantum circuits covering a large spectrum of the quantum optimization landscape: 12 optimization problem instances and their optimized QAOA, VQE, and adaptive VQE circuits. Based thereon, Agent-Q fine-tunes LLMs and constructs syntactically correct parametrized quantum circuits in OpenQASM 3.0. We have evaluated the quality of the LLM-generated circuits and parameters by comparing them to the optimized expectation values and distributions. Experimental results show superior performance of Agent-Q, compared to several state-of-the-art LLMs and better parameters than random. Agent-Q can be integrated into an agentic workflow, and the generated parametrized circuits with initial parameters can be used as a starting point for further optimization, e.g., as templates in quantum machine learning and as benchmarks for compilers and hardware.",
    "title_zh": "Agent-Q：用于量子电路生成与优化的大型语言模型微调",
    "abstract_zh": "大型语言模型（LLMs）在解决复杂问题方面取得了显著成果，涵盖数学、编程以及大量科学报告的分析。然而，很少有研究探索LLMs在量子计算领域的潜力。其中最具挑战性的问题是：如何利用LLMs大规模自动生成量子电路。根本原因在于，现有的预训练LLMs缺乏对量子电路的知识。本文通过微调LLMs并注入量子计算领域的特定知识，解决了这一挑战。我们提出了Agent-Q——一个用于生成和优化量子电路的LLM微调系统。具体而言，Agent-Q实现了生成训练数据集的机制，并构建了一个端到端的流程，以微调预训练LLMs，使其能够生成适用于各类优化问题的参数化量子电路。Agent-Q共生成了14,000个量子电路，覆盖了广泛的量子优化场景：包括12种优化问题实例及其对应的优化QAOA、VQE和自适应VQE电路。基于这些数据，Agent-Q对LLMs进行微调，并生成符合OpenQASM 3.0语法规范的参数化量子电路。我们通过与最优期望值和分布进行比较，评估了LLM生成电路及其参数的质量。实验结果表明，Agent-Q的表现优于多个最先进的LLMs，且生成的参数明显优于随机初始化。Agent-Q可集成至智能体工作流中，所生成的带有初始参数的参数化电路可作为进一步优化的起点，例如用作量子机器学习中的模板，或作为编译器与硬件的基准测试工具。"
  },
  {
    "date": "2025-12-1",
    "title": "Diagnosis Analysis of AXI Logic Build in Self-Test Failure on SoC Product",
    "authors": "Li Tian, Huan Wang, Shijun Zheng, Haijiao Bian, Jianli Yang",
    "publish": "2025 IEEE 32nd International Symposium on the Physical and Failure Analysis of Integrated Circuits (IPFA)",
    "url": "https://doi.org/10.1109/ipfa65338.2025.11256666",
    "source": "IEEE",
    "abstract": "This System-on-Chip (SoC) designs have become increasingly complex, integrating various function components or Intellectual Property (IP) within a chip through Advanced eXtensible Interface (AXI) [1]–[7]. The AXI bus provides an openstandard, on-chip interconnect specification that enables efficient IP reuse, flexibility, compatibility, high bandwidth, and low latency [8]. It defines a point-to-point protocol between two interfaces: a manager and a subordinate. In our SoC product, Logic Build in Self-Test (LBIST) was implemented on both the manager and subordinate sides respectively[9], with corresponding AXI LBIST pattern executed on Automated Test Equipment (ATE). Diagnosis analysis could localize failed FIFO cell in manager or subordinate when a failure was detected by LBIST pattern. This paper presents AXI bus LBIST hardware structure and test sequence, outlines the diagnosis flow for AXI LBIST failures, and demonstrates diagnosis accuracy through two real cases. Establishing AXI LBIST diagnosis capability in FA lab significantly improved Key Performance Indicators (KPIs): success rate increased from 50% to nearly 100% and analysis time was reduced from 90 days to 45 days. Built in SelfTest (BIST) structure and diagnosis enabled quick and easy root cause isolation for failed FIFO cells compared to traditional SoC functional analysis. However, now it must still be performed manually, and current AXI LBIST diagnosis was limited in narrowing down suspicions for controlling signals in AXI bus.",
    "title_zh": "SoC产品中AXI逻辑自检失败的诊断分析",
    "abstract_zh": "随着系统级芯片（SoC）设计日益复杂，各类功能模块或知识产权（IP）通过高级可扩展接口（AXI）[1]–[7]集成于单个芯片中。AXI总线提供了一种开放标准的片上互连规范，能够实现高效的IP复用、灵活性、兼容性、高带宽和低延迟[8]。它定义了两个接口之间的点对点协议：主控端（manager）与从属端（subordinate）。在我们的SoC产品中，分别在主控端和从属端实现了内置自测逻辑（LBIST）[9]，并在自动测试设备（ATE）上执行相应的AXI LBIST测试模式。当LBIST模式检测到故障时，诊断分析可定位出主控端或从属端中失效的FIFO单元。本文介绍了AXI总线LBIST的硬件结构与测试流程，概述了AXI LBIST故障的诊断流程，并通过两个实际案例展示了诊断的准确性。在失效分析（FA）实验室建立AXI LBIST诊断能力后，关键绩效指标（KPI）显著提升：测试成功率从50%提高至接近100%，分析时间由90天缩短至45天。相比传统的SoC功能分析，BIST结构结合诊断机制能够快速、便捷地定位失效FIFO单元的根本原因。然而，目前该过程仍需手动执行，且现有的AXI LBIST诊断在缩小控制信号异常怀疑范围方面仍存在局限性。"
  },
  {
    "date": "2025-12-1",
    "title": "A Method for Enhancing Invocation Capabilities in Tool Calling with LLM-as-a-Judge System",
    "authors": "Yinglei Shang, Chunlei Wang",
    "publish": "2025 5th International Conference on Advanced Algorithms and Neural Networks (AANN)",
    "url": "https://doi.org/10.1109/aann66429.2025.11257606",
    "source": "IEEE",
    "abstract": "The paradigm of using large models as evaluators (LLM-as-a-Judge) has shown potential in multiple tasks, but has not been fully explored in tool invocation scenarios, especially for enhancing invocation capabilities. To solve this problem, this paper proposes a method based on LLM-as-a-Judge, which integrates the advantages of different large models by building robust evaluation criteria to significantly reduce the impact of error evaluation of a single model. Research has found that: 1) methods that perform well in reasoning tasks are difficult to directly transfer to tool calling scenarios; 2) Through iterative generation and evaluation criteria guided multiple generation strategies, multiple model capabilities can be effectively integrated to enhance evaluation stability. Our experiments on the benchmark dataset of four types of tool calling show that the proposed method outperforms the baseline model in both accuracy and robustness.",
    "title_zh": "一种基于大模型作为裁判的系统来增强工具调用中调用能力的方法",
    "abstract_zh": "以大型模型作为评估者（LLM-as-a-Judge）的范式在多个任务中展现出巨大潜力，但在工具调用场景中的应用尚未得到充分探索，尤其是在提升工具调用能力方面。为解决这一问题，本文提出了一种基于LLM-as-a-Judge的方法，通过构建稳健的评估标准，整合不同大型模型的优势，显著降低单一模型错误评估带来的影响。研究发现：1）在推理任务中表现良好的方法难以直接迁移到工具调用场景；2）通过迭代生成与评估标准引导的多轮生成策略，能够有效整合多个模型的能力，从而提升评估的稳定性。在涵盖四类工具调用的基准数据集上的实验表明，所提出的方法在准确性和鲁棒性方面均优于基线模型。"
  },
  {
    "date": "2025-12-1",
    "title": "CO2 (Co-Compliance Officer): An LLM-based Ontology-Driven Methodology for Generating Knowledge Graphs and AI Compliance Checking",
    "authors": "Venkata Sai Prathyush Turaga, Timea Pahi, Simon Tjoa, Sima Siami-Namini, Akbar Siami Namin",
    "publish": "IEEE Access",
    "url": "https://doi.org/10.1109/access.2025.3639228",
    "source": "IEEE",
    "abstract": "With the advent of Artificial Intelligence (AI) technology and immense transitions to industry, it is important to regulate and establish standards for this fascinating technology. As a result, AI-powered applications need to be checked for compliance with AI regulations. Although compliance checks have been extensively discussed by the research community and industry, AI compliance checks and verification still need to be explored, and pitfalls need to be identified. This paper aims at automating the extraction of AI regulations using the knowledge graph and the ontology defined for legal documents. The paper first reports the initial effort to create knowledge graphs for legal documents (e.g., the EU AI Act) using different language models trained in general textual documents where general approaches in extracting Named-Entity Recognition (NER) are employed. Triplets in the form of <Subject-Predicate-Object> are extracted followed by enhancement achieved through augmenting NER tags by information captured using dependency parsers. The paper then presents a methodology called Co-Compliance Officer (CO2) where Large Language Models (LLMs) are employed to build knowledge graphs and NER which are solely for parsing and extracting legal documents. The LLM ontology is then used to create effective tags that are specifically designed to extract legal documents and the relationships between legal entities. The created knowledge graphs are then used to perform several verification analysis on legal documents, including inconsistency checks and violations. The results indicate that Large Language Models (LLMs) can be helpful in compliance checking of legal documents, in particular, the documents created for AI compliance checking.",
    "title_zh": "CO2（协同合规官）：一种基于大语言模型的本体驱动方法，用于生成知识图谱与人工智能合规性检查",
    "abstract_zh": "随着人工智能（AI）技术的兴起以及产业界的巨大转型，对这一令人着迷的技术进行规范并建立标准变得尤为重要。因此，必须对基于AI的应用程序进行合规性检查，以确保其符合相关AI监管要求。尽管学术界和产业界已广泛讨论了合规性检查问题，但AI合规性检查与验证仍需进一步探索，潜在陷阱也亟待识别。本文旨在利用知识图谱及为法律文件定义的本体，实现AI法规的自动化提取。文章首先报告了初步尝试：通过在通用文本数据上训练的不同语言模型，构建法律文件（如欧盟《人工智能法案》）的知识图谱，并采用通用的命名实体识别（NER）方法进行信息抽取。随后，以<主体-谓词-客体>的形式提取三元组，并通过依赖解析器捕获的信息增强NER标签。接着，本文提出了一种名为“协同合规官”（Co-Compliance Officer, CO2）的方法论，该方法利用大型语言模型（LLMs）专门构建用于解析和提取法律文件的知识图谱与NER系统。基于LLM的本体被用来生成高效且专为法律文件设计的标签，能够精准识别法律条文及其法律主体之间的关系。最终，所构建的知识图谱被用于对法律文件执行多种验证分析，包括不一致性和违规行为检测。实验结果表明，大型语言模型（LLMs）在法律文件的合规性检查中具有显著帮助，尤其适用于AI合规性相关法律文件的审查。"
  },
  {
    "date": "2025-12-1",
    "title": "Learning-Based Quantum Compilation: Translating QASM to QIR with CodeBERT",
    "authors": "Sharmin Afrose, Vicente Leyton-Ortega, Travis Humble",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.10453",
    "source": "IEEE",
    "abstract": "We propose a learning-based approach to quantum compilation by translating OpenQASM to Quantum Intermediate Representation (QIR) using a fine-tuned CodeBERT model. Trained on 10,000 synthetic QASM-QIR pairs, the model captures code semantics while addressing QIR verbosity and the 512-token limit via a custom token compression scheme. Finetuning was performed on the Frontier supercomputer, with results showing syntactic correctness and stable validation loss reduction. Our method moves toward enabling flexible, language-modeldriven quantum software tools. It also introduces syntax error handling and the possibility of incorporating classical control constructs, addressing limitations in existing rule-based compilers like qBraid-QIR. While the current model has been validated on quantum-only circuits, we propose future evaluations on hybrid quantum-classical examples. This poster will provide architecture insights, compression examples, training loss plots, and QIR outputs. Our work highlights the potential for scalable, adaptable compilation in future quantum toolchains.",
    "title_zh": "基于学习的量子编译：使用CodeBERT将QASM翻译为QIR",
    "abstract_zh": "我们提出了一种基于学习的量子编译方法，通过微调的CodeBERT模型将OpenQASM翻译为量子中间表示（QIR）。该模型在10,000个合成的QASM-QIR配对数据上进行训练，能够捕捉代码语义，并通过自定义的令牌压缩方案解决了QIR冗长和512个标记长度限制的问题。微调过程在Frontier超级计算机上完成，结果表明模型具有语法正确性且验证损失稳定下降。我们的方法推动了灵活、基于语言模型的量子软件工具的发展，同时引入了语法错误处理机制，并具备集成经典控制结构的潜力，弥补了现有基于规则的编译器（如qBraid-QIR）的局限性。尽管当前模型已在纯量子电路上进行了验证，我们建议未来在混合量子-经典示例上进行评估。本海报将展示架构细节、压缩示例、训练损失曲线以及QIR输出结果。我们的工作凸显了未来量子工具链中可扩展、可适应编译技术的巨大潜力。"
  },
  {
    "date": "2025-12-1",
    "title": "V-Models: LLMS for the Development Lifecycle of Safety-Critical Systems",
    "authors": "Amel Jelidi, Amer Kajmakovic, Alexander Palmisano, Franz Sentobe, Kay Römer",
    "publish": "2025 IEEE 36th International Symposium on Software Reliability Engineering Workshops (ISSREW)",
    "url": "https://doi.org/10.1109/issrew67781.2025.00039",
    "source": "IEEE",
    "abstract": "Functional Safety system (software & hardware) development is typically a V-Model process, which is governed by strenuous regulations & norms. This, along with use case specificity, and the scrupulous nature of functional safety creates various bottlenecks across the V-Model, i.e., redundant aspects of functional safety system development. To alleviate these bottlenecks, we introduce two LLM assistants designed to support key V-Model phases. The first assistant, the Digital Safety Assistant (DSA), provides safety engineers with general knowledge of functional safety norms through Retrieval Augmented Generation, thus decreasing norm and application domain adaptation overhead. We benchmark various models and assess the DSA using an official functional safety Certification exam, where the DSA achieves up to 70%, surpassing typical performance levels. A second assistant, the Automated Testing Assistant, developed through Parameter Efficient Fine-tuning to support the V-Model verification phase, is capable of correctly generating and debugging PLC test code with 93% correctness.",
    "title_zh": "V模型：用于安全关键系统开发生命周期的大型语言模型",
    "abstract_zh": "功能安全系统（软硬件）开发通常采用V模型流程，该流程受到严格法规和标准的约束。由于用例的高度特定性以及功能安全本身的严谨性，在V模型的各个阶段都会产生多种瓶颈，即功能安全系统开发中的冗余环节。为缓解这些瓶颈，我们引入了两个大语言模型（LLM）助手，以支持V模型的关键阶段。\n\n第一个助手是数字安全助手（Digital Safety Assistant, DSA），它通过检索增强生成（Retrieval Augmented Generation）技术，为安全工程师提供功能安全规范的通用知识，从而降低规范理解和应用领域适应的负担。我们对多种模型进行了基准测试，并使用官方的功能安全认证考试评估了DSA的表现，结果显示其最高得分达到70%，显著优于常规水平。\n\n第二个助手是自动化测试助手，通过参数高效微调（Parameter Efficient Fine-tuning）开发，用于支持V模型中的验证阶段。该助手能够以93%的准确率正确生成并调试PLC测试代码，显著提升了测试效率与质量。"
  },
  {
    "date": "2025-12-1",
    "title": "QIRopt: An Optimization Method for Quantum Intermediate Representation",
    "authors": "Junjie Luo, Haoyu Zhang, Jianjun Zhao",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00058",
    "source": "IEEE",
    "abstract": "This paper proposes a dataflow-based optimization method called Quantum Intermediate Representation Optimization (QIRopt) within the LLVM infrastructure. QIRopt has two main functions: preprocessing QIR code to expose more optimization opportunities to the LLVM optimizer and optimizing QIR code to avoid redundant loading and construction of qubits and qubit arrays. We evaluated QIRopt on the IBM Challenge Dataset, and the results demonstrate its effectiveness in reducing redundant operations in QIR code. A preliminary implementation of QIRopt and a case study on real-world code further confirm that our approach enhances the LLVM optimizer's ability to optimize preprocessed QIR code.",
    "title_zh": "QIRopt：一种量子中间表示的优化方法",
    "abstract_zh": "本文提出了一种基于数据流的优化方法——量子中间表示优化（QIRopt），该方法集成于LLVM基础设施中。QIRopt具有两大核心功能：一是对QIR代码进行预处理，以揭示更多可供LLVM优化器利用的优化机会；二是优化QIR代码，避免量子比特及量子比特数组的冗余加载与构建。我们在IBM挑战数据集上对QIRopt进行了评估，结果表明该方法能有效减少QIR代码中的冗余操作。QIRopt的初步实现以及在真实代码上的案例研究进一步证实，该方法显著提升了LLVM优化器对预处理后QIR代码的优化能力。"
  },
  {
    "date": "2025-12-1",
    "title": "Leveraging Large Language Models for Anomaly Detection in Microservices Architectures",
    "authors": "Diego Frazatto Pedroso, Luís Almeida, William Akihiro Alves Aisawa, Inês Dutra, Sarita Mazzini Bruschi",
    "publish": "2025 IEEE/SBC 37th International Symposium on Computer Architecture and High Performance Computing Workshops (SBAC-PADW)",
    "url": "https://doi.org/10.1109/sbac-padw69789.2025.00021",
    "source": "IEEE",
    "abstract": "Cloud computing has become a key enabler of scalable and high-performance applications, allowing systems to be deployed rapidly. At the same time, the increasing sophistication of cloud-native environments brings new challenges related to system dependability. Ensuring resilience under such conditions is a fundamental responsibility of IT providers, who must safeguard service continuity and operational stability. The widespread use of microservice-based designs has created an ecosystem with a growing number of interacting components, including frameworks, application layers, hypervisors, and orchestration platforms. This distributed and layered environment produces a massive volume of log data originating from heterogeneous sources. Without automated support, extracting useful insights from these logs becomes a highly complex task. One promising direction to mitigate this challenge is the use of Machine Learning, particularly methods grounded in Large Language Models (LLMs), which can dynamically detect recurring structures and anomalies in event streams. Building on this idea, our work introduces an anomaly detection framework deployed within a microservices environment running on Kubernetes with Istio. The framework integrates an LLM trained on a diverse set of fault scenarios. To create these scenarios, we relied on Chaos Mesh for fault injection and Locust for workload stress testing. The evaluation confirmed that the model achieved high accuracy in identifying anomalies. It consistently detected all injected faults, although a small number of false positives were observed. Importantly, these false alarms remained at acceptable levels, highlighting the approach’s practical applicability.",
    "title_zh": "利用大型语言模型进行微服务架构中的异常检测",
    "abstract_zh": "云计算已成为实现可扩展、高性能应用的关键技术，使系统能够快速部署。与此同时，云原生环境日益复杂，也带来了与系统可靠性相关的新挑战。在这一背景下，确保系统的弹性 resilience 是IT服务提供商的基本职责，必须保障服务的连续性与运行的稳定性。微服务架构的广泛应用，构建了一个包含大量相互交互组件的生态系统，涵盖框架、应用层、虚拟化层以及编排平台等。这种分布式的分层架构产生了来自异构源的海量日志数据。若无自动化支持，从这些日志中提取有效信息将变得极为复杂。一种有前景的应对策略是引入机器学习技术，特别是基于大语言模型（LLM）的方法，能够动态识别事件流中的重复模式和异常行为。基于这一思路，本文提出了一种部署于Kubernetes与Istio支撑的微服务环境中的异常检测框架。该框架集成了一个在多样化故障场景上训练的大语言模型。为生成这些故障场景，我们采用Chaos Mesh进行故障注入，并利用Locust开展负载压力测试。评估结果表明，该模型在异常识别方面表现出高准确率：能够持续检测出所有注入的故障，尽管存在少量误报。但这些误报数量处于可接受范围，充分体现了该方法在实际应用中的可行性与有效性。"
  },
  {
    "date": "2025-12-1",
    "title": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators",
    "authors": "Cristina Improta",
    "publish": "2025 IEEE 36th International Symposium on Software Reliability Engineering Workshops (ISSREW)",
    "url": "https://doi.org/10.1109/issrew67781.2025.00080",
    "source": "IEEE",
    "abstract": "Deep learning (DL) models for natural language-to-code generation have become integral to modern software development pipelines. However, their heavy reliance on large amounts of data, often collected from unsanitized online sources, exposes them to data poisoning attacks, where adversaries inject malicious samples to subtly bias model behavior. Recent targeted attacks silently replace secure code with semantically equivalent but vulnerable implementations without relying on explicit triggers to launch the attack, making it especially hard for detection methods to distinguish clean from poisoned samples. We present a systematic study on the effectiveness of existing poisoning detection methods under this stealthy threat model. Specifically, we perform targeted poisoning on three DL models (CodeBERT, CodeT5+, AST-T5), and evaluate spectral signatures analysis, activation clustering, and static analysis as defenses. Our results show that all methods struggle to detect triggerless poisoning, with representation-based approaches failing to isolate poisoned samples and static analysis suffering false positives and false negatives, highlighting the need for more robust, triggerindependent defenses for AI-assisted code generation.",
    "title_zh": "检测AI代码生成器中的隐蔽数据投毒攻击",
    "abstract_zh": "用于自然语言到代码生成的深度学习（DL）模型已成为现代软件开发流程中不可或缺的一部分。然而，这些模型对大量数据的高度依赖，尤其是从未经清洗的在线来源收集的数据，使其容易受到数据投毒攻击——攻击者通过注入恶意样本，微妙地扭曲模型行为。近期出现的针对性攻击在不依赖显式触发机制的情况下，悄然将安全代码替换为语义等价但存在漏洞的实现，这使得检测方法难以区分干净样本与被污染样本。本文系统研究了现有投毒检测方法在此类隐蔽威胁模型下的有效性。具体而言，我们针对三种深度学习模型（CodeBERT、CodeT5+、AST-T5）实施了定向投毒攻击，并评估了谱特征分析、激活聚类和静态分析作为防御手段的效果。结果表明，所有方法在检测无触发器投毒时均表现不佳：基于表示的方法无法有效识别被污染样本，而静态分析则面临误报和漏报问题。这一发现凸显了在人工智能辅助代码生成领域，亟需发展更鲁棒、无需依赖触发器的新型防御机制。"
  },
  {
    "date": "2025-12-1",
    "title": "On the Potential of Quantum Computing in Classical Program Analysis",
    "authors": "Yicheng Guang, Pietro Zanotta, Kai Zhou, Yueqi Chen, Ramin Ayanzadeh",
    "publish": "2025 IEEE International Conference on Quantum Computing and Engineering (QCE)",
    "url": "https://doi.org/10.1109/qce65121.2025.00257",
    "source": "IEEE",
    "abstract": "Classical program analysis techniques, such as abstract interpretation and symbolic execution, are essential for ensuring software correctness, optimizing performance, and enabling compiler optimizations. However, these techniques face computational limitations when analyzing programs with large or exponential state spaces, limiting their effectiveness in ensuring system reliability. Quantum computing, with its parallelism and ability to process superposed states, offers a promising solution to these challenges. In this work, we present <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$Q E X$</tex>, a design that uses quantum computing to analyze classical programs. By synthesizing quantum circuits that encode program states in superposition and trace data dependency between program variables through entanglement, <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$Q E X$</tex> enables the simultaneous exploration of program behaviors, significantly improving scalability and precision. This advancement has broad applications, from debugging and security verification to optimizing compilers for next-generation hardware. As a proof-of-concept, we evaluated QEX on 22 benchmark programs, demonstrating its effectiveness in analyzing program states. To support more language features and make <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$Q E X$</tex> realized sooner in Fault-Tolerant Quantum Computing (FTQC), we propose <tex xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">$\\text{QEX}-\\mathrm{H}$</tex> which hybridizes QEX with classical analysis techniques. To our knowledge, this work is the first proposal to use quantum computing for classical program analysis.",
    "title_zh": "量子计算在经典程序分析中的潜力",
    "abstract_zh": "经典程序分析技术，如抽象解释和符号执行，在确保软件正确性、优化性能以及支持编译器优化方面起着至关重要的作用。然而，当面对具有庞大或指数级状态空间的程序时，这些技术会遭遇计算上的局限性，从而限制了其在保障系统可靠性方面的有效性。量子计算凭借其并行处理能力以及对叠加态的处理优势，为解决上述挑战提供了极具前景的方案。本文提出了一种名为 $QEX$ 的设计，利用量子计算来分析经典程序。通过合成将程序状态编码于叠加态的量子电路，并借助量子纠缠追踪程序变量之间的数据依赖关系，$QEX$ 实现了对程序行为的并行探索，显著提升了分析的可扩展性和精确度。这一进展在调试、安全验证以及下一代硬件编译器优化等领域具有广泛的应用前景。作为概念验证，我们在22个基准程序上评估了QEX，证明了其在程序状态分析方面的有效性。为了支持更多语言特性，并加速 $QEX$ 在容错量子计算（FTQC）中的实现，我们进一步提出了 $\\text{QEX}-\\mathrm{H}$，该方案将 $QEX$ 与经典分析技术相结合，形成一种混合架构。据我们所知，本工作是首次提出使用量子计算进行经典程序分析的方案。"
  }
]