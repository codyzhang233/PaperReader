[
  {
    "date": "2026-01-08",
    "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
    "authors": "Chengsong Huang, Tong Zheng, Langlin Huang, Jinyuan Li, Haolin Liu, Jiaxin Huang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05167v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
    "title_zh": "RelayLLM：通过协作解码实现高效推理",
    "abstract_zh": "大型语言模型（LLMs）在复杂推理任务中常受限于高昂的计算成本和延迟，而资源高效的小型语言模型（SLMs）则通常缺乏足够的推理能力。现有的协同方法，如级联或路由机制，通常以粗粒度方式将整个查询卸载至LLM，当SLM能够处理大部分推理步骤时，这种做法会造成显著的计算浪费。为解决这一问题，我们提出了RelayLLM——一种基于令牌级协同解码的高效推理新框架。与传统路由器不同，RelayLLM使SLM能够作为主动控制器，仅在关键令牌生成时通过特殊指令动态调用LLM，从而实现生成过程的“接力”式协作。我们设计了一种两阶段训练框架，包括预热阶段和组相对策略优化（GRPO），以教会模型在独立完成任务与战略性寻求帮助之间取得平衡。在六个基准测试上的实证结果表明，RelayLLM实现了平均49.52%的准确率，有效弥合了两类模型之间的性能差距。尤为突出的是，该框架仅需调用LLM生成总令牌数的1.07%，相比性能相当的随机路由器，实现了高达98.2%的成本降低。"
  },
  {
    "date": "2026-01-08",
    "title": "OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation",
    "authors": "Yi Jiang, Sendong Zhao, Jianbo Li, Bairui Hu, Yanrui Du, Haochun Wang, Bing Qin",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05027v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.",
    "title_zh": "OptiSet：用于检索增强生成的统一优化集合选择与排序",
    "abstract_zh": "检索增强生成（Retrieval-Augmented Generation, RAG）通过引入来自大型外部语料库的证据，提升了生成质量。然而，现有大多数方法依赖于基于单个相关性静态选择前k个段落，这无法充分利用段落之间的组合增益，且常常引入大量冗余信息。为解决这一局限，我们提出OptiSet，一种以集合为中心的框架，统一了集合选择与集合级排序过程。OptiSet采用“扩展-精炼”范式：首先将查询扩展为多个视角，以生成多样化的候选集；随后通过重新筛选对候选集进行精炼，形成紧凑的证据集合。接着，我们设计了一种无需强语言模型监督的自合成策略，通过分析生成器在集合条件下的效用变化来推导偏好标签，从而识别出互补与冗余的证据。最后，我们引入一种集合-列表联合训练策略，协同优化集合选择与集合级排序，使模型更倾向于选择紧凑且高收益的证据集合。大量实验表明，OptiSet在复杂组合问题上显著提升了性能，并使生成过程更加高效。源代码已公开。"
  },
  {
    "date": "2026-01-08",
    "title": "Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable",
    "authors": "Zuhair Ahmed Khan Taha, Mohammed Mudassir Uddin, Shahnawaz Alam",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05191v1",
    "source": "arXiv",
    "abstract": "When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines",
    "title_zh": "降低AI研究成本：任务感知压缩如何让大型语言模型代理变得负担得起",
    "abstract_zh": "当研究人员将大型语言模型用于自主任务，如文献综述或生成假设时，计算费用迅速累积。仅使用一个拥有700亿参数的模型进行一次研究会话，云服务费用就可能高达约127美元，使这些工具对许多学术实验室而言遥不可及。为此，我们开发了AgentCompress来直接应对这一难题。这一想法源于我们在自身工作中的一次简单观察：撰写一个新颖的假设显然比重新排版参考文献对模型的要求更高。为什么这两类任务都要以全精度运行？我们的系统通过一个小型神经网络，仅根据任务开头的几个词，即可评估其难度，并将任务分配到相应压缩程度的模型版本中。整个决策过程不到一毫秒。在四个科学领域共500个研究工作流上的测试表明，我们实现了68.3%的计算成本降低，同时保持了原始成功率的96.2%。对于预算紧张的研究团队而言，这或许意味着能否开展实验与只能旁观之间的差别。"
  },
  {
    "date": "2026-01-08",
    "title": "A Method for Constructing a Digital Transformation Driving Mechanism Based on Semantic Understanding of Large Models",
    "authors": "Huayi Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04696v1",
    "source": "arXiv",
    "abstract": "In the process of digital transformation, enterprises are faced with problems such as insufficient semantic understanding of unstructured data and lack of intelligent decision-making basis in driving mechanisms. This study proposes a method that combines a large language model (LLM) and a knowledge graph. First, a fine-tuned BERT (Bidirectional Encoder Representations from Transformers) model is used to perform entity recognition and relationship extraction on multi-source heterogeneous texts, and GPT-4 is used to generate semantically enhanced vector representations; secondly, a two-layer graph neural network (GNN) architecture is designed to fuse the semantic vectors output by LLM with business metadata to construct a dynamic and scalable enterprise knowledge graph; then reinforcement learning is introduced to optimize decision path generation, and the reward function is used to drive the mechanism iteration. In the case of the manufacturing industry, this mechanism reduced the response time for equipment failure scenarios from 7.8 hours to 3.7 hours, the F1 value reached 94.3%, and the compensation for decision errors in the annual digital transformation cost decreased by 45.3%. This method significantly enhances the intelligence level and execution efficiency of the digital transformation driving mechanism by integrating large model semantic understanding with structured knowledge.",
    "title_zh": "一种基于大模型语义理解的数字化转型驱动机制构建方法",
    "abstract_zh": "在数字化转型过程中，企业面临非结构化数据语义理解不足、驱动机制缺乏智能决策依据等问题。本研究提出一种结合大语言模型（LLM）与知识图谱的方法：首先，采用微调后的BERT（双向编码器表示模型）对多源异构文本进行实体识别与关系抽取，并利用GPT-4生成语义增强的向量表示；其次，设计两层图神经网络（GNN）架构，将大语言模型输出的语义向量与业务元数据融合，构建动态可扩展的企业级知识图谱；随后引入强化学习优化决策路径生成，通过奖励函数驱动机制迭代优化。在制造业应用案例中，该机制将设备故障场景的响应时间从7.8小时缩短至3.7小时，F1值达到94.3%，年度数字化转型成本中因决策失误造成的补偿支出降低了45.3%。该方法通过融合大模型的语义理解能力与结构化知识体系，显著提升了数字化转型驱动机制的智能化水平与执行效率。"
  },
  {
    "date": "2026-01-08",
    "title": "Vibe Coding an LLM-powered Theorem Prover",
    "authors": "Zhe Hou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04653v1",
    "source": "arXiv",
    "abstract": "We present Isabellm, an LLM-powered theorem prover for Isabelle/HOL that performs fully automatic proof synthesis. Isabellm works with any local LLM on Ollama and APIs such as Gemini CLI, and it is designed to run on consumer grade computers. The system combines a stepwise prover, which uses large language models to propose proof commands validated by Isabelle in a bounded search loop, with a higher-level proof planner that generates structured Isar outlines and attempts to fill and repair remaining gaps. The framework includes beam search for tactics, tactics reranker ML and RL models, premise selection with small transformer models, micro-RAG for Isar proofs built from AFP, and counter-example guided proof repair. All the code is implemented by GPT 4.1 - 5.2, Gemini 3 Pro, and Claude 4.5. Empirically, Isabellm can prove certain lemmas that defeat Isabelle's standard automation, including Sledgehammer, demonstrating the practical value of LLM-guided proof search. At the same time, we find that even state-of-the-art LLMs, such as GPT 5.2 Extended Thinking and Gemini 3 Pro struggle to reliably implement the intended fill-and-repair mechanisms with complex algorithmic designs, highlighting fundamental challenges in LLM code generation and reasoning. The code of Isabellm is available at https://github.com/zhehou/llm-isabelle",
    "title_zh": "用LLM驱动的定理证明器进行氛围编程",
    "abstract_zh": "我们提出 Isabellm，这是一个基于大语言模型（LLM）的 Isabelle/HOL 定理证明器，能够实现完全自动化的证明合成。Isabellm 可在本地运行于 Ollama 的任何 LLM 上，也可通过 Gemini CLI 等 API 接入，且专为消费级计算机设计，可在普通硬件上高效运行。该系统结合了分步式证明器与高层证明规划器：前者利用大语言模型生成待验证的证明命令，并在 Isabelle 的有限搜索循环中进行迭代验证；后者则生成结构化的 Isar 证明框架，并尝试填补和修复剩余的逻辑空白。\n\n该框架集成了多种先进技术，包括用于策略选择的束搜索（beam search）、基于机器学习（ML）与强化学习（RL）的策略重排序模型、采用小型 Transformer 模型的前置条件选择机制、基于 AFP（Archive of Formal Proofs）构建的微 RAG（Retrieval-Augmented Generation）系统，以及基于反例引导的证明修复机制。所有代码均由 GPT 4.1 - 5.2、Gemini 3 Pro 和 Claude 4.5 等先进模型实现。\n\n实证研究表明，Isabellm 能够证明某些连 Isabelle 标准自动化工具（如 Sledgehammer）都无法解决的定理，充分展示了 LLM 引导的证明搜索在实际应用中的价值。然而，我们也发现，即便是当前最先进的 LLM（如 GPT 5.2 Extended Thinking 和 Gemini 3 Pro），在处理具有复杂算法设计的“填充-修复”机制时仍难以稳定可靠地实现预期功能，凸显了大语言模型在代码生成与逻辑推理方面存在的根本性挑战。\n\nIsabellm 的完整代码已开源，可访问 https://github.com/zhehou/llm-isabelle 获取。"
  },
  {
    "date": "2026-01-08",
    "title": "ToolGate: Contract-Grounded and Verified Tool Execution for LLMs",
    "authors": "Yanming Liu, Xinyue Peng, Jiannan Cao, Xinyi Wang, Songhang Deng, Jintao Chen, Jianwei Yin, Xuhong Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04688v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) augmented with external tools have demonstrated remarkable capabilities in complex reasoning tasks. However, existing frameworks rely heavily on natural language reasoning to determine when tools can be invoked and whether their results should be committed, lacking formal guarantees for logical safety and verifiability. We present \\textbf{ToolGate}, a forward execution framework that provides logical safety guarantees and verifiable state evolution for LLM tool calling. ToolGate maintains an explicit symbolic state space as a typed key-value mapping representing trusted world information throughout the reasoning process. Each tool is formalized as a Hoare-style contract consisting of a precondition and a postcondition, where the precondition gates tool invocation by checking whether the current state satisfies the required conditions, and the postcondition determines whether the tool's result can be committed to update the state through runtime verification. Our approach guarantees that the symbolic state evolves only through verified tool executions, preventing invalid or hallucinated results from corrupting the world representation. Experimental validation demonstrates that ToolGate significantly improves the reliability and verifiability of tool-augmented LLM systems while maintaining competitive performance on complex multi-step reasoning tasks. This work establishes a foundation for building more trustworthy and debuggable AI systems that integrate language models with external tools.",
    "title_zh": "ToolGate：基于合同且经过验证的工具执行用于大语言模型",
    "abstract_zh": "通过外部工具增强的大语言模型（LLMs）在复杂推理任务中展现了卓越的能力。然而，现有的框架严重依赖自然语言推理来决定何时调用工具以及是否应采纳其结果，缺乏对逻辑安全性和可验证性的形式化保障。我们提出 \\textbf{ToolGate}，一种前向执行框架，为 LLM 工具调用提供逻辑安全保证和可验证的状态演化机制。ToolGate 维护一个显式的符号状态空间，以类型化的键值映射形式表示推理过程中可信的世界信息。每个工具均被形式化为一种类似 Hoare 逻辑的契约，包含前提条件和后置条件：前提条件用于控制工具调用，通过检查当前状态是否满足所需条件；后置条件则通过运行时验证决定工具结果是否可以被确认并用于更新状态。我们的方法确保符号状态仅通过经过验证的工具执行进行演进，从而防止无效或幻觉性结果污染世界表征。实验验证表明，ToolGate 显著提升了工具增强型 LLM 系统的可靠性与可验证性，同时在复杂的多步推理任务上保持了具有竞争力的性能。本工作为构建更可信、更易调试的集成语言模型与外部工具的智能系统奠定了基础。"
  },
  {
    "date": "2026-01-08",
    "title": "Neurosymbolic Retrievers for Retrieval-augmented Generation",
    "authors": "Yash Saxena, Manas Gaur",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04568v1",
    "source": "arXiv",
    "abstract": "Retrieval Augmented Generation (RAG) has made significant strides in overcoming key limitations of large language models, such as hallucination, lack of contextual grounding, and issues with transparency. However, traditional RAG systems consist of three interconnected neural components - the retriever, re-ranker, and generator - whose internal reasoning processes remain opaque. This lack of transparency complicates interpretability, hinders debugging efforts, and erodes trust, especially in high-stakes domains where clear decision-making is essential. To address these challenges, we introduce the concept of Neurosymbolic RAG, which integrates symbolic reasoning using a knowledge graph with neural retrieval techniques. This new framework aims to answer two primary questions: (a) Can retrievers provide a clear and interpretable basis for document selection? (b) Can symbolic knowledge enhance the clarity of the retrieval process? We propose three methods to improve this integration. First is MAR (Knowledge Modulation Aligned Retrieval) that employs modulation networks to refine query embeddings using interpretable symbolic features, thereby making document matching more explicit. Second, KG-Path RAG enhances queries by traversing knowledge graphs to improve overall retrieval quality and interpretability. Lastly, Process Knowledge-infused RAG utilizes domain-specific tools to reorder retrieved content based on validated workflows. Preliminary results from mental health risk assessment tasks indicate that this neurosymbolic approach enhances both transparency and overall performance",
    "title_zh": "神经符号检索器在检索增强生成中的应用",
    "abstract_zh": "检索增强生成（Retrieval Augmented Generation, RAG）在克服大型语言模型的关键局限性方面取得了显著进展，例如幻觉、缺乏上下文依据以及透明度不足等问题。然而，传统的RAG系统由三个相互关联的神经组件构成——检索器（retriever）、重排序器（re-ranker）和生成器（generator），其内部推理过程仍不透明。这种透明度的缺失使得结果难以解释，增加了调试难度，并在高风险领域中削弱了用户信任，而这些领域对清晰、可追溯的决策尤为关键。\n\n为应对上述挑战，我们提出“神经符号RAG”（Neurosymbolic RAG）的概念，将基于知识图谱的符号推理与神经检索技术相结合。该新框架旨在回答两个核心问题：(a) 检索器能否为文档选择提供清晰且可解释的基础？(b) 符号知识是否能够提升检索过程的可解释性？为此，我们提出了三种改进集成的方法：\n\n第一，MAR（知识调制对齐检索，Knowledge Modulation Aligned Retrieval）利用调制网络，通过可解释的符号特征对查询嵌入进行优化，从而使文档匹配过程更加明确和直观；\n\n第二，KG-Path RAG 通过在知识图谱中遍历路径来增强查询表示，不仅提升了整体检索质量，也增强了检索过程的可解释性；\n\n第三，流程知识注入型RAG（Process Knowledge-infused RAG）引入领域特定工具，依据经过验证的工作流程对检索到的内容进行重新排序，确保生成结果符合实际业务逻辑。\n\n初步在心理健康风险评估任务中的实验结果表明，这一神经符号融合方法在提升系统透明度的同时，也显著改善了整体性能。"
  },
  {
    "date": "2026-01-08",
    "title": "CircuitLM: A Multi-Agent LLM-Aided Design Framework for Generating Circuit Schematics from Natural Language Prompts",
    "authors": "Khandakar Shakib Al Hasan, Syed Rifat Raiyan, Hasin Mahtab Alvee, Wahid Sadik",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04505v1",
    "source": "arXiv",
    "abstract": "Generating accurate circuit schematics from high-level natural language descriptions remains a persistent challenge in electronics design, as large language models (LLMs) frequently hallucinate in granular details, violate electrical constraints, and produce non-machine-readable outputs. We present CircuitLM, a novel multi-agent LLM-aided circuit design pipeline that translates user prompts into structured, visually interpretable CircuitJSON schematics through five sequential stages: (i) LLM-based component identification, (ii) canonical pinout retrieval, (iii) chain-of-thought reasoning by an electronics expert agent, (iv) JSON schematic synthesis, and (v) force-directed SVG visualization. Anchored by a curated, embedding-powered component knowledge base. While LLMs often violate electrical constraints, CircuitLM bridges this gap by grounding generation in a verified and dynamically extensible component database, initially comprising 50 components. To ensure safety, we incorporate a hybrid evaluation framework, namely Dual-Metric Circuit Validation (DMCV), validated against human-expert assessments, which achieves high fidelity in microcontroller-centric designs. We evaluate the system on 100 diverse embedded-systems prompts across six LLMs and introduce DMCV to assess both structural and electrical validity. This work bridges natural language input to deployable hardware designs, enabling reliable circuit prototyping by non-experts. Our code and data will be made public upon acceptance.",
    "title_zh": "CircuitLM：一种基于多智能体的LLM辅助设计框架，用于从自然语言提示生成电路原理图",
    "abstract_zh": "从高层次的自然语言描述生成准确的电路原理图，仍是电子设计领域持续面临的挑战。大型语言模型（LLMs）在细节层面常出现幻觉、违反电气约束，并生成无法被机器读取的输出。本文提出CircuitLM——一种新型的多智能体LLM辅助电路设计流程，能够将用户提示转化为结构化且可视化的CircuitJSON原理图，整个过程包含五个连续阶段：(i) 基于LLM的元件识别，(ii) 标准引脚布局检索，(iii) 由电子专家智能体执行的思维链推理，(iv) JSON格式原理图合成，以及(v) 基于力导向算法的SVG可视化。该系统依托一个经过精心整理、基于嵌入技术的元件知识库。尽管LLMs常会违背电气规则，CircuitLM通过将生成过程锚定在一个经过验证且可动态扩展的元件数据库上，有效弥合了这一差距，初始数据库包含50个元件。为确保安全性，我们引入了一种混合评估框架——双指标电路验证（Dual-Metric Circuit Validation, DMCV），其评估结果经与人类专家判断对比验证，在以微控制器为核心的电路设计中表现出高保真度。我们在6种不同LLM上对100个多样化的嵌入式系统提示进行了评估，并引入DMCV来同时衡量电路的结构与电气正确性。本研究实现了从自然语言输入到可部署硬件设计的无缝衔接，使非专业人士也能可靠地进行电路原型开发。我们的代码与数据将在论文被接受后公开发布。"
  },
  {
    "date": "2026-01-08",
    "title": "Agent-as-a-Judge",
    "authors": "Runyang You, Hongru Cai, Caiqi Zhang, Qiancheng Xu, Meng Liu, Tiezheng Yu, Yongqi Li, Wenjie Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05111v1",
    "source": "arXiv",
    "abstract": "LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.",
    "title_zh": "代理即裁判",
    "abstract_zh": "LLM-as-a-Judge 通过利用大型语言模型实现可扩展的评估，彻底改变了人工智能的评价方式。然而，随着评估对象变得日益复杂、专业化和多步骤化，LLM-as-a-Judge 的可靠性受到固有偏见、浅层单次推理以及无法与真实世界观察进行验证等局限性的制约。这一困境推动了向 Agent-as-a-Judge 的转变：智能体作为评判者，通过规划、工具增强的验证、多智能体协作以及持久记忆，实现了更稳健、可验证且更具细致性的评估。尽管智能体评估系统迅速发展，但该领域仍缺乏一个统一的框架来应对这一快速演变的格局。为弥合这一空白，我们首次提出一项全面的综述，系统追踪这一演进过程。具体而言，我们识别出表征这一范式转变的关键维度，并建立了一个发展性分类体系。我们对核心方法进行了梳理，并在通用领域与专业领域中展开应用调研。此外，我们深入分析了前沿挑战，指明了具有前景的研究方向，最终为下一代智能体评估提供了清晰的发展路线图。"
  },
  {
    "date": "2026-01-08",
    "title": "Compositional Steering of Large Language Models with Steering Tokens",
    "authors": "Gorjan Radevski, Kiril Gashteovski, Giwon Hong, Carolin Lawrence, Goran Glavaš",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05062v1",
    "source": "arXiv",
    "abstract": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.",
    "title_zh": "使用引导令牌对大型语言模型进行组合式引导",
    "abstract_zh": "在真实世界应用中部署大语言模型（LLMs）需要能够控制输出，以同时满足多种期望属性。尽管现有研究已广泛探讨针对单一行为的LLM引导方法，但“组合式引导”——即同时引导LLM实现多个行为——仍是一个未被充分探索的问题。本文提出了一种名为**组合式引导标记**（compositional steering tokens）的方法，用于多行为引导。我们首先通过自蒸馏技术，将用自然语言表达的各个行为嵌入到专用的标记中。与大多数先前工作在激活空间中操作不同，我们的行为引导机制位于输入标记的空间中，从而实现了更高效的零样本组合能力。随后，我们在行为对上训练一个专门的**组合标记**（composition token），并证明该标记成功捕捉了“组合”的概念：它能很好地泛化至**未见过的组合**，包括包含未见过的行为或具有未见过行为数量的组合。我们在不同LLM架构上的实验表明，相比其他方法（如指令引导、激活空间引导和LoRA合并），引导标记在多行为控制方面表现更优。此外，我们还展示了引导标记与自然语言指令具有互补性，两者的结合可带来进一步的性能提升。"
  },
  {
    "date": "2026-01-08",
    "title": "Differential syntactic and semantic encoding in LLMs",
    "authors": "Santiago Acevedo, Alessandro Laio, Marco Baroni",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04765v1",
    "source": "arXiv",
    "abstract": "We study how syntactic and semantic information is encoded in inner layer representations of Large Language Models (LLMs), focusing on the very large DeepSeek-V3. We find that, by averaging hidden-representation vectors of sentences sharing syntactic structure or meaning, we obtain vectors that capture a significant proportion of the syntactic and semantic information contained in the representations. In particular, subtracting these syntactic and semantic ``centroids'' from sentence vectors strongly affects their similarity with syntactically and semantically matched sentences, respectively, suggesting that syntax and semantics are, at least partially, linearly encoded. We also find that the cross-layer encoding profiles of syntax and semantics are different, and that the two signals can to some extent be decoupled, suggesting differential encoding of these two types of linguistic information in LLM representations.",
    "title_zh": "大语言模型中的差异性句法与语义编码",
    "abstract_zh": "我们研究了大型语言模型（LLMs）内部层表示中句法和语义信息的编码方式，重点关注超大规模的DeepSeek-V3模型。研究发现，通过对具有相同句法结构或语义含义的句子的隐藏表示向量进行平均，可以得到能够捕捉其表示中大量句法和语义信息的向量。特别地，从句子向量中减去这些句法和语义“中心点”后，句子之间的相似性在句法和语义匹配方面均显著下降，表明句法和语义至少部分以线性方式被编码。此外，我们还发现句法和语义在跨层编码模式上存在差异，且这两种信号在一定程度上可被解耦，提示大型语言模型中的句法与语义信息可能以不同方式被编码。"
  },
  {
    "date": "2026-01-08",
    "title": "Internal Representations as Indicators of Hallucinations in Agent Tool Selection",
    "authors": "Kait Healy, Bharathi Srinivasan, Visakh Madathil, Jing Wu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05214v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.",
    "title_zh": "智能体工具选择中内部表征作为幻觉的指示器",
    "abstract_zh": "大型语言模型（LLMs）在工具调用与使用方面展现出卓越的能力，但其仍存在幻觉问题，表现为选择错误的工具、提供格式错误的参数，以及出现“绕过工具”行为——即不调用专门工具或外部系统，而是通过模拟和生成输出来完成任务。这严重影响了基于LLM的智能体在生产环境中的可靠性，导致结果不一致，并规避了安全与审计控制机制。此类智能体在工具选择上的幻觉现象亟需早期检测与错误处理。与现有依赖多次前向传播或外部验证的幻觉检测方法不同，我们提出了一种计算高效的框架，能够在生成过程的同一前向传播中，利用LLM内部表示实现对工具调用幻觉的实时检测。我们在多个领域的推理任务上对该方法进行了评估，结果显示其具备出色的检测性能（最高达86.4%准确率），同时保持实时推理能力且计算开销极小，尤其在检测参数级幻觉和不当工具选择方面表现突出，这对实现可靠智能体部署至关重要。"
  },
  {
    "date": "2026-01-08",
    "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning",
    "authors": "Yanchang Liang, Xiaowei Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05187v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.",
    "title_zh": "SimuAgent：一种基于大语言模型并结合强化学习增强的Simulink建模助手",
    "abstract_zh": "大型语言模型（LLMs）已彻底改变了基于文本的代码自动化，但其在面向图结构的工程工作流中的潜力仍远未被充分挖掘。我们提出了 SimuAgent——一个专为 Simulink 设计的、由 LLM 驱动的建模与仿真代理。SimuAgent 将冗长的 XML 表示替换为简洁的字典式 Python 语法，显著降低 token 数量，提升可读性，并支持快速、在进程内完成的仿真。该代理采用轻量级“规划-执行”架构，通过两阶段训练，同时具备底层工具操作技能与高层设计推理能力。针对长时程任务中奖励稀疏的问题，我们提出 Reflection-GRPO（ReGRPO），在 Group Relative Policy Optimization（GRPO）基础上引入自省式反馈轨迹，提供丰富的中间反馈信息，从而加速收敛并增强模型鲁棒性。在我们新发布的 SimuBench 基准测试上（包含 5300 个跨领域建模任务），使用 SimuAgent 微调后的 Qwen2.5-7B 模型展现出比标准强化学习基线更快的收敛速度和更高的建模准确率，甚至在少样本提示条件下超越 GPT-4o 的表现。消融实验进一步验证了两阶段课程学习策略以及抽象-重构数据增强方法对泛化能力的显著提升。SimuAgent 可在本地部署，仅需普通硬件即可完成训练与运行，为工业级模型驱动工程提供了隐私保护且成本低廉的解决方案。SimuAgent 架起了大型语言模型与图形化建模环境之间的桥梁，为工业场景下的 AI 辅助工程设计提供了一种切实可行的新范式。"
  },
  {
    "date": "2026-01-08",
    "title": "Token-Level LLM Collaboration via FusionRoute",
    "authors": "Nuoya Xiong, Yuhang Zhou, Hanqing Zeng, Zhaorun Chen, Furong Huang, Shuchao Bi, Lizhu Zhang, Zhuokai Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05106v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.",
    "title_zh": "基于融合路由的分 token 级大语言模型协作",
    "abstract_zh": "大型语言模型（LLMs）在多个领域展现出显著优势。然而，要使单一通用模型在这些领域均达到优异性能，通常需要将其规模扩大到训练和部署成本极高的程度。相比之下，虽然小型领域专用模型效率更高，但其泛化能力往往受限于训练数据分布。为解决这一困境，我们提出FusionRoute——一种鲁棒且高效的基于token级别的多LLM协作框架。该框架采用一个轻量级路由器，在每个解码步骤中同时实现：(i) 选择最合适的专家模型；(ii) 通过logit相加的方式，生成一个互补的logit信号，以修正或优化所选专家的下一个token概率分布。\n\n与现有仅依赖固定专家输出的token级协作方法不同，我们提供了理论分析，表明纯粹依赖专家输出的路由机制存在根本性局限：除非满足强全局覆盖假设，否则一般无法实现最优解码策略。通过引入可训练的互补生成器来增强专家选择过程，FusionRoute扩展了有效策略类的表达能力，并在较弱条件下即可恢复最优价值函数。\n\n实验结果表明，在Llama-3与Gemma-2两大模型系列上，涵盖数学推理、代码生成和指令遵循等多种基准任务中，FusionRoute在性能上超越了序列级与token级协作、模型融合以及直接微调等方法，同时在各自擅长的任务上仍能保持与领域专家相当的竞争力。"
  },
  {
    "date": "2026-01-08",
    "title": "AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?",
    "authors": "Henan Sun, Kaichi Yu, Yuyao Wang, Bowen Liu, Xunkai Li, Rong-Hua Li, Nuo Chen, Jia Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04996v1",
    "source": "arXiv",
    "abstract": "Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm. AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.",
    "title_zh": "AlgBench：大型推理模型对算法的理解程度有多深？",
    "abstract_zh": "推理能力已成为大型推理模型（LRMs）发展中的核心关注点。尽管在MATH500和LiveCodeBench等若干推理基准上已取得显著进展，但现有的算法推理评估基准仍然有限，无法回答一个关键问题：大型推理模型是否真正掌握了算法推理能力？为解答这一问题，我们提出了AlgBench——一个由专家精心设计的基准，旨在从以算法为中心的范式出发，评估LRMs的算法推理能力。AlgBench包含超过3,000个原创题目，覆盖27种算法，由ACM算法专家构建，并依据一套全面的分类体系进行组织，涵盖欧几里得结构、非欧几里得结构、未优化、局部优化、全局优化以及启发式优化等类别。对主流LRMs（如Gemini-3-Pro、DeepSeek-v3.2-Special和GPT-o3）的实证评估揭示了显著的性能差异：模型在未优化任务上的表现良好（最高达92%），但在动态规划等全局优化算法任务上准确率骤降至约49%。进一步分析发现，模型存在**策略性过早偏离**现象，即由于必须生成低熵的中间标记而过早放弃正确的算法设计。这些发现暴露了以问题为中心的强化学习方法的根本局限性，凸显了构建以算法为中心的训练范式对于实现稳健算法推理的必要性。"
  },
  {
    "date": "2026-01-08",
    "title": "Learning from Mistakes: Negative Reasoning Samples Enhance Out-of-Domain Generalization",
    "authors": "Xueyun Tian, Minghua Ma, Bingbing Xu, Nuoyan Lyu, Wei Li, Heng Dong, Zheng Chu, Yuanzhuo Wang, Huawei Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04992v1",
    "source": "arXiv",
    "abstract": "Supervised fine-tuning (SFT) on chain-of-thought (CoT) trajectories demonstrations is a common approach for enabling reasoning in large language models. Standard practices typically only retain trajectories with correct final answers (positives) while ignoring the rest (negatives). We argue that this paradigm discards substantial supervision and exacerbates overfitting, limiting out-of-domain (OOD) generalization. Specifically, we surprisingly find that incorporating negative trajectories into SFT yields substantial OOD generalization gains over positive-only training, as these trajectories often retain valid intermediate reasoning despite incorrect final answers. To understand this effect in depth, we systematically analyze data, training dynamics, and inference behavior, identifying 22 recurring patterns in negative chains that serve a dual role: they moderate loss descent to mitigate overfitting during training and boost policy entropy by 35.67% during inference to facilitate exploration. Motivated by these observations, we further propose Gain-based LOss Weighting (GLOW), an adaptive, sample-aware scheme that exploits such distinctive training dynamics by rescaling per-sample loss based on inter-epoch progress. Empirically, GLOW efficiently leverages unfiltered trajectories, yielding a 5.51% OOD gain over positive-only SFT on Qwen2.5-7B and boosting MMLU from 72.82% to 76.47% as an RL initialization.",
    "title_zh": "从错误中学习：负向推理样本有助于提升跨领域泛化能力",
    "abstract_zh": "在链式思维（CoT）轨迹演示上进行监督微调（SFT）是提升大语言模型推理能力的常用方法。传统做法通常仅保留最终答案正确的轨迹（正例），而忽略其余轨迹（负例）。我们指出，这种范式丢弃了大量可用的监督信号，并加剧了过拟合问题，从而限制了模型在域外（OOD）场景下的泛化能力。具体而言，我们意外发现，将负例轨迹纳入SFT训练，能够显著提升模型在域外任务上的表现，优于仅使用正例的训练方式。这是因为尽管这些负例轨迹的最终答案错误，但其间的中间推理过程往往仍具有合理性与有效性。\n\n为了深入理解这一现象，我们系统地分析了数据特性、训练动态以及推理行为，识别出负例轨迹中22种反复出现的模式。这些模式在训练中发挥双重作用：一方面通过调节损失下降速度来缓解过拟合；另一方面在推理阶段使策略熵提升35.67%，从而增强探索能力。\n\n基于上述发现，我们进一步提出一种名为“基于收益的损失加权”（Gain-based LOss Weighting, GLOW）的自适应、样本感知的损失重标定机制。该方法根据样本在不同训练周期间的进展程度，动态调整每条样本的损失权重，充分挖掘负例轨迹中的独特训练动态优势。\n\n实证结果表明，GLOW能高效利用未经筛选的完整轨迹数据，在Qwen2.5-7B模型上相较仅使用正例的SFT实现5.51%的OOD性能提升，并作为强化学习（RL）初始化时，将MMLU基准得分从72.82%提升至76.47%。"
  },
  {
    "date": "2026-01-08",
    "title": "T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs",
    "authors": "Chunyu Wei, Huaiyu Qin, Siyuan He, Yunhai Wang, Yueguo Chen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04945v1",
    "source": "arXiv",
    "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.",
    "title_zh": "T-Retriever：基于树状层次结构的文本图增强生成检索方法",
    "abstract_zh": "检索增强生成（RAG）显著提升了大型语言模型获取外部知识的能力，然而现有的基于图的RAG方法在处理层次化信息时面临两大关键局限：其一，强制施加分层特定的压缩配额，破坏了局部图结构；其二，过度关注拓扑结构而忽视语义内容。我们提出了T-Retriever，一种创新框架，将属性图检索重新定义为基于树的检索，采用语义与结构引导的编码树。该方法包含两项核心创新：（1）自适应压缩编码，以全局优化策略取代人为设定的压缩配额，有效保留图的自然层次组织；（2）语义-结构熵（$S^2$-熵），在构建层次化划分时同时优化结构凝聚性与语义一致性。在多种图推理基准上的实验表明，T-Retriever显著优于当前最先进的RAG方法，在应对复杂查询时能够提供更连贯、更具上下文相关性的回答。"
  },
  {
    "date": "2026-01-08",
    "title": "Higher-Order Knowledge Representations for Agentic Scientific Reasoning",
    "authors": "Isabella A. Stewart, Markus J. Buehler",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04878v1",
    "source": "arXiv",
    "abstract": "Scientific inquiry requires systems-level reasoning that integrates heterogeneous experimental data, cross-domain knowledge, and mechanistic evidence into coherent explanations. While Large Language Models (LLMs) offer inferential capabilities, they often depend on retrieval-augmented contexts that lack structural depth. Traditional Knowledge Graphs (KGs) attempt to bridge this gap, yet their pairwise constraints fail to capture the irreducible higher-order interactions that govern emergent physical behavior. To address this, we introduce a methodology for constructing hypergraph-based knowledge representations that faithfully encode multi-entity relationships. Applied to a corpus of ~1,100 manuscripts on biocomposite scaffolds, our framework constructs a global hypergraph of 161,172 nodes and 320,201 hyperedges, revealing a scale-free topology (power law exponent ~1.23) organized around highly connected conceptual hubs. This representation prevents the combinatorial explosion typical of pairwise expansions and explicitly preserves the co-occurrence context of scientific formulations. We further demonstrate that equipping agentic systems with hypergraph traversal tools, specifically using node-intersection constraints, enables them to bridge semantically distant concepts. By exploiting these higher-order pathways, the system successfully generates grounded mechanistic hypotheses for novel composite materials, such as linking cerium oxide to PCL scaffolds via chitosan intermediates. This work establishes a \"teacherless\" agentic reasoning system where hypergraph topology acts as a verifiable guardrail, accelerating scientific discovery by uncovering relationships obscured by traditional graph methods.",
    "title_zh": "用于代理型科学推理的高阶知识表示",
    "abstract_zh": "科学探究需要系统层面的推理能力，能够将异构实验数据、跨领域知识以及机制性证据整合为连贯的解释。尽管大型语言模型（LLMs）具备一定的推断能力，但它们通常依赖于检索增强的上下文，而这些上下文往往缺乏结构深度。传统的知识图谱（KGs）试图弥合这一差距，但其成对约束无法捕捉支配涌现物理行为的不可约高阶相互作用。为此，我们提出一种构建超图基知识表征的方法，以忠实编码多实体间的关系。该方法应用于约1,100篇关于生物复合支架的研究论文语料库，构建了一个包含161,172个节点和320,201条超边的全局超图，揭示出一种无标度拓扑结构（幂律指数约为1.23），其围绕高度连接的概念枢纽组织而成。这种表征方式有效避免了传统成对扩展所导致的组合爆炸问题，并明确保留了科学表述中的共现上下文。我们进一步证明，通过赋予智能体系统超图遍历工具——特别是利用节点交集约束——可使其跨越语义上相距甚远的概念。借助这些高阶路径，系统成功生成了针对新型复合材料的有依据的机制假设，例如通过壳聚糖中间体将氧化铈与聚己内酯（PCL）支架联系起来。本研究建立了一种“无需教师”的智能体推理系统，其中超图拓扑充当可验证的约束机制，通过揭示传统图方法难以发现的关系，显著加速了科学发现进程。"
  },
  {
    "date": "2026-01-08",
    "title": "EvolSQL: Structure-Aware Evolution for Scalable Text-to-SQL Data Synthesis",
    "authors": "Xuanguang Pan, Chongyang Tao, Jiayuan Bai, Jianling Gao, Zhengwei Tao, Xiansheng Zhou, Gavin Cheung, Shuai Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04875v1",
    "source": "arXiv",
    "abstract": "Training effective Text-to-SQL models remains challenging due to the scarcity of high-quality, diverse, and structurally complex datasets. Existing methods either rely on limited human-annotated corpora, or synthesize datasets directly by simply prompting LLMs without explicit control over SQL structures, often resulting in limited structural diversity and complexity. To address this, we introduce EvolSQL, a structure-aware data synthesis framework that evolves SQL queries from seed data into richer and more semantically diverse forms. EvolSQL starts with an exploratory Query-SQL expansion to broaden question diversity and improve schema coverage, and then applies an adaptive directional evolution strategy using six atomic transformation operators derived from the SQL Abstract Syntax Tree to progressively increase query complexity across relational, predicate, aggregation, and nesting dimensions. An execution-grounded SQL refinement module and schema-aware deduplication further ensure the creation of high-quality, structurally diverse mapping pairs. Experimental results show that a 7B model fine-tuned on our data outperforms one trained on the much larger SynSQL dataset using only 1/18 of the data.",
    "title_zh": "EvolSQL：面向结构感知进化的可扩展文本到SQL数据合成",
    "abstract_zh": "由于高质量、多样化且结构复杂的语料库稀缺，训练高效的文本转SQL模型仍然面临挑战。现有方法要么依赖有限的人工标注语料，要么直接通过大语言模型（LLM）生成数据，但缺乏对SQL结构的显式控制，导致生成的查询在结构多样性与复杂性方面受限。为解决这一问题，我们提出EvolSQL——一种结构感知的数据合成框架，能够从初始数据出发，逐步演化出更丰富、语义更多样化的SQL查询。EvolSQL首先通过探索性“查询-SQL扩展”策略，扩大问题多样性并提升模式覆盖度；随后采用自适应方向演化策略，利用从SQL抽象语法树中提取的六种原子变换算子，逐步在关系、谓词、聚合和嵌套等维度上增强查询复杂性。此外，基于执行结果的SQL优化模块与模式感知去重机制进一步保障了高质量、结构多样映射对的生成。实验结果表明，仅使用1/18数据量，一个在EvolSQL生成数据上微调的7B模型，其性能已超越在更大规模的SynSQL数据集上训练的模型。"
  },
  {
    "date": "2026-01-08",
    "title": "MPM-LLM4DSE: Reaching the Pareto Frontier in HLS with Multimodal Learning and LLM-Driven Exploration",
    "authors": "Lei Xu, Shanshan Wang, Chenglong Xiao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04801v1",
    "source": "arXiv",
    "abstract": "High-Level Synthesis (HLS) design space exploration (DSE) seeks Pareto-optimal designs within expansive pragma configuration spaces. To accelerate HLS DSE, graph neural networks (GNNs) are commonly employed as surrogates for HLS tools to predict quality of results (QoR) metrics, while multi-objective optimization algorithms expedite the exploration. However, GNN-based prediction methods may not fully capture the rich semantic features inherent in behavioral descriptions, and conventional multi-objective optimization algorithms often do not explicitly account for the domain-specific knowledge regarding how pragma directives influence QoR. To address these limitations, this paper proposes the MPM-LLM4DSE framework, which incorporates a multimodal prediction model (MPM) that simultaneously fuses features from behavioral descriptions and control and data flow graphs. Furthermore, the framework employs a large language model (LLM) as an optimizer, accompanied by a tailored prompt engineering methodology. This methodology incorporates pragma impact analysis on QoR to guide the LLM in generating high-quality configurations (LLM4DSE). Experimental results demonstrate that our multimodal predictive model significantly outperforms state-of-the-art work ProgSG by up to 10.25$\\times$. Furthermore, in DSE tasks, the proposed LLM4DSE achieves an average performance gain of 39.90\\% over prior methods, validating the effectiveness of our prompting methodology. Code and models are available at https://github.com/wslcccc/MPM-LLM4DSE.",
    "title_zh": "MPM-LLM4DSE：通过多模态学习与基于大模型的探索实现HLS中的帕累托前沿",
    "abstract_zh": "高层次综合（HLS）设计空间探索（DSE）旨在大规模的pragma配置空间中寻找帕累托最优的设计方案。为加速HLS DSE过程，图神经网络（GNN）通常被用作HLS工具的代理模型，以预测质量结果（QoR）指标，同时结合多目标优化算法来提升探索效率。然而，基于GNN的预测方法可能无法充分捕捉行为描述中蕴含的丰富语义特征，而传统的多目标优化算法也往往未能显式考虑pragma指令对QoR影响的领域知识。针对上述局限，本文提出MPM-LLM4DSE框架，该框架引入一种多模态预测模型（MPM），能够同时融合行为描述与控制流图、数据流图中的特征信息。此外，该框架采用大语言模型（LLM）作为优化器，并结合一种定制化的提示工程方法，通过分析pragma对QoR的影响，引导LLM生成高质量的配置方案（即LLM4DSE）。实验结果表明，所提出的多模态预测模型在性能上显著优于当前最先进的方法ProgSG，最高提升达10.25倍。在DSE任务中，所提出的LLM4DSE相比以往方法平均性能提升39.90%，验证了提示工程方法的有效性。代码与模型已开源，地址为：https://github.com/wslcccc/MPM-LLM4DSE。"
  },
  {
    "date": "2026-01-08",
    "title": "AT$^2$PO: Agentic Turn-based Policy Optimization via Tree Search",
    "authors": "Zefang Zong, Dingwei Chen, Yang Li, Qi Yi, Bo Zhou, Chengming Li, Bo Qian, Peng Chen, Jie Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04767v1",
    "source": "arXiv",
    "abstract": "LLM agents have emerged as powerful systems for tackling multi-turn tasks by interleaving internal reasoning and external tool interactions. Agentic Reinforcement Learning has recently drawn significant research attention as a critical post-training paradigm to further refine these capabilities. In this paper, we present AT$^2$PO (Agentic Turn-based Policy Optimization via Tree Search), a unified framework for multi-turn agentic RL that addresses three core challenges: limited exploration diversity, sparse credit assignment, and misaligned policy optimization. AT$^2$PO introduces a turn-level tree structure that jointly enables Entropy-Guided Tree Expansion for strategic exploration and Turn-wise Credit Assignment for fine-grained reward propagation from sparse outcomes. Complementing this, we propose Agentic Turn-based Policy Optimization, a turn-level learning objective that aligns policy updates with the natural decision granularity of agentic interactions. ATPO is orthogonal to tree search and can be readily integrated into any multi-turn RL pipeline. Experiments across seven benchmarks demonstrate consistent improvements over the state-of-the-art baseline by up to 1.84 percentage points in average, with ablation studies validating the effectiveness of each component. Our code is available at https://github.com/zzfoutofspace/ATPO.",
    "title_zh": "AT²PO：基于树搜索的代理回合制策略优化",
    "abstract_zh": "大型语言模型（LLM）代理已发展为一种强大的系统，能够通过交织内部推理与外部工具交互来处理多轮任务。近年来，代理强化学习（Agentic Reinforcement Learning）作为一种关键的后训练范式，受到了广泛关注，旨在进一步提升这些能力。本文提出了一种统一的多轮代理强化学习框架——AT$^2$PO（基于树搜索的代理回合策略优化），以应对三个核心挑战：探索多样性有限、奖励分配稀疏以及策略优化不匹配。AT$^2$PO引入了回合级树结构，联合实现了基于熵引导的树扩展（Entropy-Guided Tree Expansion），以促进战略性探索；以及回合级信用分配（Turn-wise Credit Assignment），实现从稀疏结果中精细化地传播奖励。此外，我们提出了代理回合级策略优化（Agentic Turn-based Policy Optimization），这是一种基于回合的学习目标，使策略更新与代理交互的自然决策粒度相一致。ATPO与树搜索方法正交，可无缝集成到任何多轮强化学习流水线中。在七个基准测试上的实验表明，相较于当前最优基线，平均性能提升最高达1.84个百分点，消融实验也验证了各组件的有效性。代码已公开于 https://github.com/zzfoutofspace/ATPO。"
  },
  {
    "date": "2026-01-08",
    "title": "Revisiting Judge Decoding from First Principles via Training-Free Distributional Divergence",
    "authors": "Shengyin Sun, Yiming Li, Renxi Liu, Weizhe Lin, Hui-Ling Zhen, Xianzhi Yu, Mingxuan Yuan, Chen Ma",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04766v1",
    "source": "arXiv",
    "abstract": "Judge Decoding accelerates LLM inference by relaxing the strict verification of Speculative Decoding, yet it typically relies on expensive and noisy supervision. In this work, we revisit this paradigm from first principles, revealing that the ``criticality'' scores learned via costly supervision are intrinsically encoded in the draft-target distributional divergence. We theoretically prove a structural correspondence between learned linear judges and Kullback-Leibler (KL) divergence, demonstrating they rely on the same underlying logit primitives. Guided by this, we propose a simple, training-free verification mechanism based on KL divergence. Extensive experiments across reasoning and coding benchmarks show that our method matches or outperforms complex trained judges (e.g., AutoJudge), offering superior robustness to domain shifts and eliminating the supervision bottleneck entirely.",
    "title_zh": "通过无训练分布差异方法从基本原理重新审视法官解码",
    "abstract_zh": "判别式解码通过放宽对推测解码的严格验证来加速大语言模型的推理，但通常依赖于昂贵且噪声较大的监督信号。在本工作中，我们从基本原理重新审视这一范式，揭示出通过高成本监督学习得到的“关键性”评分，本质上已编码于草稿与目标分布之间的差异之中。我们从理论上证明了所学线性判别器与KL散度之间存在结构对应关系，表明二者均依赖于相同的底层logit原语。基于此发现，我们提出一种简单、无需训练的验证机制，该机制基于KL散度实现。大量实验在推理与编程基准上的结果表明，我们的方法在性能上可媲美甚至超越复杂的训练型判别器（如AutoJudge），同时展现出更强的领域迁移鲁棒性，并完全消除了对监督信号的依赖。"
  },
  {
    "date": "2026-01-08",
    "title": "Limited Math: Aligning Mathematical Semantics with Finite Computation",
    "authors": "Lian Wen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04634v1",
    "source": "arXiv",
    "abstract": "Classical mathematical models used in the semantics of programming languages and computation rely on idealized abstractions such as infinite-precision real numbers, unbounded sets, and unrestricted computation. In contrast, concrete computation is inherently finite, operating under bounded precision, bounded memory, and explicit resource constraints. This discrepancy complicates semantic reasoning about numerical behavior, algebraic properties, and termination under finite execution. This paper introduces Limited Math (LM), a bounded semantic framework that aligns mathematical reasoning with finite computation. Limited Math makes constraints on numeric magnitude, numeric precision, and structural complexity explicit and foundational. A finite numeric domain parameterized by a single bound \\(M\\) is equipped with a deterministic value-mapping operator that enforces quantization and explicit boundary behavior. Functions and operators retain their classical mathematical interpretation and are mapped into the bounded domain only at a semantic boundary, separating meaning from bounded evaluation. Within representable bounds, LM coincides with classical arithmetic; when bounds are exceeded, deviations are explicit, deterministic, and analyzable. By additionally bounding set cardinality, LM prevents implicit infinitary behavior from re-entering through structural constructions. As a consequence, computations realized under LM induce finite-state semantic models, providing a principled foundation for reasoning about arithmetic, structure, and execution in finite computational settings.",
    "title_zh": "有限数学：数学语义与有限计算的对齐",
    "abstract_zh": "在编程语言与计算的语义学中，传统的数学模型依赖于理想化的抽象，例如无限精度的实数、无界集合以及不受限制的计算。然而，实际的计算本质上是有限的，受限于有限的精度、有限的内存以及明确的资源约束。这种差异使得在有限执行环境下对数值行为、代数性质以及终止性进行语义推理变得复杂。本文提出了一种名为“有限数学”（Limited Math, LM）的有界语义框架，该框架将数学推理与有限计算相统一。有限数学显式地将数值范围、数值精度以及结构复杂度的约束作为其基础。一个由单一参数 \\(M\\) 参数化的有限数值域，配备了一个确定性的值映射算子，用于强制量化和明确的边界行为。函数与运算符保留其经典的数学解释，仅在语义边界处被映射到有界域中，从而实现意义与有界求值的分离。在可表示的范围内，LM 与经典算术一致；当超出边界时，偏差是显式的、确定性的，并且可分析。通过进一步限制集合的基数，LM 防止了隐含的无穷行为通过结构构造重新引入。因此，在 LM 下实现的计算会生成有限状态的语义模型，为在有限计算环境中对算术、结构和执行过程进行严谨推理提供了坚实的基础。"
  },
  {
    "date": "2026-01-08",
    "title": "Adaptive Retrieval for Reasoning-Intensive Retrieval",
    "authors": "Jongho Kim, Jaeyoung Kim, Seung-won Hwang, Jihyuk Kim, Yu Jin Kim, Moontae Lee",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04618v1",
    "source": "arXiv",
    "abstract": "We study leveraging adaptive retrieval to ensure sufficient \"bridge\" documents are retrieved for reasoning-intensive retrieval. Bridge documents are those that contribute to the reasoning process yet are not directly relevant to the initial query. While existing reasoning-based reranker pipelines attempt to surface these documents in ranking, they suffer from bounded recall. Naive solution with adaptive retrieval into these pipelines often leads to planning error propagation. To address this, we propose REPAIR, a framework that bridges this gap by repurposing reasoning plans as dense feedback signals for adaptive retrieval. Our key distinction is enabling mid-course correction during reranking through selective adaptive retrieval, retrieving documents that support the pivotal plan. Experimental results on reasoning-intensive retrieval and complex QA tasks demonstrate that our method outperforms existing baselines by 5.6%pt.",
    "title_zh": "面向推理密集型检索的自适应检索",
    "abstract_zh": "我们研究了利用自适应检索来确保在推理密集型检索任务中能够充分召回“桥梁”文档。所谓桥梁文档，是指那些虽不直接相关于初始查询，但对推理过程有贡献的文档。尽管现有的基于推理的重排序管道试图在排序过程中揭示这些文档，但它们存在召回率受限的问题。将自适应检索简单地引入此类管道，往往会导致规划错误的传播。为解决这一问题，我们提出了REPAIR框架，该框架通过将推理计划重新用作密集反馈信号，实现自适应检索，从而弥合这一差距。我们的核心创新在于：在重排序过程中通过选择性自适应检索，实现中途修正，即检索支持关键推理计划的文档。在推理密集型检索和复杂问答任务上的实验结果表明，我们的方法相比现有基线提升了5.6个百分点。"
  },
  {
    "date": "2026-01-08",
    "title": "AdaptEval: A Benchmark for Evaluating Large Language Models on Code Snippet Adaptation",
    "authors": "Tanghaoran Zhang, Xinjun Mao, Shangwen Wang, Yuxin Zhao, Yao Lu, Jin Zhang, Zhang Zhang, Kang Yang, Yue Yu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04540v1",
    "source": "arXiv",
    "abstract": "Recent advancements in large language models (LLMs) have automated various software engineering tasks, with benchmarks emerging to evaluate their capabilities. However, for adaptation, a critical activity during code reuse, there is no benchmark to assess LLMs' performance, leaving their practical utility in this area unclear. To fill this gap, we propose AdaptEval, a benchmark designed to evaluate LLMs on code snippet adaptation. Unlike existing benchmarks, AdaptEval incorporates the following three distinctive features: First, Practical Context. Tasks in AdaptEval are derived from developers' practices, preserving rich contextual information from Stack Overflow and GitHub communities. Second, Multi-granularity Annotation. Each task is annotated with requirements at both task and adaptation levels, supporting the evaluation of LLMs across diverse adaptation scenarios. Third, Fine-grained Evaluation. AdaptEval includes a two-tier testing framework combining adaptation-level and function-level tests, which enables evaluating LLMs' performance across various individual adaptations. Based on AdaptEval, we conduct the first empirical study to evaluate six instruction-tuned LLMs and especially three reasoning LLMs on code snippet adaptation. Experimental results demonstrate that AdaptEval enables the assessment of LLMs' adaptation capabilities from various perspectives. It also provides critical insights into their current limitations, particularly their struggle to follow explicit instructions. We hope AdaptEval can facilitate further investigation and enhancement of LLMs' capabilities in code snippet adaptation, supporting their real-world applications.",
    "title_zh": "AdaptEval：代码片段适配任务中大型语言模型评估的基准测试",
    "abstract_zh": "近年来，大型语言模型（LLMs）在自动化各类软件工程任务方面取得了显著进展，相关基准测试也相继出现以评估其能力。然而，在代码复用过程中至关重要的适配（adaptation）环节，目前尚缺乏专门的评估基准，导致LLMs在此领域的实际应用价值仍不明确。为填补这一空白，我们提出了AdaptEval——一个专为评估LLMs在代码片段适配能力而设计的基准测试。与现有基准不同，AdaptEval具有以下三个独特特征：第一，**实际上下文**。AdaptEval中的任务均源自开发者的实际实践，保留了来自Stack Overflow和GitHub社区的丰富上下文信息；第二，**多粒度标注**。每个任务均在任务层级和适配层级上进行了双重标注，支持对LLMs在多种适配场景下的表现进行系统评估；第三，**细粒度评估**。AdaptEval采用双层测试框架，结合适配层级与函数层级的测试，能够对LLMs在各类具体适配操作中的表现进行精细化评估。\n\n基于AdaptEval，我们首次开展了实证研究，评估了六种指令微调的LLMs，特别是三种具备推理能力的LLMs在代码片段适配任务上的表现。实验结果表明，AdaptEval能够从多个角度全面评估LLMs的适配能力，并揭示了其当前存在的关键局限，尤其是难以准确遵循明确指令的问题。我们期望AdaptEval能推动对LLMs在代码片段适配能力方面的进一步研究与优化，从而更好地支持其在真实世界中的应用。"
  },
  {
    "date": "2026-01-08",
    "title": "Advancing Language Models for Code-related Tasks",
    "authors": "Zhao Tian",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04526v1",
    "source": "arXiv",
    "abstract": "Recent advances in language models (LMs) have driven significant progress in various software engineering tasks. However, existing LMs still struggle with complex programming scenarios due to limitations in data quality, model architecture, and reasoning capability. This research systematically addresses these challenges through three complementary directions: (1) improving code data quality with a code difference-guided adversarial augmentation technique (CODA) and a code denoising technique (CodeDenoise); (2) enhancing model architecture via syntax-guided code LMs (LEAM and LEAM++); and (3) advancing model reasoning with a prompting technique (muFiX) and an agent-based technique (Specine). These techniques aim to promote the practical adoption of LMs in software development and further advance intelligent software engineering.",
    "title_zh": "推进代码相关任务的语言模型",
    "abstract_zh": "近年来，语言模型（LMs）的进展在软件工程的诸多任务中推动了显著进步。然而，现有语言模型在应对复杂的编程场景时仍面临挑战，主要受限于数据质量、模型架构和推理能力。本研究从三个互补方向系统性地解决这些问题：（1）通过一种基于代码差异引导的对抗增强技术（CODA）和一种代码去噪技术（CodeDenoise），提升代码数据质量；（2）通过语法引导的代码语言模型（LEAM 和 LEAM++），优化模型架构；（3）通过提示技术（muFiX）和基于智能体的技术（Specine），提升模型的推理能力。这些技术旨在促进语言模型在软件开发中的实际应用，并进一步推动智能软件工程的发展。"
  },
  {
    "date": "2026-01-08",
    "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
    "authors": "Shih-Yang Liu, Xin Dong, Ximing Lu, Shizhe Diao, Peter Belcak, Mingjie Liu, Min-Hung Chen, Hongxu Yin, Yu-Chiang Frank Wang, Kwang-Ting Cheng, Yejin Choi, Jan Kautz, Pavlo Molchanov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05242v1",
    "source": "arXiv",
    "abstract": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
    "title_zh": "GDPO：面向多奖励强化学习优化的分组奖励解耦归一化策略优化方法",
    "abstract_zh": "随着语言模型能力的不断提升，用户不仅期望其提供准确的回答，还希望模型在各种场景下表现出与多样化人类偏好相一致的行为。为实现这一目标，强化学习（RL）流程开始引入多种奖励信号，每种奖励捕捉一种特定偏好，以引导模型向期望行为演进。然而，近期研究在多奖励设置下默认采用组相对策略优化（GRPO），而未充分评估其适用性。本文表明，直接将GRPO应用于不同回放奖励组合的归一化，会导致这些奖励组合的优势值趋于完全相同，从而降低训练信号的分辨能力，引发次优收敛，甚至在某些情况下导致早期训练失败。为此，我们提出了一种新的策略优化方法——组奖励解耦归一化策略优化（GDPO），通过解耦各奖励的归一化过程，更真实地保留它们之间的相对差异，从而实现更精确的多奖励优化，并显著提升训练稳定性。我们在三个任务上对GDPO与GRPO进行了对比：工具调用、数学推理和代码推理，评估了正确性指标（如准确率、错误率）以及约束遵守指标（如格式、长度）。在所有实验设置中，GDPO均持续优于GRPO，充分证明了其在多奖励强化学习优化中的有效性与通用性。"
  },
  {
    "date": "2026-01-08",
    "title": "Extending Delta Debugging Minimization for Spectrum-Based Fault Localization",
    "authors": "Charaka Geethal Kapugama",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04689v1",
    "source": "arXiv",
    "abstract": "This paper introduces DDMIN-LOC, a technique that combines Delta Debugging Minimization (DDMIN) with Spectrum-Based Fault Localization (SBFL). It can be applied to programs taking string inputs, even when only a single failure-inducing input is available. DDMIN is an algorithm that systematically explores the minimal failure-inducing input that exposes a bug, given an initial failing input. However, it does not provide information about the faulty statements responsible for the failure. DDMIN-LOC addresses this limitation by collecting the passing and failing inputs generated during the DDMIN process and computing suspiciousness scores for program statements and predicates using SBFL algorithms. These scores are then combined to rank statements according to their likelihood of being faulty. DDMIN-LOC requires only one failing input of the buggy program, although it can be applied only to programs that take string inputs. DDMIN-LOC was evaluated on 136 programs selected from the QuixBugs and Codeflaws benchmarks using the SBFL algorithms Tarantula, Ochiai, GenProg, Jaccard and DStar. Experimental results show that DDMIN-LOC performs best with Jaccard: in most subjects, fewer than 20% executable lines need to be examined to locate the faulty statements. Moreover, in most subjects, faulty statements are ranked within the top 3 positions in all the generated test suites derived from different failing inputs.",
    "title_zh": "扩展Delta调试最小化以用于基于谱的故障定位",
    "abstract_zh": "本文介绍了一种名为DDMIN-LOC的技术，该技术将差分调试最小化（DDMIN）与基于谱的故障定位（SBFL）相结合。该方法适用于接收字符串输入的程序，即使仅有一个导致失败的输入也可使用。DDMIN是一种算法，能够在给定一个初始失败输入的情况下，系统地探索出能够暴露缺陷的最小失败输入。然而，它无法提供关于导致失败的错误语句的信息。DDMIN-LOC通过在DDMIN过程中收集通过和失败的输入，并利用SBFL算法为程序语句和谓词计算可疑度得分，从而弥补了这一不足。这些得分随后被综合起来，按语句可能出错的概率进行排序。DDMIN-LOC仅需一个存在缺陷程序的失败输入即可应用，但仅限于接收字符串输入的程序。研究在从QuixBugs和Codeflaws基准中选取的136个程序上对DDMIN-LOC进行了评估，采用的SBFL算法包括Tarantula、Ochiai、GenProg、Jaccard和DStar。实验结果表明，DDMIN-LOC在使用Jaccard算法时表现最佳：在大多数情况下，只需检查少于20%的可执行代码行即可定位错误语句；此外，在大多数测试用例中，错误语句在所有由不同失败输入生成的测试套件中均排在前三位。"
  },
  {
    "date": "2026-01-08",
    "title": "Adversarial Yet Cooperative: Multi-Perspective Reasoning in Retrieved-Augmented Language Models",
    "authors": "Can Xu, Lingyong Yan, Jiayi Wu, Haosen Wang, Shuaiqiang Wang, Yuchen Li, Jizhou Huang, Dawei Yin, Xiang Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04651v1",
    "source": "arXiv",
    "abstract": "Recent advances in synergizing large reasoning models (LRMs) with retrieval-augmented generation (RAG) have shown promising results, yet two critical challenges remain: (1) reasoning models typically operate from a single, unchallenged perspective, limiting their ability to conduct deep, self-correcting reasoning over external documents, and (2) existing training paradigms rely excessively on outcome-oriented rewards, which provide insufficient signal for shaping the complex, multi-step reasoning process. To address these issues, we propose an Reasoner-Verifier framework named Adversarial Reasoning RAG (ARR). The Reasoner and Verifier engage in reasoning on retrieved evidence and critiquing each other's logic while being guided by process-aware advantage that requires no external scoring model. This reward combines explicit observational signals with internal model uncertainty to jointly optimize reasoning fidelity and verification rigor. Experiments on multiple benchmarks demonstrate the effectiveness of our method.",
    "title_zh": "对抗 yet合作：检索增强型语言模型中的多视角推理",
    "abstract_zh": "近年来，将大型推理模型（LRMs）与检索增强生成（RAG）相结合的研究取得了显著进展，展现出广阔的应用前景。然而，仍存在两个关键挑战：（1）推理模型通常仅从单一、未经质疑的视角出发，难以对外部文档进行深入且具备自我修正能力的推理；（2）现有训练范式过度依赖以结果为导向的奖励机制，无法为复杂、多步骤的推理过程提供充分的信号引导。针对上述问题，我们提出了一种名为对抗性推理RAG（Adversarial Reasoning RAG, ARR）的推理-验证框架。该框架中，推理模块（Reasoner）与验证模块（Verifier）在检索到的证据基础上相互进行推理与逻辑批判，同时在过程感知优势的引导下协同优化，无需依赖外部评分模型。该奖励机制融合了显式的观察信号与模型内部的不确定性，共同提升推理的准确性与验证的严谨性。在多个基准测试上的实验结果表明，所提方法具有显著的有效性。"
  },
  {
    "date": "2026-01-08",
    "title": "AgentDevel: Reframing Self-Evolving LLM Agents as Release Engineering",
    "authors": "Di Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04620v1",
    "source": "arXiv",
    "abstract": "Recent progress in large language model (LLM) agents has largely focused on embedding self-improvement mechanisms inside the agent or searching over many concurrent variants. While these approaches can raise aggregate scores, they often yield unstable and hard-to-audit improvement trajectories, making it difficult to guarantee non-regression or to reason about failures across versions. We reframe agent improvement as \\textbf{release engineering}: agents are treated as shippable artifacts, and improvement is externalized into a regression-aware release pipeline. We introduce \\textbf{AgentDevel}, a release engineering pipeline that iteratively runs the current agent, produces implementation-blind, symptom-level quality signals from execution traces, synthesizes a single release candidate (RC) via executable diagnosis, and promotes it under flip-centered gating. AgentDevel features three core designs: (i) an implementation-blind LLM critic that characterizes failure appearances without accessing agent internals, (ii) script-based executable diagnosis that aggregates dominant symptom patterns and produces auditable engineering specifications, and (iii) flip-centered gating that prioritizes pass to fail regressions and fail to pass fixes as first-class evidence. Unlike population-based search or in-agent self-refinement, AgentDevel maintains a single canonical version line and emphasizes non-regression as a primary objective. Experiments on execution-heavy benchmarks demonstrate that AgentDevel yields stable improvements with significantly fewer regressions while producing reproducible, auditable artifacts. Overall, AgentDevel provides a practical development discipline for building, debugging, and releasing LLM agents as software development.",
    "title_zh": "AgentDevel：将自演化大语言模型代理重新定义为发布工程",
    "abstract_zh": "大型语言模型（LLM）代理的最新进展主要集中在将自我改进机制嵌入代理内部，或通过并行搜索大量变体来提升性能。尽管这些方法能够提高整体得分，但往往导致改进过程不稳定且难以审计，使得难以保证不出现回归问题，也难以对不同版本中的失败情况进行有效分析。我们重新定义了代理的改进方式为**发布工程**：将代理视为可发布的软件制品，而将改进过程外部化为一种具备回归感知能力的发布流水线。为此，我们提出了**AgentDevel**——一个迭代运行当前代理、从执行轨迹中生成不依赖实现细节的、症状级别的质量信号、通过可执行诊断合成单一发布候选（RC），并在以“翻转”为中心的门控机制下进行发布的新颖流水线。\n\nAgentDevel 具备三个核心设计：(i) 一种不依赖内部实现的 LLM 评判器，能够在不访问代理内部结构的前提下，识别和描述故障的表现形式；(ii) 基于脚本的可执行诊断机制，能够聚合主导的症状模式，并生成可审计的工程规范；(iii) 以“翻转”为核心的门控策略，将“通过变为失败”的回归与“失败变为通过”的修复作为首要证据优先处理。\n\n与基于种群的搜索或在代理内部进行自精炼的方法不同，AgentDevel 维持单一的主干版本线，将防止回归作为核心目标。在执行密集型基准测试上的实验表明，AgentDevel 能够实现稳定且显著减少回归的改进，同时生成可复现、可审计的软件制品。总体而言，AgentDevel 为构建、调试和发布 LLM 代理提供了一套实用的软件开发实践体系。"
  },
  {
    "date": "2026-01-08",
    "title": "Deep Dive into the Abuse of DL APIs To Create Malicious AI Models and How to Detect Them",
    "authors": "Mohamed Nabeel, Oleksii Starov",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04553v1",
    "source": "arXiv",
    "abstract": "According to Gartner, more than 70% of organizations will have integrated AI models into their workflows by the end of 2025. In order to reduce cost and foster innovation, it is often the case that pre-trained models are fetched from model hubs like Hugging Face or TensorFlow Hub. However, this introduces a security risk where attackers can inject malicious code into the models they upload to these hubs, leading to various kinds of attacks including remote code execution (RCE), sensitive data exfiltration, and system file modification when these models are loaded or executed (predict function). Since AI models play a critical role in digital transformation, this would drastically increase the number of software supply chain attacks. While there are several efforts at detecting malware when deserializing pickle based saved models (hiding malware in model parameters), the risk of abusing DL APIs (e.g. TensorFlow APIs) is understudied. Specifically, we show how one can abuse hidden functionalities of TensorFlow APIs such as file read/write and network send/receive along with their persistence APIs to launch attacks. It is concerning to note that existing scanners in model hubs like Hugging Face and TensorFlow Hub are unable to detect some of the stealthy abuse of such APIs. This is because scanning tools only have a syntactically identified set of suspicious functionality that is being analysed. They often do not have a semantic-level understanding of the functionality utilized. After demonstrating the possible attacks, we show how one may identify potentially abusable hidden API functionalities using LLMs and build scanners to detect such abuses.",
    "title_zh": "深入剖析DL API的滥用：用于创建恶意AI模型及其检测方法",
    "abstract_zh": "根据Gartner的预测，到2025年底，超过70%的组织将把AI模型集成到其工作流程中。为了降低成本并促进创新，通常会从Hugging Face或TensorFlow Hub等模型库中获取预训练模型。然而，这一做法引入了安全风险：攻击者可能在上传模型时注入恶意代码，当这些模型被加载或执行（如调用predict函数）时，可能导致远程代码执行（RCE）、敏感数据泄露以及系统文件篡改等各种攻击。由于AI模型在数字化转型中扮演着关键角色，这将显著增加软件供应链攻击的数量。\n\n尽管已有部分研究致力于检测基于pickle序列化保存模型时的恶意软件（例如将恶意代码隐藏在模型参数中），但对深度学习API（如TensorFlow API）的滥用风险仍缺乏足够关注。具体而言，我们展示了如何利用TensorFlow API中隐藏的功能（如文件读写、网络收发以及持久化API）发动攻击。令人担忧的是，目前Hugging Face和TensorFlow Hub等模型库中的现有扫描工具无法检测到其中一些隐蔽的API滥用行为。这是因为这些扫描工具仅依赖于语法层面识别出的可疑功能进行分析，而缺乏对所使用功能语义层面的理解。\n\n在演示了潜在攻击方式后，我们进一步提出如何利用大语言模型（LLMs）识别可能被滥用的隐藏API功能，并构建相应的检测扫描器以发现此类滥用行为。"
  },
  {
    "date": "2026-01-08",
    "title": "Nalar: An agent serving framework",
    "authors": "Marco Laju, Donghyun Son, Saurabh Agarwal, Nitin Kedia, Myungjin Lee, Jayanth Srinivasa, Aditya Akella",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05109v1",
    "source": "arXiv",
    "abstract": "LLM-driven agentic applications increasingly automate complex, multi-step tasks, but serving them efficiently remains challenging due to heterogeneous components, dynamic and model-driven control flow, long-running state, and unpredictable latencies. Nalar is a ground-up agent-serving framework that cleanly separates workflow specification from execution while providing the runtime visibility and control needed for robust performance. Nalar preserves full Python expressiveness, using lightweight auto-generated stubs that turn agent and tool invocations into futures carrying dependency and context metadata. A managed state layer decouples logical state from physical placement, enabling safe reuse, migration, and consistent retry behavior. A two-level control architecture combines global policy computation with local event-driven enforcement to support adaptive routing, scheduling, and resource management across evolving workflows. Together, these mechanisms allow Nalar to deliver scalable, efficient, and policy-driven serving of heterogeneous agentic applications without burdening developers with orchestration logic. Across three agentic workloads, Nalar cuts tail latency by 34--74\\%, achieves up to $2.9\\times$ speedups, sustains 80 RPS where baselines fail, and scales to 130K futures with sub-500 ms control overhead.",
    "title_zh": "Nalar：一个代理服务框架",
    "abstract_zh": "由大语言模型（LLM）驱动的智能体应用正日益自动化复杂且多步骤的任务，但其高效服务仍面临诸多挑战：组件异构性、动态且由模型驱动的控制流、长时间运行的状态以及不可预测的延迟。Nalar 是一个从零开始设计的智能体服务框架，它清晰地将工作流的定义与执行分离，同时提供运行时所需的可观测性和控制能力，以保障系统的稳健性能。Nalar 保持了完整的 Python 表达能力，通过轻量级自动生成的桩代码，将智能体和工具的调用转换为携带依赖关系和上下文元数据的未来对象（futures）。一个受管理的状态层实现了逻辑状态与物理位置的解耦，支持安全复用、迁移以及一致的重试行为。其两级控制架构结合全局策略计算与本地事件驱动的执行，能够灵活支持跨动态演进工作流的自适应路由、调度与资源管理。这些机制共同使 Nalar 能够在不增加开发者负担的前提下，实现对异构智能体应用的可扩展、高效且策略驱动的服务。在三个智能体工作负载上的实验表明，Nalar 将尾部延迟降低了 34%–74%，最高实现 2.9 倍的加速，维持 80 RPS 的吞吐量而基线系统已无法运行，并能扩展至 13 万个未来对象，且控制开销低于 500 毫秒。"
  },
  {
    "date": "2026-01-08",
    "title": "AVX / NEON Intrinsic Functions: When Should They Be Used?",
    "authors": "Théo Boivin, Joeffrey Legaux",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04922v1",
    "source": "arXiv",
    "abstract": "A cross-configuration benchmark is proposed to explore the capacities and limitations of AVX / NEON intrinsic functions in a generic context of development project, when a vectorisation strategy is required to optimise the code. The main aim is to guide developers to choose when using intrinsic functions, depending on the OS, architecture and/or available compiler. Intrinsic functions were observed highly efficient in conditional branching, with intrinsic version execution time reaching around 5% of plain code execution time. However, intrinsic functions were observed as unnecessary in many cases, as the compilers already well auto-vectorise the code.",
    "title_zh": "AVX / NEON 内在函数：何时应使用？",
    "abstract_zh": "提出了一种跨配置基准测试，旨在探索在通用开发项目背景下，当需要采用向量化策略优化代码时，AVX/NEON内建函数的性能潜力与局限性。其主要目标是指导开发者根据操作系统、架构和/或可用编译器的情况，合理选择是否使用内建函数。研究发现，在条件分支场景中，内建函数表现出极高的效率，其执行时间仅为普通代码的约5%。然而，在许多情况下，内建函数显得并不必要，因为现代编译器已能很好地自动完成代码向量化。"
  },
  {
    "date": "2026-01-08",
    "title": "A Navigational Approach for Comprehensive RAG via Traversal over Proposition Graphs",
    "authors": "Maxime Delmas, Lei Xu, André Freitas",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04859v1",
    "source": "arXiv",
    "abstract": "Standard RAG pipelines based on chunking excel at simple factual retrieval but fail on complex multi-hop queries due to a lack of structural connectivity. Conversely, initial strategies that interleave retrieval with reasoning often lack global corpus awareness, while Knowledge Graph (KG)-based RAG performs strongly on complex multi-hop tasks but suffers on fact-oriented single-hop queries. To bridge this gap, we propose a novel RAG framework: ToPG (Traversal over Proposition Graphs). ToPG models its knowledge base as a heterogeneous graph of propositions, entities, and passages, effectively combining the granular fact density of propositions with graph connectivity. We leverage this structure using iterative Suggestion-Selection cycles, where the Suggestion phase enables a query-aware traversal of the graph, and the Selection phase provides LLM feedback to prune irrelevant propositions and seed the next iteration. Evaluated on three distinct QA tasks (Simple, Complex, and Abstract QA), ToPG demonstrates strong performance across both accuracy- and quality-based metrics. Overall, ToPG shows that query-aware graph traversal combined with factual granularity is a critical component for efficient structured RAG systems. ToPG is available at https://github.com/idiap/ToPG.",
    "title_zh": "基于命题图遍历的全面RAG导航方法",
    "abstract_zh": "基于分块的标准RAG流程在简单事实检索任务中表现优异，但在处理复杂的多跳查询时因缺乏结构化连接而表现不佳。相反，早期将检索与推理交织的策略往往缺乏对整个语料库的全局认知，而基于知识图谱（KG）的RAG虽然在复杂多跳任务中表现强劲，却在面向事实的单跳查询上存在短板。为弥合这一差距，我们提出一种新颖的RAG框架：ToPG（命题图遍历）。ToPG将知识库建模为包含命题、实体和段落的异构图结构，有效融合了命题的细粒度事实密度与图结构的连通性优势。我们通过迭代的“建议-选择”循环来利用该结构：在建议阶段，实现基于查询感知的图遍历；在选择阶段，利用大语言模型（LLM）的反馈对无关命题进行剪枝，并为下一轮迭代提供种子节点。在三个不同类型的问答任务（简单问答、复杂问答和抽象问答）上的评估表明，ToPG在准确率和质量等多个指标上均表现出色。总体而言，ToPG验证了基于查询感知的图遍历与细粒度事实表示相结合，是构建高效结构化RAG系统的关键要素。ToPG项目代码已开源，可访问 https://github.com/idiap/ToPG 获取。"
  },
  {
    "date": "2026-01-08",
    "title": "Token Maturation: Autoregressive Language Generation via Continuous Token Dynamics",
    "authors": "Oshri Naparstek",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04854v1",
    "source": "arXiv",
    "abstract": "Autoregressive language models are conventionally defined over discrete token sequences, committing to a specific token at every generation step. This early discretization forces uncertainty to be resolved through token-level sampling, often leading to instability, repetition, and sensitivity to decoding heuristics. In this work, we introduce a continuous autoregressive formulation of language generation in which tokens are represented as continuous vectors that \\emph{mature} over multiple update steps before being discretized. Rather than sampling tokens, the model evolves continuous token representations through a deterministic dynamical process, committing to a discrete token only when the representation has sufficiently converged. Discrete text is recovered via hard decoding, while uncertainty is maintained and resolved in the continuous space. We show that this maturation process alone is sufficient to produce coherent and diverse text using deterministic decoding (argmax), without reliance on token-level sampling, diffusion-style denoising, or auxiliary stabilization mechanisms. Additional perturbations, such as stochastic dynamics or history smoothing, can be incorporated naturally but are not required for the model to function. To our knowledge, this is the first autoregressive language model that generates text by evolving continuous token representations to convergence prior to discretization, enabling stable generation without token-level sampling.",
    "title_zh": "令牌成熟：通过连续令牌动态实现自回归语言生成",
    "abstract_zh": "自回归语言模型传统上定义在离散的词元序列之上，每个生成步骤都必须确定一个具体的词元。这种早期的离散化迫使模型在词元层面进行采样以解决不确定性，常常导致生成结果不稳定、重复率高，并对解码启发式方法高度敏感。在本文中，我们提出了一种连续的自回归语言生成形式，其中词元以连续向量表示，并在多个更新步骤中逐步“成熟”，直到最终才进行离散化。与传统的词元采样不同，该模型通过一种确定性的动态过程演化连续的词元表示，仅当表示充分收敛时才确定为离散词元。最终的文本通过硬解码恢复，而不确定性则在整个连续空间中得以保留并逐步消除。我们证明，仅依靠这一“成熟”过程，即可在不依赖词元级采样、扩散式去噪或辅助稳定机制的情况下，通过确定性解码（如argmax）生成连贯且多样化的文本。此外，诸如随机动力学或历史平滑等额外扰动可自然地融入模型，但并非模型正常运行所必需。据我们所知，这是首个通过将连续词元表示演化至收敛后再进行离散化来生成文本的自回归语言模型，从而实现了无需词元级采样的稳定生成。"
  },
  {
    "date": "2026-01-08",
    "title": "SurgeQ: A Hybrid Framework for Ultra-Fast Quantum Processor Design and Crosstalk-Aware Circuit Execution",
    "authors": "Xinxuan Chen, Hongxiang Zhu, Zhaohui Yang, Zhaofeng Su, Jianxin Chen, Feng Wu, Hui-Hai Zhao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04645v1",
    "source": "arXiv",
    "abstract": "Executing quantum circuits on superconducting platforms requires balancing the trade-off between gate errors and crosstalk. To address this, we introduce SurgeQ, a hardware-software co-design strategy consisting of a design phase and an execution phase, to achieve accelerated circuit execution and improve overall program fidelity. SurgeQ employs coupling-strengthened, faster two-qubit gates while mitigating their increased crosstalk through a tailored scheduling strategy. With detailed consideration of composite noise models, we establish a systematic evaluation pipeline to identify the optimal coupling strength. Evaluations on a comprehensive suite of real-world benchmarks show that SurgeQ generally achieves higher fidelity than up-to-date baselines, and remains effective in combating exponential fidelity decay, achieving up to a million-fold improvement in large-scale circuits.",
    "title_zh": "SurgeQ：一种用于超快速量子处理器设计与串扰感知电路执行的混合框架",
    "abstract_zh": "在超导平台上执行量子电路时，需要在门错误与串扰之间取得平衡。为解决这一问题，我们提出了SurgeQ，一种软硬件协同设计策略，包含设计阶段和执行阶段，旨在实现电路的加速执行并提升整体程序保真度。SurgeQ采用增强耦合、速度更快的两比特门，同时通过量身定制的调度策略缓解其带来的串扰增加问题。在充分考虑复合噪声模型的基础上，我们建立了一套系统化的评估流程，以确定最优耦合强度。在一系列真实世界基准测试中的评估表明，SurgeQ通常能实现比当前先进基线更高的保真度，并在对抗指数级保真度衰减方面依然有效，在大规模电路中可实现高达百万倍的性能提升。"
  },
  {
    "date": "2026-01-08",
    "title": "Text as a Universal Interface for Transferable Personalization",
    "authors": "Yuting Liu, Jian Guan, Jia-Nan Li, Wei Wu, Jiang-Ming Yang, Jianzhe Zhao, Guibing Guo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04963v1",
    "source": "arXiv",
    "abstract": "We study the problem of personalization in large language models (LLMs). Prior work predominantly represents user preferences as implicit, model-specific vectors or parameters, yielding opaque ``black-box'' profiles that are difficult to interpret and transfer across models and tasks. In contrast, we advocate natural language as a universal, model- and task-agnostic interface for preference representation. The formulation leads to interpretable and reusable preference descriptions, while naturally supporting continual evolution as new interactions are observed. To learn such representations, we introduce a two-stage training framework that combines supervised fine-tuning on high-quality synthesized data with reinforcement learning to optimize long-term utility and cross-task transferability. Based on this framework, we develop AlignXplore+, a universal preference reasoning model that generates textual preference summaries. Experiments on nine benchmarks show that our 8B model achieves state-of-the-art performanc -- outperforming substantially larger open-source models -- while exhibiting strong transferability across tasks, model families, and interaction formats.",
    "title_zh": "文本作为可迁移个性化的通用接口",
    "abstract_zh": "我们研究了大型语言模型（LLMs）中的个性化问题。以往的工作主要将用户偏好表示为隐式的、与模型相关的向量或参数，从而形成难以解释且难以在不同模型和任务间迁移的“黑箱”型用户画像。相比之下，我们主张以自然语言作为通用的、与模型和任务无关的偏好表达接口。这种表述方式能够生成可解释且可复用的偏好描述，同时在观察到新交互时自然支持持续演化。为了学习此类表示，我们提出了一种两阶段训练框架，结合高质量合成数据上的监督微调与强化学习，以优化长期效用及跨任务迁移能力。基于该框架，我们开发了AlignXplore+——一种通用的偏好推理模型，能够生成文本形式的偏好摘要。在九个基准测试上的实验表明，我们的8B模型实现了领先性能，显著优于更大规模的开源模型，同时在不同任务、模型族和交互格式之间展现出强大的迁移能力。"
  },
  {
    "date": "2026-01-08",
    "title": "Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition",
    "authors": "Nils Einecke",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04920v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.",
    "title_zh": "面向快速科学原型设计的对话式人工智能：欧洲航天局ELOPE竞赛案例研究",
    "abstract_zh": "大型语言模型（LLMs）正越来越多地被用作编程伙伴，但其在加速科学发现方面的潜力仍鲜有探索。本文通过一个案例研究，展示了使用ChatGPT在欧洲航天局（ESA）ELOPE（基于事件的月球光学流自运动估计）竞赛中进行快速原型开发的应用。该竞赛要求参赛者处理事件相机数据以估计月球着陆器的轨迹。尽管我们参赛较晚，但仍取得了第二名的成绩，得分为0.01282，充分展现了人机协作在竞争性科研环境中的巨大潜力。ChatGPT不仅提供了可执行代码，还贡献了算法推理、数据处理流程以及方法论建议，例如建议采用固定数量的事件而非固定时间窗口进行滑动窗口处理。然而，我们也观察到一些局限性：模型常引入不必要的结构改动，在涉及中间替代方案讨论时容易混淆，偶尔出现关键性错误，并在较长的科学讨论中忽略重要细节。通过对这些优势与不足的分析，本文揭示了对话式人工智能如何既能加速研发进程，又能促进科学概念的深入理解。我们主张，将大型语言模型以结构化方式融入科研工作流程，能够显著提升快速原型开发效率，并提出了一系列AI辅助科研的最佳实践建议。"
  },
  {
    "date": "2026-01-08",
    "title": "Analyzing Message-Code Inconsistency in AI Coding Agent-Authored Pull Requests",
    "authors": "Jingzhi Gong, Giovanni Pinna, Yixin Bian, Jie M. Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04886v1",
    "source": "arXiv",
    "abstract": "Pull request (PR) descriptions generated by AI coding agents are the primary channel for communicating code changes to human reviewers. However, the alignment between these messages and the actual changes remains unexplored, raising concerns about the trustworthiness of AI agents. To fill this gap, we analyzed 23,247 agentic PRs across five agents using PR message-code inconsistency (PR-MCI). We contributed 974 manually annotated PRs, found 406 PRs (1.7%) exhibited high PR-MCI, and identified eight PR-MCI types, revealing that descriptions claiming unimplemented changes was the most common issue (45.4%). Statistical tests confirmed that high-MCI PRs had 51.7% lower acceptance rates (28.3% vs. 80.0%) and took 3.5x longer to merge (55.8 vs. 16.0 hours). Our findings suggest that unreliable PR descriptions undermine trust in AI agents, highlighting the need for PR-MCI verification mechanisms and improved PR generation to enable trustworthy human-AI collaboration.",
    "title_zh": "分析AI编码代理编写的拉取请求中的消息-代码不一致问题",
    "abstract_zh": "由AI编程代理生成的拉取请求（PR）描述是向人类审阅者传达代码变更信息的主要渠道。然而，这些描述与实际代码变更之间的对齐程度尚未得到充分研究，这引发了人们对AI代理可信度的担忧。为填补这一空白，我们利用PR消息-代码不一致性（PR-MCI）指标，分析了五个AI代理生成的23,247个代理型PR。我们手动标注了974个PR，并发现其中406个（1.7%）表现出较高的PR-MCI。通过分析，我们识别出八种PR-MCI类型，其中最常见的问题是描述中声称了未实现的变更（占比45.4%）。统计检验表明，高MCI PR的接受率低51.7%（28.3% vs. 80.0%），合并时间也延长了3.5倍（55.8小时 vs. 16.0小时）。研究结果表明，不可靠的PR描述会削弱人类对AI代理的信任，凸显了建立PR-MCI验证机制以及改进PR生成质量的必要性，以促进可信赖的人机协作。"
  },
  {
    "date": "2026-01-08",
    "title": "SCALER:Synthetic Scalable Adaptive Learning Environment for Reasoning",
    "authors": "Caijun Xu, Changyi Xiao, Zhongyuan Peng, Xinrun Wang, Yixin Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04809v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning (RL) offers a principled way to enhance the reasoning capabilities of large language models, yet its effectiveness hinges on training signals that remain informative as models evolve. In practice, RL progress often slows when task difficulty becomes poorly aligned with model capability, or when training is dominated by a narrow set of recurring problem patterns. To jointly address these issues, we propose SCALER (Synthetic sCalable Adaptive Learning Environment for Reasoning), a framework that sustains effective learning signals through adaptive environment design. SCALER introduces a scalable synthesis pipeline that converts real-world programming problems into verifiable reasoning environments with controllable difficulty and unbounded instance generation, enabling RL training beyond finite datasets while preserving strong correctness guarantees. Building on this, SCALER further employs an adaptive multi-environment RL strategy that dynamically adjusts instance difficulty and curates the active set of environments to track the model's capability frontier and maintain distributional diversity. This co-adaptation prevents reward sparsity, mitigates overfitting to narrow task patterns, and supports sustained improvement throughout training. Extensive experiments show that SCALER consistently outperforms dataset-based RL baselines across diverse reasoning benchmarks and exhibits more stable, long-horizon training dynamics.",
    "title_zh": "SCALER：用于推理的合成可扩展自适应学习环境",
    "abstract_zh": "强化学习（RL）为提升大型语言模型的推理能力提供了一种系统化的方法，但其有效性依赖于在模型演进过程中仍保持信息量的训练信号。实践中，当任务难度与模型能力不匹配时，或当训练被少数重复出现的问题模式主导时，RL的进展往往会放缓。为共同解决这些问题，我们提出了SCALER（用于推理的合成可扩展自适应学习环境），一种通过自适应环境设计持续提供有效学习信号的框架。SCALER引入了一个可扩展的合成流程，能够将现实世界的编程问题转化为具备可控难度和无限实例生成能力的可验证推理环境，从而在超越有限数据集的同时，仍保持强大的正确性保障。在此基础上，SCALER进一步采用一种自适应的多环境强化学习策略，动态调整实例难度，并优化当前活跃环境集合，以跟踪模型的能力边界并维持分布多样性。这种协同适应机制有效避免了奖励稀疏问题，缓解了对狭窄任务模式的过拟合，支持训练过程中的持续改进。大量实验表明，SCALER在多种推理基准测试中均显著优于基于数据集的RL基线方法，展现出更稳定、更持久的长周期训练动态。"
  },
  {
    "date": "2026-01-08",
    "title": "Neural-Symbolic Integration with Evolvable Policies",
    "authors": "Marios Thoma, Vassilis Vassiliades, Loizos Michael",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04799v1",
    "source": "arXiv",
    "abstract": "Neural-Symbolic (NeSy) Artificial Intelligence has emerged as a promising approach for combining the learning capabilities of neural networks with the interpretable reasoning of symbolic systems. However, existing NeSy frameworks typically require either predefined symbolic policies or policies that are differentiable, limiting their applicability when domain expertise is unavailable or when policies are inherently non-differentiable. We propose a framework that addresses this limitation by enabling the concurrent learning of both non-differentiable symbolic policies and neural network weights through an evolutionary process. Our approach casts NeSy systems as organisms in a population that evolve through mutations (both symbolic rule additions and neural weight changes), with fitness-based selection guiding convergence toward hidden target policies. The framework extends the NEUROLOG architecture to make symbolic policies trainable, adapts Valiant's Evolvability framework to the NeSy context, and employs Machine Coaching semantics for mutable symbolic representations. Neural networks are trained through abductive reasoning from the symbolic component, eliminating differentiability requirements. Through extensive experimentation, we demonstrate that NeSy systems starting with empty policies and random neural weights can successfully approximate hidden non-differentiable target policies, achieving median correct performance approaching 100%. This work represents a step toward enabling NeSy research in domains where the acquisition of symbolic knowledge from experts is challenging or infeasible.",
    "title_zh": "可演化策略的神经符号集成",
    "abstract_zh": "神经符号（NeSy）人工智能作为一种有前景的方法，旨在结合神经网络的学习能力与符号系统的可解释推理能力。然而，现有的NeSy框架通常需要预先定义的符号策略或可微分的策略，这在缺乏领域专家知识或策略本身不可微的情况下限制了其应用范围。为此，我们提出了一种新框架，通过进化过程实现对非可微符号策略和神经网络权重的并行学习，从而克服这一局限。我们的方法将NeSy系统视为种群中的有机体，通过突变（包括符号规则的增加和神经权重的变化）进行演化，并以适应度为基础的选择机制引导系统收敛至隐藏的目标策略。该框架扩展了NEUROLOG架构，使符号策略具备可训练性；借鉴Valiant的可演化性理论，将其适配到NeSy场景中；并采用机器辅导（Machine Coaching）语义来支持可变的符号表示。神经网络通过从符号组件出发进行溯因推理进行训练，从而无需满足可微性要求。通过大量实验，我们证明：即使从空的符号策略和随机初始化的神经网络权重开始，NeSy系统也能成功逼近隐藏的非可微目标策略，其中位正确率接近100%。本研究为在难以获取专家提供的符号知识或无法获得此类知识的领域中开展NeSy研究迈出了重要一步。"
  },
  {
    "date": "2026-01-08",
    "title": "Defense Against Indirect Prompt Injection via Tool Result Parsing",
    "authors": "Qiang Yu, Xinran Cheng, Chuanyi Liu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04795v1",
    "source": "arXiv",
    "abstract": "As LLM agents transition from digital assistants to physical controllers in autonomous systems and robotics, they face an escalating threat from indirect prompt injection. By embedding adversarial instructions into the results of tool calls, attackers can hijack the agent's decision-making process to execute unauthorized actions. This vulnerability poses a significant risk as agents gain more direct control over physical environments. Existing defense mechanisms against Indirect Prompt Injection (IPI) generally fall into two categories. The first involves training dedicated detection models; however, this approach entails high computational overhead for both training and inference, and requires frequent updates to keep pace with evolving attack vectors. Alternatively, prompt-based methods leverage the inherent capabilities of LLMs to detect or ignore malicious instructions via prompt engineering. Despite their flexibility, most current prompt-based defenses suffer from high Attack Success Rates (ASR), demonstrating limited robustness against sophisticated injection attacks. In this paper, we propose a novel method that provides LLMs with precise data via tool result parsing while effectively filtering out injected malicious code. Our approach achieves competitive Utility under Attack (UA) while maintaining the lowest Attack Success Rate (ASR) to date, significantly outperforming existing methods. Code is available at GitHub.",
    "title_zh": "通过工具结果解析防御间接提示注入",
    "abstract_zh": "随着大型语言模型（LLM）代理从数字助手逐步演变为自主系统与机器人中的物理控制核心，它们正面临日益严重的间接提示注入（Indirect Prompt Injection, IPI）威胁。攻击者通过在工具调用结果中嵌入恶意指令，可劫持代理的决策流程，执行未经授权的操作。这一漏洞风险随着代理对物理环境的直接控制能力增强而急剧上升。现有的IPI防御机制大致可分为两类：第一类是训练专用检测模型，但该方法在训练和推理阶段均带来高昂的计算开销，且需频繁更新以应对不断演变的攻击手段；第二类是基于提示的方法，利用LLM自身的能力，通过提示工程实现对恶意指令的检测或忽略。尽管这类方法具有较高的灵活性，但当前多数基于提示的防御仍存在较高的攻击成功率（ASR），对复杂注入攻击表现出较弱的鲁棒性。\n\n本文提出一种新方法，通过精确解析工具返回结果，向LLM提供结构化数据，同时有效过滤掉被注入的恶意代码。该方法在保持最低攻击成功率（ASR）的同时，实现了具有竞争力的抗攻击实用性（UA），显著优于现有技术。相关代码已开源，可在GitHub上获取。"
  },
  {
    "date": "2026-01-08",
    "title": "NC2C: Automated Convexification of Generic Non-Convex Optimization Problems",
    "authors": "Xinyue Peng, Yanming Liu, Yihan Cang, Yuwei Zhang, Xinyi Wang, Songhang Deng, Jiannan Cao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04789v1",
    "source": "arXiv",
    "abstract": "Non-convex optimization problems are pervasive across mathematical programming, engineering design, and scientific computing, often posing intractable challenges for traditional solvers due to their complex objective functions and constrained landscapes. To address the inefficiency of manual convexification and the over-reliance on expert knowledge, we propose NC2C, an LLM-based end-to-end automated framework designed to transform generic non-convex optimization problems into solvable convex forms using large language models. NC2C leverages LLMs' mathematical reasoning capabilities to autonomously detect non-convex components, select optimal convexification strategies, and generate rigorous convex equivalents. The framework integrates symbolic reasoning, adaptive transformation techniques, and iterative validation, equipped with error correction loops and feasibility domain correction mechanisms to ensure the robustness and validity of transformed problems. Experimental results on a diverse dataset of 100 generic non-convex problems demonstrate that NC2C achieves an 89.3\\% execution rate and a 76\\% success rate in producing feasible, high-quality convex transformations. This outperforms baseline methods by a significant margin, highlighting NC2C's ability to leverage LLMs for automated non-convex to convex transformation, reduce expert dependency, and enable efficient deployment of convex solvers for previously intractable optimization tasks.",
    "title_zh": "NC2C：通用非凸优化问题的自动化凸化方法",
    "abstract_zh": "非凸优化问题在数学规划、工程设计和科学计算中普遍存在，由于其复杂的目标函数和约束结构，常常给传统求解器带来难以处理的挑战。为解决人工凸化效率低下以及过度依赖专家知识的问题，我们提出了NC2C——一种基于大语言模型（LLM）的端到端自动化框架，旨在利用大语言模型将通用的非凸优化问题自动转化为可求解的凸形式。NC2C充分利用大语言模型的数学推理能力，自主识别非凸成分，选择最优的凸化策略，并生成严谨的凸等价形式。该框架融合符号推理、自适应变换技术以及迭代验证机制，配备错误纠正环路和可行域修正机制，确保转换后问题的鲁棒性与正确性。在包含100个典型非凸问题的多样化数据集上的实验结果表明，NC2C实现了89.3%的执行率和76%的成功率，能够生成可行且高质量的凸化结果。这一性能显著优于基线方法，充分展示了NC2C利用大语言模型实现非凸到凸自动转化的能力，有效降低了对专家经验的依赖，并推动了凸优化求解器在以往难以处理的优化任务中的高效部署。"
  },
  {
    "date": "2026-01-08",
    "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation",
    "authors": "Jinze Yu, Dayuan Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05162v1",
    "source": "arXiv",
    "abstract": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.",
    "title_zh": "GenAI-DrawIO-Creator：一种自动绘图生成框架",
    "abstract_zh": "图表对于传达复杂信息至关重要，但其创建与修改仍是一项耗时费力的任务。我们提出了 GenAI-DrawIO-Creator——一种创新的框架，利用大型语言模型（LLM）自动化生成和操作 draw.io 所使用的结构化 XML 格式的图表。该系统集成 Claude 3.7，以实现对结构化视觉数据的推理，并生成符合规范的图表表示。主要贡献包括：支持实时更新的高层系统架构、针对特定任务优化的提示工程以及错误检查机制，确保输出的 XML 内容格式正确。我们展示了一个可运行的原型系统，能够从自然语言或代码生成准确的图表（如网络架构图和流程图），甚至可从图像中复现已有图表。模拟评估表明，该方法显著缩短了图表创建时间，并生成具有高度结构一致性的输出。研究结果凸显了 Claude 3.7 在处理结构化视觉推理任务方面的潜力，为未来人工智能辅助绘图应用的研究奠定了基础。"
  },
  {
    "date": "2026-01-08",
    "title": "Supporting Secured Integration of Microarchitectural Defenses",
    "authors": "Kartik Ramkrishnan, Stephen McCamant, Antonia Zhai, Pen-Chung Yew",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05057v1",
    "source": "arXiv",
    "abstract": "There has been a plethora of microarchitectural-level attacks leading to many proposed countermeasures. This has created an unexpected and unaddressed security issue where naive integration of those defenses can potentially lead to security vulnerabilities. This occurs when one defense changes an aspect of a microarchitecture that is crucial for the security of another defense. We refer to this problem as a microarchitectural defense assumption violation} (MDAV). We propose a two-step methodology to screen for potential MDAVs in the early-stage of integration. The first step is to design and integrate a composed model, guided by bounded model checking of security properties. The second step is to implement the model concretely on a simulator and to evaluate with simulated attacks. As a contribution supporting the first step, we propose an event-based modeling framework, called Maestro, for testing and evaluating microarchitectural models with integrated defenses. In our evaluation, Maestro reveals MDAVs (8), supports compact expression (~15x Alloy LoC ratio), enables semantic composability and eliminates performance degradations (>100x). As a contribution supporting the second step, we use an event-based simulator (GEM5) for investigating integrated microarchitectural defenses. We show that a covert channel attack is possible on a naively integrated implementation of some state-of-the-art defenses, and a repaired implementation using our integration methodology is resilient to the attack.",
    "title_zh": "支持微架构防御的受保护集成",
    "abstract_zh": "近年来，针对微架构层面的攻击层出不穷，由此催生了大量防御方案。然而，这些防御措施的简单集成却引发了一个未被充分关注且尚未解决的安全问题：即不当整合可能反而引入新的安全漏洞。这种情况发生在某项防御机制改变了微架构中对另一项防御至关重要的特性时。我们将这一问题称为“微架构防御假设违背”（Microarchitectural Defense Assumption Violation, MDAV）。为此，我们提出了一种两步法，用于在集成早期阶段筛查潜在的MDAV问题。第一步是基于安全属性的有界模型检测，设计并集成一个组合化模型；第二步是在模拟器上具体实现该模型，并通过模拟攻击进行评估。作为支持第一步的贡献，我们提出了一个基于事件的建模框架——Maestro，用于测试和评估集成了多种防御机制的微架构模型。在我们的评估中，Maestro成功揭示了8个MDAV问题，支持紧凑的表达方式（相比Alloy代码量减少约15倍），实现了语义上的可组合性，并完全避免了性能下降（提升超过100倍）。作为支持第二步的贡献，我们采用基于事件的模拟器（GEM5）来研究集成后的微架构防御机制。实验表明，对于某些前沿防御方案的粗略集成实现，存在可行的隐蔽信道攻击；而使用我们提出的集成方法修复后的实现，则能够有效抵御此类攻击。"
  },
  {
    "date": "2026-01-08",
    "title": "The Squirrel Parser: A Linear-Time PEG Packrat Parser Capable of Left Recursion and Optimal Error Recovery",
    "authors": "Luke A. D. Hutchison",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.05012v1",
    "source": "arXiv",
    "abstract": "We present the squirrel parser, a PEG packrat parser that directly handles all forms of left recursion with optimal error recovery, while maintaining linear time complexity in the length of the input even in the presence of an arbitrary number of errors. Traditional approaches to handling left recursion in a recursive descent parser require grammar rewriting or complex algorithmic extensions. We derive a minimal algorithm from first principles: cycle detection via per-position state tracking and $O(1)$-per-LR-cycle communication from descendant to ancestor recursion frames, and fixed-point search via iterative expansion. For error recovery, we derived a set of four axioms and twelve constraints that must be imposed upon an optimal error recovery design to ensure completeness, correctness, optimality of performance, and intuitiveness of behavior. We utilized a constraint satisfaction mechanism to search the space of all possibilities, arriving at a provably optimal and robust error recovery strategy that maintains perfect performance linearity.",
    "title_zh": "松鼠解析器：一种能够处理左递归并实现最优错误恢复的线性时间PEG打包机解析器",
    "abstract_zh": "我们提出了一种名为松鼠解析器（squirrel parser）的PEG packrat解析器，该解析器能够直接处理所有形式的左递归，并具备最优的错误恢复能力，同时在输入长度上保持线性时间复杂度，即使存在任意数量的错误也是如此。传统递归下降解析器处理左递归的方法通常需要重写文法或引入复杂的算法扩展。我们从基本原理出发，推导出一种最小化的算法：通过位置级状态追踪实现循环检测，并在每个左递归循环中实现自下而上的递归帧间 $O(1)$ 的通信；同时采用迭代展开的方式进行不动点搜索。在错误恢复方面，我们推导出一组四条公理和十二条约束条件，这些条件必须被施加于一个最优错误恢复设计之上，以确保其完整性、正确性、性能最优性以及行为直观性。我们利用约束满足机制对所有可能方案进行搜索，最终获得了一个可证明最优且鲁棒的错误恢复策略，该策略能够维持完美的性能线性。"
  },
  {
    "date": "2026-01-08",
    "title": "LLM-Guided Quantified SMT Solving over Uninterpreted Functions",
    "authors": "Kunhang Lv, Yuhang Dong, Rui Han, Fuqi Jia, Feifei Ma, Jian Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04675v1",
    "source": "arXiv",
    "abstract": "Quantified formulas with Uninterpreted Functions (UFs) over non-linear real arithmetic pose fundamental challenges for Satisfiability Modulo Theories (SMT) solving. Traditional quantifier instantiation methods struggle because they lack semantic understanding of UF constraints, forcing them to search through unbounded solution spaces with limited guidance. We present AquaForte, a framework that leverages Large Language Models to provide semantic guidance for UF instantiation by generating instantiated candidates for function definitions that satisfy the constraints, thereby significantly reducing the search space and complexity for solvers. Our approach preprocesses formulas through constraint separation, uses structured prompts to extract mathematical reasoning from LLMs, and integrates the results with traditional SMT algorithms through adaptive instantiation. AquaForte maintains soundness through systematic validation: LLM-guided instantiations yielding SAT solve the original problem, while UNSAT results generate exclusion clauses for iterative refinement. Completeness is preserved by fallback to traditional solvers augmented with learned constraints. Experimental evaluation on SMT-COMP benchmarks demonstrates that AquaForte solves numerous instances where state-of-the-art solvers like Z3 and CVC5 timeout, with particular effectiveness on satisfiable formulas. Our work shows that LLMs can provide valuable mathematical intuition for symbolic reasoning, establishing a new paradigm for SMT constraint solving.",
    "title_zh": "基于大语言模型引导的未解释函数上的量化SMT求解",
    "abstract_zh": "带有未解释函数（UFs）的非线性实数算术量化公式给可满足性模理论（SMT）求解带来了根本性的挑战。传统的量化实例化方法由于缺乏对UF约束的语义理解，难以有效应对，不得不在无界解空间中进行搜索，且缺乏充分的引导。我们提出了一种名为AquaForte的框架，该框架利用大型语言模型（LLMs）为UF实例化提供语义指导，通过生成满足约束条件的函数定义实例候选，显著缩小了求解器的搜索空间与计算复杂度。我们的方法首先通过约束分离对公式进行预处理，采用结构化提示（structured prompts）从LLMs中提取数学推理能力，并将结果以自适应实例化的方式与传统SMT算法集成。AquaForte通过系统化的验证机制保证了逻辑正确性：若LLM引导的实例化得到SAT结果，则原问题可被解决；而UNSAT结果则生成排除条款，用于迭代优化。同时，通过回退至增强学习约束的传统求解器，确保了方法的完备性。在SMT-COMP基准测试上的实验表明，AquaForte能够解决大量Z3和CVC5等先进求解器因超时而无法处理的实例，尤其在可满足公式的求解上表现出显著优势。本研究证明，大型语言模型能够为符号推理提供宝贵的数学直觉，开创了SMT约束求解的新范式。"
  },
  {
    "date": "2026-01-08",
    "title": "Know Thy Enemy: Securing LLMs Against Prompt Injection via Diverse Data Synthesis and Instruction-Level Chain-of-Thought Learning",
    "authors": "Zhiyuan Chang, Mingyang Li, Yuekai Huang, Ziyou Jiang, Xiaojun Jia, Qian Xiong, Junjie Wang, Zhaoyang Li, Qing Wang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04666v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM)-integrated applications have become increasingly prevalent, yet face critical security vulnerabilities from prompt injection (PI) attacks. Defending against PI attacks faces two major issues: malicious instructions can be injected through diverse vectors, and injected instructions often lack clear semantic boundaries from the surrounding context, making them difficult to identify. To address these issues, we propose InstruCoT, a model enhancement method for PI defense that synthesizes diverse training data and employs instruction-level chain-of-thought fine-tuning, enabling LLMs to effectively identify and reject malicious instructions regardless of their source or position in the context. We evaluate InstruCoT across three critical dimensions: Behavior Deviation, Privacy Leakage, and Harmful Output. Experimental results across four LLMs demonstrate that InstruCoT significantly outperforms baselines in all dimensions while maintaining utility performance without degradation",
    "title_zh": "知己知彼：通过多样化数据合成与指令级思维链学习防范大语言模型的提示注入攻击",
    "abstract_zh": "集成大型语言模型（LLM）的应用日益普及，但面临着提示注入（Prompt Injection, PI）攻击带来的严重安全漏洞。防御PI攻击面临两大挑战：恶意指令可通过多种途径注入，且被注入的指令往往与上下文缺乏清晰的语义边界，难以识别。为应对这些问题，我们提出InstruCoT——一种面向PI防御的模型增强方法。该方法通过合成多样化的训练数据，并采用指令级别的思维链（Chain-of-Thought）微调策略，使LLM能够有效识别并拒绝来自任意来源或上下文中任意位置的恶意指令。我们在三个关键维度上评估了InstruCoT的表现：行为偏离、隐私泄露和有害输出。在四种不同LLM上的实验结果表明，InstruCoT在所有维度上均显著优于基线方法，同时保持了良好的任务性能，未出现性能退化。"
  },
  {
    "date": "2026-01-08",
    "title": "BackdoorAgent: A Unified Framework for Backdoor Attacks on LLM-based Agents",
    "authors": "Yunhao Feng, Yige Li, Yutao Wu, Yingshui Tan, Yanming Guo, Yifan Ding, Kun Zhai, Xingjun Ma, Yugang Jiang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04566v1",
    "source": "arXiv",
    "abstract": "Large language model (LLM) agents execute tasks through multi-step workflows that combine planning, memory, and tool use. While this design enables autonomy, it also expands the attack surface for backdoor threats. Backdoor triggers injected into specific stages of an agent workflow can persist through multiple intermediate states and adversely influence downstream outputs. However, existing studies remain fragmented and typically analyze individual attack vectors in isolation, leaving the cross-stage interaction and propagation of backdoor triggers poorly understood from an agent-centric perspective. To fill this gap, we propose \\textbf{BackdoorAgent}, a modular and stage-aware framework that provides a unified, agent-centric view of backdoor threats in LLM agents. BackdoorAgent structures the attack surface into three functional stages of agentic workflows, including \\textbf{planning attacks}, \\textbf{memory attacks}, and \\textbf{tool-use attacks}, and instruments agent execution to enable systematic analysis of trigger activation and propagation across different stages. Building on this framework, we construct a standardized benchmark spanning four representative agent applications: \\textbf{Agent QA}, \\textbf{Agent Code}, \\textbf{Agent Web}, and \\textbf{Agent Drive}, covering both language-only and multimodal settings. Our empirical analysis shows that \\textit{triggers implanted at a single stage can persist across multiple steps and propagate through intermediate states.} For instance, when using a GPT-based backbone, we observe trigger persistence in 43.58\\% of planning attacks, 77.97\\% of memory attacks, and 60.28\\% of tool-stage attacks, highlighting the vulnerabilities of the agentic workflow itself to backdoor threats. To facilitate reproducibility and future research, our code and benchmark are publicly available at GitHub.",
    "title_zh": "BackdoorAgent：一种面向基于大语言模型的智能体的后门攻击统一框架",
    "abstract_zh": "大型语言模型（LLM）代理通过多步骤工作流执行任务，这些工作流结合了规划、记忆和工具使用。尽管这种设计赋予了代理自主性，但也扩大了后门攻击的潜在威胁面。嵌入到代理工作流特定阶段的后门触发器能够穿越多个中间状态，并对下游输出产生不利影响。然而，现有研究仍较为零散，通常孤立地分析单一攻击向量，从代理视角出发，对后门触发器在不同阶段间的交互与传播机制理解不足。为填补这一空白，我们提出 \\textbf{BackdoorAgent}——一个模块化且阶段感知的框架，为 LLM 代理中的后门威胁提供统一的、以代理为中心的视角。BackdoorAgent 将攻击面划分为代理工作流的三个功能阶段：\\textbf{规划攻击}、\\textbf{记忆攻击} 和 \\textbf{工具使用攻击}，并通过对代理执行过程的精细化 instrumentation，实现对触发器激活与跨阶段传播的系统性分析。基于该框架，我们构建了一个标准化基准，涵盖四种具有代表性的代理应用：\\textbf{Agent QA}、\\textbf{Agent Code}、\\textbf{Agent Web} 和 \\textbf{Agent Drive}，覆盖纯文本与多模态场景。我们的实证分析表明：\\textit{单个阶段植入的触发器能够在多个步骤中持续存在，并通过中间状态进行传播。} 例如，在基于 GPT 的主干模型上，我们观察到规划攻击中触发器的持久性达 43.58\\%，记忆攻击中为 77.97\\%，工具阶段攻击中为 60.28\\%，凸显了代理工作流本身在面对后门威胁时的脆弱性。为促进可复现性和未来研究，我们的代码与基准数据已公开发布于 GitHub。"
  },
  {
    "date": "2026-01-08",
    "title": "Not All Steps are Informative: On the Linearity of LLMs' RLVR Training",
    "authors": "Tianle Wang, Zhongyuan Wu, Shenghao Jin, Hao Xu, Wei Chen, Ning Miao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04537v1",
    "source": "arXiv",
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has become a central component of large language model (LLM) post-training. Unlike supervised fine-tuning (SFT), RLVR lets an LLM generate multiple candidate solutions and reinforces those that lead to a verifiably correct final answer. However, in practice, RLVR often requires thousands of training steps to reach strong performance, incurring substantial computation largely attributed to prolonged exploration. In this work, we make a surprising observation: during RLVR, LLMs evolve in a strongly linear manner. Specifically, both model weights and model output log-probabilities exhibit strong linear correlations with RL training steps. This suggests that RLVR predominantly amplifies trends that emerge early in training, rather than continuously discovering new behaviors throughout the entire optimization trajectory. Motivated by this linearity, we investigate whether future model states can be predicted from intermediate checkpoints via extrapolation, avoiding continued expensive training. We show that Weight Extrapolation produces models with performance comparable to standard RL training while requiring significantly less computation. Moreover, Logits Extrapolation consistently outperforms continued RL training on all four benchmarks by extrapolating beyond the step range where RL training remains stable.",
    "title_zh": "并非所有步骤都具有信息量：关于大语言模型RLVR训练的线性问题",
    "abstract_zh": "基于可验证奖励的强化学习（RLVR）已成为大语言模型（LLM）后训练中的核心组成部分。与监督微调（SFT）不同，RLVR允许大语言模型生成多个候选解，并强化那些最终能得出可验证正确答案的解。然而在实际应用中，RLVR通常需要数千次训练步骤才能达到优异性能，这带来了巨大的计算开销，主要源于长期探索过程。在本研究中，我们发现一个令人意外的现象：在RLVR过程中，大语言模型呈现出强烈的线性演化特征。具体而言，模型权重和输出对数概率均与强化学习训练步数表现出显著的线性相关性。这一发现表明，RLVR主要是在放大训练早期就已出现的趋势，而非在整个优化轨迹中持续发现新的行为模式。受此线性特性的启发，我们探究了是否可以通过外推法从中间检查点预测未来的模型状态，从而避免持续进行昂贵的训练。我们证明，权重外推法（Weight Extrapolation）能够在显著降低计算成本的同时，获得与标准RL训练相当的性能。此外，对数概率外推法（Logits Extrapolation）在所有四个基准测试中均持续优于继续进行RL训练的表现，其外推范围甚至超过了RL训练保持稳定的有效步数区间。"
  },
  {
    "date": "2026-01-08",
    "title": "Beyond Monolithic Architectures: A Multi-Agent Search and Knowledge Optimization Framework for Agentic Search",
    "authors": "Yiqun Chen, Lingyong Yan, Zixuan Yang, Erhan Zhang, Jiashu Zhao, Shuaiqiang Wang, Dawei Yin, Jiaxin Mao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04703v1",
    "source": "arXiv",
    "abstract": "Agentic search has emerged as a promising paradigm for complex information seeking by enabling Large Language Models (LLMs) to interleave reasoning with tool use. However, prevailing systems rely on monolithic agents that suffer from structural bottlenecks, including unconstrained reasoning outputs that inflate trajectories, sparse outcome-level rewards that complicate credit assignment, and stochastic search noise that destabilizes learning. To address these challenges, we propose \\textbf{M-ASK} (Multi-Agent Search and Knowledge), a framework that explicitly decouples agentic search into two complementary roles: Search Behavior Agents, which plan and execute search actions, and Knowledge Management Agents, which aggregate, filter, and maintain a compact internal context. This decomposition allows each agent to focus on a well-defined subtask and reduces interference between search and context construction. Furthermore, to enable stable coordination, M-ASK employs turn-level rewards to provide granular supervision for both search decisions and knowledge updates. Experiments on multi-hop QA benchmarks demonstrate that M-ASK outperforms strong baselines, achieving not only superior answer accuracy but also significantly more stable training dynamics.\\footnote{The source code for M-ASK is available at https://github.com/chenyiqun/M-ASK.}",
    "title_zh": "超越单体架构：一种用于智能搜索的多智能体搜索与知识优化框架",
    "abstract_zh": "代理搜索（Agentic search）作为一种新兴范式，通过使大型语言模型（LLMs）能够将推理与工具使用交织进行，为复杂信息检索任务提供了有力支持。然而，当前主流系统依赖于单一结构的代理，存在诸多结构性瓶颈：不受约束的推理输出导致搜索轨迹过长，结果层面的奖励稀疏使得信用分配困难，以及随机搜索噪声引发学习过程不稳定。为解决这些问题，我们提出了**M-ASK**（Multi-Agent Search and Knowledge）框架，该框架显式地将代理搜索分解为两个互补角色：**搜索行为代理**（Search Behavior Agents），负责规划和执行搜索动作；以及**知识管理代理**（Knowledge Management Agents），负责聚合、过滤并维护一个紧凑的内部上下文。这种分解使每个代理能够专注于明确的子任务，有效减少了搜索与上下文构建之间的相互干扰。此外，为了实现稳定的协同机制，M-ASK引入了逐轮奖励（turn-level rewards），对搜索决策和知识更新提供细粒度的监督信号。在多跳问答基准测试上的实验表明，M-ASK显著优于现有强基线方法，在获得更高答案准确率的同时，也展现出更稳定的学习动态。  \n\\footnote{M-ASK 的源代码可在 https://github.com/chenyiqun/M-ASK 获取。}"
  },
  {
    "date": "2026-01-08",
    "title": "PRISM: A Unified Framework for Post-Training LLMs Without Verifiable Rewards",
    "authors": "Mukesh Ghimire, Aosong Feng, Liwen You, Youzhi Luo, Fang Liu, Xuan Zhu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2601.04700v1",
    "source": "arXiv",
    "abstract": "Current techniques for post-training Large Language Models (LLMs) rely either on costly human supervision or on external verifiers to boost performance on tasks such as mathematical reasoning and code generation. However, as LLMs improve their problem-solving, any further improvement will potentially require high-quality solutions to difficult problems that are not available to humans. As a result, learning from unlabeled data is becoming increasingly attractive in the research community. Existing methods extract learning signal from a model's consistency, either by majority voting or by converting the model's internal confidence into reward. Although internal consistency metric such as entropy or self-certainty require no human intervention, as we show in this work, these are unreliable signals for large-scale and long-term training. To address the unreliability, we propose PRISM, a unified training framework that uses a Process Reward Model (PRM) to guide learning alongside model's internal confidence in the absence of ground-truth labels. We show that effectively combining PRM with self-certainty can lead to both stable training and better test-time performance, and also keep the model's internal confidence in check.",
    "title_zh": "PRISM：一种无需可验证奖励的后训练大语言模型统一框架",
    "abstract_zh": "当前用于大语言模型（LLM）后训练的技术，要么依赖昂贵的人工监督，要么借助外部验证器来提升在数学推理和代码生成等任务上的表现。然而，随着LLM解决问题能力的不断提升，未来进一步的性能改进可能需要高质量的复杂问题解决方案，而这些方案对人类而言并不可得。因此，从无标签数据中学习正日益受到研究界的青睐。现有方法通过模型的一致性提取学习信号，例如采用多数投票或将模型内部置信度转化为奖励。尽管像熵或自认证这类内部一致性指标无需人工干预，但正如本文所展示的，它们在大规模、长期训练中是不可靠的信号。为解决这一可靠性问题，我们提出了PRISM——一种统一的训练框架，该框架在缺乏真实标签的情况下，利用过程奖励模型（PRM）与模型自身的内部置信度共同指导学习。我们证明，有效结合PRM与自认证机制，不仅能实现稳定的训练过程，还能带来更优的测试阶段表现，同时保持模型内部置信度的合理性和可控性。"
  },
  {
    "date": "2026-1-8",
    "title": "Proceedings of the 2026 ACM SIGPLAN International Workshop on Partial Evaluation and Program Manipulation",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1145/3779209",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "2026年ACM SIGPLAN国际部分求值与程序操作研讨会论文集",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-8",
    "title": "DafnyMPI: A Dafny Library for Verifying Message-Passing Concurrent Programs",
    "authors": "Aleksandr Fedchin, Antero Mejr, Hari Sundar, Jeffrey S. Foster",
    "publish": "Proceedings of the ACM on Programming Languages",
    "url": "https://doi.org/10.1145/3776705",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "DafnyMPI：一个用于验证消息传递并发程序的Dafny库",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-8",
    "title": "Accelerating Syntax-Guided Program Synthesis by Optimizing Domain-Specific Languages",
    "authors": "Zhentao Ye, Ruyi Ji, Yingfei Xiong, Xin Zhang",
    "publish": "Proceedings of the ACM on Programming Languages",
    "url": "https://doi.org/10.1145/3776679",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "通过优化领域特定语言加速语法引导的程序合成",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-8",
    "title": "ChopChop: A Programmable Framework for Semantically Constraining the Output of Language Models",
    "authors": "Shaan Nagy, Timothy Zhou, Nadia Polikarpova, Loris D'Antoni",
    "publish": "Proceedings of the ACM on Programming Languages",
    "url": "https://doi.org/10.1145/3776708",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "ChopChop：一种用于语义约束语言模型输出的可编程框架",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-8",
    "title": "ChiSA: Static Analysis for Lightweight Chisel Verification",
    "authors": "Jiacai Cui, Qinlin Chen, Zhongsheng Zhan, Tian Tan, Yue Li",
    "publish": "Proceedings of the ACM on Programming Languages",
    "url": "https://doi.org/10.1145/3776660",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "ChiSA：面向轻量级Chisel验证的静态分析工具",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-8",
    "title": "Miri: Practical Undefined Behavior Detection for Rust",
    "authors": "Ralf Jung, Benjamin Kimock, Christian Poveda, Eduardo Sánchez Muñoz, Oli Scherer, Qian Wang",
    "publish": "Proceedings of the ACM on Programming Languages",
    "url": "https://doi.org/10.1145/3776690",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "Miri：Rust 的实用未定义行为检测工具",
    "abstract_zh": "None"
  },
  {
    "date": "2026-1-8",
    "title": "Proceedings of the 15th ACM SIGPLAN International Conference on Certified Programs and Proofs",
    "authors": "N/A",
    "publish": "N/A",
    "url": "https://doi.org/10.1145/3779031",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "第15届ACM SIGPLAN国际认证程序与证明会议论文集",
    "abstract_zh": "None"
  }
]