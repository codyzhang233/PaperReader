[
  {
    "date": "2025-12-23",
    "title": "Memory as Resonance: A Biomimetic Architecture for Infinite Context Memory on Ergodic Phonetic Manifolds",
    "authors": "Tarik Houichime, Abdelghani Souhar, Younes El Amrani",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20245v1",
    "source": "arXiv",
    "abstract": "The memory of contemporary Large Language Models is bound by a physical paradox: as they learn, they fill up. The linear accumulation (O(N)) of Key-Value states treats context as a warehouse of static artifacts, eventually forcing a destructive choice between amnesia and latency. We challenge this discrete orthodoxy, proposing that long-term memory is not the storage of items, but the persistence of a trajectory. We introduce Phonetic Trajectory Memory (PTM), a neuro-symbolic architecture that encodes language not as a sequence of tensors, but as a continuous path on an ergodic manifold governed by irrational rotation matrices. By decoupling the navigation (an invariant O(1) geometric signal) from the reconstruction (a probabilistic generative act), PTM achieves a compression magnitude of greater than 3,000x relative to dense caches. We demonstrate that retrieval becomes a process of resonance: the phonetic trace stabilizes the model against hallucination via \"Signal Consensus\" mechanism, securing up to approximately 92% factual accuracy. While this aggressive abstraction alters generative texture, it unlocks immediate access latency (approximately 34ms) independent of depth. Our results suggest that infinite context does not require infinite silicon; it requires treating memory not as data to be stored, but as a reconstructive process acting on a conserved, undying physical signal.",
    "title_zh": "记忆即共鸣：基于遍历语音流形的无限上下文记忆仿生架构",
    "abstract_zh": "当代大型语言模型的记忆受限于一个物理悖论：随着学习的进行，它们不断“填满”。线性累积（O(N)）的键值状态将上下文视为静态信息的仓库，最终迫使模型在遗忘与延迟之间做出毁灭性的选择。我们挑战这一离散的正统观念，提出长期记忆并非对信息的存储，而是对轨迹的持续存在。为此，我们引入了**语音轨迹记忆**（Phonetic Trajectory Memory, PTM），一种神经符号架构，它不将语言编码为张量序列，而是将其视为由无理旋转矩阵所支配的遍历流形上的连续路径。通过将导航（一种不变的 O(1) 几何信号）与重建（一种概率生成行为）解耦，PTM 相较于密集缓存实现了超过 3000 倍的压缩率。我们证明，检索过程演变为一种共振机制：语音痕迹通过“信号共识”机制稳定模型，有效抑制幻觉，使事实准确性高达约 92%。尽管这种激进的抽象改变了生成的语感质地，但它实现了与深度无关的即时访问延迟（约 34ms）。我们的研究结果表明，无限上下文并不需要无限硅基资源；它需要的不是将记忆视为待存储的数据，而是将其理解为作用于一个守恒、永生物理信号之上的重构过程。"
  },
  {
    "date": "2025-12-23",
    "title": "Reaching Agreement Among Reasoning LLM Agents",
    "authors": "Chaoyi Ruan, Yiliang Wang, Ziji Shi, Jialin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20184v1",
    "source": "arXiv",
    "abstract": "Multi-agent systems have extended the capability of agentic AI. Instead of single inference passes, multiple agents perform collective reasoning to derive high quality answers. However, existing multi-agent orchestration relies on static heuristic workflows such as fixed loop limits and barrier synchronization. These ad-hoc approaches waste computational resources, incur high latency due to stragglers, and risk finalizing transient agreements. We argue that reliable multi-agent reasoning requires a formal foundation analogous to classical distributed consensus problem. To that end, we propose a formal model of the multi-agent refinement problem. The model includes definitions of the correctness guarantees and formal semantics of agent reasoning. We then introduce Aegean, a consensus protocol designed for stochastic reasoning agents that solves multi-agent refinement. We implement the protocol in Aegean-Serve, a consensus-aware serving engine that performs incremental quorum detection across concurrent agent executions, enabling early termination when sufficient agents converge. Evaluation using four mathematical reasoning benchmarks shows that Aegean provides provable safety and liveness guarantees while reducing latency by 1.2--20$\\times$ compared to state-of-the-art baselines, maintaining answer quality within 2.5%. Consistent gains across both local GPU deployments and commercial API providers validate that consensus-based orchestration eliminates straggler delays without sacrificing correctness.",
    "title_zh": "推理型大语言模型代理之间的共识达成",
    "abstract_zh": "多智能体系统扩展了代理型人工智能的能力。与单一推理过程不同，多个智能体通过集体推理来生成高质量的答案。然而，现有的多智能体编排依赖于静态启发式工作流，例如固定的循环限制和屏障同步机制。这些临时性的方法会浪费计算资源，由于“拖后腿”（stragglers）导致高延迟，并可能在瞬时共识上做出错误的最终决定。我们认为，可靠的多智能体推理需要类似于经典分布式共识问题的正式基础。为此，我们提出了一个多智能体精炼问题的形式化模型，该模型包含正确性保障的定义以及智能体推理的形式语义。随后，我们引入了Aegean——一种专为随机推理智能体设计的共识协议，能够解决多智能体精炼问题。我们在Aegean-Serve中实现了该协议，这是一个具备共识感知能力的服务引擎，能够在并发的智能体执行过程中进行增量式多数派检测，当足够多智能体达成一致时即可提前终止。在四个数学推理基准上的评估表明，Aegean在提供可证明的安全性和活性保证的同时，相比当前最先进的基线方法将延迟降低了1.2至20倍，且答案质量仅下降2.5%以内。无论是在本地GPU部署还是商业API服务提供商上，均表现出一致的性能提升，验证了基于共识的编排方式能够有效消除“拖后腿”延迟，同时不牺牲正确性。"
  },
  {
    "date": "2025-12-23",
    "title": "AXIOM: Benchmarking LLM-as-a-Judge for Code via Rule-Based Perturbation and Multisource Quality Calibration",
    "authors": "Ruiqi Wang, Xinchen Wang, Cuiyun Gao, Chun Yong Chong, Xin Xia, Qing Liao",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20159v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) have been increasingly deployed in real-world software engineering, fostering the development of code evaluation metrics to study the quality of LLM-generated code. Conventional rule-based metrics merely score programs based on their surface-level similarities with reference programs instead of analyzing functionality and code quality in depth. To address this limitation, researchers have developed LLM-as-a-judge metrics, prompting LLMs to evaluate and score code, and curated various code evaluation benchmarks to validate their effectiveness. However, these benchmarks suffer from critical limitations, hindering reliable assessments of evaluation capability: Some feature coarse-grained binary labels, which reduce rich code behavior to a single bit of information, obscuring subtle errors. Others propose fine-grained but subjective, vaguely-defined evaluation criteria, introducing unreliability in manually-annotated scores, which is the ground-truth they rely on. Furthermore, they often use uncontrolled data synthesis methods, leading to unbalanced score distributions that poorly represent real-world code generation scenarios. To curate a diverse benchmark with programs of well-balanced distributions across various quality levels and streamline the manual annotation procedure, we propose AXIOM, a novel perturbation-based framework for synthesizing code evaluation benchmarks at scale. It reframes program scores as the refinement effort needed for deployment, consisting of two stages: (1) Rule-guided perturbation, which prompts LLMs to apply sequences of predefined perturbation rules to existing high-quality programs to modify their functionality and code quality, enabling us to precisely control each program's target score to achieve balanced score distributions. (2) Multisource quality calibration, which first selects a subset of...",
    "title_zh": "AXIOM：通过基于规则的扰动与多源质量校准对代码进行大语言模型作为裁判的基准测试",
    "abstract_zh": "大型语言模型（LLMs）在现实世界软件工程中的应用日益广泛，推动了代码评估指标的发展，以研究 LLM 生成代码的质量。传统的基于规则的评估指标仅根据程序与参考程序在表面特征上的相似性进行打分，而未能深入分析其功能正确性与代码质量。为解决这一局限性，研究人员提出了“以 LLM 作为评判者”的评估方法，通过提示 LLM 对代码进行评价和打分，并构建了多种代码评估基准数据集以验证其有效性。然而，这些基准数据集存在关键缺陷，阻碍了对评估能力的可靠评估：部分基准采用粗粒度的二值标签，将丰富的代码行为简化为单一比特信息，掩盖了细微的错误；另一些则提出细粒度但主观且定义模糊的评估标准，导致人工标注分数不可靠，而这些分数正是其依赖的“真实标签”。此外，它们通常使用不受控的数据生成方法，造成评分分布失衡，无法真实反映实际代码生成场景。\n\n为了构建一个涵盖多样程序、在不同质量等级上具有均衡分布的基准数据集，并简化人工标注流程，我们提出了 AXIOM——一种基于扰动的新型框架，可大规模合成代码评估基准。该框架将程序评分重新定义为代码达到可部署状态所需的改进工作量，包含两个阶段：(1) 规则引导的扰动，通过提示 LLM 对高质量现有程序应用一系列预定义的扰动规则，以改变其功能和代码质量，从而精确控制每个程序的目标评分，实现评分分布的均衡；(2) 多源质量校准，首先从……"
  },
  {
    "date": "2025-12-23",
    "title": "The Limitations and Power of NP-Oracle-Based Functional Synthesis Techniques",
    "authors": "Brendan Juba, Kuldeep S. Meel",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20572v1",
    "source": "arXiv",
    "abstract": "Given a Boolean relational specification between inputs and outputs, the problem of functional synthesis is to construct a function that maps each assignment of the input to an assignment of the output such that each tuple of input and output assignments meets the specification. The past decade has witnessed significant improvement in the scalability of functional synthesis tools, allowing them to handle problems with tens of thousands of variables. A common ingredient in these approaches is their reliance on SAT solvers, thereby exploiting the breakthrough advances in SAT solving over the past three decades. While the recent techniques have been shown to perform well in practice, there is little theoretical understanding of the limitations and power of these approaches. The primary contribution of this work is to initiate a systematic theoretical investigation into the power of functional synthesis approaches that rely on NP oracles. We first show that even when small Skolem functions exist, naive bit-by-bit learning approaches fail due to the relational nature of specifications. We establish fundamental limitations of interpolation-based approaches, proving that even when small Skolem functions exist, resolution-based interpolation must produce exponential-size circuits. We prove that access to an NP oracle is inherently necessary for efficient synthesis. Our main technical result shows that it is possible to use NP oracles to synthesize small Skolem functions in time polynomial in the size of the specification and the size of the smallest sufficient set of witnesses, establishing positive results for a broad class of relational specifications.",
    "title_zh": "基于NP-Oracle的函数综合技术的局限性与能力",
    "abstract_zh": "给定输入与输出之间的布尔关系规范，函数综合问题的目标是构造一个函数，将每个输入赋值映射到一个输出赋值，使得每一对输入和输出赋值都满足该规范。过去十年中，函数综合工具的可扩展性取得了显著提升，使其能够处理包含数万个变量的问题。这些方法的一个共同特点在于它们依赖于SAT求解器，从而利用了过去三十年中SAT求解技术的重大突破。尽管最近的技术在实践中表现良好，但人们对这些方法的局限性和能力缺乏充分的理论理解。本文的主要贡献在于系统地开展对依赖NP预言机的函数综合方法之能力的理论研究。我们首先证明，即使存在较小的Skolem函数，朴素的逐位学习方法也会因规范的关联性质而失败。我们揭示了基于插值的方法的根本局限性，证明即使存在小规模的Skolem函数，基于归结的插值也必须生成指数规模的电路。我们进一步证明，高效综合本质上需要访问NP预言机。本文的核心技术成果表明，通过使用NP预言机，可以在多项式时间内合成出小规模的Skolem函数，其时间复杂度仅与规范大小以及最小充分见证集的大小相关，从而为一大类关系型规范建立了积极的理论结果。"
  },
  {
    "date": "2025-12-23",
    "title": "Laser: Governing Long-Horizon Agentic Search via Structured Protocol and Context Register",
    "authors": "Shuting Wang, Qiaolin Xia, Hao Wang, Yu Lu, Bobsimons, Zhicheng Dou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20458v1",
    "source": "arXiv",
    "abstract": "Recent advances in Large Language Models (LLMs) and Large Reasoning Models (LRMs) have enabled agentic search systems that interleave multi-step reasoning with external tool use. However, existing frameworks largely rely on unstructured natural-language reasoning and accumulate raw intermediate traces in the context, which often leads to unstable reasoning trajectories, context overflow, and degraded performance on complex multi-hop queries. In this study, we introduce Laser, a general framework for stabilizing and scaling agentic search. Laser defines a symbolic action protocol that organizes agent behaviors into three spaces: planning, task-solving, and retrospection. Each action is specified with explicit semantics and a deterministic execution format, enabling structured and logical reasoning processes and reliable action parsing. This design makes intermediate decisions interpretable and traceable, enhancing explicit retrospection and fine-grained control over reasoning trajectories. In coordination with parsable actions, Laser further maintains a compact context register that stores only essential states of the reasoning process, allowing the agent to reason over long horizons without uncontrolled context expansion. Experiments on Qwen2.5/3-series models across challenging multi-hop QA datasets show that Laser consistently outperforms existing agentic search baselines under both prompting-only and fine-tuning settings, demonstrating that Laser provides a principled and effective foundation for robust, scalable agentic search.",
    "title_zh": "激光：通过结构化协议与上下文寄存器实现长时程智能体搜索的治理",
    "abstract_zh": "近年来，大型语言模型（LLMs）和大型推理模型（LRMs）的进展使得能够实现将多步推理与外部工具使用相结合的智能体搜索系统。然而，现有框架大多依赖于非结构化的自然语言推理，并在上下文中累积原始的中间过程记录，这常常导致推理轨迹不稳定、上下文溢出，以及在复杂多跳查询任务上性能下降。在本研究中，我们提出了Laser——一种通用的框架，用于稳定并扩展智能体搜索能力。Laser定义了一种符号化动作协议，将智能体行为组织为三个核心空间：规划、任务求解和回顾反思。每个动作均具有明确的语义和确定性的执行格式，从而支持结构化且逻辑严谨的推理过程，并确保动作解析的可靠性。这一设计使中间决策具备可解释性和可追溯性，增强了显式的反思能力，并实现了对推理轨迹的细粒度控制。结合可解析的动作机制，Laser还维护一个紧凑的上下文寄存器，仅存储推理过程中必要的状态信息，使智能体能够在不发生上下文无序膨胀的前提下进行长程推理。在Qwen2.5/3系列模型上，针对具有挑战性的多跳问答数据集进行的实验表明，无论是在仅通过提示（prompting-only）还是微调（fine-tuning）设置下，Laser均持续优于现有的智能体搜索基线方法。这充分证明了Laser为构建稳健、可扩展的智能体搜索系统提供了一个原理清晰且高效的基石。"
  },
  {
    "date": "2025-12-23",
    "title": "A Comprehensive Study of Bugs in Modern Distributed Deep Learning Systems",
    "authors": "Xiaoxue Ma, Wanwei Zhan, Jiale Chen, Yishu Li, Jacky Keung, Federica Sarro",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20345v1",
    "source": "arXiv",
    "abstract": "In today's data-driven era, deep learning is vital for processing massive datasets, yet single-device training is constrained by computational and memory limits. Distributed deep learning overcomes these challenges by leveraging multiple GPUs or machines in parallel. While general-purpose frameworks (e.g., TensorFlow and PyTorch) provide distributed capabilities, these are often add-on features that demand significant manual effort for advanced parallelism, underscoring the need for specialized frameworks. This study conducts the first large-scale empirical analysis of practitioner challenges in dedicated distributed frameworks. We examine 849 real-world issues from DeepSpeed, Megatron-LM, and Colossal-AI and construct a taxonomy of 34 bug symptoms, 28 root causes, and 6 fix patterns. Crucially, we establish explicit mappings between symptoms, causes, and fixes across distributed training stages, enabling a systematic understanding of how issues emerge and are resolved. Our results show that 45.1\\% of bug symptoms are unique to distributed frameworks, with setup failures, memory issues, and performance anomalies being the most prevalent. Moreover, 95\\% of issues in the communication setup stage occur exclusively in distributed contexts. We also find over 60\\% of cases can be resolved through version and dependency management, and distributed feature, API, and communication tuning. Based on these findings, we provide actionable implications.",
    "title_zh": "现代分布式深度学习系统中漏洞的综合研究",
    "abstract_zh": "在当今数据驱动的时代，深度学习对于处理海量数据集至关重要，但单设备训练受限于计算能力和内存容量。分布式深度学习通过并行使用多个GPU或机器来克服这些挑战。尽管通用框架（如TensorFlow和PyTorch）提供了分布式功能，但这些功能往往是附加特性，实现高级并行化需要大量手动工作，凸显了专用框架的必要性。本研究首次对专用分布式框架中实践者面临的挑战进行了大规模实证分析。我们分析了DeepSpeed、Megatron-LM和Colossal-AI中的849个真实问题，构建了一个包含34种错误症状、28种根本原因和6种修复模式的分类体系。尤为重要的是，我们建立了不同分布式训练阶段中症状、原因与修复方法之间的明确映射关系，从而系统地揭示了问题的产生与解决机制。研究结果表明，45.1%的错误症状仅存在于分布式框架中，其中设置失败、内存问题和性能异常最为常见。此外，通信设置阶段95%的问题仅在分布式环境中出现。我们还发现，超过60%的问题可通过版本与依赖管理、分布式特性调整、API优化以及通信调优得以解决。基于这些发现，本文提出了具有实际指导意义的建议。"
  },
  {
    "date": "2025-12-23",
    "title": "AI Security Beyond Core Domains: Resume Screening as a Case Study of Adversarial Vulnerabilities in Specialized LLM Applications",
    "authors": "Honglin Mu, Jinghao Liu, Kaiyang Wan, Rui Xing, Xiuying Chen, Timothy Baldwin, Wanxiang Che",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20164v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) excel at text comprehension and generation, making them ideal for automated tasks like code review and content moderation. However, our research identifies a vulnerability: LLMs can be manipulated by \"adversarial instructions\" hidden in input data, such as resumes or code, causing them to deviate from their intended task. Notably, while defenses may exist for mature domains such as code review, they are often absent in other common applications such as resume screening and peer review. This paper introduces a benchmark to assess this vulnerability in resume screening, revealing attack success rates exceeding 80% for certain attack types. We evaluate two defense mechanisms: prompt-based defenses achieve 10.1% attack reduction with 12.5% false rejection increase, while our proposed FIDS (Foreign Instruction Detection through Separation) using LoRA adaptation achieves 15.4% attack reduction with 10.4% false rejection increase. The combined approach provides 26.3% attack reduction, demonstrating that training-time defenses outperform inference-time mitigations in both security and utility preservation.",
    "title_zh": "超越核心领域的AI安全：以简历筛选为例探讨专用大模型应用中的对抗性漏洞",
    "abstract_zh": "大型语言模型（LLMs）在文本理解与生成方面表现出色，使其成为自动化任务（如代码审查和内容审核）的理想工具。然而，我们的研究发现了一个潜在漏洞：攻击者可通过在输入数据（如简历或代码）中隐藏“对抗性指令”，操纵LLM偏离其预期任务。值得注意的是，尽管在成熟领域（如代码审查）可能存在防御措施，但在其他常见应用（如简历筛选和同行评审）中，此类防御往往缺失。本文提出一个基准测试，用于评估简历筛选场景中的这一漏洞，结果显示某些攻击类型的成功率超过80%。我们评估了两种防御机制：基于提示的防御可实现10.1%的攻击减少，但伴随12.5%的误拒率上升；而我们提出的FIDS（通过分离检测外源指令）方法结合LoRA适配，可实现15.4%的攻击减少，且误拒率仅上升10.4%。两者结合后，攻击减少率达到26.3%，表明训练阶段的防御策略在安全性和实用性保持方面均优于推理阶段的缓解措施。"
  },
  {
    "date": "2025-12-23",
    "title": "Bohrium + SciMaster: Building the Infrastructure and Ecosystem for Agentic Science at Scale",
    "authors": "Linfeng Zhang, Siheng Chen, Yuzhu Cai, Jingyi Chai, Junhan Chang, Kun Chen, Zhi X. Chen, Zhaohan Ding, Yuwen Du, Yuanpeng Gao, Yuan Gao, Jing Gao, Zhifeng Gao, Qiangqiang Gu, Yanhui Hong, Yuan Huang, Xi Fang, Xiaohong Ji, Guolin Ke, Zixing Lei, Xinyu Li, Yongge Li, Ruoxue Liao, Hang Lin, Xiaolu Lin, Yuxiang Liu, Xinzijian Liu, Zexi Liu, Jintan Lu, Tingjia Miao, Haohui Que, Weijie Sun, Yanfeng Wang, Bingyang Wu, Tianju Xue, Rui Ye, Jinzhe Zeng, Duo Zhang, Jiahui Zhang, Linfeng Zhang, Tianhan Zhang, Wenchang Zhang, Yuzhi Zhang, Zezhong Zhang, Hang Zheng, Hui Zhou, Tong Zhu, Xinyu Zhu, Qingguo Zhou, Weinan E",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20469v1",
    "source": "arXiv",
    "abstract": "AI agents are emerging as a practical way to run multi-step scientific workflows that interleave reasoning with tool use and verification, pointing to a shift from isolated AI-assisted steps toward \\emph{agentic science at scale}. This shift is increasingly feasible, as scientific tools and models can be invoked through stable interfaces and verified with recorded execution traces, and increasingly necessary, as AI accelerates scientific output and stresses the peer-review and publication pipeline, raising the bar for traceability and credible evaluation. However, scaling agentic science remains difficult: workflows are hard to observe and reproduce; many tools and laboratory systems are not agent-ready; execution is hard to trace and govern; and prototype AI Scientist systems are often bespoke, limiting reuse and systematic improvement from real workflow signals. We argue that scaling agentic science requires an infrastructure-and-ecosystem approach, instantiated in Bohrium+SciMaster. Bohrium acts as a managed, traceable hub for AI4S assets -- akin to a HuggingFace of AI for Science -- that turns diverse scientific data, software, compute, and laboratory systems into agent-ready capabilities. SciMaster orchestrates these capabilities into long-horizon scientific workflows, on which scientific agents can be composed and executed. Between infrastructure and orchestration, a \\emph{scientific intelligence substrate} organizes reusable models, knowledge, and components into executable building blocks for workflow reasoning and action, enabling composition, auditability, and improvement through use. We demonstrate this stack with eleven representative master agents in real workflows, achieving orders-of-magnitude reductions in end-to-end scientific cycle time and generating execution-grounded signals from real workloads at multi-million scale.",
    "title_zh": "博尔海姆 + 科学大师：构建规模化智能科学的基础设施与生态系统",
    "abstract_zh": "人工智能代理正成为一种切实可行的方式，用于执行多步骤的科学工作流，这些工作流将推理、工具使用与验证相结合，预示着从孤立的AI辅助步骤向**大规模智能体科学**（agentic science at scale）的转变。这一转变日益成为可能：科学工具和模型可通过稳定接口调用，并借助记录的执行轨迹进行验证；同时，它也变得愈发必要——因为AI正在加速科学产出，给同行评审和出版流程带来压力，对可追溯性和可信评估的要求不断提高。然而，要实现智能体科学的大规模扩展仍面临诸多挑战：工作流难以观察与复现；许多工具和实验室系统尚未具备代理就绪能力；执行过程难以追踪与管控；而现有的AI科学家原型系统往往为定制化设计，限制了复用性，也阻碍了基于真实工作流数据的系统性改进。\n\n我们认为，要实现智能体科学的规模化，必须采用基础设施与生态系统相结合的方法，这在Bohrium+SciMaster中得以具体体现。Bohrium作为AI for Science（AI4S）资产的受管理、可追溯枢纽，类似于“科学领域的HuggingFace”，将多样化的科学数据、软件、计算资源以及实验室系统转化为可供代理使用的功能能力。SciMaster则负责将这些能力编排为长期视角的科学工作流，使科学智能体得以构建并执行。在基础设施与编排之间，一个**科学智能底座**（scientific intelligence substrate）将可复用的模型、知识和组件组织成可执行的构建模块，支持工作流中的推理与行动，从而实现组合性、可审计性以及通过实际使用不断优化的能力。\n\n我们通过在真实工作流中部署十一个代表性主代理（master agents），展示了该技术栈的强大效能：实现了端到端科学周期时间的量级级缩短，并从数百万级别的真实负载中生成了以执行为基础的反馈信号，为未来系统的迭代与优化提供了坚实依据。"
  },
  {
    "date": "2025-12-23",
    "title": "Energy-Efficient Multi-LLM Reasoning for Binary-Free Zero-Day Detection in IoT Firmware",
    "authors": "Saeid Jamshidi, Omar Abdul-Wahab, Martine Bellaïche, Foutse Khomh",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.19945v1",
    "source": "arXiv",
    "abstract": "Securing Internet of Things (IoT) firmware remains difficult due to proprietary binaries, stripped symbols, heterogeneous architectures, and limited access to executable code. Existing analysis methods, such as static analysis, symbolic execution, and fuzzing, depend on binary visibility and functional emulation, making them unreliable when firmware is encrypted or inaccessible. To address this limitation, we propose a binary-free, architecture-agnostic solution that estimates the likelihood of conceptual zero-day vulnerabilities using only high-level descriptors. The approach integrates a tri-LLM reasoning architecture combining a LLaMA-based configuration interpreter, a DeepSeek-based structural abstraction analyzer, and a GPT-4o semantic fusion model. The solution also incorporates LLM computational signatures, including latency patterns, uncertainty markers, and reasoning depth indicators, as well as an energy-aware symbolic load model, to enhance interpretability and operational feasibility. In addition, we formally derive the mathematical foundations of the reasoning pipeline, establishing monotonicity, divergence, and energy-risk coupling properties that theoretically justify the model's behavior. Simulation-based evaluation reveals that high exposure conditions increase the predicted zero-day likelihood by 20 to 35 percent across models, with GPT-4o demonstrating the strongest cross-layer correlations and the highest sensitivity. Energy and divergence metrics significantly predict elevated risk (p < 0.01), reinforcing the effectiveness of the proposed reasoning framework.",
    "title_zh": "面向物联网固件的无二进制零日检测中的节能型多大语言模型推理",
    "abstract_zh": "由于专有二进制文件、符号被剥离、架构异构以及可执行代码访问受限，物联网（IoT）固件的安全性始终难以保障。现有的分析方法，如静态分析、符号执行和模糊测试，依赖于二进制的可见性和功能模拟，在固件加密或无法访问的情况下往往不可靠。为克服这一局限，我们提出了一种无需二进制、与架构无关的解决方案，仅通过高层次描述即可估算概念性零日漏洞的可能性。该方法采用三重大语言模型（LLM）推理架构，融合基于LLaMA的配置解释器、基于DeepSeek的结构抽象分析器以及基于GPT-4o的语义融合模型。此外，方案还引入了LLM计算特征签名，包括延迟模式、不确定性标记和推理深度指标，并结合一种能量感知的符号负载模型，以提升模型的可解释性与实际运行可行性。我们还从理论上推导了推理流程的数学基础，确立了单调性、发散性以及能效-风险耦合等性质，为模型行为提供了理论支持。基于仿真的评估结果表明，在高暴露条件下，各模型预测的零日漏洞概率提升了20%至35%，其中GPT-4o展现出最强的跨层相关性与最高敏感度。能量消耗与发散性指标对高风险具有显著预测能力（p < 0.01），进一步验证了所提推理框架的有效性。"
  },
  {
    "date": "2025-12-23",
    "title": "Graph-Symbolic Policy Enforcement and Control (G-SPEC): A Neuro-Symbolic Framework for Safe Agentic AI in 5G Autonomous Networks",
    "authors": "Divya Vijay, Vignesh Ethiraj",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20275v1",
    "source": "arXiv",
    "abstract": "As networks evolve toward 5G Standalone and 6G, operators face orchestration challenges that exceed the limits of static automation and Deep Reinforcement Learning. Although Large Language Model (LLM) agents offer a path toward intent-based networking, they introduce stochastic risks, including topology hallucinations and policy non-compliance. To mitigate this, we propose Graph-Symbolic Policy Enforcement and Control (G-SPEC), a neuro-symbolic framework that constrains probabilistic planning with deterministic verification. The architecture relies on a Governance Triad - a telecom-adapted agent (TSLAM-4B), a Network Knowledge Graph (NKG), and SHACL constraints. We evaluated G-SPEC on a simulated 450-node 5G Core, achieving zero safety violations and a 94.1% remediation success rate, significantly outperforming the 82.4% baseline. Ablation analysis indicates that NKG validation drives the majority of safety gains (68%), followed by SHACL policies (24%). Scalability tests on topologies ranging from 10K to 100K nodes demonstrate that validation latency scales as $O(k^{1.2})$ where $k$ is subgraph size. With a processing overhead of 142ms, G-SPEC is viable for SMO-layer operations.",
    "title_zh": "图-符号策略执行与控制（G-SPEC）：一种用于5G自治网络中安全代理型人工智能的神经符号框架",
    "abstract_zh": "随着网络向5G独立组网（Standalone）和6G演进，运营商面临的编排挑战已超出静态自动化与深度强化学习的极限。尽管大语言模型（LLM）代理为意图驱动网络提供了可行路径，但其引入了随机性风险，包括拓扑幻觉和策略不合规等问题。为缓解这一问题，我们提出了一种神经符号框架——图-符号策略执行与控制（Graph-Symbolic Policy Enforcement and Control, G-SPEC），该框架通过确定性验证约束概率规划过程。G-SPEC架构基于“治理三元组”：适配电信场景的代理（TSLAM-4B）、网络知识图谱（NKG）以及SHACL约束。我们在一个模拟的450节点5G核心网环境中对G-SPEC进行了评估，实现了零安全违规，并达到94.1%的修复成功率，显著优于82.4%的基线表现。消融分析表明，NKG验证贡献了大部分安全性提升（68%），其次为SHACL策略（24%）。在从1万到10万个节点的拓扑规模下进行的可扩展性测试显示，验证延迟随子图规模k呈$O(k^{1.2})$增长。在142毫秒的处理开销下，G-SPEC具备在SMO层操作中的实际可行性。"
  },
  {
    "date": "2025-12-23",
    "title": "Hierarchical Rectangle Packing Solved by Multi-Level Recursive Logic-based Benders Decomposition",
    "authors": "Josef Grus, Zdeněk Hanzálek, Christian Artigues, Cyrille Briand, Emmanuel Hebrard",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20239v1",
    "source": "arXiv",
    "abstract": "We study the two-dimensional hierarchical rectangle packing problem, motivated by applications in analog integrated circuit layout, facility layout, and logistics. Unlike classical strip or bin packing, the dimensions of the container are not fixed, and the packing is inherently hierarchical: each item is either a rectangle or a block occurrence, whose dimensions are a solution of another packing problem. This recursive structure reflects real-world scenarios in which components, boxes, or modules must be packed within higher-level containers. We formally define the problem and propose exact formulations in Mixed-Integer Linear Programming and Constraint Programming. Given the computational difficulty of solving complex packing instances directly, we propose decomposition heuristics. First, we implement an existing Bottom-Up baseline method that solves subblocks before combining them at higher levels. Building upon this, we introduce a novel multilevel Logic-based Benders Decomposition method. This heuristic method dynamically refines block dimension constraints, eliminating the need for manual selection of candidate widths or aspect ratios. Experiments on synthetic instances with up to seven hierarchy levels, 80 items per block, and limited computation time show that the proposed decomposition significantly outperforms both monolithic formulations and the Bottom-Up method in terms of solution quality and scalability.",
    "title_zh": "基于多级递归逻辑Benders分解的分层矩形打包问题求解",
    "abstract_zh": "我们研究二维分层矩形装箱问题，该问题源于模拟集成电路布局、设施布局以及物流等实际应用。与经典的条带装箱或箱子装箱问题不同，本问题中容器的尺寸并非固定，且装箱过程具有内在的层次结构：每个物品要么是一个矩形，要么是一个块实例，其尺寸由另一个装箱问题的解决定。这种递归结构反映了现实世界中组件、盒子或模块需被装入更高层级容器的情形。我们对这一问题进行了形式化定义，并提出了基于混合整数线性规划（MILP）和约束编程（CP）的精确数学模型。鉴于直接求解复杂装箱实例存在巨大计算挑战，我们提出了一系列分解启发式算法。首先，我们实现了一种现有的自底向上基准方法，该方法先求解子块，再在高层级进行组合。在此基础上，我们提出一种新颖的多层逻辑Benders分解方法。该启发式算法能够动态地细化块尺寸约束，从而无需人工预设候选宽度或长宽比。在包含最多七层嵌套结构、每块最多80个物品、且计算时间受限的合成实例上的实验表明，所提出的分解方法在解的质量和可扩展性方面均显著优于单一整体模型以及自底向上方法。"
  },
  {
    "date": "2025-12-23",
    "title": "MoE-DiffuSeq: Enhancing Long-Document Diffusion Models with Sparse Attention and Mixture of Experts",
    "authors": "Alexandros Christoforos, Chadbourne Davis",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20604v1",
    "source": "arXiv",
    "abstract": "We present MoE-DiffuSeq, a mixture of experts based framework for enhancing diffusion models in long document generation. Existing diffusion based text generation models, such as DiffuSeq, suffer from high computational cost and memory overhead when applied to extended sequences. To address these challenges, MoE-DiffuSeq integrates sparse attention with a mixture of experts architecture, enabling efficient and scalable long sequence modeling. Our approach introduces a customized sparse attention mechanism designed to reduce computational complexity while preserving text quality and coherence. In addition, we incorporate a soft absorbing state within the diffusion process to accelerate sequence reconstruction and improve generation precision. Extensive experiments demonstrate that MoE-DiffuSeq significantly improves training efficiency and sampling speed compared to existing diffusion models. These advantages are particularly effective for long document scenarios, including scientific article generation, code repository modeling, and long form dialogue generation. Benchmark results further show that MoE-DiffuSeq improves efficiency, speed, accuracy, and expressiveness, advancing the practical applicability of diffusion models for high quality long form text generation.",
    "title_zh": "MoE-DiffuSeq：通过稀疏注意力与专家混合机制增强长文档扩散模型",
    "abstract_zh": "我们提出MoE-DiffuSeq，一种基于专家混合（Mixture of Experts）框架的扩散模型增强方法，用于提升长文档生成性能。现有的基于扩散模型的文本生成方法，如DiffuSeq，在处理长序列时面临计算成本高和内存开销大的问题。为解决这些挑战，MoE-DiffuSeq将稀疏注意力机制与专家混合架构相结合，实现了高效且可扩展的长序列建模。我们的方法引入了一种定制化的稀疏注意力机制，能够在降低计算复杂度的同时保持文本的质量与连贯性。此外，我们在扩散过程中引入软吸收态（soft absorbing state），以加速序列重建过程并提高生成精度。大量实验表明，相较于现有扩散模型，MoE-DiffuSeq在训练效率和采样速度方面均有显著提升。这一优势在长文档生成场景中尤为突出，包括科学论文生成、代码库建模以及长篇对话生成等任务。基准测试结果进一步显示，MoE-DiffuSeq在效率、速度、准确性和表达能力方面均表现优异，显著提升了扩散模型在高质量长文本生成中的实际应用价值。"
  },
  {
    "date": "2025-12-23",
    "title": "Symmaries: Automatic Inference of Formal Security Summaries for Java Programs",
    "authors": "Narges Khakpour, Nicolas Berthier",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20396v1",
    "source": "arXiv",
    "abstract": "We introduce a scalable, modular, and sound approach for automatically constructing formal security specifications for Java bytecode programs in the form of method summaries. A summary provides an abstract representation of a method's security behavior, consisting of the conditions under which the method can be securely invoked, together with specifications of information flows and aliasing updates. Such summaries can be consumed by static code analysis tools and also help developers understand the behavior of code segments, such as libraries, in order to evaluate their security implications when reused in applications. Our approach is implemented in a tool called Symmaries, which automates the generation of security summaries. We applied Symmaries to Java API libraries to extract their security specifications and to large real-world applications to evaluate its scalability. Our results show that the tool successfully scales to analyze applications with hundreds of thousands of lines of code, and that Symmaries achieves a promising precision depending on the heap model used. We prove the soundness of our approach in terms of guaranteeing termination-insensitive non-interference.",
    "title_zh": "自动推断Java程序的形式化安全摘要",
    "abstract_zh": "我们提出了一种可扩展、模块化且可靠的方法，用于自动构建Java字节码程序的形式化安全规范，以方法摘要的形式呈现。摘要提供了一个方法安全行为的抽象表示，包括该方法可被安全调用的前提条件，以及信息流和别名更新的规范。此类摘要可被静态代码分析工具所使用，同时也有助于开发人员理解代码片段（如库）的行为，从而评估其在应用程序中重用时的安全影响。我们的方法已通过一个名为Symmaries的工具实现，该工具可自动化生成安全摘要。我们将Symmaries应用于Java API库，以提取其安全规范，并对大型真实世界的应用程序进行了可扩展性评估。结果表明，该工具能够成功扩展至分析包含数十万行代码的应用程序，且在不同堆模型下均表现出良好的精度。我们还从理论上证明了该方法的正确性，确保其满足终止无关非干扰性（termination-insensitive non-interference）的保证。"
  },
  {
    "date": "2025-12-23",
    "title": "Identifying Appropriately-Sized Services with Deep Reinforcement Learning",
    "authors": "Syeda Tasnim Fabiha, Saad Shafiq, Wesley Klewerton Guez Assunção, Nenad Medvidović",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20381v1",
    "source": "arXiv",
    "abstract": "Service-based architecture (SBA) has gained attention in industry and academia as a means to modernize legacy systems. It refers to a design style that enables systems to be developed as suites of small, loosely coupled, and autonomous components (services) that encapsulate functionality and communicate via language-agnostic APIs. However, defining appropriately sized services that capture cohesive subsets of system functionality remains challenging. Existing work often relies on the availability of documentation, access to project personnel, or a priori knowledge of the target number of services, assumptions that do not hold in many real-world scenarios. Our work addresses these limitations using a deep reinforcement learning-based approach to identify appropriately sized services directly from implementation artifacts. We present Rake, a reinforcement learning-based technique that leverages available system documentation and source code to guide service decomposition at the level of implementation methods. Rake does not require specific documentation or access to project personnel and is language-agnostic. It also supports a customizable objective function that balances modularization quality and business capability alignment, i.e., the degree to which a service covers the targeted business capability. We applied Rake to four open-source legacy projects and compared it with two state-of-the-art techniques. On average, Rake achieved 7-14 percent higher modularization quality and 18-22 percent stronger business capability alignment. Our results further show that optimizing solely for business context can degrade decomposition quality in tightly coupled systems, highlighting the need for balanced objectives.",
    "title_zh": "使用深度强化学习识别适当规模的服务",
    "abstract_zh": "基于服务的架构（SBA）在工业界和学术界都受到了广泛关注，被视为现代化遗留系统的一种有效手段。它是一种设计范式，使系统能够被构建为一系列小型、松耦合且自治的组件（即服务），这些服务封装了特定功能，并通过语言无关的API进行通信。然而，如何定义恰当规模的服务以准确捕捉系统功能的内聚子集，仍然是一个挑战。现有的研究方法通常依赖于文档的可用性、对项目人员的访问权限，或对目标服务数量的先验知识，而这些假设在许多真实场景中并不成立。本文提出了一种基于深度强化学习的方法，直接从实现代码中识别出合适规模的服务，以克服上述局限性。\n\n我们提出了Rake——一种基于强化学习的技术，利用现有的系统文档和源代码，指导实现层面的方法级服务分解。Rake无需特定格式的文档，也不需要与项目人员交互，具有语言无关性。此外，它支持可定制的目标函数，能够在模块化质量与业务能力对齐之间取得平衡，即衡量一个服务覆盖目标业务能力的程度。\n\n我们将Rake应用于四个开源遗留项目，并与两种最先进的技术进行了对比。实验结果表明，Rake在平均情况下实现了7%-14%更高的模块化质量，以及18%-22%更强的业务能力对齐效果。进一步分析显示，在高度耦合的系统中，仅优化业务上下文可能导致分解质量下降，这凸显了在服务划分过程中兼顾多方面目标的重要性。"
  },
  {
    "date": "2025-12-23",
    "title": "Synthesizing Procedural Memory: Challenges and Architectures in Automated Workflow Generation",
    "authors": "Nishant Gaurav, Adit Akarsh, Ankit Ranjan, Manoj Bajaj",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20278v1",
    "source": "arXiv",
    "abstract": "While CodeMem establishes executable code as the optimal representation for agentic procedural memory, the mechanism for autonomously synthesizing this memory from a blank slate remains underexplored. This paper operationalizes the transition of Large Language Models from passive tool-users to active workflow architects. Through a high-fidelity case study of a cross-service orchestration task involving Outlook and OneDrive, we identify and address four structural bottlenecks in automated skill generation: the Discovery Gap involving navigation of large tool registries, the Verification Gap regarding grounding tool response structures, the Decomposition Gap which replaces inefficient search with Linear State Anchoring, and the Scaling Gap focused on concurrency and persistence. We demonstrate that by enforcing a scientific methodology of hypothesize, probe, and code, agents can autonomously write robust, production-grade code skills.",
    "title_zh": "合成程序性记忆：自动化工作流生成中的挑战与架构",
    "abstract_zh": "尽管CodeMem将可执行代码确立为智能体过程记忆的最优表示形式，但如何从零开始自主合成这种记忆的机制仍鲜有研究。本文实现了大型语言模型从被动工具使用者向主动工作流架构师的转变。通过一个涉及Outlook与OneDrive跨服务编排任务的高保真案例研究，我们识别并解决了自动化技能生成中的四个结构性瓶颈：发现鸿沟（涉及大型工具注册表的导航）、验证鸿沟（关于工具响应结构的可靠性）、分解鸿沟（以线性状态锚定替代低效搜索）以及扩展鸿沟（聚焦于并发性与持久性）。研究表明，通过强制执行“假设—探测—编码”的科学方法，智能体能够自主编写出稳健且符合生产标准的代码技能。"
  },
  {
    "date": "2025-12-23",
    "title": "Toward Explaining Large Language Models in Software Engineering Tasks",
    "authors": "Antonio Vitale, Khai-Nguyen Nguyen, Denys Poshyvanyk, Rocco Oliveto, Simone Scalabrino, Antonio Mastropaolo",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20328v1",
    "source": "arXiv",
    "abstract": "Recent progress in Large Language Models (LLMs) has substantially advanced the automation of software engineering (SE) tasks, enabling complex activities such as code generation and code summarization. However, the black-box nature of LLMs remains a major barrier to their adoption in high-stakes and safety-critical domains, where explainability and transparency are vital for trust, accountability, and effective human supervision. Despite increasing interest in explainable AI for software engineering, existing methods lack domain-specific explanations aligned with how practitioners reason about SE artifacts. To address this gap, we introduce FeatureSHAP, the first fully automated, model-agnostic explainability framework tailored to software engineering tasks. Based on Shapley values, FeatureSHAP attributes model outputs to high-level input features through systematic input perturbation and task-specific similarity comparisons, while remaining compatible with both open-source and proprietary LLMs. We evaluate FeatureSHAP on two bi-modal SE tasks: code generation and code summarization. The results show that FeatureSHAP assigns less importance to irrelevant input features and produces explanations with higher fidelity than baseline methods. A practitioner survey involving 37 participants shows that FeatureSHAP helps practitioners better interpret model outputs and make more informed decisions. Collectively, FeatureSHAP represents a meaningful step toward practical explainable AI in software engineering. FeatureSHAP is available at https://github.com/deviserlab/FeatureSHAP.",
    "title_zh": "解释大型语言模型在软件工程任务中的应用",
    "abstract_zh": "近年来，大型语言模型（LLMs）的进展显著推动了软件工程（SE）任务的自动化，使得代码生成、代码摘要等复杂活动成为可能。然而，LLMs的“黑箱”特性仍是其在高风险和安全关键领域应用的主要障碍，因为在这些领域中，可解释性与透明性对于建立信任、确保责任追究以及实现有效的人机协作至关重要。尽管可解释人工智能（XAI）在软件工程领域日益受到关注，但现有方法仍缺乏与工程师实际推理方式相契合的领域特定解释。为填补这一空白，我们提出了FeatureSHAP——首个完全自动化、模型无关的可解释性框架，专为软件工程任务量身定制。基于Shapley值，FeatureSHAP通过系统性的输入扰动与任务特定的相似性比较，将模型输出归因于高层次输入特征，同时兼容开源与专有大型语言模型。我们在两个多模态软件工程任务——代码生成与代码摘要上对FeatureSHAP进行了评估。结果表明，相较于基线方法，FeatureSHAP能更有效地降低无关输入特征的重要性，并生成具有更高保真度的解释。一项包含37名从业者的调查研究显示，FeatureSHAP有助于工程师更好地理解模型输出，从而做出更明智的决策。总体而言，FeatureSHAP标志着向实用化可解释人工智能在软件工程中的应用迈出了重要一步。FeatureSHAP项目已开源，访问地址为：https://github.com/deviserlab/FeatureSHAP。"
  },
  {
    "date": "2025-12-23",
    "title": "Error Localization, Certificates, and Hints for Probabilistic Program Verification via Slicing (Extended Version)",
    "authors": "Philipp Schröer, Darion Haase, Joost-Pieter Katoen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20214v1",
    "source": "arXiv",
    "abstract": "This paper focuses on effective user diagnostics generated during the deductive verification of probabilistic programs. Our key principle is based on providing slices for (1) error reporting, (2) proof simplification, and (3) preserving successful verification results. By formally defining these different notions on HeyVL, an existing quantitative intermediate verification language (IVL), our concepts (and implementation) can be used to obtain diagnostics for a range of probabilistic programming languages. Slicing for error reporting is a novel notion of error localization for quantitative assertions. We demonstrate slicing-based diagnostics on a variety of proof rules such as quantitative versions of the specification statement and invariant-based loop rules, and formally prove the correctness of specialized error messages and verification hints. We implemented our user diagnostics into the deductive verifier Caesar. Our novel implementation -- called \\emph{Brutus} -- can search for slices which do or do not verify, corresponding to each of the three diagnostic notions. For error reporting (1), it exploits a binary search-based algorithm that minimizes error-witnessing slices. To solve for slices that verify (2 and 3), we empirically compare different algorithms based on unsatisfiable cores, minimal unsatisfiable subset enumeration, and a direct SMT encoding of the slicing problem. Our empirical evaluation of Brutus on existing and new benchmarks shows that we can find slices that are both small and informative.",
    "title_zh": "基于切片的 probabilistic 程序验证中的错误定位、证书与提示（扩展版）",
    "abstract_zh": "本文聚焦于在概率程序的演绎验证过程中生成的有效用户诊断。我们的核心原则是提供切片（slices），以实现（1）错误报告、（2）证明简化，以及（3）保留已成功验证的结果。通过在现有的定量中间验证语言（IVL）HeyVL上形式化定义这些不同概念，我们的方法及其实现可应用于多种概率编程语言，以获得相应的诊断信息。针对量化断言的错误定位，我们提出了一种新颖的切片化错误报告机制。我们在多种证明规则（如规范语句的量化版本和基于不变量的循环规则）上展示了基于切片的诊断方法，并形式化证明了特定错误消息与验证提示的正确性。我们将该用户诊断功能集成到了演绎验证器Caesar中。我们提出的新型实现——称为\\emph{Brutus}——能够搜索出满足或不满足验证条件的切片，分别对应上述三种诊断目标。对于错误报告（1），Brutus采用基于二分查找的算法，以最小化揭示错误的切片；而对于需验证的切片（2和3），我们通过实验比较了多种算法，包括不可满足核心（unsatisfiable cores）、极小不可满足子集枚举，以及对切片问题的直接SMT编码方法。对现有及新基准的实证评估表明，Brutus能够找到既简洁又具有信息量的切片。"
  },
  {
    "date": "2025-12-23",
    "title": "Well Begun is Half Done: Location-Aware and Trace-Guided Iterative Automated Vulnerability Repair",
    "authors": "Zhenlei Ye, Xiaobing Sun, Sicong Cao, Lili Bo, Bin Li",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20203v1",
    "source": "arXiv",
    "abstract": "The advances of large language models (LLMs) have paved the way for automated software vulnerability repair approaches, which iteratively refine the patch until it becomes plausible. Nevertheless, existing LLM-based vulnerability repair approaches face notable limitations: 1) they ignore the concern of locations that need to be patched and focus solely on the repair content. 2) they lack quality assessment for generated candidate patches in the iterative process. To tackle the two limitations, we propose \\sysname, an LLM-based approach that provides information about where should be patched first. Furthermore, \\sysname improves the iterative repair strategy by assessing the quality of test-failing patches and selecting the best patch for the next iteration. We introduce two dimensions to assess the quality of patches: whether they introduce new vulnerabilities and the taint statement coverage. We evaluated \\sysname on a real-world C/C++ vulnerability repair dataset VulnLoc+, which contains 40 vulnerabilities and their Proofs-of-Vulnerability. The experimental results demonstrate that \\sysname exhibits substantial improvements compared with the Neural Machine Translation-based, Program Analysis-based, and LLM-based state-of-the-art vulnerability repair approaches. Specifically, \\sysname is able to generate 27 plausible patches, which is comparable to or even 8 to 22 more plausible patches than the baselines. In terms of correct patch generation, \\sysname repairs 8 to 13 additional vulnerabilities compared with existing approaches.",
    "title_zh": "好的开始是成功的一半：基于位置感知与追踪引导的迭代式自动化漏洞修复",
    "abstract_zh": "大型语言模型（LLMs）的发展为自动化软件漏洞修复方法铺平了道路，这些方法通过迭代优化补丁直至其变得合理。然而，现有的基于LLM的漏洞修复方法仍存在显著局限性：1）它们忽略了需要修补位置的问题，仅关注修复内容本身；2）在迭代过程中缺乏对生成候选补丁的质量评估。针对上述两个问题，我们提出了\\sysname，一种基于LLM的方法，能够首先提供应修补位置的信息。此外，\\sysname通过评估测试失败补丁的质量，并选择最优补丁进入下一轮迭代，从而改进了迭代修复策略。我们引入两个维度来评估补丁质量：是否引入了新的漏洞，以及污点语句覆盖率。我们在一个真实世界的C/C++漏洞修复数据集VulnLoc+上对\\sysname进行了评估，该数据集包含40个漏洞及其漏洞证明（Proofs-of-Vulnerability）。实验结果表明，与基于神经机器翻译、基于程序分析以及基于LLM的现有最先进漏洞修复方法相比，\\sysname表现出显著提升。具体而言，\\sysname能够生成27个合理的补丁，这一数量与基线方法相当，甚至比基线多出8至22个合理补丁。在正确补丁生成方面，\\sysname比现有方法额外修复了8到13个漏洞。"
  },
  {
    "date": "2025-12-23",
    "title": "Retrieval-augmented Prompt Learning for Pre-trained Foundation Models",
    "authors": "Xiang Chen, Yixin Ou, Quan Feng, Lei Li, Piji Li, Haibo Ye, Sheng-Jun Huang, Shuofei Qiao, Shumin Deng, Huajun Chen, Ningyu Zhang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20145v1",
    "source": "arXiv",
    "abstract": "The pre-trained foundation models (PFMs) have become essential for facilitating large-scale multimodal learning. Researchers have effectively employed the ``pre-train, prompt, and predict'' paradigm through prompt learning to induce improved few-shot performance. However, prompt learning approaches for PFMs still follow a parametric learning paradigm. As such, the stability of generalization in memorization and rote learning can be compromised. More specifically, conventional prompt learning might face difficulties in fully utilizing atypical instances and avoiding overfitting to shallow patterns with limited data during the process of fully-supervised training. To overcome these constraints, we present our approach, named RetroPrompt, which aims to achieve a balance between memorization and generalization by decoupling knowledge from mere memorization. Unlike traditional prompting methods, RetroPrompt leverages a publicly accessible knowledge base generated from the training data and incorporates a retrieval mechanism throughout the input, training, and inference stages. This enables the model to actively retrieve relevant contextual information from the corpus, thereby enhancing the available cues. We conduct comprehensive experiments on a variety of datasets across natural language processing and computer vision tasks to demonstrate the superior performance of our proposed approach, RetroPrompt, in both zero-shot and few-shot scenarios. Through detailed analysis of memorization patterns, we observe that RetroPrompt effectively reduces the reliance on rote memorization, leading to enhanced generalization.",
    "title_zh": "预训练基础模型的检索增强提示学习",
    "abstract_zh": "预训练基础模型（PFMs）已成为推动大规模多模态学习的关键。研究人员通过提示学习有效采用了“预训练、提示、预测”范式，从而提升了少样本学习的表现。然而，现有的PFM提示学习方法仍遵循参数化学习范式，这可能导致在记忆与机械学习中的泛化稳定性受损。具体而言，传统的提示学习在全监督训练过程中，可能难以充分利用异常样本，并容易因数据有限而过度拟合于浅层模式。为克服这些局限性，我们提出了一种名为RetroPrompt的新方法，旨在通过将知识从单纯记忆中解耦，实现记忆与泛化的平衡。与传统提示方法不同，RetroPrompt利用从训练数据中生成的公开可访问知识库，并在整个输入、训练和推理阶段引入检索机制。这使得模型能够主动从语料库中检索相关上下文信息，从而增强可用线索。我们在自然语言处理和计算机视觉任务的多种数据集上进行了全面实验，结果表明，所提出的RetroPrompt方法在零样本和少样本场景下均表现出卓越性能。通过对记忆模式的深入分析，我们发现RetroPrompt显著降低了对死记硬背的依赖，从而提升了模型的泛化能力。"
  },
  {
    "date": "2025-12-23",
    "title": "The Design of an Interactive Proof Mode for Dafny",
    "authors": "Ştefan Ciobâcă, K. Rustan M. Leino, Ştefan-Alexandru Mercaş, Roxana-Mihaela Timon",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20486v1",
    "source": "arXiv",
    "abstract": "We propose to extend the Dafny system with an interactive proof mode. We present a motivating example, how the IPM works, including the main design choices we make, and a prototype implementation.",
    "title_zh": "达夫尼的交互式证明模式设计",
    "abstract_zh": "我们提议扩展Dafny系统，增加交互式证明模式（IPM）。本文提出一个激励性示例，介绍IPM的工作原理，包括我们做出的主要设计选择以及一个原型实现。"
  },
  {
    "date": "2025-12-23",
    "title": "ABBEL: LLM Agents Acting through Belief Bottlenecks Expressed in Language",
    "authors": "Aly Lidayan, Jakob Bjorner, Satvik Golechha, Kartik Goyal, Alane Suhr",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20111v1",
    "source": "arXiv",
    "abstract": "As the length of sequential decision-making tasks increases, it becomes computationally impractical to keep full interaction histories in context. We introduce a general framework for LLM agents to maintain concise contexts through multi-step interaction: Acting through Belief Bottlenecks Expressed in Language (ABBEL), and methods to further improve ABBEL agents with RL post-training. ABBEL replaces long multi-step interaction history by a belief state, i.e., a natural language summary of what has been discovered about task-relevant unknowns. Under ABBEL, at each step the agent first updates a prior belief with the most recent observation from the environment to form a posterior belief, then uses only the posterior to select an action. We systematically evaluate frontier models under ABBEL across six diverse multi-step environments, finding that ABBEL supports generating interpretable beliefs while maintaining near-constant memory use over interaction steps. However, bottleneck approaches are generally prone to error propagation, which we observe causing inferior performance when compared to the full context setting due to errors in belief updating. Therefore, we train LLMs to generate and act on beliefs within the ABBEL framework via reinforcement learning (RL). We experiment with belief grading, to reward higher quality beliefs, as well as belief length penalties to reward more compressed beliefs. Our experiments demonstrate the ability of RL to improve ABBEL's performance beyond the full context setting, while using less memory than contemporaneous approaches.",
    "title_zh": "ABBEL：通过语言表达的信念瓶颈驱动的大型语言模型智能体",
    "abstract_zh": "随着顺序决策任务长度的增加，将完整的交互历史保留在上下文中变得在计算上不可行。为此，我们提出了一种通用框架，用于大语言模型（LLM）代理通过多步交互来维持简洁的上下文：以语言表达的信念瓶颈进行行动（Acting through Belief Bottlenecks Expressed in Language, ABBEL），并引入强化学习（RL）后训练方法进一步提升ABBEL代理的性能。ABBEL 用一个“信念状态”替代冗长的多步交互历史，该信念状态即是对任务相关未知信息所获知识的自然语言摘要。在 ABBEL 框架下，每一步中，代理首先利用环境中的最新观测更新先验信念，形成后验信念，然后仅基于该后验信念选择行动。我们在六个多样化的多步环境中系统评估了前沿模型在 ABBEL 框架下的表现，发现 ABBEL 能够生成可解释的信念，同时在交互步骤中保持近乎恒定的内存使用量。然而，瓶颈类方法通常容易出现误差传播问题，我们观察到这导致其在信念更新出错时性能低于完整上下文设置。因此，我们采用强化学习（RL）训练 LLM 在 ABBEL 框架内生成并依据信念采取行动。我们尝试了信念评分机制，以奖励高质量的信念；同时引入信念长度惩罚，以鼓励更紧凑的信念表示。实验结果表明，RL 能够使 ABBEL 的性能超越完整上下文设置，且所需内存少于同期其他方法。"
  },
  {
    "date": "2025-12-23",
    "title": "VSA:Visual-Structural Alignment for UI-to-Code",
    "authors": "Xian Wu, Ming Zhang, Zhiyu Fang, Fei Li, Bin Wang, Yong Jiang, Hao Zhou",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20034v1",
    "source": "arXiv",
    "abstract": "The automation of user interface development has the potential to accelerate software delivery by mitigating intensive manual implementation. Despite the advancements in Large Multimodal Models for design-to-code translation, existing methodologies predominantly yield unstructured, flat codebases that lack compatibility with component-oriented libraries such as React or Angular. Such outputs typically exhibit low cohesion and high coupling, complicating long-term maintenance. In this paper, we propose \\textbf{VSA (VSA)}, a multi-stage paradigm designed to synthesize organized frontend assets through visual-structural alignment. Our approach first employs a spatial-aware transformer to reconstruct the visual input into a hierarchical tree representation. Moving beyond basic layout extraction, we integrate an algorithmic pattern-matching layer to identify recurring UI motifs and encapsulate them into modular templates. These templates are then processed via a schema-driven synthesis engine, ensuring the Large Language Model generates type-safe, prop-drilled components suitable for production environments. Experimental results indicate that our framework yields a substantial improvement in code modularity and architectural consistency over state-of-the-art benchmarks, effectively bridging the gap between raw pixels and scalable software engineering.",
    "title_zh": "VSA：用于UI到代码的视觉-结构对齐",
    "abstract_zh": "用户界面开发的自动化有望通过减少繁琐的手动实现，加速软件交付。尽管大型多模态模型在设计到代码的转换方面取得了显著进展，但现有方法生成的代码库通常结构松散、扁平化，难以与 React 或 Angular 等面向组件的库兼容。这类输出往往具有低内聚性和高耦合性，给长期维护带来困难。本文提出一种名为 \\textbf{VSA（Visual-Structural Alignment）} 的多阶段范式，旨在通过视觉-结构对齐机制合成结构清晰的前端资产。我们的方法首先利用一种空间感知 Transformer 将视觉输入重构为层次化的树状表示。在超越基础布局提取的基础上，我们引入了一种算法模式匹配层，用于识别重复出现的 UI 模式，并将其封装为模块化模板。随后，这些模板通过基于模式驱动的合成引擎进行处理，确保大型语言模型生成的代码具备类型安全性，并支持属性传递（prop-drilled），适用于生产环境。实验结果表明，与当前最先进的基准相比，我们的框架在代码模块化程度和架构一致性方面均有显著提升，有效弥合了原始像素与可扩展软件工程之间的鸿沟。"
  },
  {
    "date": "2025-12-23",
    "title": "On the Effectiveness of Instruction-Tuning Local LLMs for Identifying Software Vulnerabilities",
    "authors": "Sangryu Park, Gihyuk Ko, Homook Cho",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20062v1",
    "source": "arXiv",
    "abstract": "Large Language Models (LLMs) show significant promise in automating software vulnerability analysis, a critical task given the impact of security failure of modern software systems. However, current approaches in using LLMs to automate vulnerability analysis mostly rely on using online API-based LLM services, requiring the user to disclose the source code in development. Moreover, they predominantly frame the task as a binary classification(vulnerable or not vulnerable), limiting potential practical utility. This paper addresses these limitations by reformulating the problem as Software Vulnerability Identification (SVI), where LLMs are asked to output the type of weakness in Common Weakness Enumeration (CWE) IDs rather than simply indicating the presence or absence of a vulnerability. We also tackle the reliance on large, API-based LLMs by demonstrating that instruction-tuning smaller, locally deployable LLMs can achieve superior identification performance. In our analysis, instruct-tuning a local LLM showed better overall performance and cost trade-off than online API-based LLMs. Our findings indicate that instruct-tuned local models represent a more effective, secure, and practical approach for leveraging LLMs in real-world vulnerability management workflows.",
    "title_zh": "指令微调本地大语言模型在识别软件漏洞中的有效性",
    "abstract_zh": "大型语言模型（LLMs）在自动化软件漏洞分析方面展现出巨大潜力，这一任务至关重要，因为现代软件系统的安全失效会产生重大影响。然而，当前利用LLMs实现漏洞分析的方法大多依赖于在线API形式的LLM服务，这要求用户将源代码暴露给第三方，存在严重的隐私与安全风险。此外，这些方法通常将问题简化为二分类任务（即判断是否存在漏洞），限制了其在实际场景中的应用价值。本文通过将问题重新定义为“软件漏洞识别”（Software Vulnerability Identification, SVI），克服了上述局限：在此框架下，LLMs被要求输出漏洞类型对应的通用弱点枚举（CWE）ID，而非仅判断漏洞是否存在。同时，我们还解决了对大型、基于API的LLM的依赖问题，证明通过指令微调（instruction-tuning）小型且可本地部署的LLM，同样能够实现更优的漏洞识别性能。我们的实验分析表明，经过指令微调的本地模型在整体性能和成本效益方面均优于在线API服务提供的大模型。研究结果表明，经过指令微调的本地模型是实际应用中更高效、更安全、更具可行性的LLM使用方式，适用于真实世界的漏洞管理流程。"
  },
  {
    "date": "2025-12-23",
    "title": "Neuron-Guided Interpretation of Code LLMs: Where, Why, and How?",
    "authors": "Zhe Yin, Xiaodong Gu, Beijun Shen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.19980v1",
    "source": "arXiv",
    "abstract": "Code language models excel on code intelligence tasks, yet their internal interpretability is underexplored. Existing neuron interpretability techniques from NLP are suboptimal for source code due to programming languages formal, hierarchical, and executable nature. We empirically investigate code LLMs at the neuron level, localizing language-specific neurons (selectively responsive to one language) and concept layers (feed-forward layers encoding language-agnostic code representations). We analyze Llama-3.1-8B and Qwen2.5-Coder-32B on multilingual inputs in C++, Java, Python, Go, and JavaScript, measuring neuron selectivity and layerwise contributions during generation. We find (1) neurons specialized for individual languages alongside a universal subset supporting general-purpose generation; and (2) lower layers mainly encode language-specific syntax, while middle layers capture semantic abstractions shared across languages, emerging as concept layers. We demonstrate utility on three tasks: neuron-guided fine-tuning for code generation, clone detection via concept-layer embeddings, and concept-layer-guided transfer for code summarization, each yielding consistent gains in multilingual settings.",
    "title_zh": "神经元引导的代码大模型解释：在何处、为何以及如何实现？",
    "abstract_zh": "代码语言模型在代码智能任务上表现优异，但其内部可解释性仍缺乏深入研究。现有的自然语言处理（NLP）神经元可解释性技术对源代码并不理想，因为编程语言具有形式化、层次化和可执行的特性。本文从实证角度对代码大语言模型（LLM）进行了神经元层面的探究，定位出针对特定编程语言的神经元（仅对某一语言有选择性响应）以及概念层（前馈层编码跨语言通用的代码表征）。我们以Llama-3.1-8B和Qwen2.5-Coder-32B为研究对象，在C++、Java、Python、Go和JavaScript等多种语言输入下，分析了生成过程中神经元的选择性及各层级的贡献度。研究发现：（1）存在专门针对单一语言的神经元，同时也有一个通用子集支持通用代码生成；（2）底层主要编码语言特有的语法特征，而中层则捕捉到跨语言共享的语义抽象，逐渐形成“概念层”。我们进一步在三个任务中验证了该发现的实际价值：基于神经元引导的微调用于代码生成，利用概念层嵌入进行代码克隆检测，以及通过概念层引导实现代码摘要的迁移学习，均在多语言场景下取得了稳定提升。"
  },
  {
    "date": "2025-12-23",
    "title": "Can LLMs Predict Their Own Failures? Self-Awareness via Internal Circuits",
    "authors": "Amirhosein Ghasemabadi, Di Niu",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20578v1",
    "source": "arXiv",
    "abstract": "Large language models (LLMs) generate fluent and complex outputs but often fail to recognize their own mistakes and hallucinations. Existing approaches typically rely on external judges, multi-sample consistency, or text-based self-critique, which incur additional compute or correlate weakly with true correctness. We ask: can LLMs predict their own failures by inspecting internal states during inference? We introduce Gnosis, a lightweight self-awareness mechanism that enables frozen LLMs to perform intrinsic self-verification by decoding signals from hidden states and attention patterns. Gnosis passively observes internal traces, compresses them into fixed-budget descriptors, and predicts correctness with negligible inference cost, adding only ~5M parameters and operating independently of sequence length. Across math reasoning, open-domain question answering, and academic knowledge benchmarks, and over frozen backbones ranging from 1.7B to 20B parameters, Gnosis consistently outperforms strong internal baselines and large external judges in both accuracy and calibration. Moreover, it generalizes zero-shot to partial generations, enabling early detection of failing trajectories and compute-aware control. These results show that reliable correctness cues are intrinsic to generation process and can be extracted efficiently without external supervision.",
    "title_zh": "大语言模型能否预测自身的失败？通过内部机制实现自我意识",
    "abstract_zh": "大型语言模型（LLMs）能够生成流畅且复杂的输出，但常常无法识别自身错误或幻觉。现有的方法通常依赖外部评判者、多样本一致性检测，或基于文本的自我批判，这些方法要么增加额外计算开销，要么与真实正确性相关性较弱。我们提出一个问题：大模型能否通过分析推理过程中的内部状态，来预测自身的失败？我们提出了Gnosis——一种轻量级的自知机制，使冻结的LLM能够通过解码隐藏状态和注意力模式中的信号，实现内在的自我验证。Gnosis被动观察内部轨迹，将信息压缩为固定预算的特征表示，并以几乎可忽略的推理成本预测输出的正确性，仅增加约500万参数，且不依赖于序列长度。在数学推理、开放域问答和学术知识等多个基准测试中，针对从17亿到200亿参数的多种冻结模型骨干网络，Gnosis在准确率和校准度方面均持续优于强效的内部基线和大型外部评判者。此外，它具备零样本泛化能力，适用于部分生成结果，从而实现对失败路径的早期检测和面向计算资源的动态控制。这些结果表明，可靠的正确性线索本质上存在于生成过程中，且无需外部监督即可高效提取。"
  },
  {
    "date": "2025-12-23",
    "title": "SweRank+: Multilingual, Multi-Turn Code Ranking for Software Issue Localization",
    "authors": "Revanth Gangi Reddy, Ye Liu, Wenting Zhao, JaeHyeok Doo, Tarun Suresh, Daniel Lee, Caiming Xiong, Yingbo Zhou, Semih Yavuz, Shafiq Joty",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20482v1",
    "source": "arXiv",
    "abstract": "Maintaining large-scale, multilingual codebases hinges on accurately localizing issues, which requires mapping natural-language error descriptions to the relevant functions that need to be modified. However, existing ranking approaches are often Python-centric and perform a single-pass search over the codebase. This work introduces SweRank+, a framework that couples SweRankMulti, a cross-lingual code ranking tool, with SweRankAgent, an agentic search setup, for iterative, multi-turn reasoning over the code repository. SweRankMulti comprises a code embedding retriever and a listwise LLM reranker, and is trained using a carefully curated large-scale issue localization dataset spanning multiple popular programming languages. SweRankAgent adopts an agentic search loop that moves beyond single-shot localization with a memory buffer to reason and accumulate relevant localization candidates over multiple turns. Our experiments on issue localization benchmarks spanning various languages demonstrate new state-of-the-art performance with SweRankMulti, while SweRankAgent further improves localization over single-pass ranking.",
    "title_zh": "SweRank+：面向软件问题定位的多语言、多轮代码排序",
    "abstract_zh": "维护大规模、多语言代码库的关键在于准确地定位问题，这需要将自然语言的错误描述映射到需要修改的相关函数。然而，现有的排序方法通常以 Python 为中心，仅对代码库进行单次遍历搜索。本文提出 SweRank+ 框架，该框架将 SweRankMulti（一种跨语言代码排序工具）与 SweRankAgent（一种智能体式搜索机制）相结合，实现对代码仓库的迭代式、多轮推理。SweRankMulti 包含一个代码嵌入检索器和一个列表级大语言模型重排序器，并基于精心构建的大规模跨语言问题定位数据集进行训练，覆盖多种主流编程语言。SweRankAgent 采用智能体式搜索循环，通过引入记忆缓冲区，突破了单次定位的局限，能够在多轮交互中持续推理并积累相关的问题定位候选。在涵盖多种语言的问题定位基准测试中，SweRankMulti 表现出了新的最先进水平，而 SweRankAgent 进一步提升了相对于单次遍历排序的定位效果。"
  },
  {
    "date": "2025-12-23",
    "title": "BRIDGE: Budget-aware Reasoning via Intermediate Distillation with Guided Examples",
    "authors": "Xuan-An Le, Minh-Nam Tran, Son Nguyen",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20403v1",
    "source": "arXiv",
    "abstract": "Distilling knowledge from large proprietary models (e.g., GPT-4) to tiny deployable models (less than 1B parameters) faces a critical capacity-budget trap: the 1000x capacity gap between teachers and students prevents effective direct transfer, while API costs prohibit extensive data collection. We introduce BRIDGE (Budget-Aware Reasoning via Intermediate Distillation), a two-phase framework that resolves these constraints through strategic intermediation and budget asymmetry. In Phase 1, a mid-sized Teacher Assistant (TA; e.g., about 7B) learns from the black-box teacher on a strictly limited subset of data (e.g., 3-5%), selected via a zero-API-cost pipeline that balances entropic difficulty and semantic diversity using only local TA inference. In Phase 2, we exploit this asymmetry-teacher queries are expensive, whereas TA inference is free to amplify supervision: the refined TA generates synthetic rationales for the full dataset to train the tiny student. Crucially, we apply an instruction-tuning curriculum to establish behavioral alignment in the tiny student before transferring reasoning. Our theoretical analysis shows that BRIDGE yields tighter generalization bounds than direct distillation when data is abundant. Experiments across medical, legal, and financial benchmarks demonstrate consistent improvements: BRIDGE delivers student performance gains of 28-41%, closing the capability gap with proprietary teachers by 12-16% while using 10x fewer teacher queries. Notably, BRIDGE defies the conventional cost-performance frontier, surpassing direct distillation baselines that use 100% of the budget while consuming only 5% of the resources.",
    "title_zh": "桥接：基于引导示例的中间蒸馏实现预算感知推理",
    "abstract_zh": "从大型专有模型（如GPT-4）向极小的可部署模型（参数量少于10亿）进行知识蒸馏，面临一个关键的“容量-预算陷阱”：教师与学生之间存在高达1000倍的容量差距，导致直接迁移效果不佳；同时，API调用成本又限制了大规模数据的获取。我们提出了BRIDGE（基于预算感知的中间推理蒸馏），一种两阶段框架，通过战略性中间代理和预算不对称性来突破上述限制。\n\n在第一阶段，一个中等规模的教师助手（TA，例如约70亿参数）在严格受限的数据子集（例如3%-5%）上学习来自黑箱教师的知识。该子集通过一种零API成本的筛选管道选取，仅依赖本地TA的推理能力，综合平衡信息熵难度与语义多样性。\n\n在第二阶段，我们利用这种不对称性——教师查询代价高昂，而TA推理免费——实现监督信号的高效放大：经过优化的TA为全量数据生成合成推理过程，用于训练极小的学生模型。尤为重要的是，我们在知识迁移前采用指令微调课程，确保学生模型的行为与教师保持一致。\n\n理论分析表明，当数据充足时，BRIDGE的泛化界优于直接蒸馏方法。在医疗、法律和金融等多个基准上的实验验证了其持续提升性能：BRIDGE使学生模型性能提升28%-41%，将与专有教师之间的能力差距缩小了12%-16%，且所用教师查询次数仅为直接蒸馏的十分之一。尤为突出的是，BRIDGE打破了传统“成本-性能”权衡的边界，在仅消耗5%资源的情况下，超越了使用100%预算的直接蒸馏基线。"
  },
  {
    "date": "2025-12-23",
    "title": "Generative Digital Twins: Vision-Language Simulation Models for Executable Industrial Systems",
    "authors": "YuChe Hsu, AnJui Wang, TsaiChing Ni, YuanFu Yang",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20387v1",
    "source": "arXiv",
    "abstract": "We propose a Vision-Language Simulation Model (VLSM) that unifies visual and textual understanding to synthesize executable FlexScript from layout sketches and natural-language prompts, enabling cross-modal reasoning for industrial simulation systems. To support this new paradigm, the study constructs the first large-scale dataset for generative digital twins, comprising over 120,000 prompt-sketch-code triplets that enable multimodal learning between textual descriptions, spatial structures, and simulation logic. In parallel, three novel evaluation metrics, Structural Validity Rate (SVR), Parameter Match Rate (PMR), and Execution Success Rate (ESR), are proposed specifically for this task to comprehensively evaluate structural integrity, parameter fidelity, and simulator executability. Through systematic ablation across vision encoders, connectors, and code-pretrained language backbones, the proposed models achieve near-perfect structural accuracy and high execution robustness. This work establishes a foundation for generative digital twins that integrate visual reasoning and language understanding into executable industrial simulation systems.",
    "title_zh": "生成式数字孪生：用于可执行工业系统的视觉-语言仿真模型",
    "abstract_zh": "我们提出了一种视觉-语言仿真模型（VLSM），该模型统一了视觉与文本理解能力，能够从布局草图和自然语言提示中合成可执行的FlexScript代码，从而实现工业仿真系统中的跨模态推理。为支持这一新范式，本研究构建了首个用于生成式数字孪生的大规模数据集，包含超过12万组“提示-草图-代码”三元组，实现了文本描述、空间结构与仿真逻辑之间的多模态学习。同时，针对该任务提出了三项新颖的评估指标：结构有效性率（SVR）、参数匹配率（PMR）和执行成功率（ESR），以全面评估代码的结构完整性、参数准确性以及仿真器可执行性。通过系统性的消融实验，考察了视觉编码器、连接模块及代码预训练语言模型对性能的影响，所提出的模型在结构准确率上接近完美，并展现出优异的执行鲁棒性。本研究为将视觉推理与语言理解融合进可执行的工业仿真系统奠定了基础，推动了生成式数字孪生的发展。"
  },
  {
    "date": "2025-12-23",
    "title": "Comment Traps: How Defective Commented-out Code Augment Defects in AI-Assisted Code Generation",
    "authors": "Yuan Huang, Yukang Zhou, Xiangping Chen, Zibin Zheng",
    "publish": "arXiv",
    "url": "https://arxiv.org/abs/2512.20334v1",
    "source": "arXiv",
    "abstract": "With the rapid development of large language models in code generation, AI-powered editors such as GitHub Copilot and Cursor are revolutionizing software development practices. At the same time, studies have identified potential defects in the generated code. Previous research has predominantly examined how code context influences the generation of defective code, often overlooking the impact of defects within commented-out code (CO code). AI coding assistants' interpretation of CO code in prompts affects the code they generate. This study evaluates how AI coding assistants, GitHub Copilot and Cursor, are influenced by defective CO code. The experimental results show that defective CO code in the context causes AI coding assistants to generate more defective code, reaching up to 58.17 percent. Our findings further demonstrate that the tools do not simply copy the defective code from the context. Instead, they actively reason to complete incomplete defect patterns and continue to produce defective code despite distractions such as incorrect indentation or tags. Even with explicit instructions to ignore the defective CO code, the reduction in defects does not exceed 21.84 percent. These findings underscore the need for improved robustness and security measures in AI coding assistants.",
    "title_zh": "注释陷阱：被注释的缺陷代码如何加剧人工智能辅助代码生成中的缺陷",
    "abstract_zh": "随着大型语言模型在代码生成领域的快速发展，GitHub Copilot、Cursor等AI驱动的代码编辑器正在彻底改变软件开发实践。然而，已有研究指出生成代码中可能存在潜在缺陷。以往的研究主要关注代码上下文如何影响缺陷代码的生成，却常常忽视了注释掉代码（CO代码）中缺陷的影响。AI编码助手对提示中注释掉代码的解读，会直接影响其生成的代码质量。本研究评估了AI编码助手GitHub Copilot和Cursor在面对存在缺陷的注释掉代码时的表现。实验结果表明，上下文中存在的缺陷性注释代码会导致AI编码助手生成更多缺陷代码，最高可达58.17%。研究进一步发现，这些工具并非简单复制上下文中的缺陷代码，而是主动推理以补全不完整的缺陷模式，并在受到错误缩进或标签等干扰的情况下仍持续生成缺陷代码。即使明确指示忽略注释掉的缺陷代码，缺陷率的降低也未超过21.84%。这些发现凸显了提升AI编码助手鲁棒性与安全性的迫切需求。"
  },
  {
    "date": "2025-12-23",
    "title": "Effect of Thermal Distribution on Signal and Power Analysis of Large Complex 3D-IC System",
    "authors": "Yu Tomonaga, Tejas Jeurkar, Anushruti Jaiswal",
    "publish": "2025 IEEE CPMT Symposium Japan (ICSJ)",
    "url": "https://doi.org/10.1109/icsj66986.2025.11302514",
    "source": "IEEE",
    "abstract": "In this work, the effect of thermal distribution on signal (SI) and power integrity performance of a large complex 3D-IC system is investigated and discussed. Full-wave 3D solverbased simulations are performed to analyse the system. 3D-IC system is composed of BGA package, and a silicon interposer stacked with HBM and CPU Die's. Eight HBM's are stacked vertically on interposer. Interposer is the bridge between HBM and CPU Dies. SI parameters such as return, insertion loss, crosstalk parameters, and eye diagram opening are observed for high-speed lines between the CPU and HBM die. SI parameters with respect with to varying temperature are compared. Eye opening is also reduced with rise in temperature.",
    "title_zh": "热分布对大型复杂三维集成电路系统信号与功率分析的影响",
    "abstract_zh": "本文研究并讨论了热分布对大型复杂3D-IC系统中信号完整性（SI）和电源完整性性能的影响。通过全波三维求解器仿真对系统进行了分析。该3D-IC系统由BGA封装以及堆叠在硅中介层上的HBM和CPU芯片组成，其中八个HBM芯片垂直堆叠在中介层上，中介层作为HBM与CPU芯片之间的连接桥梁。针对CPU与HBM芯片之间的高速信号线，观察了回波损耗、插入损耗、串扰参数及眼图开度等信号完整性参数。同时对比了不同温度条件下各项信号完整性参数的变化情况，结果表明，随着温度升高，眼图开度也相应减小。"
  },
  {
    "date": "2025-12-24",
    "title": "CCCI: Code Completion with Contextual Information for Complex Data Transfer Tasks Using Large Language Models",
    "authors": "Hangzhan Jin, Mohammad Hamdaqa",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756954",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CCCI：基于上下文信息的代码补全方法在使用大语言模型进行复杂数据传输任务中的应用",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects",
    "authors": "Ahmed Aljohani, Hyunsook Do",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756976",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "提示债务：对大型语言模型项目中技术债务的全面研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Leveraging GPT-4 for Vulnerability-Witnessing Unit Test Generation",
    "authors": "Gábor Antal, Dénes Bán, Martin Isztin, Rudolf Ferenc, Péter Hegedus",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757075",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "利用GPT-4进行漏洞见证单元测试生成",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-23",
    "title": "Comparison of Vector Database Management Systems for Retrieval Augmented Generation",
    "authors": "Marko Niinimaki, Sunny Raj Shrestha, Atamfon Udofia",
    "publish": "2025 29th International Computer Science and Engineering Conference (ICSEC)",
    "url": "https://doi.org/10.1109/icsec67360.2025.11298006",
    "source": "IEEE",
    "abstract": "Retrieval Augmented Generation (RAG) is the de-facto technology used by pre-trained large language models to access data in databases, in addition to the data stored in their parameters. Typically, RAG technologies use vector databases. In this paper, we compare two competing vector databases for RAG, one \"native\" vector database management system and one relational database management system with a vector extension. We concentrate on measuring their performance and relevance in vector similarity search. Our data set consists of 6.1 million Wikipedia abstracts, queried using over 100 000 questions from the MS MARCO data. For each query, we retrieved the abstract that - according to the DBMS's algorithm - most closely matched the query.For the performance evaluation, we executed the queries sequentially on a high-end consumer grade PC. Our tests indicated that the native vector database management system was faster than the vector extension. However, we found that the Hierarchical Navigable Small World (HNSW) indexing and retrieval method used by the vector extension provided better performance than the earlier inverted file method.To evaluate the relevance of the retrieved results, we used a simplistic method of letting OpenAI's GTP-3.5-turbo model assess the quality of each query - answer pair. This test indicated that the native vector database and the HNSW method provided the best results.",
    "title_zh": "面向检索增强生成的向量数据库管理系统比较",
    "abstract_zh": "检索增强生成（RAG）是预训练大型语言模型用于访问数据库中数据的主流技术，除了利用其参数中存储的数据之外。通常，RAG 技术使用向量数据库。在本文中，我们对比了两种用于 RAG 的竞争性向量数据库：一种是“原生”的向量数据库管理系统，另一种是带有向量扩展功能的关系型数据库管理系统。我们的研究重点在于衡量它们在向量相似性搜索中的性能与相关性表现。\n\n实验所用数据集包含 610 万条维基百科摘要，查询语句来自 MS MARCO 数据集中的超过十万个问题。对于每个查询，我们根据数据库管理系统（DBMS）的算法，检索出最匹配该查询的摘要。在性能评估方面，我们在一台高端消费级个人电脑上顺序执行所有查询。测试结果表明，原生向量数据库管理系统比带有向量扩展的关系型数据库系统更快。然而，我们发现该向量扩展所采用的分层可导航小世界（HNSW）索引与检索方法，相较于早期的倒排文件方法，表现出更优的性能。\n\n为了评估检索结果的相关性，我们采用了一种简化的评估方法：让 OpenAI 的 GPT-3.5-turbo 模型对每个查询-答案对的质量进行评分。该测试结果显示，原生向量数据库以及 HNSW 方法在结果相关性方面表现最佳。"
  },
  {
    "date": "2025-12-23",
    "title": "On Rust and C Variability of Fault Sensitivity across Different Runtimes and Cache-Aware Source Codes",
    "authors": "A. Martínez-Álvarez, D. González-Montesoro, R. Possamai Bastos, S. Cuenca-Asensi, A. Serrano-Cases",
    "publish": "2024 24th European Conference on Radiation and Its Effects on Components and Systems (RADECS)",
    "url": "https://doi.org/10.1109/radecs61970.2024.11298588",
    "source": "IEEE",
    "abstract": "This paper explores how cache-optimized C and Rust source code impact the performance of a critical system under radiation. Several implementations of the matrix multiplication algorithm have been tested to show how the variability of fault sensitivity is affected. The versions exposed to radiation were those presenting the highest dissimilarities in terms of the following static and dynamic software metrics: initialized and uninitialized required data memory and code, L1 and L2 data cache impact, and execution time. Static and dynamic measures from the generated binary executable were collected and correlated with radiation-induced effects. Results show that cache optimization has a positive impact on fault tolerance, regardless of the selected language, compiler, or runtime. Particularly, Rust implementation emerged as the top-performing version under radiation, surpassing the C versions. Rust exhibited the highest Mean Work To Failure (MWTF) without negatively affecting the cross section. These results suggest Rust as a promising option for implementing fault-tolerant applications.",
    "title_zh": "在不同运行时环境和缓存感知源代码中，Rust与C语言故障敏感性的差异性研究",
    "abstract_zh": "本文探讨了经过缓存优化的C语言与Rust语言源代码在辐射环境下对关键系统性能的影响。通过测试多种矩阵乘法算法的实现，展示了故障敏感性差异如何受到这些实现方式的影响。在辐射暴露的版本中，选取了在以下静态和动态软件度量方面差异最大的版本：已初始化与未初始化的数据内存及代码、L1和L2数据缓存的影响，以及执行时间。从生成的二进制可执行文件中收集了静态和动态度量数据，并将其与辐射引起的效应进行相关性分析。结果表明，无论选择何种语言、编译器或运行时环境，缓存优化均对容错能力具有积极影响。特别是，Rust实现版本在辐射环境下表现最佳，优于所有C语言版本。Rust在不降低截面（cross section）的前提下，表现出最高的平均失效前工作量（Mean Work To Failure, MWTF）。这些结果表明，Rust是实现容错应用的一个极具前景的选择。"
  },
  {
    "date": "2025-12-24",
    "title": "CallNavi, A challenge and empirical study on LLM function calling and routing",
    "authors": "Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawendé Bissyande, Andrey Boytsov, Ulrick Ble, Anne Goujon",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756975",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "CallNavi：大语言模型函数调用与路由的挑战与实证研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-23",
    "title": "Study on Artificial Intelligence-Driven Cybersecurity Risk Surveillance",
    "authors": "Le Tian, Yanchao Liu, Jiawei Yan, Ran Qian",
    "publish": "Proceedings of the 2025 11th Annual International Conference on Network and Information Systems for Computers",
    "url": "https://doi.org/10.1145/3776942.3776980",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于人工智能的网络安全风险监测研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-23",
    "title": "A Comparative Analysis of Generative AI and Student Solutions in Java Programming Assignments",
    "authors": "Htoo Htoo Sandi Kyaw, Tomoyuki Hata, Nobuo Funabiki",
    "publish": "2025 IEEE International Symposium on Consumer Technology (ISCT)",
    "url": "https://doi.org/10.1109/isct66099.2025.11297232",
    "source": "IEEE",
    "abstract": "Currently, Java serves as the core object-oriented programming language that is essential for students studying ICT. To support learners in acquiring Java programming skills, we have developed the Java Programming Learning Assistant System (JPLAS). In JPLAS, Code Writing Problem (CWP) is designed for the students to write the source code from scratch by following the test code and problem statement. However, with the advancement of generative AI, it has become possible for students to generate answer code from the given test code and problem statement. To address this issue, this study investigates the impact of generative AI in solving CWP by generating 54 sample codes from three major generative AIs. Then, these generated codes were compared with students’ codes using the code plagiarism checking program. The average similarity is found to be 38.17%, and the analysis showed that simpler problems tend to produce higher similarity scores. In addition, different coding styles were observed for each AI, with certain prompt patterns resulting in higher similarity.",
    "title_zh": "生成式人工智能与学生解决方案在Java编程作业中的比较分析",
    "abstract_zh": "目前，Java作为信息技术（ICT）专业学生必须掌握的核心面向对象编程语言。为了帮助学习者提升Java编程能力，我们开发了Java编程学习助手系统（JPLAS）。在JPLAS中，代码编写题（CWP）要求学生根据测试代码和题目说明从零开始编写源代码。然而，随着生成式人工智能的发展，学生已能够基于给定的测试代码和题目说明自动生成答案代码。为应对这一挑战，本研究探讨了生成式AI在解决CWP问题中的影响，通过三种主流生成式AI分别生成了54个示例代码，并利用代码抄袭检测程序将这些生成代码与学生提交的代码进行对比分析。结果显示，平均相似度为38.17%；进一步分析表明，题目越简单，生成代码与学生代码之间的相似度越高。此外，不同AI表现出各异的编码风格，特定提示模式也会影响生成代码的相似性水平。"
  },
  {
    "date": "2025-12-23",
    "title": "8-Bit Pipelined Accuracy-Configurable Radix-4 Adder with Dynamic Output Adjustment",
    "authors": "Hamsavardini C, R Muthaiah",
    "publish": "2025 International Conference on Power, Instrumentation, Control, and Computing (PICC)",
    "url": "https://doi.org/10.1109/picc67314.2025.11291328",
    "source": "IEEE",
    "abstract": "The development of mobile, embedded and Internet of things applications is driving a growing need for arithmetic processors with high processing speeds and low battery consumption. These programs often have moderate to high computational accuracy requirements and operate within high power constraints. The trade-offs between accuracy, power, and performance are often not optimally balanced by adder implementations like Carry Look Ahead Adders (CLA) and Ripple carry Adders (RLA) under dynamic workloads. To overcome these limitations, an 8-bit pipelined Radix-4 adder with programmable accuracy is proposed in this work, enabling the system to meet its needs. Radix-4 improves performance by reducing propagation time and logic depth through the concurrent processing of four bits. Real time and logic depth through the concurrent processing of four bits. Real-time switching between accurate and approximation modes in a reconfigurable output adjustment system saves energy without sacrificing required accuracy. Targeting a Zynq-7000 FPGA (Zedboard), the architecture is written in Verilog HDL and Vivado tool. Modelsim is used to verify functionality. The architecture minimizes the latency and power consumption while achieving during approximation mode, according to experimental comparisons. These results show that the proposed adder is suitable for digital systems that are adaptive, low power, and high speed.",
    "title_zh": "8位流水线可配置精度的基4加法器及其动态输出调节",
    "abstract_zh": "移动、嵌入式及物联网应用的发展，正推动对高速处理且低功耗算术处理器日益增长的需求。这些应用通常具有中等到较高的计算精度要求，并在高功耗约束下运行。在动态工作负载下，传统的加法器实现方式（如进位前瞻加法器CLA和行波进位加法器RLA）在精度、功耗与性能之间的权衡往往无法达到最优。为克服这些局限性，本文提出了一种可编程精度的8位流水线Radix-4加法器，使系统能够灵活满足不同需求。Radix-4结构通过并行处理四位数据，有效缩短了信号传播时间并降低了逻辑深度，从而提升了性能。同时，基于可重构输出调节系统的实时模式切换机制，可在精确模式与近似模式之间快速转换，在不牺牲必要精度的前提下显著节省能耗。该架构采用Verilog HDL语言编写，并在Zynq-7000 FPGA（Zedboard）平台上实现，使用Vivado工具进行综合，Modelsim用于功能验证。实验对比结果表明，该加法器在近似模式下能有效降低延迟和功耗。这些结果证明，所提出的加法器适用于自适应、低功耗且高速的数字系统。"
  },
  {
    "date": "2025-12-24",
    "title": "Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation",
    "authors": "Lola Solovyeva, Eduardo Carneiro Oliveira, Shiyu Fan, Alper Tuncay, Shamil Gareev, Andrea Capiluppi",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757007",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "利用大语言模型实现遗留代码的自动化翻译：PL/SQL到Java转换的案例研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection",
    "authors": "Seyed Shayan Daneshvar, Da Tan, Shaowei Wang, Carson Leung",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3757017",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "一种基于Mixup的增强方法在软件漏洞检测中的研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Towards Automated Detection of Inline Code Comment Smells",
    "authors": "Ipek Oztas, U. Boran Torun, Eray Tüzün",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756988",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "面向自动检测内联代码注释异味",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-23",
    "title": "Hybrid Retrieval Enhancement and Domain Prompt Guidance Based Auxiliary Decision-Making for Differentiated Scenarios in Power Equipment Operation and Maintenance",
    "authors": "Xu Jiannan, Zhu Jiazheng, Zhao Ruyi, Zhao Qi, Zhao Baohua, Shi Mengjie",
    "publish": "2025 International Conference on New Power System Technology (PowerCon)",
    "url": "https://doi.org/10.1109/powercon66300.2025.11295678",
    "source": "IEEE",
    "abstract": "The operation and maintenance of power equipment is an important part of the construction of the new power system. The transformation of artificial intelligence represented by large language models has provided new opportunities for the digital and intelligent transformation of traditional power equipment operation and maintenance. For two typical business scenarios in the power operation and maintenance field, namely knowledge service and equipment condition evaluation, considering the differences in demand and technical adaptability of different scenarios, a customized technical route for adaptation based on large language models is designed, and a hybrid retrieval enhancement and domain prompt guidance based auxiliary decision-making method for differentiated scenarios in power equipment operation and maintenance is proposed. By constructing a knowledge base for the operation and maintenance of power equipment and a sparse-dense hybrid retrieval strategy, the associated knowledge of queries can be efficiently retrieved and integrated through the large language model to generate precision responses. By incorporating multi-dimensional condition evaluation rules into the prompt, the large language model is guided to conduct logical reasoning of the equipment operation condition, and the complete reasoning process and condition evaluation results are output. Finally, the superiority and effectiveness of the operation and maintenance knowledge service and equipment condition evaluation method proposed in this paper were verified on the power dataset.",
    "title_zh": "基于混合检索增强与领域提示引导的辅助决策方法在电力设备运维差异化场景中的应用",
    "abstract_zh": "电力设备的运行与维护是新型电力系统建设的重要组成部分。以大语言模型为代表的人工智能技术变革，为传统电力设备运行与维护的数字化、智能化转型提供了新的机遇。针对电力运检领域中两类典型业务场景——知识服务与设备状态评估，考虑到不同场景在需求特征和技术适配性上的差异，本文设计了一条基于大语言模型的定制化技术路径，并提出一种融合混合检索增强与领域提示引导的差异化辅助决策方法，以适应不同应用场景。通过构建电力设备运检知识库及稀疏-密集混合检索策略，利用大语言模型高效地检索并整合查询相关知识，生成精准响应。同时，将多维度状态评估规则嵌入提示（prompt）中，引导大语言模型对设备运行状态进行逻辑推理，输出完整的推理过程与状态评估结果。最后，基于电力数据集验证了本文所提运检知识服务与设备状态评估方法的优越性与有效性。"
  },
  {
    "date": "2025-12-23",
    "title": "The Impact of Allocating Weights and Biases in SRAM Parity Checking Areas on the Soft Error Reliability of CNN Inference Models",
    "authors": "J. Gava, L. Laurini, R. Possamai Bastos, F. Moraes, R. Reis, L. Ost",
    "publish": "2024 24th European Conference on Radiation and Its Effects on Components and Systems (RADECS)",
    "url": "https://doi.org/10.1109/radecs61970.2024.11298584",
    "source": "IEEE",
    "abstract": "This paper promotes a novel semi-automated compiler-based technique that allocates CNN weights and bias to SRAM parity checking areas. Radiation results suggest that it is possible to reduce critical SDC events by up to 90%.",
    "title_zh": "权重与偏置分配对SRAM奇偶校验区域在CNN推理模型软错误可靠性中的影响",
    "abstract_zh": "本文提出了一种新颖的半自动化编译器技术，将CNN的权重和偏置分配至SRAM的奇偶校验区域。辐射实验结果表明，该方法可将关键的SDD事件减少高达90%。"
  },
  {
    "date": "2025-12-24",
    "title": "How Well Do Large Language Models Serve as End-to-End Secure Code Agents for Python?",
    "authors": "Jianian Gong, Nachuan Duan, Ziheng Tao, Zhaohui Gong, Yuan Yuan, Minlie Huang",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756984",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型在作为 Python 的端到端安全代码代理方面表现如何？",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-24",
    "title": "Quality Assessment of Python Tests Generated by Large Language Models",
    "authors": "Victor Alves, Carla Bezerra, Ivan Machado, Larissa Rocha, Tassio Virgínio, Publio Silva",
    "publish": "Proceedings of the 29th International Conference on Evaluation and Assessment in Software Engineering",
    "url": "https://doi.org/10.1145/3756681.3756964",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型生成的Python测试用例的质量评估",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-23",
    "title": "A Systematic Literature Review on Static Application Security Testing (SAST) Tools: Evaluation, Benchmarks, Challenges, and Future Directions",
    "authors": "Doaa Dalaq, Kaniz Fatima Daya, Alaa Dalaq, Muhammed Nazmul Arefin, Mahmood Khan Niazi",
    "publish": "Proceedings of the 2025 29th International Conference on Evaluation and Assessment in Software Engineering Companion",
    "url": "https://doi.org/10.1145/3727967.3756838",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "关于静态应用安全测试（SAST）工具的系统性文献综述：评估、基准测试、挑战与未来方向",
    "abstract_zh": "None"
  }
]