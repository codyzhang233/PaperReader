[
  {
    "date": "2025-12-19",
    "title": "AI-Based Security Engineering for Fintech and Regulated Industries",
    "authors": "Ilakiya Ulaganathan, FNU Antara, Santhosh Chitraju Gopal Varma, Zokir Mamadiyarov, Ziyadulla Turayev",
    "publish": "2025 International Conference on Sustainability, Innovation &amp;amp; Technology (ICSIT)",
    "url": "https://doi.org/10.1109/icsit65336.2025.11294748",
    "source": "IEEE",
    "abstract": "Fintech and other highly regulated sectors that face growing cyber threats, compounding compliance requirements and even faster digital change are now dependent on AI-based security engineering. The more basic enabling technologies, including machine learning algorithms, systems design, and automated compliance integration, are discussed in this review, and how AI can be used to detect threats, score risk, and react to incidents where false positives and latency are the key elements. It provides a comparison between classical and deep learning architecture, describing the architectures that adopt a mixture of CNNs, LSTMs, and other technologies to provide accuracy and robustness in intrusion detection. It proposes a novel multi-tier security model, which dwells upon the feedbackbased learning, regulation compliance, and adversarial resistance. The key research gaps such as explainable AI, federated learning in order to maintain privacy and policy-conscious response to threats are described. The article unites both theoretical and experimental results, along with the solutions to the technological and regulatory problems.",
    "title_zh": "基于人工智能的金融科技与监管行业安全工程",
    "abstract_zh": "金融科技及其他高度监管的领域，正面临日益严峻的网络威胁、不断加码的合规要求以及更快速的数字化变革，因此如今已高度依赖基于人工智能的安全工程。本文综述了支撑AI安全技术的基础性技术，包括机器学习算法、系统架构设计以及自动化合规集成，并探讨了如何利用AI实现威胁检测、风险评分及事件响应，尤其关注误报率和延迟等关键问题。文章对比了传统与深度学习架构，描述了融合卷积神经网络（CNN）、长短期记忆网络（LSTM）及其他技术的混合架构，以在入侵检测中实现更高的准确性和鲁棒性。本文提出了一种新颖的多层级安全模型，该模型强调基于反馈的学习机制、合规性保障以及对抗性攻击的抵御能力。同时，文章指出了若干关键研究空白，如可解释性AI、用于保护隐私的联邦学习，以及对政策敏感的威胁响应策略。全文结合理论分析与实验结果，为解决技术和监管层面的问题提供了综合性解决方案。"
  },
  {
    "date": "2025-12-19",
    "title": "Research on Enterprise Security Operation Based on Large Model Technology",
    "authors": "Ling Li, Ting Wang, Qi An, Jie Dong",
    "publish": "Proceedings of the 2025 8th International Conference on Computer Information Science and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3773365.3773614",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "基于大模型技术的企业安全运营研究",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-19",
    "title": "Composable Open-Source Toolchain for Synthesizing Hardware Accelerators from OpenCL Command Buffers",
    "authors": "Topi Leppänen, Leevi Leppänen, Zainab Jamil, Jan Solanti, Joonas Multanen, Pekka Jääskeläinen",
    "publish": "ACM Transactions on Reconfigurable Technology and Systems",
    "url": "https://doi.org/10.1145/3786204",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "从OpenCL命令缓冲区合成硬件加速器的可组合开源工具链",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-19",
    "title": "Advanced Mutation Testing with Zero and Few-Shot Evaluation Using GPT-V4",
    "authors": "Arshia Hemmat, Fatame Aghababaei, Mohammadreza Sharbaf, Shekoufeh Kolahdouz-Rahimi",
    "publish": "2025 9th International Conference on Internet of Things and Applications (IoT)",
    "url": "https://doi.org/10.1109/iot69654.2025.11297643",
    "source": "IEEE",
    "abstract": "In the pursuit of software reliability, mutation testing plays a critical role in evaluating and enhancing the efficacy of test suites. However, a pervasive challenge in this domain is generating optimal mutations that align with the existing test cases, often resulting in inadequate coverage of the codebase. This gap leads to missed opportunities to identify potential faults and weaknesses in software, undermining the robustness of test suites. In this paper, we propose a novel approach utilizing the capabilities of Large Language Models (LLMs) to identify a diverse array of mutations tailored to thoroughly probe different segments of the code, thereby ensuring comprehensive coverage. By leveraging LLMs, we generate mutations that are not only varied but also contextually relevant to the given code and test suites. This method facilitates the generation of mutations that are more likely to be ‘killed’ by the test suites, significantly increasing the number of detected faults. This, in turn, leads to a deeper understanding of the code's behavior and the enhancement of the overall quality of the software testing process. Our findings indicate a substantial improvement in test suite effectiveness, showcasing the power of AI in advancing software engineering practices.",
    "title_zh": "使用 GPT-V4 进行零样本和少样本评估的高级变异测试",
    "abstract_zh": "在追求软件可靠性过程中，变异测试在评估和提升测试套件有效性方面发挥着关键作用。然而，该领域普遍存在一个难题：生成与现有测试用例相匹配的最优变异，常常导致代码库覆盖不充分。这一缺陷使得潜在的软件故障和弱点未能被及时发现，从而削弱了测试套件的稳健性。本文提出一种创新方法，利用大型语言模型（LLMs）的能力，识别出多样化且针对代码不同部分进行深入探测的变异，以确保全面覆盖。通过运用LLMs，我们生成的变异不仅种类丰富，而且与给定代码及测试套件具有高度上下文相关性。这种方法显著提高了测试套件“杀死”变异的可能性，从而大幅增加可检测到的缺陷数量。这进一步加深了对代码行为的理解，并有效提升了软件测试的整体质量。研究结果表明，测试套件的有效性得到显著提升，充分展示了人工智能在推动软件工程实践方面的巨大潜力。"
  },
  {
    "date": "2025-12-19",
    "title": "Symbolic Sequence Frameworks for Ultra-High Fidelity with Hierarchical Representation in Multi-Stage Processing Pipelines",
    "authors": "Aarav Kannan J, R. Rajalakshmi, G. Kavitha, Gracelin Sheena, P.Sardar Maran, Beschi I S",
    "publish": "2025 International Conference on Sustainability, Innovation &amp;amp; Technology (ICSIT)",
    "url": "https://doi.org/10.1109/icsit65336.2025.11294453",
    "source": "IEEE",
    "abstract": "This outstanding research has paved a unique approach of context processing with the use of LLM in leveraging advanced characteristics of sequences. Algorithms like machine learning and other integrative tools has predominantly outlined the application of neural language processing. The feasibility measures of the model system are showcased with the help of evaluation metrics by integrating multi-stage processing pipelines. Integrative tools like T5 for sequence generation, GPT 4 for sequence creation and BERT for sequence identification are utilized. In addition, metric scores like ROUGE and METEOR scores are significantly employed for analyzing the model performance.",
    "title_zh": "用于多阶段处理流水线中分层表示的超高保真度符号序列框架",
    "abstract_zh": "这项杰出的研究通过利用大语言模型（LLM）在序列高级特征方面的优势，开创了一种独特的上下文处理方法。机器学习算法及其他集成工具主要阐述了神经语言处理的应用。通过整合多阶段处理流程，借助评估指标展示了模型系统的可行性。研究中还采用了T5进行序列生成、GPT-4用于序列创建，以及BERT用于序列识别等集成工具。此外，ROUGE和METEOR等指标得分被广泛应用于分析模型性能。"
  },
  {
    "date": "2025-12-19",
    "title": "Risk2Scenario: LLM-Assisted Scenario Generation for Autonomous Driving Testing Based on Hierarchical Risk Analysis",
    "authors": "Pin Wang, Junyan Ma",
    "publish": "2025 5th International Conference on Computer Systems (ICCS)",
    "url": "https://doi.org/10.1109/iccs67844.2025.11292126",
    "source": "IEEE",
    "abstract": "Ensuring the safety and reliability of autonomous driving systems requires rigorous testing across diverse and safety-critical conditions. Traditional mileage-based evaluations often fail to capture rare but high-risk scenarios that lie in the long tail of real-world distributions. To address this challenge, we propose Risk2Scenario, a scenario generation framework assisted by Large Language Models (LLMs). Our approach leverages real-world traffic accident reports and employs prompt-based hierarchical analysis to extract structured risk factors, constructing a domain-specific risk factor database. These risk factors are then retrieved and integrated into the LLM, enabling the generation of semantically rich, high-risk test scenarios. To further enhance scenario diversity and coverage, we employ a genetic algorithm to explore and mutate the generated scenarios. We validate Risk2Scenario in the CARLA simulator using the Basic Agent, demonstrating its effectiveness in uncovering safety-critical situations and revealing potential vulnerabilities in autonomous driving systems.",
    "title_zh": "基于层次化风险分析的LLM辅助场景生成用于自动驾驶测试",
    "abstract_zh": "确保自动驾驶系统的安全性和可靠性，需要在多样且具有安全关键性的条件下进行严格测试。传统的基于里程数的评估方法往往难以捕捉到真实世界分布中“长尾”部分的罕见但高风险场景。为应对这一挑战，我们提出了Risk2Scenario——一种由大语言模型（LLM）辅助的场景生成框架。该方法利用真实交通事故报告，通过基于提示的分层分析，提取出结构化的风险因素，并构建领域特定的风险因素数据库。随后，将这些风险因素检索并整合进大语言模型中，从而生成语义丰富、高风险的测试场景。为进一步提升场景的多样性与覆盖范围，我们采用遗传算法对生成的场景进行探索与变异。我们在CARLA仿真器中使用Basic Agent对Risk2Scenario进行了验证，结果表明该框架能够有效发现安全关键情境，并揭示自动驾驶系统潜在的安全漏洞。"
  },
  {
    "date": "2025-12-19",
    "title": "Threats and Defenses for Large Language Models: A Survey",
    "authors": "Xiaobao Sheng, Qinhui Jiang",
    "publish": "Proceedings of the 2025 8th International Conference on Computer Information Science and Artificial Intelligence",
    "url": "https://doi.org/10.1145/3773365.3773631",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "大型语言模型的威胁与防御：一项综述",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-19",
    "title": "Decentralized Finance (DeFi) Risk Management Using Blockchain and AI",
    "authors": "Godwin Francis, Ch Paramaiah",
    "publish": "2025 3rd International Conference on Cyber Resilience (ICCR)",
    "url": "https://doi.org/10.1109/iccr67387.2025.11291888",
    "source": "IEEE",
    "abstract": "Decentralized finance (DeFi) is indeed transforming the financial ecology, offering technological solutions for lending, borrowing, and trading that operate without intermediaries. However, with the rapidity of DeFi's growth comes immense risks like smart contract vulnerabilities, untypical market behavior, or scams. The objective of this study is to investigate the application of Artificial Intelligence (AI) and Blockchain technology to efficiently manage risks in DeFi platforms. Transparency, nonrepudiation, and decentralized control are the qualities guaranteed by Blockchain, and on the other hand, predictive analytics, proactive anomaly detection, and fraud prevention are the strengths of AI. The best use of these technologies in terms of risk assessment would be to design a system based on AI and blockchain - real-time risk assessment directly from the blockchain, secure data sharing assistance, and automating the risk mitigation strategies. We developed an artificial intelligence-based risk prediction model that was trained using past DeFi transaction data and we also drew up a framework that helps smart contracts provide automated responses to cybersecurity incidents. Our framework is more accurate in comparison with existing methods through simulations and case studies when it comes to risk detection and mitigation. This study proposes a reliable and resilient approach to the DeFi ecosystem that will boost further acceptance and credibility of blockchain-based financial systems.",
    "title_zh": "基于区块链与人工智能的去中心化金融（DeFi）风险管理",
    "abstract_zh": "去中心化金融（DeFi）确实在重塑金融生态，通过无需中介的技术方案，为借贷、借款和交易提供支持。然而，随着DeFi的迅猛发展，也伴随着巨大的风险，如智能合约漏洞、非典型市场行为或诈骗事件。本研究旨在探讨人工智能（AI）与区块链技术在高效管理DeFi平台风险方面的应用。区块链保障了透明性、不可否认性和去中心化控制，而人工智能则在预测分析、主动异常检测和欺诈防范方面具有显著优势。将这两项技术有机结合，最佳实践是构建一个基于AI与区块链的综合系统：实现从区块链实时获取风险评估数据、安全地共享数据，并自动化执行风险缓解策略。我们开发了一种基于人工智能的风险预测模型，利用历史DeFi交易数据进行训练，并设计了一个框架，使智能合约能够在网络安全事件发生时自动响应。通过模拟和案例研究对比，该框架在风险检测与缓解方面比现有方法更为精准。本研究提出了一种可靠且具备韧性的DeFi生态系统解决方案，有望进一步提升基于区块链的金融系统的接受度与可信度。"
  },
  {
    "date": "2025-12-20",
    "title": "ParEval-Repo: A Benchmark Suite for Evaluating LLMs with Repository-level HPC Translation Tasks",
    "authors": "Joshua H. Davis, Daniel Nichols, Ishan Khillan, Abhinav Bhatele",
    "publish": "Proceedings of the 54th International Conference on Parallel Processing",
    "url": "https://doi.org/10.1145/3754598.3754669",
    "source": "ACM",
    "abstract": "None",
    "title_zh": "ParEval-Repo：一个用于评估大语言模型在仓库级高性能计算翻译任务中的基准测试套件",
    "abstract_zh": "None"
  },
  {
    "date": "2025-12-19",
    "title": "Optimizing Power, Performance, and Area in Digital Design Using ML Based Design Space Exploration",
    "authors": "Vedashree B S, Shilpa D R",
    "publish": "2025 9th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)",
    "url": "https://doi.org/10.1109/csitss67709.2025.11295118",
    "source": "IEEE",
    "abstract": "With increasing complexity in VLSI design and shrinking technology nodes, optimizing Power, Performance, and Area (PPA) has become a critical challenge. Traditional manual and heuristic-based methods often fall short in exploring the vast design space efficiently. This work proposes a machine learningbased design space exploration approach using Synopsys DSO.ai integrated with Fusion Compiler for RTL-to-GDSII digital flow. The methodology intelligently explores various design parameters at the compile, clock, and route stages, guided by user defined metrics. Compared to the traditional Fusion Compiler flow, the DSO.ai enhanced flow achieved notable improvements: congestion was reduced by 19.42 %, standard cell area decreased by 5.27 %, and frequency increased by 16.44 %. In addition, all timing violations were resolved, including WNS and TNS, and the total power consumption was reduced by approximately 10.22 %. The design also saw significant reduction in design rule check (DRC) violations and better overall utilization. These results validate the effectiveness of AI-driven optimization in improving design QoR, reducing closure time, and minimizing manual intervention, thereby paving the way for intelligent, automated, and scalable physical design flows.",
    "title_zh": "基于机器学习的设计空间探索在数字设计中的功耗、性能与面积优化",
    "abstract_zh": "随着VLSI设计复杂度的不断提升以及工艺节点的持续缩小，优化功耗、性能和面积（PPA）已成为一项关键挑战。传统的手动及基于启发式的方法在高效探索广阔的设计空间方面往往力不从心。本文提出了一种基于机器学习的设计空间探索方法，结合Synopsys DSO.ai与Fusion Compiler的RTL到GDSII数字设计流程。该方法在编译、时钟和布线阶段智能地探索多种设计参数，并依据用户定义的指标进行引导。相较于传统Fusion Compiler流程，采用DSO.ai增强后的流程取得了显著改进：拥塞程度降低19.42%，标准单元面积减少5.27%，频率提升16.44%；所有时序违规问题均被解决，包括WNS和TNS，总功耗降低约10.22%。此外，设计规则检查（DRC）违规数量大幅减少，整体资源利用率也得到明显改善。这些结果验证了人工智能驱动优化在提升设计质量与收敛性（QoR）、缩短设计闭合时间以及减少人工干预方面的有效性，为实现智能化、自动化且可扩展的物理设计流程奠定了坚实基础。"
  },
  {
    "date": "2025-12-19",
    "title": "Malicious Vulnerability Scanning Detection Using Ensemble-Based Machine-Learning and Explainability-Based Feature Selection",
    "authors": "Mohammed M. Alani",
    "publish": "2025 3rd International Conference on Cyber Resilience (ICCR)",
    "url": "https://doi.org/10.1109/iccr67387.2025.11292026",
    "source": "IEEE",
    "abstract": "The rapid rate of adoption of Internet-of-Things in various applications in our daily lives have made it an important target for malicious actors. Most of these threats emerge from simple scans that could result in finding significant vulnerabilities. In this paper we address an important security threat which is vulnerability scanning conducted by malicious actors. This scanning takes place in the reconnaissance phase of the attack, and helps the attack gain important insights into the vulnerabilities that exist in the device leading to exploiting them. We introduce a machine learning-based vulnerability scanning detector that utilizes explainable machine learning for feature selection. The proposed detector analyzes network traffic patterns to identify malicious vulnerability scanning and enables the network to stop it. SHAP-based explainability is used to identify the most effective features to perform feature selection. The proposed system was trained and tested using CIC-IoT-2023 dataset. Tests have shown reliable results with accuracy exceeding 99.9% and F<inf xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</inf> Score of 0.999 while reducing the number of features from 46 to 24.",
    "title_zh": "基于集成学习与可解释性特征选择的恶意漏洞扫描检测",
    "abstract_zh": "物联网在我们日常生活的各种应用中迅速普及，使其成为恶意攻击者的重要目标。大多数威胁源于简单的扫描行为，这些扫描可能发现重大的安全漏洞。本文针对一个重要的安全威胁——由恶意攻击者实施的漏洞扫描问题展开研究。此类扫描发生在攻击的侦察阶段，能够帮助攻击者获取设备中存在的漏洞信息，从而为后续的利用提供关键线索。为此，本文提出了一种基于机器学习的漏洞扫描检测系统，并采用可解释性机器学习方法进行特征选择。该检测系统通过分析网络流量模式，识别恶意漏洞扫描行为，并使网络能够及时阻止此类活动。基于SHAP（SHapley Additive exPlanations）的可解释性方法被用于识别最具影响力的特征，实现有效的特征筛选。所提出的系统使用CIC-IoT-2023数据集进行训练与测试，实验结果表明，系统性能优异，准确率超过99.9%，F1分数达到0.999，同时将特征数量从46个减少至24个。"
  },
  {
    "date": "2025-12-19",
    "title": "Smart Scan: A Next-Gen Android Vulnerability Framework Powered by CVE Intelligence",
    "authors": "Saptadeepa Kalita, Anand Kiran, Avinash Kumar, Shweta Soni, Venkata Sai Rahul Trivedi Kothapalli",
    "publish": "2025 International Conference on Sustainability, Innovation &amp;amp; Technology (ICSIT)",
    "url": "https://doi.org/10.1109/icsit65336.2025.11295152",
    "source": "IEEE",
    "abstract": "The mobile phone has evolved into an essential tool in modern life, extending far beyond its original purpose of voice communication. Today, it plays a crucial role in banking, entertainment, education, and countless daily tasks, handling a vast amount of personal and sensitive data. As a result, securing mobile applications and their operating systems has become a pressing necessity. With Android dominating the global smartphone market, it has also become a prime target for cyberattacks due to its open architecture and widespread use. Recognizing these vulnerabilities, this work proposes a comprehensive scanning tool that integrates all critical features required to identify potential threats and system weaknesses. The scanner is designed to detect vulnerabilities effectively, ensuring better protection for end users. Additionally, the system leverages the Common Vulnerabilities and Exposures (CVE) database to recognize recent and critical threats, enabling timely detection and mitigation. By combining essential scanning capabilities with up-to-date threat intelligence, the proposed solution aims to enhance mobile security, particularly for Android devices, and address the growing concern of mobile-based cyber threats.",
    "title_zh": "智能扫描：基于CVE情报的下一代Android漏洞检测框架",
    "abstract_zh": "手机已演变为现代生活中不可或缺的工具，其功能远远超出了最初语音通信的范畴。如今，它在银行、娱乐、教育以及无数日常任务中发挥着关键作用，处理着大量个人和敏感数据。因此，保障移动应用程序及其操作系统的安全已成为当务之急。由于Android在全球智能手机市场占据主导地位，其开放的架构和广泛的应用使其成为网络攻击的主要目标。针对这些潜在漏洞，本文提出了一款综合性扫描工具，集成了识别潜在威胁和系统弱点所需的所有关键功能。该扫描器旨在高效检测各类漏洞，从而为终端用户提供更有效的保护。此外，系统还利用通用漏洞与暴露（CVE）数据库，识别最新且严重的安全威胁，实现及时发现与应对。通过将核心扫描能力与最新的威胁情报相结合，本方案旨在提升移动安全水平，尤其针对Android设备，以应对日益增长的移动网络安全威胁。"
  },
  {
    "date": "2025-12-19",
    "title": "From Voice to Efficiency: Natural Language Processing for Energy-Optimized Robot Programs",
    "authors": "Zeynep Sezen Osmanpasaoglu, Mustafa Caner Akuner",
    "publish": "2025 14th International Conference on Renewable Energy Research and Applications (ICRERA)",
    "url": "https://doi.org/10.1109/icrera66237.2025.11283991",
    "source": "IEEE",
    "abstract": "Despite robotic automation is crucial for producing renewable energy technology, operational energy optimization is often overlooked as it typically requires expert intervention. This study proposes a hybrid architecture using natural language commands to optimize robot programs for either speed or energy efficiency. The framework integrates a Large Language Model (LLM) with an expert-defined Knowledge Base (KB) to create a verifiable optimization tool. Evaluated in a simulated pick-and-place task, the energy-prioritized program achieved a $42.1 \\%$ reduction in total energy consumption with a $15.8 \\%$ increase in process time compared to its speed-prioritized counterpart. These results confirm that significant energy savings, made accessible through natural language, can substantially reduce the carbon footprint of renewable energy production.",
    "title_zh": "从语音到效率：自然语言处理在节能机器人程序中的应用",
    "abstract_zh": "尽管机器人自动化对于可再生能源技术的生产至关重要，但运行能耗优化往往被忽视，因为这通常需要专家干预。本研究提出了一种混合架构，通过自然语言指令来优化机器人程序，以实现速度或能效的提升。该框架将大型语言模型（LLM）与专家定义的知识库（KB）相结合，构建了一个可验证的优化工具。在模拟的拾取-放置任务中评估表明，相较于以速度优先的程序，以能效优先的程序实现了总能耗降低42.1%，仅增加15.8%的工艺时间。结果证实，通过自然语言即可实现的显著节能效果，能够大幅降低可再生能源生产过程中的碳足迹。"
  },
  {
    "date": "2025-12-19",
    "title": "SQL Injection Detection, Prevention and Deception Using ML Classifiers",
    "authors": "Lakshmi M R, Shalini S, Chethan S, C Dharshan, Gandrajupalli Naga Koushik, Adarsh Bhaskar Shetty",
    "publish": "2025 International Conference on Sustainability, Innovation &amp;amp; Technology (ICSIT)",
    "url": "https://doi.org/10.1109/icsit65336.2025.11294383",
    "source": "IEEE",
    "abstract": "SQL injection (SQLi) attacks are arguably the most prevalent and destructive security attacks against web applications currently in use. SQLi attacks allow malicious users to exploit input validation vulnerabilities, thus granting unauthorized database access, data exfiltration, and even complete system compromise. To address this critical issue, this paper proposes a combined framework that employs machine learning techniques along with secure coding practices for the prevention, detection, and mitigation of SQL injection attacks. A Naïve Bayes classifier identifies anomaly-based SQLi attacks by monitoring HTTP requests for anomaly-based signatures that indicate the existence of evil SQL code. This machine learning-based detection system learns to evolve with new and changing attack vectors and gets better with time. In addition to detection, preventive measures such as prepared statement usage, input validation, and real escape string functions are employed to clean user input and eliminate injection points. Moreover, the system also includes a deception system, which leads the attackers to a decoy or imaginary database, so there can be ongoing observation of malicious activity without any loss of actual assets. This not only helps with threat analysis but also serves as a deterrent. The integration of proactive defense, reactive detection, and strategic deception greatly improves web application security. The system as presented shows strong immunity to both currently known and as-yet unknown SQL injection attacks, and thus it is a complete solution to one of the most vexing problems on web application security. [2].",
    "title_zh": "使用机器学习分类器进行SQL注入检测、预防与欺骗",
    "abstract_zh": "SQL注入（SQLi）攻击无疑是当前Web应用中最普遍且破坏性最强的安全威胁之一。SQLi攻击使恶意用户能够利用输入验证漏洞，从而获得未经授权的数据库访问权限，导致数据窃取，甚至完全控制系统。为应对这一关键问题，本文提出了一种结合机器学习技术与安全编码实践的综合框架，用于预防、检测和缓解SQL注入攻击。该框架采用朴素贝叶斯分类器，通过监控HTTP请求中的异常特征签名，识别基于异常的SQL注入攻击，这些签名可指示恶意SQL代码的存在。这种基于机器学习的检测系统能够随着新型和不断变化的攻击手段持续进化，并随着时间推移不断提升性能。除了检测功能外，系统还采用了多种预防措施，如使用预编译语句、输入验证以及真实转义字符串函数，以清理用户输入并消除注入点。此外，系统还集成了欺骗机制，引导攻击者进入一个诱饵或虚拟数据库，从而在不损失实际资产的情况下持续监控恶意行为。这不仅有助于威胁分析，还能起到威慑作用。主动防御、被动检测与战略欺骗的有机结合，显著提升了Web应用的整体安全性。实验结果表明，该系统对目前已知及尚未发现的SQL注入攻击均表现出强大的免疫力，因此为Web应用安全领域中最棘手的问题提供了一个全面的解决方案。[2]"
  },
  {
    "date": "2025-12-19",
    "title": "A Multi-Layered Security Concept Model for SDN-Enabled Smart Grids",
    "authors": "Seref Sagiroglu, Murat Dener, M. Sedef Demirci, Ali Kara, Yilmaz Atay, Mehmet Demirci, Samed Al, Selcuk Yilmaz",
    "publish": "2025 14th International Conference on Renewable Energy Research and Applications (ICRERA)",
    "url": "https://doi.org/10.1109/icrera66237.2025.11283878",
    "source": "IEEE",
    "abstract": "Smart grids integrate advanced communication and control technologies to improve efficiency and reliability of power delivery, but their interconnected nature exposes new cybersecurity vulnerabilities. Recent attacks ranging from malware to false data injection have demonstrated the need for robust, multi-layered defenses spanning physical devices, network infrastructure, control systems, and applications. SoftwareDefined Networking (SDN) offers centralized, programmable control over grid communications to dynamically isolate threats and reroute traffic during attacks. However, securing SDNenabled smart grids requires a defense-in-depth approach that combines diverse emerging technologies. This paper proposes a multi-layered security concept model leveraging blockchain for data integrity, explainable AI for transparent decision-making, generative AI for adaptive threat detection, quantum-safe cryptography for future resilience, big data analytics for anomaly detection, and radio frequency fingerprinting for device authentication. We present our model and discuss how each layer and technology contributes to a cohesive security architecture. We also identify open research challenges for integrating these solutions seamlessly to move towards the secure grids of the future.",
    "title_zh": "面向SDN赋能的智能电网的多层安全概念模型",
    "abstract_zh": "智能电网融合了先进的通信与控制技术，以提升电力输送的效率和可靠性，但其互联特性也带来了新的网络安全漏洞。近年来，从恶意软件到虚假数据注入等攻击事件频发，凸显出需要构建覆盖物理设备、网络基础设施、控制系统及应用的多层次、强健的防御体系。软件定义网络（SDN）通过集中化、可编程的控制机制，实现了对电网通信的动态管理，能够在攻击发生时快速隔离威胁并重新路由流量。然而，保障SDN赋能的智能电网安全，需采用纵深防御策略，整合多种新兴技术。本文提出一种多层安全概念模型，综合利用区块链保障数据完整性、可解释人工智能实现决策透明化、生成式人工智能实现自适应威胁检测、抗量子密码学确保未来韧性、大数据分析用于异常检测，以及射频指纹技术实现设备身份认证。我们阐述了该模型的架构，并探讨各层级及技术如何协同构建一体化的安全体系。同时，本文还指出了在实现这些技术无缝集成方面存在的开放性研究挑战，以推动迈向更加安全可靠的未来电网。"
  },
  {
    "date": "2025-12-19",
    "title": "Intelligent Cloud Deployment via GNNs",
    "authors": "Akash Potti, Nishaant N. U, Sharan Reddy, Dhanya Bharadwaj, Asha Rani K. P, Gowrishankar S",
    "publish": "2025 9th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)",
    "url": "https://doi.org/10.1109/csitss67709.2025.11295173",
    "source": "IEEE",
    "abstract": "The rapid expansion of cloud computing has catalyzed an increasing demand for robust Infrastructure as Code (IaC) tools capable of facilitating automated deployment management. The traditional manual configuration of YAML/JSON within conventional IaC tools is time-consuming and elevates the risk of errors. This research introduces an innovative framework that integrates natural language processing (NLP) in conjunction with graph neural networks (GNNs) to automate the generation of Infrastructure as Code (IaC). Ollama Llama3 converts user prompts into structured components, which are subsequently transformed into a graph representing cloud service dependencies. A graph neural network constructed using PyTorch analyzes this graph to generate optimized YAML configurations that conform to cloud best practices. The system achieves an impressive 92% edge prediction accuracy over synthetic datasets while concurrently reducing deployment time when compared to manual methodologies. Furthermore, this system supports DevOps automation, optimizes costs, and effectively manages multi-cloud environments. This research bridges user requirements with IaC execution, rendering cloud resource management attainable for non-expert users. The approach demonstrated significant reduction in YAML configuration generation time, processing requests in around 15-20 seconds.",
    "title_zh": "通过图神经网络实现智能云部署",
    "abstract_zh": "云计算的迅速扩展催生了对强大基础设施即代码（IaC）工具日益增长的需求，以实现自动化部署管理。传统IaC工具中通过手动编写YAML/JSON配置的方式耗时费力，且容易引入错误。本研究提出了一种创新框架，将自然语言处理（NLP）与图神经网络（GNN）相结合，实现基础设施即代码（IaC）的自动化生成。Ollama Llama3将用户输入的自然语言提示转化为结构化组件，并进一步构建为表示云服务依赖关系的图结构。基于PyTorch构建的图神经网络对这一图进行分析，生成符合云最佳实践的优化YAML配置。该系统在合成数据集上实现了92%的边预测准确率，同时相比传统人工方法显著缩短了部署时间。此外，该系统支持DevOps自动化、成本优化，并有效管理多云环境。本研究成功实现了用户需求与IaC执行之间的无缝衔接，使非专业用户也能轻松完成云资源管理。该方法在YAML配置生成方面表现出显著的时间优势，平均仅需15至20秒即可处理请求。"
  },
  {
    "date": "2025-12-19",
    "title": "Design and Implementation of Multi-Parameter Weighted Scheduling Circuit Based on DTN Mechanism in Ad Hoc Networks",
    "authors": "Rongjian Li, Lufeng Qiao, Zhanyou Du, Xue Qin, Jinxu Wang, Qinghua Chen",
    "publish": "2025 5th International Conference on Network Communication and Information Security (ICNCIS)",
    "url": "https://doi.org/10.1109/icncis67521.2025.11296137",
    "source": "IEEE",
    "abstract": "A multi-parameter weighted scheduling algorithm that applies Delay-Tolerant Networks (DTN) technology to Ad Hoc networks has been designed, and the key circuit has been implemented. This algorithm can calculate the forwarding weights and screen the messages to be sent based on five-dimensional parameters, including DTN message priority, remaining lifespan, local waiting time, number of forwarding hops, and routing type, in a full-hardware manner. The forwarding weight values of all parameters can be configured by the upper-layer software according to different network states. When there is a direct route to the destination node for the message to be sent, the message is forwarded according to the route; when there is no direct route to the destination node, the Multi-Path Cooperative Transmission (MPCT) mode is supported for forwarding. The entire design is coded in Verilog HDL, implemented on the Xilinx xc7z100ffg900 - 2 FPGA platform, and simulated and analyzed using ModelSim SE - 64 10.6d, which verifies the correctness of the multi-parameter weighted scheduling algorithm and the circuit design.",
    "title_zh": "基于DTN机制的Ad Hoc网络中多参数加权调度电路的设计与实现",
    "abstract_zh": "一种多参数加权调度算法，结合延迟容忍网络（DTN）技术应用于自组织网络，并已实现关键电路。该算法能够基于五维参数——DTN消息优先级、剩余生存时间、本地等待时间、转发跳数及路由类型——以全硬件方式计算转发权重并筛选待发送消息。所有参数的转发权重值均可由上层软件根据不同的网络状态进行配置。当待发送消息存在直达目标节点的路径时，按该路径进行转发；当不存在直达路径时，则支持多路径协同传输（MPCT）模式进行转发。整个设计采用Verilog HDL语言编写，在Xilinx xc7z100ffg900-2 FPGA平台上实现，并使用ModelSim SE-64 10.6d进行仿真与分析，验证了多参数加权调度算法及电路设计的正确性。"
  },
  {
    "date": "2025-12-19",
    "title": "AI-Driven Priority-Based Predictive Maintenance of Automotive Systems",
    "authors": "Manojith Bhat V, Aneesh Sai Grandhi, Aditya Ravi, Ganesh N Naik, Sujay Arun Kudtarkar, Anala M R",
    "publish": "2025 9th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)",
    "url": "https://doi.org/10.1109/csitss67709.2025.11294531",
    "source": "IEEE",
    "abstract": "The application of artificial intelligence (AI) has become very important in the rapidly evolving automotive sector for improving vehicle maintenance plans. The paper presents an AI-driven, priority-based predictive maintenance system designed to improve service schedules by classifying vehicle failures and providing guided troubleshooting. The system utilizes a Light Gradient Boosting (LightGBM) model to perform multiclass classification on data collected from OnBoard Diagnostics (OBD). The model predicts one of four states: Heat Dissipation Failure, Overstrain Failure, Power Failure, or No Failure. The system also integrates a Large Language Model (LLM) with a Retrieval Augmented Generation (RAG) framework that uses the model's predicted failure type as a query to the vehicle's technical manual, generating contextually relevant troubleshooting steps and providing actionable guidance for maintenance personnel. The classification model demonstrates high performance, achieving an overall accuracy of 98%. This integrated solution provides a practical end to end workflow, from data-driven prediction to guided repair, enhancing the efficiency of automotive maintenance.",
    "title_zh": "基于人工智能的汽车系统优先级预测性维护",
    "abstract_zh": "人工智能（AI）在快速发展的汽车行业中应用日益重要，对于优化车辆维护计划具有重要意义。本文提出了一种基于人工智能的、优先级驱动的预测性维护系统，旨在通过分类车辆故障并提供指导性排障建议来改进服务调度。该系统采用轻量梯度提升（LightGBM）模型，对车载诊断系统（OBD）采集的数据进行多类别分类，能够预测四种状态之一：散热故障、过载故障、供电故障或无故障。此外，系统还集成了大型语言模型（LLM）与检索增强生成（RAG）框架，将模型预测的故障类型作为查询语句，从车辆技术手册中检索相关信息，生成上下文相关的维修步骤，并为维修人员提供可操作的指导建议。分类模型表现出优异性能，整体准确率达到98%。这一集成解决方案构建了一个从数据驱动预测到引导式维修的完整工作流程，显著提升了汽车维护的效率。"
  },
  {
    "date": "2025-12-19",
    "title": "Generative Artificial Intelligence for code generation based on CodeT5 algorithm",
    "authors": "Amna U. Hamed, Safwan O. Hasoon",
    "publish": "2025 3rd International Conference on Cyber Resilience (ICCR)",
    "url": "https://doi.org/10.1109/iccr67387.2025.11292118",
    "source": "IEEE",
    "abstract": "This research proposes a generative AI-based framework that uses the CodeT5 Transformer model to automate the translation of structured pseudocode into C++ source code. The system was trained and evaluated on a curated dataset and achieved promising results: 80% exact match accuracy, precision of 79.58%, recall of 78.83%, and an F1-score of 78.80%. These results highlight CodeT5’s capability to understand logic and generate syntactically valid code, making it a viable tool for enhancing productivity in software development.",
    "title_zh": "基于CodeT5算法的代码生成式人工智能",
    "abstract_zh": "本研究提出了一种基于生成式AI的框架，利用CodeT5 Transformer模型实现将结构化伪代码自动翻译为C++源代码。该系统在经过精心筛选的数据集上进行训练和评估，取得了令人鼓舞的结果：精确匹配准确率为80%，精确率为79.58%，召回率为78.83%，F1分数为78.80%。这些结果凸显了CodeT5在理解程序逻辑及生成语法正确代码方面的能力，使其成为提升软件开发效率的可行工具。"
  },
  {
    "date": "2025-12-19",
    "title": "Design and Optimization of the Florian Shared FPU Architecture",
    "authors": "Sree Vidya J, Deepika P",
    "publish": "2025 9th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)",
    "url": "https://doi.org/10.1109/csitss67709.2025.11295159",
    "source": "IEEE",
    "abstract": "The proliferation of computation-intensive tasks in embedded System-on-Chip (SoC) environments has amplified the necessity for optimized floating-point arithmetic units that exhibit minimal power dissipation and silicon footprint. This study introduces a centralized and power-efficient Floating-Point Unit (FPU) architecture intended for concurrent access by multiple lightweight processing cores. Unlike conventional percore FPU replication, the proposed model incorporates a shared computation paradigm governed by FIFO queuing and arbiterbased control mechanisms to facilitate equitable and conflict-free access. To further enhance energy efficiency, the design integrates operand reuse detection, dynamic precision scaling, and clock gating–techniques that collectively curtail redundant switching and lower dynamic power consumption. The Xilinx Artix-7 FPGA is used to realize the proposed architecture, which is implemented using Verilog HDL via the Vivado 2024.2 toolchain. Simulation and functional validation are performed using ModelSim, affirming IEEE-754 compliance and timing correctness. Empirical synthesis results reveal a significant reduction in area and power metrics: 52.9% fewer Lookup Tables (LUTs), 53.8% reduction in flip-flop usage, and 45% lower total power compared to traditional FPU deployments. The system achieves a sustained clock frequency of 150 MHz while maintaining computational integrity. The findings underscore the suitability of the proposed centralized FPU for integration in resource-constrained, power-aware embedded computing platforms.",
    "title_zh": "弗洛里安共享浮点单元架构的设计与优化",
    "abstract_zh": "嵌入式系统级芯片（SoC）环境中计算密集型任务的激增，使得设计功耗低、硅面积小的优化浮点运算单元变得尤为迫切。本研究提出一种集中式且节能的浮点运算单元（FPU）架构，专为多个轻量级处理核的并发访问而设计。与传统的每个核心独立配置FPU的方式不同，该方案采用共享计算范式，通过先进先出（FIFO）队列机制与仲裁控制策略，实现各核心间公平且无冲突的访问。为进一步提升能效，设计中引入操作数复用检测、动态精度调节以及时钟门控等技术，有效减少冗余翻转，降低动态功耗。所提出的架构基于Xilinx Artix-7 FPGA平台实现，采用Verilog HDL语言并通过Vivado 2024.2工具链完成综合。使用ModelSim进行仿真与功能验证，结果表明其符合IEEE-754标准且时序正确。实测综合结果显示，与传统FPU部署相比，该设计在面积和功耗方面均取得显著优化：查找表（LUT）减少52.9%，触发器使用量降低53.8%，总功耗下降45%。系统在保持计算完整性的前提下，可稳定运行于150 MHz的时钟频率。研究结果充分证明，所提出的集中式FPU架构适用于资源受限、注重能效的嵌入式计算平台集成。"
  },
  {
    "date": "2025-12-19",
    "title": "Decentralized Finance Platforms for Promoting Secure Peer-to-Peer Lending Through Trustless Smart Contracts",
    "authors": "Mustafa M. Abd Zaid, Ali Abdulkareem Hadi Al-Magsoosi, Kawther Al-Fatlawi, Orhan M. Albayati, Labeeb Saadoon Alyassri, Aqeel H. Al-Fatlawi",
    "publish": "2025 3rd International Conference on Cyber Resilience (ICCR)",
    "url": "https://doi.org/10.1109/iccr67387.2025.11292209",
    "source": "IEEE",
    "abstract": "Decentralized Finance (DeFi) platforms are reshaping the financial landscape by enabling secure, peer-to-peer (P2P) lending through blockchain technology and trustless smart contracts. These platforms eliminate the need for traditional intermediaries, offering transparency, automation, and reduced transactional friction. However, existing DeFi lending solutions face challenges such as smart contract vulnerabilities, poor user trust, limited risk management, and inefficient system design processes. These issues often result in security breaches, collateral mismanagement, and reduced adoption. To address these limitations, this paper proposes a framework using the Blockchain-Based System Development Life Cycle (BSDLC) methodology. BSDLC introduces structured phases—including requirement analysis, system design, smart contract development, testing, deployment, and maintenance—tailored to the unique needs of blockchain-based systems. These phases ensure systematic identification of risks, secure coding practices, and continuous verification of smart contract behavior through rigorous testing. The proposed BSDLC-based method is applied to develop a safe, trustless P2P lending application on the Ethereum blockchain. The platform enables users to borrow and lend digital assets using collateralized smart contracts, which are enforced by oracles for real-time asset valuation. The implementation ensures tamper-proof loan execution, automated liquidation, and complete transparency, all without requiring central oversight. The findings reveal that applying BSDLC significantly enhances the security, reliability, and usability of decentralized finance (DeFi) lending applications. It reduces vulnerabilities and ensures system integrity, making it a scalable and trustworthy solution for modern financial ecosystems.",
    "title_zh": "通过无信任智能合约促进安全点对点借贷的去中心化金融平台",
    "abstract_zh": "去中心化金融（DeFi）平台正通过区块链技术和无信任智能合约，实现安全的点对点（P2P）借贷，从而重塑金融格局。这些平台消除了传统中介的需求，提供了透明性、自动化以及更低的交易摩擦。然而，现有的DeFi借贷解决方案仍面临诸多挑战，如智能合约漏洞、用户信任度低、风险管理体系不完善以及系统设计流程效率低下等问题。这些问题常常导致安全漏洞、抵押品管理失误以及应用采纳率下降。为解决上述局限性，本文提出一种基于区块链系统开发生命周期（BSDLC）的方法论。BSDLC引入了结构化的开发阶段——包括需求分析、系统设计、智能合约开发、测试、部署和维护——专门针对区块链系统的特点进行优化。这些阶段确保了风险的系统性识别、安全编码实践的落实，以及通过严格测试对智能合约行为的持续验证。本文所提出的基于BSDLC的方法被应用于在以太坊区块链上构建一个安全、无信任的P2P借贷应用。该平台使用户能够通过抵押型智能合约借入或出借数字资产，其资产估值由预言机实时提供支持，确保合约执行的不可篡改性、自动清算机制以及全程透明，且无需中央监管。研究结果表明，采用BSDLC显著提升了去中心化金融（DeFi）借贷应用的安全性、可靠性和可用性，有效降低了潜在漏洞，保障了系统完整性，使其成为现代金融生态系统中可扩展且值得信赖的解决方案。"
  },
  {
    "date": "2025-12-19",
    "title": "Low Power Implementation of RISC V Processor with Fine Grained Clock Gating/Power Gating",
    "authors": "Santhosh V, Abhay Deshpande",
    "publish": "2025 9th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)",
    "url": "https://doi.org/10.1109/csitss67709.2025.11295650",
    "source": "IEEE",
    "abstract": "In modern low-power VLSI design, power efficiency has become a critical consideration, especially in processors intended for embedded and battery-powered systems. RISC-V, an open-source and modular instruction set architecture (ISA), provides an excellent platform for implementing customized low-power designs. Fine-grained clock gating and power gating are two effective techniques used to minimize dynamic and static power consumption, respectively. These methods allow selective disabling of the clock or power supply to idle functional units within the processor, thereby significantly reducing unnecessary energy usage without compromising performance. These techniques are particularly beneficial in pipelined RISC-V cores, where not all stages or submodules are active during every clock cycle. By integrating control logic that dynamically determines when a unit is idle, fine-grained gating ensures that only the required sections of the processor are active at any given time. This selective activation reduces switching activity, which directly lowers dynamic power. Similarly, power gating is applied to completely shut off leakage-prone blocks like caches or memory buffers during idle periods. The implementation of such power-saving mechanisms requires careful RTL design and synthesis strategies to ensure functional correctness and timing closure.",
    "title_zh": "基于细粒度时钟门控/电源门控的RISC-V处理器低功耗实现",
    "abstract_zh": "在现代低功耗VLSI设计中，能效已成为关键考量因素，尤其是在面向嵌入式系统和电池供电设备的处理器设计中。RISC-V作为一种开源且模块化的指令集架构（ISA），为实现定制化低功耗设计提供了理想的平台。细粒度时钟门控（clock gating）和电源门控（power gating）是分别降低动态功耗和静态功耗的有效技术。这些方法允许对处理器中处于空闲状态的功能单元选择性地关闭时钟信号或电源供应，从而显著减少不必要的能量消耗，同时不损害性能。这类技术在流水线式RISC-V核心中尤为有益，因为并非所有流水级或子模块在每个时钟周期都处于活动状态。通过集成控制逻辑，动态判断各功能单元是否处于空闲状态，细粒度门控可确保在任意时刻仅有必要的处理器部分处于激活状态。这种选择性激活有效降低了开关活动，直接减少了动态功耗。类似地，电源门控可在空闲期间完全关闭易产生漏电的模块，如缓存或内存缓冲区。实现此类节能机制需要精心的RTL设计与综合策略，以保证功能正确性和时序收敛。"
  },
  {
    "date": "2025-12-19",
    "title": "Integrating LLMs for Automated Bug Triaging and Root Cause Localization in Software Systems",
    "authors": "Prajwal Pisal, Prateek Jalan, Solomon R Chigurupati, Chandrakanth Puligundla, Srinivas Bhogavalli",
    "publish": "2025 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings)",
    "url": "https://doi.org/10.1109/aibthings66987.2025.11296163",
    "source": "IEEE",
    "abstract": "Existing techniques often depend on manual processes or limited models for machine learning that do not capture complex, multimodal dependencies between code, infrastructure and runtime behaviour. This paper presents an AI-driven approach using Large Language Models (LLMs) for efficient bug triaging and proactive root cause analysis. Our system integrates graph-based modelling, multimodal learning, and LLMs to automatically triage bugs, predict root causes, and generate effective test cases for bug reproduction. We evaluate the proposed framework’s effectiveness using various basic models from existing literature, including traditional machine-learning classifiers and graph-based models. The results show that our method is significantly higher than the baseline approaches in the average time to resolution (MTTR), the accuracy of the root cause (RCA) and the effectiveness of the test case (THE), achieving a reduction of MTTR by more than 50%, an RCA of 84.7% and a THE of 83.2%. Our approach improves the efficiency and accuracy of bug triaging and software quality assurance by generating reliable test cases.",
    "title_zh": "利用大语言模型实现软件系统中自动化缺陷分类与根本原因定位",
    "abstract_zh": "现有技术通常依赖于人工流程或有限的机器学习模型，难以捕捉代码、基础设施与运行时行为之间的复杂多模态依赖关系。本文提出一种基于大语言模型（LLM）的AI驱动方法，用于高效进行缺陷分类和主动根因分析。我们的系统融合了基于图的建模、多模态学习与大语言模型，能够自动对缺陷进行分类、预测根本原因，并生成有效的测试用例以重现缺陷。我们采用现有文献中的多种基础模型（包括传统机器学习分类器和基于图的模型）对所提出的框架进行了评估。实验结果表明，与基线方法相比，我们的方法在平均修复时间（MTTR）、根因分析准确率（RCA）以及测试用例有效性（THE）方面均有显著提升，实现了MTTR降低超过50%、RCA达到84.7%、THE达到83.2%的优异表现。该方法通过生成可靠的测试用例，显著提升了缺陷分类与软件质量保障的效率与准确性。"
  },
  {
    "date": "2025-12-19",
    "title": "Guest Editorial Special Section on Edge AI Strategies for Fortifying Security and Privacy in Healthcare Devices",
    "authors": "Md. Jalil Piran, Paolo Napoletano, Mechelle Gittens",
    "publish": "IEEE Transactions on Consumer Electronics",
    "url": "https://doi.org/10.1109/tce.2025.3601344",
    "source": "IEEE",
    "abstract": "As the healthcare sector undergoes rapid digital transformation; a new era of personalized healthcare services has begun. Wearable electronics, ubiquitous sensing, and intelligent data-driven analytics accelerate this process. In this transformation, Edge Artificial Intelligence (Edge AI) and the Internet of Medical Things (IoMT) work together to enable real-time diagnostics, continuous patient monitoring, and intelligent decision-making at the network edge. However, as these devices become more interconnected and autonomous, they also present significant vulnerabilities related to data privacy, cyber-security, model robustness, and system resilience.",
    "title_zh": "特稿：面向医疗设备安全与隐私保护的边缘人工智能策略专题",
    "abstract_zh": "随着医疗保健行业经历快速的数字化转型，个性化医疗服务的新时代已然开启。可穿戴电子设备、无处不在的传感技术以及智能数据驱动分析正在加速这一进程。在这一变革中，边缘人工智能（Edge AI）与医疗物联网（IoMT）协同作用，实现了网络边缘的实时诊断、持续患者监测以及智能决策。然而，随着这些设备日益互联和自主，它们也带来了数据隐私、网络安全、模型鲁棒性及系统韧性等方面的重大安全隐患。"
  },
  {
    "date": "2025-12-19",
    "title": "Research on Malicious C2 Regression and Prediction",
    "authors": "Lu Gao, Menglei Xu, Li Sun, Xiaoling Bai",
    "publish": "2025 5th International Conference on Network Communication and Information Security (ICNCIS)",
    "url": "https://doi.org/10.1109/icncis67521.2025.11296087",
    "source": "IEEE",
    "abstract": "This paper focuses on the regression and prediction of malicious code in information and network security, primarily covering cryptography, regression prediction models, static configuration, configuration decryption, malicious code analysis, artificial intelligence, and computer applications. The research focuses on C2 samples found in backdoor malware. For prevalent C2 samples, the research method utilizes regression prediction methods based on static configuration decryption and symbolic regression. The experimental data for this paper is sourced from the multi-engine scanning and analysis platform VT. 139,998,761 VT samples were collected from June 2024 to June 2025, of which 22,153,930 had domain name hits. Based on the family classification criteria of the antivirus vendor ESET-NOD32, the analysis targets were selected by comprehensively considering the top backdoor malware rankings and C2 linking behavior. Based on VT dynamic data and manual analysis, a regression and prediction model for malicious C2s was developed based on static configuration decryption. Based on the model established above, a static configuration decryption engine is implemented on a computer using C and Lua programming languages to achieve regression of malicious C2 and output of related IOC information; and corresponding predictions are made based on the decrypted data stream generated by the engine using methods such as symbolic regression, ultimately realizing the application of cryptography and artificial intelligence in computer, information and network security.",
    "title_zh": "恶意C2回归与预测研究",
    "abstract_zh": "本文聚焦于信息与网络安全领域中恶意代码的回归与预测，主要涵盖密码学、回归预测模型、静态配置分析、配置解密、恶意代码分析、人工智能及计算机应用等方面。研究重点针对后门木马中发现的C2（命令与控制）样本。对于常见的C2样本，研究方法采用基于静态配置解密和符号回归的回归预测技术。本文实验数据来源于多引擎扫描与分析平台VT，共收集了2024年6月至2025年6月期间的139,998,761个VT样本，其中包含22,153,930个具有域名命中记录的样本。基于杀毒软件厂商ESET-NOD32的家族分类标准，结合主流后门木马排名及C2连接行为特征，综合筛选出分析目标。基于VT动态数据与人工分析结果，构建了基于静态配置解密的恶意C2回归与预测模型。在此基础上，使用C语言和Lua语言在计算机上实现了一个静态配置解密引擎，用于完成恶意C2的回归分析，并输出相关IOC（指示器）信息；同时，利用该引擎生成的解密数据流，通过符号回归等方法进行相应预测，最终实现了密码学与人工智能在计算机、信息安全与网络安全部署中的实际应用。"
  },
  {
    "date": "2025-12-19",
    "title": "CodeSketch: A Real-Time Multi-Language Code Visualization Tool with UML and Animation Support - A Comparative Study",
    "authors": "Harsda Shrivastava, Lohitha Kanisettypalli, Jiya Borikar, Adhikari Bhavishya, Aiswariya Milan K",
    "publish": "2025 9th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)",
    "url": "https://doi.org/10.1109/csitss67709.2025.11294623",
    "source": "IEEE",
    "abstract": "This paper presents an innovative code visualization tool that simplifies code comprehension and improves conceptual clarity for students and educators, while significantly enhancing software development workflows and educational outcomes by converting source code into interactive graphical representations. It automatically generates flowcharts, UML diagrams, and animations for Python, Java, and C++. The accuracy of parsing is ensured through the Python AST module and regular expressions, while user interaction is streamlined via the Tkinter framework. A key contribution of this work is a comparative study that rigorously evaluates the proposed tool against existing visualization solutions across multiple dimensions such as language support, usability, feature richness, and educational applicability. This study demonstrates the superior functionality and user experience offered by the tool, reinforcing its impact in both academic and professional environments.",
    "title_zh": "CodeSketch：一种支持UML与动画的实时多语言代码可视化工具——对比研究",
    "abstract_zh": "本文提出了一种创新的代码可视化工具，能够简化代码理解过程，提升学生与教育工作者的概念清晰度，并通过将源代码转换为交互式图形表示，显著优化软件开发工作流程及教育效果。该工具可自动为Python、Java和C++生成流程图、UML图以及动画。代码解析的准确性通过Python的AST模块和正则表达式得以保障，而用户交互则借助Tkinter框架实现高效流畅。本研究的一项重要贡献是开展了一项对比性研究，从语言支持、易用性、功能丰富度以及教育适用性等多个维度，对所提出的工具与现有可视化解决方案进行了严格评估。研究结果表明，该工具在功能性能与用户体验方面均表现更优，充分证明了其在学术与专业环境中的深远影响。"
  }
]